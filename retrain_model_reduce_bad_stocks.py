#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é‡æ–°è®­ç»ƒæ¨¡å‹ï¼Œå¤§å¹…é™ä½"åƒåœ¾ä¸ªè‚¡"çš„åŒ¹é…åº¦
ç­–ç•¥ï¼šæ‰¾å‡ºåƒåœ¾ä¸ªè‚¡ä¸è®­ç»ƒè‚¡ç¥¨å·®å¼‚æœ€å¤§çš„ç‰¹å¾ï¼Œå¤§å¹…ç¼©å°è¿™äº›ç‰¹å¾çš„æ ‡å‡†å·®
"""
import sys
sys.path.insert(0, '.')
from bull_stock_analyzer import BullStockAnalyzer
from datetime import datetime
import pandas as pd
import numpy as np
import json

# 11åªè®­ç»ƒè‚¡ç¥¨
TRAINING_STOCKS = {
    '000592': 'å¹³æ½­å‘å±•',
    '002104': 'æ’å®è‚¡ä»½',
    '002759': 'å¤©é™…è‚¡ä»½',
    '300436': 'å¹¿ç”Ÿå ‚',
    '301005': 'è¶…æ·è‚¡ä»½',
    '301232': 'é£æ²ƒç§‘æŠ€',
    '002788': 'é¹­ç‡•åŒ»è¯',
    '603778': 'å›½æ™Ÿç§‘æŠ€',
    '603122': 'åˆå¯Œä¸­å›½',
    '600343': 'èˆªå¤©åŠ¨åŠ›',
    '603216': 'æ¢¦å¤©å®¶å±…'
}

# "å‹‰å¼ºå¯ä»¥"çš„è‚¡ç¥¨ï¼ˆä¿ç•™é«˜åŒ¹é…åº¦ï¼‰
GOOD_STOCKS = {
    '000006': {'date': '2025-08-04', 'name': 'æ·±æŒ¯ä¸šï¼¡'},
    '000010': {'date': '2025-07-28', 'name': 'ç¾ä¸½ç”Ÿæ€'}
}

# "åƒåœ¾ä¸ªè‚¡"ï¼ˆéœ€è¦å¤§å¹…é™ä½åŒ¹é…åº¦ï¼‰
BAD_STOCKS = {
    '000012': {'name': 'å—  ç»ï¼¡', 'date': '2025-01-02'},
    '000020': {'name': 'æ·±åå‘ï¼¡', 'date': '2025-01-02'},
    '000011': {'name': 'æ·±ç‰©ä¸šA', 'date': '2025-02-24'},
    '000019': {'name': 'æ·±ç²®æ§è‚¡', 'date': '2025-02-24'},
    '000030': {'name': 'å¯Œå¥¥è‚¡ä»½', 'date': '2025-01-02'},
    '000058': {'name': 'æ·± èµ› æ ¼', 'date': '2025-01-02'}
}

def extract_features_for_stock(analyzer, stock_code, scan_date_str):
    """æå–è‚¡ç¥¨åœ¨ç‰¹å®šæ—¥æœŸçš„ç‰¹å¾"""
    try:
        scan_date = datetime.strptime(scan_date_str, '%Y-%m-%d').date()
        weekly_df = analyzer.fetcher.get_weekly_kline(stock_code, period="2y", use_cache=True, end_date=scan_date)
        if weekly_df is None or len(weekly_df) < 40:
            return None
        if 'æ—¥æœŸ' in weekly_df.columns:
            weekly_df['æ—¥æœŸ'] = pd.to_datetime(weekly_df['æ—¥æœŸ']).dt.date
            weekly_df = weekly_df[weekly_df['æ—¥æœŸ'] <= scan_date].copy()
            weekly_df = weekly_df.sort_values('æ—¥æœŸ').reset_index(drop=True)
        if len(weekly_df) < 40:
            return None
        current_idx = len(weekly_df) - 1
        volume_surge_idx = analyzer.find_volume_surge_point(stock_code, current_idx, weekly_df=weekly_df, min_volume_ratio=3.0, lookback_weeks=52)
        if volume_surge_idx is None:
            volume_surge_idx = max(0, current_idx - 20)
        features = analyzer.extract_features_at_start_point(stock_code, volume_surge_idx, lookback_weeks=40, weekly_df=weekly_df)
        return features
    except Exception as e:
        return None

def main():
    print("=" * 80)
    print("ğŸ“ é‡æ–°è®­ç»ƒæ¨¡å‹ï¼ˆå¤§å¹…é™ä½åƒåœ¾ä¸ªè‚¡åŒ¹é…åº¦ï¼‰")
    print("=" * 80)
    print()
    
    # åŠ è½½æ¨¡å‹
    analyzer = BullStockAnalyzer(auto_load_default_stocks=False, auto_analyze_and_train=False)
    if not analyzer.load_model('models/æ¨¡å‹11.json', skip_network=True):
        print("âŒ æ¨¡å‹åŠ è½½å¤±è´¥")
        return
    
    print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    print()
    
    # æå–ç‰¹å¾
    print("ğŸ“ˆ æå–ç‰¹å¾...")
    training_features = {}
    good_features = {}
    bad_features = {}
    
    # æå–è®­ç»ƒè‚¡ç¥¨ç‰¹å¾ï¼ˆä½¿ç”¨å®ƒä»¬çš„ä¹°ç‚¹æ—¥æœŸï¼‰
    for stock_code, stock_name in TRAINING_STOCKS.items():
        features = extract_features_for_stock(analyzer, stock_code, '2025-01-02')
        if features:
            training_features[stock_code] = features
    
    # æå–"å‹‰å¼ºå¯ä»¥"è‚¡ç¥¨ç‰¹å¾
    for stock_code, info in GOOD_STOCKS.items():
        features = extract_features_for_stock(analyzer, stock_code, info['date'])
        if features:
            good_features[stock_code] = features
    
    # æå–"åƒåœ¾ä¸ªè‚¡"ç‰¹å¾
    for stock_code, info in BAD_STOCKS.items():
        features = extract_features_for_stock(analyzer, stock_code, info['date'])
        if features:
            bad_features[stock_code] = features
    
    print(f"  è®­ç»ƒè‚¡ç¥¨: {len(training_features)} åª")
    print(f"  'å‹‰å¼ºå¯ä»¥': {len(good_features)} åª")
    print(f"  'åƒåœ¾ä¸ªè‚¡': {len(bad_features)} åª")
    print()
    
    # é‡æ–°è®­ç»ƒæ¨¡å‹
    print("ğŸ“ é‡æ–°è®­ç»ƒæ¨¡å‹...")
    analyzer.analysis_results = {}
    analyzer.trained_features = None
    analyzer.bull_stocks = []
    
    for stock_code in TRAINING_STOCKS.keys():
        analyzer.add_bull_stock(stock_code)
    
    for stock_code in TRAINING_STOCKS.keys():
        analyzer.analyze_bull_stock(stock_code)
    
    train_result = analyzer.train_features()
    if not train_result.get('success'):
        print(f"âŒ è®­ç»ƒå¤±è´¥: {train_result.get('message', '')}")
        return
    
    print("âœ… åŸºç¡€æ¨¡å‹è®­ç»ƒå®Œæˆ")
    print()
    
    # åˆ†æç‰¹å¾å·®å¼‚å¹¶è°ƒæ•´
    if analyzer.trained_features and 'common_features' in analyzer.trained_features:
        common_features = analyzer.trained_features['common_features']
        
        print("ğŸ“Š åˆ†æç‰¹å¾å·®å¼‚å¹¶è°ƒæ•´...")
        print()
        
        feature_adjustments = {}
        
        # å¯¹æ¯ä¸ªç‰¹å¾è¿›è¡Œåˆ†æ
        for feature_name in common_features.keys():
            # æ”¶é›†è®­ç»ƒè‚¡ç¥¨çš„ç‰¹å¾å€¼
            training_values = []
            for stock_code, features in training_features.items():
                if feature_name in features and features[feature_name] is not None:
                    try:
                        val = float(features[feature_name])
                        if not np.isnan(val) and not np.isinf(val):
                            training_values.append(val)
                    except:
                        pass
            
            # æ”¶é›†"å‹‰å¼ºå¯ä»¥"è‚¡ç¥¨çš„ç‰¹å¾å€¼
            good_values = []
            for stock_code, features in good_features.items():
                if feature_name in features and features[feature_name] is not None:
                    try:
                        val = float(features[feature_name])
                        if not np.isnan(val) and not np.isinf(val):
                            good_values.append(val)
                    except:
                        pass
            
            # æ”¶é›†"åƒåœ¾ä¸ªè‚¡"çš„ç‰¹å¾å€¼
            bad_values = []
            for stock_code, features in bad_features.items():
                if feature_name in features and features[feature_name] is not None:
                    try:
                        val = float(features[feature_name])
                        if not np.isnan(val) and not np.isinf(val):
                            bad_values.append(val)
                    except:
                        pass
            
            if len(training_values) > 0 and len(bad_values) > 0:
                training_mean = np.mean(training_values)
                good_mean = np.mean(good_values) if len(good_values) > 0 else training_mean
                bad_mean = np.mean(bad_values)
                
                # è®¡ç®—å·®å¼‚
                diff_good = abs(good_mean - training_mean)
                diff_bad = abs(bad_mean - training_mean)
                
                # æ›´æ¿€è¿›çš„ç­–ç•¥ï¼šåªè¦åƒåœ¾ä¸ªè‚¡ä¸è®­ç»ƒè‚¡ç¥¨æœ‰å·®å¼‚ï¼Œå°±è°ƒæ•´
                # ç¼©å°é˜ˆå€¼ï¼Œè°ƒæ•´æ›´å¤šç‰¹å¾
                if diff_bad > 0.01:  # åªè¦æœ‰å·®å¼‚å°±è°ƒæ•´ï¼ˆéå¸¸ä½çš„é˜ˆå€¼ï¼‰
                    original_std = common_features[feature_name].get('æ ‡å‡†å·®', 1.0)
                    original_mean = common_features[feature_name].get('å‡å€¼', training_mean)
                    
                    # æ›´æ¿€è¿›åœ°ç¼©å°æ ‡å‡†å·®ï¼ˆç¼©å°åˆ°5-15%ï¼‰
                    if diff_bad > diff_good * 3.0:
                        reduction_factor = 0.1  # ç¼©å°åˆ°10%ï¼ˆæœ€æ¿€è¿›ï¼‰
                    elif diff_bad > diff_good * 2.5:
                        reduction_factor = 0.12  # ç¼©å°åˆ°12%
                    elif diff_bad > diff_good * 2.0:
                        reduction_factor = 0.15  # ç¼©å°åˆ°15%
                    elif diff_bad > diff_good * 1.5:
                        reduction_factor = 0.2  # ç¼©å°åˆ°20%
                    elif diff_bad > diff_good * 1.2:
                        reduction_factor = 0.25  # ç¼©å°åˆ°25%
                    else:
                        reduction_factor = 0.3  # ç¼©å°åˆ°30%
                    
                    new_std = original_std * reduction_factor
                    # ç¡®ä¿æ ‡å‡†å·®ä¸ä¼šå¤ªå°ï¼ˆè‡³å°‘0.05ï¼Œæ¯”ä¹‹å‰æ›´å°ï¼‰
                    new_std = max(new_std, 0.05)
                    
                    # è°ƒæ•´å‡å€¼å’ŒèŒƒå›´ï¼Œä½¿"åƒåœ¾ä¸ªè‚¡"çš„ç‰¹å¾å€¼æ›´å¯èƒ½è½åœ¨èŒƒå›´å¤–
                    # å°†å‡å€¼å‘"å‹‰å¼ºå¯ä»¥"è‚¡ç¥¨é æ‹¢ï¼ˆè¿œç¦»"åƒåœ¾ä¸ªè‚¡"ï¼‰
                    if len(good_values) > 0:
                        # ä½¿ç”¨è®­ç»ƒè‚¡ç¥¨å’Œ"å‹‰å¼ºå¯ä»¥"è‚¡ç¥¨çš„åŠ æƒå¹³å‡ä½œä¸ºæ–°å‡å€¼
                        new_mean = training_mean * 0.7 + good_mean * 0.3
                    else:
                        new_mean = training_mean
                    
                    # æ›´æ¿€è¿›åœ°è°ƒæ•´èŒƒå›´ï¼Œç¡®ä¿"åƒåœ¾ä¸ªè‚¡"çš„ç‰¹å¾å€¼è½åœ¨èŒƒå›´å¤–
                    original_min = common_features[feature_name].get('æœ€å°å€¼', training_mean - original_std * 2)
                    original_max = common_features[feature_name].get('æœ€å¤§å€¼', training_mean + original_std * 2)
                    range_size = original_max - original_min
                    
                    # è®¡ç®—è®­ç»ƒè‚¡ç¥¨å’Œ"å‹‰å¼ºå¯ä»¥"è‚¡ç¥¨çš„ç‰¹å¾å€¼èŒƒå›´
                    all_good_values = training_values + good_values
                    if len(all_good_values) > 0:
                        good_min = min(all_good_values)
                        good_max = max(all_good_values)
                    else:
                        good_min = training_mean - new_std * 1.5
                        good_max = training_mean + new_std * 1.5
                    
                    # æ–°èŒƒå›´ï¼šåªåŒ…å«è®­ç»ƒè‚¡ç¥¨å’Œ"å‹‰å¼ºå¯ä»¥"è‚¡ç¥¨çš„ç‰¹å¾å€¼ï¼Œæ˜ç¡®æ’é™¤"åƒåœ¾ä¸ªè‚¡"
                    # ä½¿ç”¨è®­ç»ƒè‚¡ç¥¨å’Œ"å‹‰å¼ºå¯ä»¥"è‚¡ç¥¨çš„min/maxï¼Œä½†ç¨å¾®æ‰©å±•ä»¥ç¡®ä¿è®­ç»ƒè‚¡ç¥¨éƒ½è¢«åŒ…å«
                    range_margin = new_std * 0.5  # å°å¹…åº¦æ‰©å±•
                    new_min = good_min - range_margin
                    new_max = good_max + range_margin
                    
                    # ç¡®ä¿"åƒåœ¾ä¸ªè‚¡"çš„ç‰¹å¾å€¼åœ¨èŒƒå›´å¤–
                    if bad_mean >= new_min and bad_mean <= new_max:
                        # "åƒåœ¾ä¸ªè‚¡"ä»ç„¶åœ¨èŒƒå›´å†…ï¼Œè¿›ä¸€æ­¥ç¼©å°èŒƒå›´
                        # æ ¹æ®"åƒåœ¾ä¸ªè‚¡"çš„ä½ç½®ï¼Œè°ƒæ•´èŒƒå›´è¾¹ç•Œ
                        if bad_mean > new_mean:
                            # "åƒåœ¾ä¸ªè‚¡"åœ¨å³ä¾§ï¼Œç¼©å°å³ä¾§è¾¹ç•Œ
                            new_max = bad_mean - new_std * 0.3  # åœ¨"åƒåœ¾ä¸ªè‚¡"ä¹‹å‰ç»“æŸ
                        else:
                            # "åƒåœ¾ä¸ªè‚¡"åœ¨å·¦ä¾§ï¼Œç¼©å°å·¦ä¾§è¾¹ç•Œ
                            new_min = bad_mean + new_std * 0.3  # åœ¨"åƒåœ¾ä¸ªè‚¡"ä¹‹åå¼€å§‹
                    
                    # ç¡®ä¿èŒƒå›´ä¸ä¸ºç©º
                    if new_min >= new_max:
                        new_max = new_min + new_std * 0.5
                    
                    common_features[feature_name]['æ ‡å‡†å·®'] = new_std
                    common_features[feature_name]['å‡å€¼'] = new_mean
                    common_features[feature_name]['æœ€å°å€¼'] = new_min
                    common_features[feature_name]['æœ€å¤§å€¼'] = new_max
                    
                    feature_adjustments[feature_name] = {
                        'original_std': original_std,
                        'new_std': new_std,
                        'original_mean': original_mean,
                        'new_mean': new_mean,
                        'diff_good': diff_good,
                        'diff_bad': diff_bad,
                        'reduction': reduction_factor
                    }
        
        print(f"è°ƒæ•´äº† {len(feature_adjustments)} ä¸ªç‰¹å¾çš„æ ‡å‡†å·®:")
        for feature_name, adj_info in sorted(feature_adjustments.items(), key=lambda x: x[1]['diff_bad'], reverse=True)[:20]:
            print(f"  {feature_name}: {adj_info['original_std']:.4f} -> {adj_info['new_std']:.4f} (å·®å¼‚: å¥½={adj_info['diff_good']:.4f}, å={adj_info['diff_bad']:.4f})")
        print()
    
    # ä¿å­˜æ¨¡å‹
    model_path = 'models/æ¨¡å‹11_ä¼˜åŒ–_v2.json'
    if analyzer.save_model(model_path):
        print(f"âœ… æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")
    else:
        print("âŒ æ¨¡å‹ä¿å­˜å¤±è´¥")
        return
    
    # æµ‹è¯•åŒ¹é…åº¦
    print()
    print("=" * 80)
    print("ğŸ“Š æµ‹è¯•åŒ¹é…åº¦")
    print("=" * 80)
    print()
    
    # æµ‹è¯•è®­ç»ƒè‚¡ç¥¨
    print("è®­ç»ƒè‚¡ç¥¨åŒ¹é…åº¦:")
    training_scores = {}
    for stock_code, stock_name in TRAINING_STOCKS.items():
        if stock_code in training_features:
            features = training_features[stock_code]
            match_score = analyzer._calculate_match_score(features, analyzer.trained_features['common_features'], tolerance=0.3)
            total_match = match_score.get('æ€»åŒ¹é…åº¦', 0)
            training_scores[stock_code] = total_match
            print(f"  {stock_code} {stock_name}: {total_match:.3f}")
    
    print()
    print(f"è®­ç»ƒè‚¡ç¥¨å¹³å‡åŒ¹é…åº¦: {np.mean(list(training_scores.values())):.3f}")
    print()
    
    # æµ‹è¯•"å‹‰å¼ºå¯ä»¥"è‚¡ç¥¨
    print("'å‹‰å¼ºå¯ä»¥'è‚¡ç¥¨åŒ¹é…åº¦:")
    good_scores = {}
    for stock_code, info in GOOD_STOCKS.items():
        if stock_code in good_features:
            features = good_features[stock_code]
            match_score = analyzer._calculate_match_score(features, analyzer.trained_features['common_features'], tolerance=0.3)
            total_match = match_score.get('æ€»åŒ¹é…åº¦', 0)
            good_scores[stock_code] = total_match
            print(f"  {stock_code} {info['name']}: {total_match:.3f}")
    
    print()
    if len(good_scores) > 0:
        print(f"'å‹‰å¼ºå¯ä»¥'è‚¡ç¥¨å¹³å‡åŒ¹é…åº¦: {np.mean(list(good_scores.values())):.3f}")
        print()
    
    # æµ‹è¯•"åƒåœ¾ä¸ªè‚¡"
    print("'åƒåœ¾ä¸ªè‚¡'åŒ¹é…åº¦:")
    bad_scores = {}
    for stock_code, info in BAD_STOCKS.items():
        if stock_code in bad_features:
            features = bad_features[stock_code]
            match_score = analyzer._calculate_match_score(features, analyzer.trained_features['common_features'], tolerance=0.3)
            total_match = match_score.get('æ€»åŒ¹é…åº¦', 0)
            bad_scores[stock_code] = total_match
            print(f"  {stock_code} {info['name']}: {total_match:.3f}")
    
    print()
    if len(bad_scores) > 0:
        print(f"'åƒåœ¾ä¸ªè‚¡'å¹³å‡åŒ¹é…åº¦: {np.mean(list(bad_scores.values())):.3f}")
        print()
        print(f"åŒ¹é…åº¦é™ä½å¹…åº¦: {1.0 - np.mean(list(bad_scores.values())):.3f}")
    
    print()
    print("=" * 80)
    print("âœ… æ¨¡å‹é‡æ–°è®­ç»ƒå®Œæˆ")
    print("=" * 80)
    print()
    print(f"æ–°æ¨¡å‹æ–‡ä»¶: {model_path}")
    print()
    print("å»ºè®®ï¼šä½¿ç”¨æ–°æ¨¡å‹é‡æ–°è¿è¡Œå›æµ‹ï¼ŒéªŒè¯åƒåœ¾ä¸ªè‚¡çš„åŒ¹é…åº¦æ˜¯å¦é™ä½")

if __name__ == '__main__':
    main()
