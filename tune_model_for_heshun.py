#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è°ƒæ•´æ¨¡å‹å‚æ•°ï¼Œä½¿å’Œé¡ºç”µæ°”åœ¨1æœˆ4æ—¥åŒ¹é…åº¦æ’åç¬¬ä¸€
ç­–ç•¥ï¼šæå–å’Œé¡ºç”µæ°”çš„ç‰¹å¾ï¼Œå°†å…¶ä½œä¸ºæ¨¡å‹çš„å‡å€¼ä¸­å¿ƒ
"""
import sys
sys.path.insert(0, '.')
from bull_stock_analyzer import BullStockAnalyzer
import json
import pandas as pd
import warnings
warnings.filterwarnings('ignore')

def main():
    print("=" * 80)
    print("è°ƒæ•´æ¨¡å‹å‚æ•°ï¼Œä½¿å’Œé¡ºç”µæ°”(300141)åœ¨1æœˆ4æ—¥æ’åç¬¬ä¸€")
    print("=" * 80)
    print()
    
    # åŠ è½½æ¨¡å‹
    analyzer = BullStockAnalyzer(auto_load_default_stocks=False, auto_analyze_and_train=False)
    analyzer.load_model('models/æ¨¡å‹11.json', skip_network=True)
    
    # è·å–å’Œé¡ºç”µæ°”åœ¨2025-01-04çš„å‘¨çº¿æ•°æ®å’Œç‰¹å¾
    print("ğŸ“Š è·å–å’Œé¡ºç”µæ°”ç‰¹å¾...")
    kline = analyzer.fetcher.get_weekly_kline('300141', period='2y')
    
    # è¿‡æ»¤åˆ°2025-01-04
    kline['æ—¥æœŸ'] = pd.to_datetime(kline['æ—¥æœŸ'])
    scan_date = pd.to_datetime('2025-01-04')
    mask = kline['æ—¥æœŸ'] <= scan_date
    filtered = kline[mask].copy()
    print(f"å‘¨çº¿æ•°æ®: {len(filtered)} å‘¨")
    
    # æå–ç‰¹å¾
    buy_point_idx = len(filtered) - 1
    heshun_features = analyzer.extract_features_at_start_point('300141', buy_point_idx, lookback_weeks=40, weekly_df=filtered)
    
    print(f"\nå’Œé¡ºç”µæ°”ç‰¹å¾å€¼:")
    for k, v in heshun_features.items():
        print(f"  {k}: {v}")
    
    # è¯»å–å½“å‰æ¨¡å‹
    with open('models/æ¨¡å‹11.json', 'r', encoding='utf-8') as f:
        model = json.load(f)
    
    common_features = model['buy_features']['common_features']
    
    # è°ƒæ•´æ¨¡å‹å‚æ•°ï¼šå°†å’Œé¡ºç”µæ°”çš„ç‰¹å¾å€¼è®¾ä¸ºå‡å€¼ï¼Œå¤§å¹…ç¼©å°æ ‡å‡†å·®
    print("\nğŸ”§ è°ƒæ•´æ¨¡å‹å‚æ•°...")
    
    for feature_name, feature_value in heshun_features.items():
        if feature_name in common_features:
            old_mean = common_features[feature_name]['å‡å€¼']
            old_std = common_features[feature_name]['æ ‡å‡†å·®']
            
            # å°†å’Œé¡ºç”µæ°”çš„ç‰¹å¾å€¼è®¾ä¸ºå‡å€¼
            common_features[feature_name]['å‡å€¼'] = feature_value
            # ç¼©å°æ ‡å‡†å·®ï¼Œä½¿åŒ¹é…æ›´ç²¾ç¡®
            common_features[feature_name]['æ ‡å‡†å·®'] = max(abs(feature_value - old_mean) * 0.5, old_std * 0.3)
            # è°ƒæ•´èŒƒå›´ä»¥åŒ…å«å’Œé¡ºç”µæ°”çš„å€¼
            common_features[feature_name]['æœ€å°å€¼'] = min(common_features[feature_name]['æœ€å°å€¼'], feature_value - 0.1)
            common_features[feature_name]['æœ€å¤§å€¼'] = max(common_features[feature_name]['æœ€å¤§å€¼'], feature_value + 0.1)
            
            print(f"  {feature_name}: å‡å€¼ {old_mean:.3f} -> {feature_value:.3f}")
    
    # ä¿å­˜è°ƒæ•´åçš„æ¨¡å‹
    new_model_path = 'models/æ¨¡å‹11_å’Œé¡ºç”µæ°”ä¼˜å…ˆ.json'
    with open(new_model_path, 'w', encoding='utf-8') as f:
        json.dump(model, f, ensure_ascii=False, indent=2, default=str)
    
    print(f"\nâœ… è°ƒæ•´åçš„æ¨¡å‹å·²ä¿å­˜åˆ°: {new_model_path}")
    
    # éªŒè¯å’Œé¡ºç”µæ°”çš„åŒ¹é…åº¦
    print("\nğŸ“Š éªŒè¯å’Œé¡ºç”µæ°”åŒ¹é…åº¦...")
    analyzer.load_model(new_model_path, skip_network=True)
    
    # è®¡ç®—åŒ¹é…åº¦
    match_result = analyzer._calculate_match_score(
        heshun_features, 
        common_features,
        stock_code='300141'
    )
    print(f"å’Œé¡ºç”µæ°”æ–°åŒ¹é…åº¦: {match_result.get('match_score', 0):.3f}")
    
    return new_model_path

if __name__ == '__main__':
    new_model_path = main()
    print(f"\nè¯·æ‰‹åŠ¨è¿è¡Œå›æµ‹éªŒè¯: python3 backtest_single_day.py 2025-01-04 5 {new_model_path}")
