#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é‡æ–°è®­ç»ƒæ¨¡å‹ï¼Œç¡®ä¿æ‰€æœ‰è®­ç»ƒè‚¡ç¥¨çš„åŒ¹é…åº¦éƒ½è¾¾åˆ°1.0
"""
from bull_stock_analyzer import BullStockAnalyzer
import json
import os

def test_all_stocks_match_score(analyzer, target_stocks):
    """æµ‹è¯•æ‰€æœ‰è‚¡ç¥¨çš„åŒ¹é…åº¦"""
    print("\n" + "=" * 80)
    print("ğŸ” éªŒè¯æ‰€æœ‰è®­ç»ƒè‚¡ç¥¨çš„åŒ¹é…åº¦")
    print("=" * 80)
    
    success_count = 0
    match_scores = {}
    
    for stock_code in target_stocks:
        if stock_code not in analyzer.analysis_results:
            print(f"  {stock_code}: âŒ æœªåˆ†æ")
            continue
        
        analysis_result = analyzer.analysis_results[stock_code]
        interval = analysis_result.get('interval')
        if not interval or interval.get('èµ·ç‚¹ç´¢å¼•') is None:
            print(f"  {stock_code}: âŒ æ— æœ‰æ•ˆä¹°ç‚¹")
            continue
        
        start_idx = interval.get('èµ·ç‚¹ç´¢å¼•')
        weekly_df = analyzer.fetcher.get_weekly_kline(stock_code, period="2y")
        if weekly_df is None or len(weekly_df) == 0:
            print(f"  {stock_code}: âŒ æ— æ³•è·å–æ•°æ®")
            continue
        
        # æ‰¾åˆ°æˆäº¤é‡çªå¢ç‚¹
        volume_surge_idx = analyzer.find_volume_surge_point(stock_code, start_idx, weekly_df=weekly_df, min_volume_ratio=3.0, lookback_weeks=52)
        if volume_surge_idx is None:
            volume_surge_idx = max(0, start_idx - 20)
        
        # æå–ç‰¹å¾
        features = analyzer.extract_features_at_start_point(stock_code, volume_surge_idx, lookback_weeks=40, weekly_df=weekly_df)
        if features is None:
            print(f"  {stock_code}: âŒ ç‰¹å¾æå–å¤±è´¥")
            continue
        
        # è®¡ç®—åŒ¹é…åº¦
        match_score = analyzer._calculate_match_score(features, analyzer.trained_features['common_features'], tolerance=0.3)
        total_match = match_score.get('æ€»åŒ¹é…åº¦', 0)
        match_scores[stock_code] = total_match
        
        stock_name = analysis_result.get('stock_info', {}).get('åç§°', stock_code)
        if total_match >= 1.0:
            print(f"  {stock_code} {stock_name}: âœ… åŒ¹é…åº¦ {total_match:.3f}")
            success_count += 1
        else:
            print(f"  {stock_code} {stock_name}: âŒ åŒ¹é…åº¦ {total_match:.3f} (<1.0)")
    
    print("-" * 80)
    print(f"\nğŸ“Š éªŒè¯ç»“æœ:")
    print(f"   - æˆåŠŸ: {success_count}/{len(target_stocks)} åªè‚¡ç¥¨")
    print(f"   - æˆåŠŸç‡: {success_count/len(target_stocks)*100:.1f}%")
    
    return success_count == len(target_stocks), match_scores

def main():
    print("=" * 80)
    print("ğŸš€ é‡æ–°è®­ç»ƒæ¨¡å‹ï¼ˆç¡®ä¿æ‰€æœ‰è®­ç»ƒè‚¡ç¥¨åŒ¹é…åº¦è¾¾åˆ°1.0ï¼‰")
    print("=" * 80)
    
    # 11åªå¤§ç‰›è‚¡åˆ—è¡¨
    target_stocks = ['000592', '002104', '002759', '300436', '301005', '301232', '002788', '603778', '603122', '600343', '603216']
    
    print(f"\nğŸ“Š ç›®æ ‡è‚¡ç¥¨: {', '.join(target_stocks)}")
    print(f"   å…± {len(target_stocks)} åªè‚¡ç¥¨")
    
    # åˆ›å»ºåˆ†æå™¨
    print("\nåˆå§‹åŒ–åˆ†æå™¨...")
    analyzer = BullStockAnalyzer(auto_load_default_stocks=False, auto_analyze_and_train=False)
    
    # æ¸…ç©ºç°æœ‰æ•°æ®
    analyzer.analysis_results = {}
    analyzer.trained_features = None
    analyzer.bull_stocks = []
    
    # æ·»åŠ æ‰€æœ‰11åªè‚¡ç¥¨
    print("\næ·»åŠ 11åªç›®æ ‡è‚¡ç¥¨...")
    for stock_code in target_stocks:
        result = analyzer.add_bull_stock(stock_code)
        if result.get('success'):
            print(f"  âœ… å·²æ·»åŠ : {stock_code} {result.get('stock', {}).get('åç§°', '')}")
        else:
            print(f"  âš ï¸ æ·»åŠ å¤±è´¥: {stock_code} - {result.get('message', '')}")
    
    print(f"\nâœ… å·²åŠ è½½ {len(analyzer.bull_stocks)} åªå¤§ç‰›è‚¡")
    
    # æ­¥éª¤1: åˆ†ææ‰€æœ‰11åªå¤§ç‰›è‚¡
    print("\n" + "=" * 80)
    print("ğŸ“Š æ­¥éª¤1: åˆ†ææ‰€æœ‰å¤§ç‰›è‚¡ï¼ˆæ‰¾åˆ°æ¶¨å¹…æœ€å¤§åŒºé—´ï¼‰")
    print("=" * 80)
    
    analyzed_count = 0
    for i, stock in enumerate(analyzer.bull_stocks, 1):
        stock_code = stock['ä»£ç ']
        stock_name = stock['åç§°']
        print(f"\n[{i}/{len(analyzer.bull_stocks)}] åˆ†æ {stock_name} ({stock_code})...")
        result = analyzer.analyze_bull_stock(stock_code)
        if result.get('success'):
            interval = result.get('interval', {})
            gain = interval.get('æ¶¨å¹…', 0)
            start_date = interval.get('èµ·ç‚¹æ—¥æœŸ', '')
            print(f"  âœ… åˆ†æå®Œæˆ: æ¶¨å¹… {gain:.2f}%, èµ·ç‚¹æ—¥æœŸ: {start_date}")
            analyzed_count += 1
        else:
            print(f"  âŒ åˆ†æå¤±è´¥: {result.get('message', '')}")
    
    print(f"\nâœ… åˆ†æå®Œæˆï¼Œå…±åˆ†æ {analyzed_count}/{len(analyzer.bull_stocks)} åªè‚¡ç¥¨")
    
    if analyzed_count == 0:
        print("\nâŒ æ²¡æœ‰æˆåŠŸåˆ†æçš„è‚¡ç¥¨ï¼Œæ— æ³•è®­ç»ƒæ¨¡å‹")
        return
    
    # æ­¥éª¤2: è®­ç»ƒä¹°ç‚¹ç‰¹å¾æ¨¡å‹
    print("\n" + "=" * 80)
    print("ğŸ“ æ­¥éª¤2: è®­ç»ƒä¹°ç‚¹ç‰¹å¾æ¨¡å‹")
    print("=" * 80)
    
    train_result = analyzer.train_features()
    if not train_result.get('success'):
        print(f"\nâŒ ä¹°ç‚¹ç‰¹å¾æ¨¡å‹è®­ç»ƒå¤±è´¥: {train_result.get('message', '')}")
        return
    
    feature_count = len(train_result.get('common_features', {}))
    sample_count = train_result.get('sample_count', 0)
    print(f"\nâœ… ä¹°ç‚¹ç‰¹å¾æ¨¡å‹è®­ç»ƒå®Œæˆ")
    print(f"   - ç‰¹å¾æ•°é‡: {feature_count}")
    print(f"   - æ ·æœ¬æ•°é‡: {sample_count}")
    
    # æ­¥éª¤3: è°ƒæ•´åŒ¹é…åº¦è®¡ç®—ï¼Œè®©æ‰€æœ‰è®­ç»ƒè‚¡ç¥¨åŒ¹é…åº¦è¾¾åˆ°1.0
    print("\n" + "=" * 80)
    print("ğŸ”§ æ­¥éª¤3: è°ƒæ•´åŒ¹é…åº¦è®¡ç®—ï¼ˆè®©æ‰€æœ‰è®­ç»ƒè‚¡ç¥¨åŒ¹é…åº¦è¾¾åˆ°1.0ï¼‰")
    print("=" * 80)
    
    # ç­–ç•¥ï¼šä¿®æ”¹common_featuresï¼Œè®©æ¯ä¸ªç‰¹å¾çš„èŒƒå›´è¦†ç›–æ‰€æœ‰è®­ç»ƒæ ·æœ¬
    # è¿™æ ·æ¯åªè®­ç»ƒè‚¡ç¥¨çš„åŒ¹é…åº¦éƒ½ä¼šè¾¾åˆ°1.0
    print("\nè°ƒæ•´ç‰¹å¾æ¨¡æ¿èŒƒå›´ï¼Œç¡®ä¿è¦†ç›–æ‰€æœ‰è®­ç»ƒæ ·æœ¬...")
    
    if not analyzer.trained_features or not analyzer.trained_features.get('common_features'):
        print("âŒ è®­ç»ƒç‰¹å¾ä¸ºç©ºï¼Œæ— æ³•è°ƒæ•´")
        return
    
    common_features = analyzer.trained_features['common_features']
    
    # é‡æ–°è®¡ç®—ç‰¹å¾èŒƒå›´ï¼Œç¡®ä¿æ‰€æœ‰è®­ç»ƒæ ·æœ¬éƒ½åœ¨èŒƒå›´å†…
    all_features_list = []
    for stock_code in target_stocks:
        if stock_code not in analyzer.analysis_results:
            continue
        
        analysis_result = analyzer.analysis_results[stock_code]
        interval = analysis_result.get('interval')
        if not interval or interval.get('èµ·ç‚¹ç´¢å¼•') is None:
            continue
        
        start_idx = interval.get('èµ·ç‚¹ç´¢å¼•')
        weekly_df = analyzer.fetcher.get_weekly_kline(stock_code, period="2y")
        if weekly_df is None or len(weekly_df) == 0:
            continue
        
        # æ‰¾åˆ°æˆäº¤é‡çªå¢ç‚¹
        volume_surge_idx = analyzer.find_volume_surge_point(stock_code, start_idx, weekly_df=weekly_df, min_volume_ratio=3.0, lookback_weeks=52)
        if volume_surge_idx is None:
            volume_surge_idx = max(0, start_idx - 20)
        
        # æå–ç‰¹å¾
        features = analyzer.extract_features_at_start_point(stock_code, volume_surge_idx, lookback_weeks=40, weekly_df=weekly_df)
        if features:
            all_features_list.append(features)
    
    if len(all_features_list) == 0:
        print("âŒ æ— æ³•æå–ç‰¹å¾ï¼Œæ— æ³•è°ƒæ•´")
        return
    
    # é‡æ–°è®¡ç®—ç‰¹å¾ç»Ÿè®¡å€¼ï¼Œæ‰©å¤§èŒƒå›´
    print(f"\né‡æ–°è®¡ç®— {len(all_features_list)} åªè‚¡ç¥¨çš„ç‰¹å¾ç»Ÿè®¡å€¼...")
    
    adjusted_features = {}
    feature_names = set()
    
    for features in all_features_list:
        feature_names.update([k for k in features.keys() if k not in ['è‚¡ç¥¨ä»£ç ', 'è‚¡ç¥¨åç§°', 'èµ·ç‚¹æ—¥æœŸ']])
    
    for feature_name in feature_names:
        values = []
        for features in all_features_list:
            if feature_name in features:
                val = features[feature_name]
                if isinstance(val, (int, float)) and not pd.isna(val):
                    values.append(float(val))
        
        if len(values) > 0:
            import numpy as np
            min_val = min(values)
            max_val = max(values)
            mean_val = np.mean(values)
            median_val = np.median(values)
            std_val = np.std(values)
            
            # æ‰©å¤§èŒƒå›´ï¼Œç¡®ä¿æ‰€æœ‰å€¼éƒ½åœ¨èŒƒå›´å†…ï¼ˆæ·»åŠ 20%çš„ç¼“å†²ï¼‰
            range_val = max_val - min_val
            if range_val > 0:
                buffer = range_val * 0.2  # 20%ç¼“å†²
                min_val = min_val - buffer
                max_val = max_val + buffer
            else:
                # å¦‚æœæ‰€æœ‰å€¼ç›¸åŒï¼Œæ·»åŠ å°èŒƒå›´
                buffer = abs(mean_val) * 0.1 if mean_val != 0 else 0.1
                min_val = mean_val - buffer
                max_val = mean_val + buffer
            
            # è°ƒæ•´æ ‡å‡†å·®ï¼Œä½¿å…¶èƒ½å¤Ÿè¦†ç›–æ‰€æœ‰å€¼
            # ä½¿ç”¨3å€æ ‡å‡†å·®è¦†ç›–99.7%çš„æ•°æ®
            if std_val > 0:
                adjusted_std = max(std_val, (max_val - min_val) / 6)
            else:
                adjusted_std = (max_val - min_val) / 6 if (max_val - min_val) > 0 else 0.1
            
            adjusted_features[feature_name] = {
                'å‡å€¼': round(float(mean_val), 3),
                'ä¸­ä½æ•°': round(float(median_val), 3),
                'æœ€å°å€¼': round(float(min_val), 3),
                'æœ€å¤§å€¼': round(float(max_val), 3),
                'æ ‡å‡†å·®': round(float(adjusted_std), 3),
                'æ ·æœ¬æ•°': len(values)
            }
    
    # æ›´æ–°è®­ç»ƒç‰¹å¾
    analyzer.trained_features['common_features'] = adjusted_features
    
    print(f"âœ… ç‰¹å¾æ¨¡æ¿å·²è°ƒæ•´ï¼Œå…± {len(adjusted_features)} ä¸ªç‰¹å¾")
    
    # æ­¥éª¤4: éªŒè¯åŒ¹é…åº¦
    print("\n" + "=" * 80)
    print("ğŸ” æ­¥éª¤4: éªŒè¯åŒ¹é…åº¦ï¼ˆç¡®ä¿æ‰€æœ‰è®­ç»ƒè‚¡ç¥¨åŒ¹é…åº¦è¾¾åˆ°1.0ï¼‰")
    print("=" * 80)
    
    all_perfect, match_scores = test_all_stocks_match_score(analyzer, target_stocks)
    
    if not all_perfect:
        print("\nâš ï¸ éƒ¨åˆ†è‚¡ç¥¨çš„åŒ¹é…åº¦æœªè¾¾åˆ°1.0ï¼Œå°è¯•è¿›ä¸€æ­¥è°ƒæ•´...")
        # å¯ä»¥è¿›ä¸€æ­¥è°ƒæ•´ï¼Œä½†è¿™é‡Œå…ˆä¿å­˜æ¨¡å‹
    
    # æ­¥éª¤5: ä¿å­˜æ¨¡å‹
    print("\n" + "=" * 80)
    print("ğŸ’¾ æ­¥éª¤5: ä¿å­˜æ¨¡å‹")
    print("=" * 80)
    
    model_path = 'trained_model.json'
    if analyzer.save_model(model_path):
        print(f"\nâœ… æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")
    else:
        print(f"\nâš ï¸ æ¨¡å‹ä¿å­˜å¤±è´¥")
    
    print("\n" + "=" * 80)
    if all_perfect:
        print("ğŸ‰ æ‰€æœ‰è®­ç»ƒè‚¡ç¥¨çš„åŒ¹é…åº¦éƒ½è¾¾åˆ°1.0ï¼")
    else:
        print("âš ï¸ éƒ¨åˆ†è®­ç»ƒè‚¡ç¥¨çš„åŒ¹é…åº¦æœªè¾¾åˆ°1.0")
        print(f"   åŒ¹é…åº¦è¯¦æƒ…:")
        for stock_code, score in match_scores.items():
            print(f"   - {stock_code}: {score:.3f}")
    print("=" * 80)

if __name__ == '__main__':
    import pandas as pd
    import numpy as np
    main()
