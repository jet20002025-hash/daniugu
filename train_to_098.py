#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è®­ç»ƒæ¨¡å‹ä½¿å¤§ç‰›è‚¡åŒ¹é…åº¦è¾¾åˆ°1.0
é€šè¿‡è°ƒæ•´ç‰¹å¾æƒé‡å’Œé˜ˆå€¼æ¥ä¼˜åŒ–åŒ¹é…åº¦
"""
import os
import sys
import json
import pandas as pd
import numpy as np
from datetime import datetime
from copy import deepcopy

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))


def load_weekly_kline_from_cache(code):
    """ä»æœ¬åœ°ç¼“å­˜åŠ è½½å‘¨Kçº¿æ•°æ®"""
    cache_dir = 'cache/weekly_kline'
    csv_path = os.path.join(cache_dir, f'{code}.csv')
    json_path = os.path.join(cache_dir, f'{code}.json')
    
    if os.path.exists(csv_path):
        try:
            df = pd.read_csv(csv_path)
            if 'æ—¥æœŸ' in df.columns:
                df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
                df = df.dropna(subset=['æ—¥æœŸ']).sort_values('æ—¥æœŸ').reset_index(drop=True)
            return df
        except Exception as e:
            pass
    
    if os.path.exists(json_path):
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            df = pd.DataFrame(data)
            if 'æ—¥æœŸ' in df.columns:
                df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
                df = df.dropna(subset=['æ—¥æœŸ']).sort_values('æ—¥æœŸ').reset_index(drop=True)
            return df
        except Exception:
            pass
    
    return None


def load_daily_kline_from_cache(code):
    """ä»æœ¬åœ°ç¼“å­˜åŠ è½½æ—¥Kçº¿æ•°æ®"""
    cache_dir = 'cache'
    csv_path = os.path.join(cache_dir, 'daily_kline', f'{code}.csv')
    json_path = os.path.join(cache_dir, 'daily_kline', f'{code}.json')
    if os.path.exists(csv_path):
        try:
            df = pd.read_csv(csv_path)
            if 'æ—¥æœŸ' in df.columns:
                df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
                df = df.dropna(subset=['æ—¥æœŸ']).sort_values('æ—¥æœŸ').reset_index(drop=True)
            return df
        except Exception:
            pass
    if os.path.exists(json_path):
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            df = pd.DataFrame(data)
            if 'æ—¥æœŸ' in df.columns:
                df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
                df = df.dropna(subset=['æ—¥æœŸ']).sort_values('æ—¥æœŸ').reset_index(drop=True)
            return df
        except Exception:
            pass
    return None


def extract_all_features(weekly_df, start_idx, lookback_weeks=40, stock_code=None):
    """æå–æ‰€æœ‰ç‰¹å¾ï¼ˆå«ä¹°ç‚¹å‰ä¸¤æœˆå†…æ›¾æ¶¨åœï¼‰"""
    if start_idx >= len(weekly_df) or start_idx < 20:
        return None
    
    actual_lookback = min(lookback_weeks, start_idx)
    before_start_df = weekly_df.iloc[start_idx - actual_lookback:start_idx].copy()
    
    volume_col = 'å‘¨æˆäº¤é‡' if 'å‘¨æˆäº¤é‡' in weekly_df.columns else 'æˆäº¤é‡'
    if volume_col not in weekly_df.columns:
        return None

    start_price = float(weekly_df.iloc[start_idx]['æ”¶ç›˜'])
    start_volume = float(weekly_df.iloc[start_idx][volume_col])
    
    features = {}
    
    # 1. æˆäº¤é‡ç‰¹å¾
    if len(before_start_df) >= 10:
        avg_volume_10 = float(before_start_df[volume_col].tail(10).mean())
        if avg_volume_10 > 0:
            features['èµ·ç‚¹å½“å‘¨é‡æ¯”'] = round(start_volume / avg_volume_10, 2)
        features['èµ·ç‚¹å‰10å‘¨å‡é‡'] = round(float(before_start_df[volume_col].tail(10).mean()), 0)
    
    if len(before_start_df) >= 20:
        features['èµ·ç‚¹å‰20å‘¨å‡é‡'] = round(float(before_start_df[volume_col].tail(20).mean()), 0)
        vol_10 = float(before_start_df[volume_col].tail(10).mean())
        vol_20 = float(before_start_df[volume_col].tail(20).mean())
        if vol_20 > 0:
            features['æˆäº¤é‡èç¼©ç¨‹åº¦'] = round(vol_10 / vol_20, 2)
    
    if len(before_start_df) >= 40:
        features['èµ·ç‚¹å‰40å‘¨å‡é‡'] = round(float(before_start_df[volume_col].tail(40).mean()), 0)
        max_volume_idx = before_start_df[volume_col].tail(40).idxmax()
        max_volume = float(before_start_df.loc[max_volume_idx, volume_col])
        max_volume_low = float(before_start_df.loc[max_volume_idx, 'æœ€ä½'])
        features['èµ·ç‚¹å‰40å‘¨æœ€å¤§é‡'] = round(max_volume, 0)
        features['æœ€å¤§é‡å¯¹åº”æœ€ä½ä»·'] = round(max_volume_low, 2)
        if max_volume_low > 0:
            features['æ˜¯å¦è·Œç ´æœ€å¤§é‡æœ€ä½ä»·'] = 1 if start_price < max_volume_low else 0
            features['ç›¸å¯¹æœ€å¤§é‡æœ€ä½ä»·è·Œå¹…'] = round((max_volume_low - start_price) / max_volume_low * 100, 2) if start_price < max_volume_low else 0
        if max_volume > 0:
            features['èµ·ç‚¹é‡æ¯”æœ€å¤§é‡'] = round(start_volume / max_volume, 2)
    
    # 2. ä»·æ ¼ç‰¹å¾
    if len(before_start_df) >= 20:
        max_price_20 = float(before_start_df['æœ€é«˜'].tail(20).max())
        min_price_20 = float(before_start_df['æœ€ä½'].tail(20).min())
        if max_price_20 > min_price_20:
            features['ä»·æ ¼ç›¸å¯¹ä½ç½®'] = round((start_price - min_price_20) / (max_price_20 - min_price_20) * 100, 2)
            features['ç›¸å¯¹é«˜ç‚¹è·Œå¹…'] = round((max_price_20 - start_price) / max_price_20 * 100, 2)
        features['èµ·ç‚¹å‰20å‘¨æœ€é«˜ä»·'] = round(max_price_20, 2)
        features['èµ·ç‚¹å‰20å‘¨æœ€ä½ä»·'] = round(min_price_20, 2)
        features['èµ·ç‚¹å‰20å‘¨æ³¢åŠ¨å¹…åº¦'] = round((max_price_20 - min_price_20) / min_price_20 * 100, 2) if min_price_20 > 0 else 0
    
    if len(before_start_df) >= 40:
        features['èµ·ç‚¹å‰40å‘¨æœ€é«˜ä»·'] = round(float(before_start_df['æœ€é«˜'].tail(40).max()), 2)
        features['èµ·ç‚¹å‰40å‘¨æœ€ä½ä»·'] = round(float(before_start_df['æœ€ä½'].tail(40).min()), 2)
    
    # 3. å‡çº¿ç‰¹å¾
    if len(before_start_df) >= 5:
        ma5 = float(before_start_df['æ”¶ç›˜'].tail(5).mean())
        features['ä»·æ ¼ç›¸å¯¹MA5'] = round((start_price - ma5) / ma5 * 100, 2) if ma5 > 0 else 0
        features['MA5å€¼'] = round(ma5, 2)
    
    if len(before_start_df) >= 10:
        ma10 = float(before_start_df['æ”¶ç›˜'].tail(10).mean())
        features['ä»·æ ¼ç›¸å¯¹MA10'] = round((start_price - ma10) / ma10 * 100, 2) if ma10 > 0 else 0
        features['MA10å€¼'] = round(ma10, 2)
        features['èµ·ç‚¹å‰10å‘¨æ³¢åŠ¨ç‡'] = round(float((before_start_df['æ”¶ç›˜'].tail(10).max() - before_start_df['æ”¶ç›˜'].tail(10).min()) / before_start_df['æ”¶ç›˜'].tail(10).min() * 100), 2)
    
    if len(before_start_df) >= 20:
        ma20 = float(before_start_df['æ”¶ç›˜'].tail(20).mean())
        features['ä»·æ ¼ç›¸å¯¹MA20'] = round((start_price - ma20) / ma20 * 100, 2) if ma20 > 0 else 0
        features['MA20å€¼'] = round(ma20, 2)
        ma20_recent = float(before_start_df['æ”¶ç›˜'].tail(5).mean())
        ma20_earlier = float(before_start_df['æ”¶ç›˜'].iloc[-20:-15].mean()) if len(before_start_df) >= 20 else ma20
        if ma20_earlier > 0:
            features['MA20æ–œç‡'] = round((ma20_recent - ma20_earlier) / ma20_earlier * 100, 2)
        features['èµ·ç‚¹å‰20å‘¨æ³¢åŠ¨ç‡'] = round(float((before_start_df['æ”¶ç›˜'].tail(20).max() - before_start_df['æ”¶ç›˜'].tail(20).min()) / before_start_df['æ”¶ç›˜'].tail(20).min() * 100), 2)
    
    if len(before_start_df) >= 40:
        ma40 = float(before_start_df['æ”¶ç›˜'].tail(40).mean())
        features['ä»·æ ¼ç›¸å¯¹MA40'] = round((start_price - ma40) / ma40 * 100, 2) if ma40 > 0 else 0
        features['MA40å€¼'] = round(ma40, 2)
    
    # 4. é‡ä»·é…åˆç‰¹å¾
    if len(before_start_df) >= 20:
        price_changes = before_start_df['æ”¶ç›˜'].tail(20).pct_change().dropna()
        volume_changes = before_start_df[volume_col].tail(20).pct_change().dropna()
        if len(price_changes) > 5 and len(volume_changes) > 5:
            min_len = min(len(price_changes), len(volume_changes))
            correlation = price_changes.tail(min_len).corr(volume_changes.tail(min_len))
            if pd.notna(correlation):
                features['èµ·ç‚¹å‰20å‘¨é‡ä»·ç›¸å…³ç³»æ•°'] = round(float(correlation), 3)
    
    if start_idx > 0:
        prev_price = float(weekly_df.iloc[start_idx - 1]['æ”¶ç›˜'])
        prev_volume = float(weekly_df.iloc[start_idx - 1][volume_col])
        features['èµ·ç‚¹å½“å‘¨ä»·æ¶¨'] = 1 if start_price > prev_price else 0
        features['èµ·ç‚¹å½“å‘¨é‡å¢'] = 1 if start_volume > prev_volume else 0
        features['èµ·ç‚¹å½“å‘¨ä»·æ¶¨é‡å¢'] = 1 if (start_price > prev_price and start_volume > prev_volume) else 0
    
    features['èµ·ç‚¹ä»·æ ¼'] = round(start_price, 2)
    
    # 5. MACD
    if len(before_start_df) >= 26:
        try:
            prices = before_start_df['æ”¶ç›˜']
            ema12 = prices.ewm(span=12, adjust=False).mean()
            ema26 = prices.ewm(span=26, adjust=False).mean()
            dif = ema12 - ema26
            dea = dif.ewm(span=9, adjust=False).mean()
            macd = (dif - dea) * 2
            
            features['MACD_DIF'] = round(float(dif.iloc[-1]), 4)
            features['MACD_DEA'] = round(float(dea.iloc[-1]), 4)
            features['MACDæŸ±'] = round(float(macd.iloc[-1]), 4)
            
            if len(dif) >= 2:
                prev_diff = dif.iloc[-2] - dea.iloc[-2]
                curr_diff = dif.iloc[-1] - dea.iloc[-1]
                features['MACDé‡‘å‰'] = 1 if (prev_diff < 0 and curr_diff >= 0) else 0
                features['MACDé›¶è½´ä¸Šæ–¹'] = 1 if dif.iloc[-1] > 0 else 0
        except Exception:
            pass
    
    # 6. RSI
    if len(before_start_df) >= 14:
        try:
            prices = before_start_df['æ”¶ç›˜']
            delta = prices.diff()
            gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
            rs = gain / (loss + 0.0001)
            rsi = 100 - (100 / (1 + rs))
            
            features['RSI'] = round(float(rsi.iloc[-1]), 2)
            features['RSIè¶…å–'] = 1 if rsi.iloc[-1] < 30 else 0
            features['RSIå¼ºåŠ¿åŒº'] = 1 if 50 < rsi.iloc[-1] < 70 else 0
        except Exception:
            pass
    
    # 7. KDJ
    if len(before_start_df) >= 9:
        try:
            high_9 = before_start_df['æœ€é«˜'].rolling(window=9).max()
            low_9 = before_start_df['æœ€ä½'].rolling(window=9).min()
            rsv = (before_start_df['æ”¶ç›˜'] - low_9) / (high_9 - low_9 + 0.0001) * 100
            
            k_values, d_values = [], []
            k, d = 50, 50
            for r in rsv.dropna():
                k = 2/3 * k + 1/3 * r
                d = 2/3 * d + 1/3 * k
                k_values.append(k)
                d_values.append(d)
            
            if k_values:
                features['KDJ_K'] = round(k_values[-1], 2)
                features['KDJ_D'] = round(d_values[-1], 2)
                features['KDJ_J'] = round(3 * k_values[-1] - 2 * d_values[-1], 2)
                features['KDJè¶…å–'] = 1 if k_values[-1] < 20 and d_values[-1] < 20 else 0
        except Exception:
            pass
    
    # 8. OBV
    if len(before_start_df) >= 10:
        try:
            obv = [0]
            prices = before_start_df['æ”¶ç›˜'].values
            volumes = before_start_df[volume_col].values
            for i in range(1, len(prices)):
                if prices[i] > prices[i-1]:
                    obv.append(obv[-1] + volumes[i])
                elif prices[i] < prices[i-1]:
                    obv.append(obv[-1] - volumes[i])
                else:
                    obv.append(obv[-1])
            
            obv_series = pd.Series(obv)
            if len(obv_series) >= 10:
                obv_recent = obv_series.tail(10)
                obv_slope = (obv_recent.iloc[-1] - obv_recent.iloc[0]) / (abs(obv_recent.iloc[0]) + 1) * 100
                features['OBVè¶‹åŠ¿'] = round(obv_slope, 2)
            
            if len(obv_series) >= 20:
                features['OBVåˆ›æ–°é«˜'] = 1 if obv_series.iloc[-1] >= obv_series.tail(20).max() * 0.95 else 0
        except Exception:
            pass
    
    # 9. å‡çº¿ç²˜åˆåº¦
    if len(before_start_df) >= 20:
        try:
            ma5 = float(before_start_df['æ”¶ç›˜'].tail(5).mean())
            ma10 = float(before_start_df['æ”¶ç›˜'].tail(10).mean())
            ma20 = float(before_start_df['æ”¶ç›˜'].tail(20).mean())
            avg_ma = (ma5 + ma10 + ma20) / 3
            if avg_ma > 0:
                dispersion = (abs(ma5-avg_ma) + abs(ma10-avg_ma) + abs(ma20-avg_ma)) / avg_ma * 100
                features['å‡çº¿ç²˜åˆåº¦'] = round(dispersion, 2)
            features['å‡çº¿å¤šå¤´æ’åˆ—'] = 1 if (ma5 > ma10 > ma20) else 0
        except Exception:
            pass
    
    # 10. å¸ƒæ—å¸¦
    if len(before_start_df) >= 20:
        try:
            prices = before_start_df['æ”¶ç›˜']
            ma20 = prices.rolling(window=20).mean()
            std20 = prices.rolling(window=20).std()
            upper = ma20 + 2 * std20
            lower = ma20 - 2 * std20
            
            bb_width = ((upper.iloc[-1] - lower.iloc[-1]) / ma20.iloc[-1] * 100) if ma20.iloc[-1] > 0 else 0
            features['å¸ƒæ—å¸¦å®½åº¦'] = round(bb_width, 2)
            
            bb_position = ((start_price - lower.iloc[-1]) / (upper.iloc[-1] - lower.iloc[-1] + 0.01) * 100)
            features['å¸ƒæ—å¸¦ä½ç½®'] = round(bb_position, 2)
            
            if len(ma20) >= 10 and ma20.iloc[-10] > 0 and pd.notna(upper.iloc[-10]) and pd.notna(lower.iloc[-10]):
                bb_width_10 = (upper.iloc[-10] - lower.iloc[-10]) / ma20.iloc[-10] * 100
                features['å¸ƒæ—å¸¦æ”¶çª„'] = 1 if bb_width < bb_width_10 * 0.8 else 0
        except Exception:
            pass
    
    # 11. ç­¹ç é›†ä¸­åº¦
    if len(before_start_df) >= 20:
        try:
            total_vol = before_start_df[volume_col].tail(20).sum()
            if total_vol > 0:
                weighted_price = (before_start_df['æ”¶ç›˜'].tail(20) * before_start_df[volume_col].tail(20)).sum() / total_vol
                features['æˆæœ¬åç¦»åº¦'] = round((start_price - weighted_price) / weighted_price * 100, 2)
                
                price_std = np.sqrt(((before_start_df['æ”¶ç›˜'].tail(20) - weighted_price) ** 2 * before_start_df[volume_col].tail(20)).sum() / total_vol)
                features['ç­¹ç é›†ä¸­åº¦'] = round(price_std / weighted_price * 100, 2) if weighted_price > 0 else 0
        except Exception:
            pass
    
    # 12. çªç ´ç‰¹å¾
    if len(before_start_df) >= 20:
        try:
            high_20 = before_start_df['æœ€é«˜'].tail(20).max()
            features['çªç ´20å‘¨é«˜ç‚¹'] = 1 if start_price > high_20 else 0
            features['æ¥è¿‘20å‘¨é«˜ç‚¹'] = 1 if start_price > high_20 * 0.95 else 0
        except Exception:
            pass
    
    if len(before_start_df) >= 40:
        try:
            high_40 = before_start_df['æœ€é«˜'].tail(40).max()
            features['çªç ´40å‘¨é«˜ç‚¹'] = 1 if start_price > high_40 else 0
        except Exception:
            pass
    
    # 13. å¹³å°æ•´ç†
    if len(before_start_df) >= 20:
        try:
            sideways_weeks = 0
            for i in range(len(before_start_df) - 20, len(before_start_df)):
                if i >= 0:
                    low_val = before_start_df['æœ€ä½'].iloc[i]
                    if low_val > 0:
                        range_pct = (before_start_df['æœ€é«˜'].iloc[i] - low_val) / low_val * 100
                        if range_pct < 10:
                            sideways_weeks += 1
            features['å¹³å°æ•´ç†å‘¨æ•°'] = sideways_weeks
        except Exception:
            pass
    
    # 14. ä¹°ç‚¹å‰æœ€è¿‘ä¸¤ä¸ªæœˆè‡³å°‘æœ‰ä¸€ä¸ªæ¶¨åœï¼ˆæ—¥çº¿ 44 ä¸ªäº¤æ˜“æ—¥å†…æ¶¨è·Œå¹…>=9.5%ï¼‰
    if stock_code:
        try:
            bp_date = pd.to_datetime(weekly_df.iloc[start_idx]['æ—¥æœŸ'])
            daily_df = load_daily_kline_from_cache(stock_code)
            if daily_df is not None and len(daily_df) >= 2 and 'æ”¶ç›˜' in daily_df.columns and 'æ—¥æœŸ' in daily_df.columns:
                daily_df = daily_df.copy()
                daily_df['æ—¥æœŸ'] = pd.to_datetime(daily_df['æ—¥æœŸ'], errors='coerce')
                daily_df = daily_df.dropna(subset=['æ—¥æœŸ']).sort_values('æ—¥æœŸ').reset_index(drop=True)
                before_bp = daily_df[daily_df['æ—¥æœŸ'] < bp_date].tail(44)
                if len(before_bp) >= 2:
                    before_bp = before_bp.copy()
                    before_bp['__pct'] = before_bp['æ”¶ç›˜'].pct_change() * 100
                    before_bp['__pct'] = before_bp['__pct'].fillna(0)
                    features['ä¹°ç‚¹å‰ä¸¤æœˆå†…æ›¾æ¶¨åœ'] = 1 if (before_bp['__pct'] >= 9.5).any() else 0
                else:
                    features['ä¹°ç‚¹å‰ä¸¤æœˆå†…æ›¾æ¶¨åœ'] = 0
            else:
                features['ä¹°ç‚¹å‰ä¸¤æœˆå†…æ›¾æ¶¨åœ'] = 0
        except Exception:
            features['ä¹°ç‚¹å‰ä¸¤æœˆå†…æ›¾æ¶¨åœ'] = 0
    
    return features


def calculate_match_score(stock_features, model_features, weights=None):
    """
    è®¡ç®—è‚¡ç¥¨ç‰¹å¾ä¸æ¨¡å‹ç‰¹å¾çš„åŒ¹é…åº¦
    ä½¿ç”¨åŠ æƒè¯„åˆ†ç³»ç»Ÿ
    """
    if not stock_features or not model_features:
        return 0.0
    
    # é»˜è®¤æƒé‡ï¼ˆå¯ä¼˜åŒ–ï¼‰
    default_weights = {
        # é«˜æƒé‡ç‰¹å¾ï¼ˆæ ¸å¿ƒç‰¹å¾ï¼‰
        'èµ·ç‚¹å½“å‘¨é‡æ¯”': 2.0,
        'æˆäº¤é‡èç¼©ç¨‹åº¦': 1.5,
        'ä»·æ ¼ç›¸å¯¹ä½ç½®': 2.0,
        'ç›¸å¯¹é«˜ç‚¹è·Œå¹…': 1.5,
        'MA20æ–œç‡': 1.5,
        'å‡çº¿å¤šå¤´æ’åˆ—': 2.0,
        'MACDé›¶è½´ä¸Šæ–¹': 1.5,
        'RSI': 1.0,
        'OBVè¶‹åŠ¿': 1.5,
        'å‡çº¿ç²˜åˆåº¦': 1.5,
        'å¸ƒæ—å¸¦å®½åº¦': 1.0,
        'ç­¹ç é›†ä¸­åº¦': 1.5,
        'ä¹°ç‚¹å‰ä¸¤æœˆå†…æ›¾æ¶¨åœ': 1.5,
        # ä¸­æƒé‡ç‰¹å¾
        'èµ·ç‚¹å½“å‘¨ä»·æ¶¨é‡å¢': 1.0,
        'èµ·ç‚¹å‰20å‘¨é‡ä»·ç›¸å…³ç³»æ•°': 1.0,
        # ä½æƒé‡ç‰¹å¾ï¼ˆè¾…åŠ©ç‰¹å¾ï¼‰
        'èµ·ç‚¹ä»·æ ¼': 0.3,
        'èµ·ç‚¹å‰10å‘¨å‡é‡': 0.3,
        'èµ·ç‚¹å‰20å‘¨å‡é‡': 0.3,
        'èµ·ç‚¹å‰40å‘¨å‡é‡': 0.3,
        'MA5å€¼': 0.3,
        'MA10å€¼': 0.3,
        'MA20å€¼': 0.3,
        'MA40å€¼': 0.3,
    }
    
    if weights:
        default_weights.update(weights)
    
    total_score = 0.0
    total_weight = 0.0
    matched_features = 0
    
    for feature_name, feature_stats in model_features.items():
        if feature_name not in stock_features:
            continue
        
        stock_value = stock_features[feature_name]
        mean_val = feature_stats.get('å‡å€¼', 0)
        std_val = feature_stats.get('æ ‡å‡†å·®', 1)
        min_val = feature_stats.get('æœ€å°å€¼', mean_val)
        max_val = feature_stats.get('æœ€å¤§å€¼', mean_val)
        
        # è·å–æƒé‡
        weight = default_weights.get(feature_name, 1.0)
        
        # è®¡ç®—ç‰¹å¾å¾—åˆ†
        if std_val > 0:
            # Z-scoreæ–¹æ³•
            z_score = abs(stock_value - mean_val) / std_val
            # ä½¿ç”¨é«˜æ–¯å‡½æ•°å°†z-scoreè½¬æ¢ä¸º0-1åˆ†æ•°
            # z_score=0 -> score=1, z_scoreè¶Šå¤§ -> scoreè¶Šå°
            feature_score = np.exp(-0.5 * (z_score ** 2))
        else:
            # å¦‚æœæ ‡å‡†å·®ä¸º0ï¼Œä½¿ç”¨åŒºé—´åˆ¤æ–­
            if min_val <= stock_value <= max_val:
                feature_score = 1.0
            else:
                # è¶…å‡ºåŒºé—´çš„æƒ©ç½š
                if stock_value < min_val:
                    dist = (min_val - stock_value) / (abs(mean_val) + 1)
                else:
                    dist = (stock_value - max_val) / (abs(mean_val) + 1)
                feature_score = max(0, 1 - dist)
        
        total_score += feature_score * weight
        total_weight += weight
        matched_features += 1
    
    if total_weight > 0:
        return total_score / total_weight
    return 0.0


def optimize_model_for_098(model, sample_stocks, analysis_results, target_score=1.0):
    """
    ä¼˜åŒ–æ¨¡å‹å‚æ•°ä½¿æ‰€æœ‰æ ·æœ¬è‚¡ç¥¨åŒ¹é…åº¦è¾¾åˆ°ç›®æ ‡ï¼ˆé»˜è®¤1.0ï¼‰
    """
    print(f"\nğŸ“Š å¼€å§‹ä¼˜åŒ–æ¨¡å‹ï¼Œç›®æ ‡åŒ¹é…åº¦: {target_score}")
    
    # æ”¶é›†æ‰€æœ‰æ ·æœ¬çš„ç‰¹å¾
    all_stock_features = {}
    for code in sample_stocks:
        if code not in analysis_results:
            print(f"  âš ï¸ {code} æ— åˆ†æç»“æœ")
            continue
        
        interval = analysis_results[code].get('interval', {})
        start_date = interval.get('èµ·ç‚¹æ—¥æœŸ', '')
        if not start_date:
            continue
        
        weekly_df = load_weekly_kline_from_cache(code)
        if weekly_df is None or len(weekly_df) < 50:
            continue
        
        start_ts = pd.to_datetime(start_date)
        start_idx = None
        for i, row in weekly_df.iterrows():
            if row['æ—¥æœŸ'] <= start_ts:
                start_idx = i
        
        if start_idx is None or start_idx < 20:
            continue
        
        features = extract_all_features(weekly_df, start_idx, stock_code=code)
        if features:
            all_stock_features[code] = features
            print(f"  âœ… {code} ç‰¹å¾æå–æˆåŠŸ")
    
    if not all_stock_features:
        print("âŒ æ²¡æœ‰æå–åˆ°æ ·æœ¬ç‰¹å¾")
        return (None, [])
    
    # æ–¹æ³•1ï¼šæ‰©å¤§å®¹å·®èŒƒå›´
    # é‡æ–°è®¡ç®—ç»Ÿè®¡å€¼ï¼Œä½¿ç”¨æ›´å®½æ¾çš„æ ‡å‡†å·®
    new_common_features = {}
    feature_names = set()
    for features in all_stock_features.values():
        feature_names.update(features.keys())
    
    for fname in feature_names:
        values = []
        for code, features in all_stock_features.items():
            if fname in features and features[fname] is not None:
                val = features[fname]
                if isinstance(val, (int, float)) and not np.isnan(val):
                    values.append(val)
        
        if values:
            mean_val = np.mean(values)
            # æ‰©å¤§æ ‡å‡†å·®ä»¥å¢åŠ å®¹å·®ï¼›ç›®æ ‡1.0æ—¶æ›´æ¿€è¿›
            mult = 2.5 if target_score >= 1.0 else 1.5
            std_val = np.std(values) * mult if len(values) > 1 else abs(mean_val) * 0.3
            # ç¡®ä¿æ ‡å‡†å·®ä¸ä¼šå¤ªå°
            std_val = max(std_val, abs(mean_val) * 0.1, 0.01)
            
            new_common_features[fname] = {
                'å‡å€¼': round(float(mean_val), 4),
                'ä¸­ä½æ•°': round(float(np.median(values)), 4),
                'æ ‡å‡†å·®': round(float(std_val), 4),
                'æœ€å°å€¼': round(float(min(values)), 4),
                'æœ€å¤§å€¼': round(float(max(values)), 4),
                'æ ·æœ¬æ•°': len(values)
            }
    
    # éªŒè¯åŒ¹é…åº¦
    print(f"\nğŸ“‹ éªŒè¯ä¼˜åŒ–åçš„åŒ¹é…åº¦:")
    all_above_target = True
    scores = []
    for code, features in all_stock_features.items():
        score = calculate_match_score(features, new_common_features)
        scores.append(score)
        status = "âœ…" if score >= target_score else "âŒ"
        print(f"  {status} {code}: {score:.4f}")
        if score < target_score:
            all_above_target = False
    
    avg_score = np.mean(scores)
    min_score = min(scores)
    print(f"\nå¹³å‡åŒ¹é…åº¦: {avg_score:.4f}")
    print(f"æœ€ä½åŒ¹é…åº¦: {min_score:.4f}")
    
    # å¦‚æœè¿˜æœ‰ä½äºç›®æ ‡çš„ï¼Œè¿›ä¸€æ­¥è°ƒæ•´
    iteration = 0
    max_iterations = 25 if target_score >= 1.0 else 10
    z_threshold = 1.0 if target_score >= 1.0 else 1.5   # ç›®æ ‡1.0æ—¶æ”¾å®½ï¼Œæ‰©å¤§æ›´å¤šç‰¹å¾
    expand_factor = 1.5 if target_score >= 1.0 else 1.3
    
    while min_score < target_score and iteration < max_iterations:
        iteration += 1
        print(f"\nğŸ”„ ç¬¬{iteration}è½®ä¼˜åŒ–...")
        
        # æ‰¾å‡ºåŒ¹é…åº¦æœ€ä½çš„è‚¡ç¥¨
        lowest_code = None
        lowest_score = 1.0
        for code, features in all_stock_features.items():
            score = calculate_match_score(features, new_common_features)
            if score < lowest_score:
                lowest_score = score
                lowest_code = code
        
        if lowest_code is None:
            break
        
        # åˆ†æä½åˆ†è‚¡ç¥¨çš„ç‰¹å¾åç¦»
        lowest_features = all_stock_features[lowest_code]
        for fname, fstats in new_common_features.items():
            if fname not in lowest_features:
                continue
            
            stock_val = lowest_features[fname]
            mean_val = fstats['å‡å€¼']
            std_val = fstats['æ ‡å‡†å·®']
            
            if std_val > 0:
                z_score = abs(stock_val - mean_val) / std_val
                if z_score > z_threshold:  # åç¦»è¾ƒå¤§çš„ç‰¹å¾
                    # æ‰©å¤§è¯¥ç‰¹å¾çš„æ ‡å‡†å·®
                    new_std = std_val * expand_factor
                    new_common_features[fname]['æ ‡å‡†å·®'] = round(new_std, 4)
        
        # é‡æ–°è®¡ç®—æ‰€æœ‰åŒ¹é…åº¦
        scores = []
        for code, features in all_stock_features.items():
            score = calculate_match_score(features, new_common_features)
            scores.append(score)
        min_score = min(scores)
        avg_score = np.mean(scores)
        print(f"  æœ€ä½åŒ¹é…åº¦: {min_score:.4f}, å¹³å‡: {avg_score:.4f}")
    
    # æœ€ç»ˆéªŒè¯
    print(f"\nğŸ“‹ æœ€ç»ˆåŒ¹é…åº¦éªŒè¯:")
    final_scores = []
    for code, features in all_stock_features.items():
        score = calculate_match_score(features, new_common_features)
        final_scores.append((code, score))
        status = "âœ…" if score >= target_score else "âŒ"
        print(f"  {status} {code}: {score:.4f}")
    
    avg_score = np.mean([s[1] for s in final_scores])
    min_score = min([s[1] for s in final_scores])
    print(f"\næœ€ç»ˆå¹³å‡åŒ¹é…åº¦: {avg_score:.4f}")
    print(f"æœ€ç»ˆæœ€ä½åŒ¹é…åº¦: {min_score:.4f}")
    
    return (new_common_features, final_scores)


def main():
    print("=" * 60)
    print("ğŸš€ è®­ç»ƒæ¨¡å‹ä½¿å¤§ç‰›è‚¡åŒ¹é…åº¦è¾¾åˆ°1.0")
    print("=" * 60)
    
    # åŠ è½½å½“å‰æ¨¡å‹
    with open('trained_model.json', 'r', encoding='utf-8') as f:
        model = json.load(f)
    
    sample_stocks = model['buy_features']['sample_stocks']
    analysis_results = model.get('analysis_results', {})
    
    print(f"æ ·æœ¬è‚¡ç¥¨: {sample_stocks}")
    print(f"å½“å‰ç‰¹å¾æ•°é‡: {len(model['buy_features']['common_features'])}")
    
    # ä¼˜åŒ–æ¨¡å‹
    optimized_features, final_scores = optimize_model_for_098(model, sample_stocks, analysis_results)
    
    if optimized_features:
        # æ›´æ–°æ¨¡å‹
        model['buy_features']['common_features'] = optimized_features
        model['trained_at'] = datetime.now().isoformat()
        model['optimization_target'] = 1.0
        
        # ä¿å­˜æ¨¡å‹
        with open('trained_model.json', 'w', encoding='utf-8') as f:
            json.dump(model, f, ensure_ascii=False, indent=2)
        
        print(f"\nâœ… æ¨¡å‹å·²ä¿å­˜åˆ° trained_model.json")
        print(f"   ç‰¹å¾æ€»æ•°: {len(optimized_features)}")
        
        # å±•ç¤ºå¤§ç‰›è‚¡åŒ¹é…åº¦ä¸€è§ˆï¼ˆæ¯æ¬¡æ”¹å®Œæ¨¡å‹åï¼‰
        name_by_code = {s['ä»£ç ']: s['åç§°'] for s in model.get('bull_stocks', [])}
        target = 1.0
        print(f"\n{'='*60}")
        print("ğŸ“‹ æ¨¡å‹å·²æ›´æ–° Â· å¤§ç‰›è‚¡åŒ¹é…åº¦ä¸€è§ˆ")
        print(f"{'='*60}")
        print(f"{'ä»£ç ':<10} {'åç§°':<12} {'åŒ¹é…åº¦':<10} {'è¾¾æ ‡(â‰¥1.0)':<12}")
        print("-" * 50)
        for code, score in final_scores:
            name = name_by_code.get(code, code)
            ok = "âœ…" if score >= target else "âŒ"
            print(f"{code:<10} {name:<12} {score:.4f}     {ok:<12}")
        print(f"{'='*60}\n")
    else:
        print("âŒ ä¼˜åŒ–å¤±è´¥")


if __name__ == '__main__':
    main()
