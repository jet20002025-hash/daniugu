#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºç‰ˆå¤§ç‰›è‚¡æ¨¡å‹ - åŸºäºå…¨ç½‘é‡ä»·å…³ç³»ç ”ç©¶æˆæœ
ç‰¹å¾ä½“ç³»ï¼š
1. OBVèƒ½é‡æ½® - ç´¯ç§¯èµ„é‡‘æµå‘
2. ç­¹ç é›†ä¸­åº¦ - ä»·æ ¼åŒºé—´é›†ä¸­åº¦
3. å‡çº¿ç²˜åˆåº¦ - å˜ç›˜å‰å…†
4. MACDä¿¡å· - è¶‹åŠ¿ç¡®è®¤
5. é‡ä»·èƒŒç¦»/åŒå‘ - è¶‹åŠ¿å¼ºåº¦
6. çªç ´ä¿¡å· - å½¢æ€è¯†åˆ«
"""
import os
import sys
import json
import pandas as pd
import numpy as np
from datetime import datetime
from typing import Dict, List, Optional

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))


class EnhancedFeatureExtractor:
    """å¢å¼ºç‰ˆç‰¹å¾æå–å™¨"""
    
    @staticmethod
    def calculate_obv(df: pd.DataFrame, volume_col: str = 'å‘¨æˆäº¤é‡') -> pd.Series:
        """
        è®¡ç®—OBVèƒ½é‡æ½®
        é€»è¾‘ï¼šä»·æ ¼ä¸Šæ¶¨åŠ æˆäº¤é‡ï¼Œä»·æ ¼ä¸‹è·Œå‡æˆäº¤é‡
        """
        obv = [0]
        for i in range(1, len(df)):
            if df['æ”¶ç›˜'].iloc[i] > df['æ”¶ç›˜'].iloc[i-1]:
                obv.append(obv[-1] + df[volume_col].iloc[i])
            elif df['æ”¶ç›˜'].iloc[i] < df['æ”¶ç›˜'].iloc[i-1]:
                obv.append(obv[-1] - df[volume_col].iloc[i])
            else:
                obv.append(obv[-1])
        return pd.Series(obv, index=df.index)
    
    @staticmethod
    def calculate_ad_line(df: pd.DataFrame, volume_col: str = 'å‘¨æˆäº¤é‡') -> pd.Series:
        """
        è®¡ç®—A/Dç´¯ç§¯æ´¾å‘çº¿
        è€ƒè™‘æ”¶ç›˜ä»·åœ¨å½“æ—¥é«˜ä½åŒºé—´çš„ä½ç½®
        """
        clv = ((df['æ”¶ç›˜'] - df['æœ€ä½']) - (df['æœ€é«˜'] - df['æ”¶ç›˜'])) / (df['æœ€é«˜'] - df['æœ€ä½'] + 0.0001)
        ad = (clv * df[volume_col]).cumsum()
        return ad
    
    @staticmethod
    def calculate_macd(prices: pd.Series, fast=12, slow=26, signal=9):
        """è®¡ç®—MACDæŒ‡æ ‡"""
        ema_fast = prices.ewm(span=fast, adjust=False).mean()
        ema_slow = prices.ewm(span=slow, adjust=False).mean()
        dif = ema_fast - ema_slow
        dea = dif.ewm(span=signal, adjust=False).mean()
        macd = (dif - dea) * 2
        return dif, dea, macd
    
    @staticmethod
    def calculate_rsi(prices: pd.Series, period=14):
        """è®¡ç®—RSIæŒ‡æ ‡"""
        delta = prices.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
        rs = gain / (loss + 0.0001)
        rsi = 100 - (100 / (1 + rs))
        return rsi
    
    @staticmethod
    def calculate_bollinger_bands(prices: pd.Series, period=20, num_std=2):
        """è®¡ç®—å¸ƒæ—å¸¦"""
        ma = prices.rolling(window=period).mean()
        std = prices.rolling(window=period).std()
        upper = ma + num_std * std
        lower = ma - num_std * std
        return ma, upper, lower
    
    @staticmethod
    def calculate_ma_convergence(df: pd.DataFrame, idx: int) -> float:
        """
        è®¡ç®—å‡çº¿ç²˜åˆåº¦
        å‡çº¿è¶Šç²˜åˆï¼Œå€¼è¶Šå°ï¼Œé¢„ç¤ºå˜ç›˜
        """
        if idx < 20:
            return 100.0
        
        prices = df['æ”¶ç›˜'].iloc[:idx+1]
        ma5 = prices.rolling(5).mean().iloc[-1]
        ma10 = prices.rolling(10).mean().iloc[-1]
        ma20 = prices.rolling(20).mean().iloc[-1]
        
        # è®¡ç®—å‡çº¿ä¹‹é—´çš„ç¦»æ•£åº¦
        avg_ma = (ma5 + ma10 + ma20) / 3
        if avg_ma > 0:
            dispersion = (abs(ma5-avg_ma) + abs(ma10-avg_ma) + abs(ma20-avg_ma)) / avg_ma * 100
            return round(dispersion, 2)
        return 100.0
    
    @staticmethod
    def calculate_chip_concentration(df: pd.DataFrame, idx: int, lookback=20) -> Dict:
        """
        è®¡ç®—ç­¹ç é›†ä¸­åº¦ï¼ˆç®€åŒ–ç‰ˆï¼‰
        ä½¿ç”¨ä»·æ ¼åŒºé—´ä»£æ›¿çœŸå®ç­¹ç åˆ†å¸ƒ
        """
        if idx < lookback:
            return {'chip_concentration': 0, 'cost_center': 0}
        
        recent_df = df.iloc[idx-lookback:idx+1]
        
        # åŠ æƒå¹³å‡æˆæœ¬ï¼ˆç”¨æˆäº¤é‡åŠ æƒï¼‰
        volume_col = 'å‘¨æˆäº¤é‡' if 'å‘¨æˆäº¤é‡' in df.columns else 'æˆäº¤é‡'
        total_volume = recent_df[volume_col].sum()
        if total_volume > 0:
            weighted_price = (recent_df['æ”¶ç›˜'] * recent_df[volume_col]).sum() / total_volume
        else:
            weighted_price = recent_df['æ”¶ç›˜'].mean()
        
        # 90%ç­¹ç çš„ä»·æ ¼åŒºé—´
        price_range = recent_df['æœ€é«˜'].max() - recent_df['æœ€ä½'].min()
        
        # å½“å‰ä»·æ ¼ç›¸å¯¹æˆæœ¬ä¸­å¿ƒ
        current_price = df['æ”¶ç›˜'].iloc[idx]
        cost_deviation = (current_price - weighted_price) / weighted_price * 100 if weighted_price > 0 else 0
        
        # ç­¹ç é›†ä¸­åº¦ = æˆäº¤é‡åŠ æƒæ ‡å‡†å·®
        if total_volume > 0:
            price_std = np.sqrt(((recent_df['æ”¶ç›˜'] - weighted_price) ** 2 * recent_df[volume_col]).sum() / total_volume)
            concentration = price_std / weighted_price * 100 if weighted_price > 0 else 0
        else:
            concentration = 0
        
        return {
            'chip_concentration': round(concentration, 2),  # è¶Šå°è¶Šé›†ä¸­
            'cost_center': round(weighted_price, 2),
            'cost_deviation': round(cost_deviation, 2)  # æ­£å€¼=ä»·æ ¼åœ¨æˆæœ¬ä¸Šæ–¹
        }
    
    def extract_enhanced_features(self, df: pd.DataFrame, idx: int, volume_col: str = 'å‘¨æˆäº¤é‡') -> Optional[Dict]:
        """
        æå–å¢å¼ºç‰ˆç‰¹å¾
        """
        if idx < 40 or len(df) < 40:
            return None
        
        try:
            features = {}
            current_price = df['æ”¶ç›˜'].iloc[idx]
            current_volume = df[volume_col].iloc[idx]
            
            # ========== 1. OBVèƒ½é‡æ½®ç‰¹å¾ ==========
            obv = self.calculate_obv(df.iloc[:idx+1], volume_col)
            
            # OBVè¶‹åŠ¿ï¼ˆè¿‘10å‘¨OBVæ–œç‡ï¼‰
            if len(obv) >= 10:
                obv_recent = obv.tail(10)
                obv_slope = (obv_recent.iloc[-1] - obv_recent.iloc[0]) / (obv_recent.iloc[0] + 1) * 100
                features['OBVè¶‹åŠ¿'] = round(obv_slope, 2)
            
            # OBVæ˜¯å¦åˆ›æ–°é«˜ï¼ˆç›¸å¯¹å‰20å‘¨ï¼‰
            if len(obv) >= 20:
                obv_high_20 = obv.tail(20).max()
                features['OBVåˆ›æ–°é«˜'] = 1 if obv.iloc[-1] >= obv_high_20 * 0.95 else 0
            
            # OBVä¸ä»·æ ¼èƒŒç¦»
            if len(obv) >= 10:
                price_trend = (df['æ”¶ç›˜'].iloc[idx] - df['æ”¶ç›˜'].iloc[idx-10]) / df['æ”¶ç›˜'].iloc[idx-10]
                obv_trend = (obv.iloc[-1] - obv.iloc[-10]) / (abs(obv.iloc[-10]) + 1)
                # æ­£èƒŒç¦»ï¼šä»·æ ¼è·ŒOBVæ¶¨ï¼ˆä¹°å…¥ä¿¡å·ï¼‰
                features['OBVæ­£èƒŒç¦»'] = 1 if (price_trend < -0.05 and obv_trend > 0.1) else 0
            
            # ========== 2. A/Dç´¯ç§¯æ´¾å‘ç‰¹å¾ ==========
            ad = self.calculate_ad_line(df.iloc[:idx+1], volume_col)
            if len(ad) >= 10:
                ad_trend = (ad.iloc[-1] - ad.iloc[-10]) / (abs(ad.iloc[-10]) + 1) * 100
                features['ADè¶‹åŠ¿'] = round(ad_trend, 2)
            
            # ========== 3. MACDç‰¹å¾ ==========
            prices = df['æ”¶ç›˜'].iloc[:idx+1]
            dif, dea, macd = self.calculate_macd(prices)
            
            features['MACD_DIF'] = round(dif.iloc[-1], 3)
            features['MACD_DEA'] = round(dea.iloc[-1], 3)
            features['MACDæŸ±'] = round(macd.iloc[-1], 3)
            
            # MACDé‡‘å‰/æ­»å‰
            if len(dif) >= 2:
                prev_diff = dif.iloc[-2] - dea.iloc[-2]
                curr_diff = dif.iloc[-1] - dea.iloc[-1]
                features['MACDé‡‘å‰'] = 1 if (prev_diff < 0 and curr_diff >= 0) else 0
                features['MACDé›¶è½´ä¸Šæ–¹'] = 1 if dif.iloc[-1] > 0 else 0
            
            # ========== 4. RSIç‰¹å¾ ==========
            rsi = self.calculate_rsi(prices, 14)
            if len(rsi) > 0 and not pd.isna(rsi.iloc[-1]):
                features['RSI'] = round(rsi.iloc[-1], 2)
                features['RSIè¶…å–'] = 1 if rsi.iloc[-1] < 30 else 0
                features['RSIå¼ºåŠ¿åŒº'] = 1 if 50 < rsi.iloc[-1] < 70 else 0
            
            # ========== 5. å¸ƒæ—å¸¦ç‰¹å¾ ==========
            ma, upper, lower = self.calculate_bollinger_bands(prices, 20, 2)
            if not pd.isna(upper.iloc[-1]) and not pd.isna(lower.iloc[-1]):
                bb_width = (upper.iloc[-1] - lower.iloc[-1]) / ma.iloc[-1] * 100
                features['å¸ƒæ—å¸¦å®½åº¦'] = round(bb_width, 2)
                
                # ä»·æ ¼åœ¨å¸ƒæ—å¸¦ä¸­çš„ä½ç½®
                bb_position = (current_price - lower.iloc[-1]) / (upper.iloc[-1] - lower.iloc[-1] + 0.01) * 100
                features['å¸ƒæ—å¸¦ä½ç½®'] = round(bb_position, 2)
                
                # å¸ƒæ—å¸¦æ”¶çª„ï¼ˆå˜ç›˜ä¿¡å·ï¼‰
                if len(ma) >= 10:
                    bb_width_10 = ((upper.iloc[-10] - lower.iloc[-10]) / ma.iloc[-10] * 100) if ma.iloc[-10] > 0 else bb_width
                    features['å¸ƒæ—å¸¦æ”¶çª„'] = 1 if bb_width < bb_width_10 * 0.8 else 0
            
            # ========== 6. å‡çº¿ç²˜åˆåº¦ ==========
            features['å‡çº¿ç²˜åˆåº¦'] = self.calculate_ma_convergence(df, idx)
            
            # å‡çº¿å¤šå¤´æ’åˆ—
            if idx >= 20:
                ma5 = df['æ”¶ç›˜'].iloc[idx-4:idx+1].mean()
                ma10 = df['æ”¶ç›˜'].iloc[idx-9:idx+1].mean()
                ma20 = df['æ”¶ç›˜'].iloc[idx-19:idx+1].mean()
                features['å‡çº¿å¤šå¤´'] = 1 if (ma5 > ma10 > ma20) else 0
                features['ä»·æ ¼åœ¨MA20ä¸Šæ–¹'] = 1 if current_price > ma20 else 0
            
            # ========== 7. ç­¹ç é›†ä¸­åº¦ ==========
            chip_info = self.calculate_chip_concentration(df, idx, 20)
            features['ç­¹ç é›†ä¸­åº¦'] = chip_info['chip_concentration']
            features['æˆæœ¬åç¦»åº¦'] = chip_info['cost_deviation']
            
            # ========== 8. é‡æ¯”ç‰¹å¾ ==========
            # é‡æ¯” = å½“å‰æˆäº¤é‡ / è¿‡å»Nå‘¨å¹³å‡æˆäº¤é‡
            avg_vol_5 = df[volume_col].iloc[idx-5:idx].mean()
            avg_vol_10 = df[volume_col].iloc[idx-10:idx].mean()
            avg_vol_20 = df[volume_col].iloc[idx-20:idx].mean()
            
            features['é‡æ¯”5å‘¨'] = round(current_volume / avg_vol_5, 2) if avg_vol_5 > 0 else 1
            features['é‡æ¯”10å‘¨'] = round(current_volume / avg_vol_10, 2) if avg_vol_10 > 0 else 1
            features['é‡æ¯”20å‘¨'] = round(current_volume / avg_vol_20, 2) if avg_vol_20 > 0 else 1
            
            # åœ°é‡ä¿¡å·ï¼ˆæˆäº¤é‡æåº¦èç¼©ï¼‰
            min_vol_20 = df[volume_col].iloc[idx-20:idx].min()
            features['åœ°é‡ä¿¡å·'] = 1 if current_volume <= min_vol_20 * 1.2 else 0
            
            # ========== 9. çªç ´ä¿¡å· ==========
            high_20 = df['æœ€é«˜'].iloc[idx-20:idx].max()
            high_40 = df['æœ€é«˜'].iloc[idx-40:idx].max()
            
            features['çªç ´20å‘¨é«˜ç‚¹'] = 1 if current_price > high_20 else 0
            features['çªç ´40å‘¨é«˜ç‚¹'] = 1 if current_price > high_40 else 0
            features['æ¥è¿‘20å‘¨é«˜ç‚¹'] = 1 if current_price > high_20 * 0.95 else 0
            
            # ========== 10. ä»·æ ¼å½¢æ€ ==========
            # è¿‘æœŸæ¶¨è·Œå¹…
            if idx >= 4:
                ret_4w = (current_price - df['æ”¶ç›˜'].iloc[idx-4]) / df['æ”¶ç›˜'].iloc[idx-4] * 100
                features['è¿‘4å‘¨æ¶¨è·Œå¹…'] = round(ret_4w, 2)
            
            if idx >= 8:
                ret_8w = (current_price - df['æ”¶ç›˜'].iloc[idx-8]) / df['æ”¶ç›˜'].iloc[idx-8] * 100
                features['è¿‘8å‘¨æ¶¨è·Œå¹…'] = round(ret_8w, 2)
            
            # ä»·æ ¼æ³¢åŠ¨ç‡
            if idx >= 20:
                returns = df['æ”¶ç›˜'].iloc[idx-20:idx+1].pct_change().dropna()
                volatility = returns.std() * np.sqrt(52) * 100  # å¹´åŒ–æ³¢åŠ¨ç‡
                features['æ³¢åŠ¨ç‡'] = round(volatility, 2)
            
            # ========== 11. é‡ä»·é…åˆ ==========
            # é‡ä»·åŒå‘æ€§
            if idx >= 10:
                price_changes = df['æ”¶ç›˜'].iloc[idx-10:idx+1].pct_change().dropna()
                vol_changes = df[volume_col].iloc[idx-10:idx+1].pct_change().dropna()
                
                if len(price_changes) > 0 and len(vol_changes) > 0:
                    correlation = price_changes.corr(vol_changes)
                    if not pd.isna(correlation):
                        features['é‡ä»·ç›¸å…³æ€§'] = round(correlation, 3)
            
            # ä»·æ¶¨é‡å¢å¾—åˆ†
            up_vol_score = 0
            for i in range(max(0, idx-10), idx+1):
                if i > 0:
                    if df['æ”¶ç›˜'].iloc[i] > df['æ”¶ç›˜'].iloc[i-1] and df[volume_col].iloc[i] > df[volume_col].iloc[i-1]:
                        up_vol_score += 1
            features['ä»·æ¶¨é‡å¢å¾—åˆ†'] = up_vol_score
            
            # ========== 12. åº•éƒ¨å½¢æ€ç‰¹å¾ ==========
            # ä»·æ ¼ç›¸å¯¹40å‘¨ä½ç‚¹
            low_40 = df['æœ€ä½'].iloc[idx-40:idx].min()
            features['ç›¸å¯¹40å‘¨ä½ç‚¹'] = round((current_price - low_40) / low_40 * 100, 2) if low_40 > 0 else 0
            
            # æ¨ªç›˜æ•´ç†å¤©æ•°ï¼ˆä»·æ ¼æ³¢åŠ¨å°äº10%çš„å‘¨æ•°ï¼‰
            sideways_weeks = 0
            for i in range(idx-20, idx):
                if i >= 0:
                    range_pct = (df['æœ€é«˜'].iloc[i] - df['æœ€ä½'].iloc[i]) / df['æœ€ä½'].iloc[i] * 100
                    if range_pct < 10:
                        sideways_weeks += 1
            features['æ¨ªç›˜å‘¨æ•°'] = sideways_weeks
            
            return features
            
        except Exception as e:
            print(f"ç‰¹å¾æå–é”™è¯¯: {e}")
            return None


class EnhancedBullStockModel:
    """å¢å¼ºç‰ˆå¤§ç‰›è‚¡æ¨¡å‹"""
    
    def __init__(self):
        self.feature_extractor = EnhancedFeatureExtractor()
        self.model = None
        self.feature_stats = {}
        self.sample_stocks = []
    
    def train(self, sample_data: List[Dict]) -> Dict:
        """
        è®­ç»ƒæ¨¡å‹
        sample_data: [{'code': '000592', 'weekly_df': pd.DataFrame, 'start_idx': 92}, ...]
        """
        all_features = []
        
        for sample in sample_data:
            df = sample['weekly_df']
            idx = sample['start_idx']
            code = sample['code']
            
            volume_col = 'å‘¨æˆäº¤é‡' if 'å‘¨æˆäº¤é‡' in df.columns else 'æˆäº¤é‡'
            features = self.feature_extractor.extract_enhanced_features(df, idx, volume_col)
            
            if features:
                features['è‚¡ç¥¨ä»£ç '] = code
                all_features.append(features)
                self.sample_stocks.append(code)
                print(f"âœ… {code} ç‰¹å¾æå–æˆåŠŸï¼Œå…± {len(features)} ä¸ªç‰¹å¾")
        
        if not all_features:
            return {}
        
        # è®¡ç®—ç‰¹å¾ç»Ÿè®¡å€¼
        feature_df = pd.DataFrame(all_features)
        numeric_cols = feature_df.select_dtypes(include=[np.number]).columns
        
        for col in numeric_cols:
            values = feature_df[col].dropna()
            if len(values) > 0:
                self.feature_stats[col] = {
                    'å‡å€¼': round(float(values.mean()), 4),
                    'ä¸­ä½æ•°': round(float(values.median()), 4),
                    'æ ‡å‡†å·®': round(float(values.std()), 4),
                    'æœ€å°å€¼': round(float(values.min()), 4),
                    'æœ€å¤§å€¼': round(float(values.max()), 4),
                    'æ ·æœ¬æ•°': len(values)
                }
        
        self.model = {
            'feature_stats': self.feature_stats,
            'sample_stocks': self.sample_stocks,
            'sample_count': len(all_features),
            'trained_at': datetime.now().isoformat(),
            'model_type': 'enhanced_volume_price_model'
        }
        
        print(f"\nâœ… æ¨¡å‹è®­ç»ƒå®Œæˆ")
        print(f"   æ ·æœ¬æ•°: {len(all_features)}")
        print(f"   ç‰¹å¾æ•°: {len(self.feature_stats)}")
        
        return self.model
    
    def calculate_match_score(self, features: Dict) -> float:
        """è®¡ç®—åŒ¹é…åº¦"""
        if not self.feature_stats:
            return 0
        
        # å®šä¹‰æ ¸å¿ƒç‰¹å¾åŠå…¶æƒé‡
        core_features = {
            'OBVè¶‹åŠ¿': 3.0,
            'OBVåˆ›æ–°é«˜': 2.0,
            'MACDé‡‘å‰': 2.0,
            'MACDé›¶è½´ä¸Šæ–¹': 1.5,
            'å‡çº¿ç²˜åˆåº¦': 2.0,
            'å‡çº¿å¤šå¤´': 2.0,
            'é‡æ¯”5å‘¨': 2.0,
            'åœ°é‡ä¿¡å·': 1.5,
            'çªç ´20å‘¨é«˜ç‚¹': 2.0,
            'ç­¹ç é›†ä¸­åº¦': 1.5,
            'å¸ƒæ—å¸¦æ”¶çª„': 1.5,
            'ä»·æ¶¨é‡å¢å¾—åˆ†': 1.5,
            'RSIå¼ºåŠ¿åŒº': 1.0,
        }
        
        total_score = 0
        total_weight = 0
        
        for feature_name, stats in self.feature_stats.items():
            if feature_name not in features:
                continue
            
            target_value = features[feature_name]
            min_val = stats['æœ€å°å€¼']
            max_val = stats['æœ€å¤§å€¼']
            median_val = stats['ä¸­ä½æ•°']
            std_val = stats['æ ‡å‡†å·®']
            
            # è®¡ç®—åŒ¹é…åˆ†æ•°
            if min_val <= target_value <= max_val:
                # åœ¨èŒƒå›´å†…ï¼Œæ ¹æ®åˆ°ä¸­ä½æ•°çš„è·ç¦»è¯„åˆ†
                if std_val > 0:
                    z_score = abs(target_value - median_val) / std_val
                    import math
                    score = math.exp(-0.1 * z_score * z_score)
                else:
                    score = 1.0
            else:
                # èŒƒå›´å¤–
                if max_val > min_val:
                    range_size = max_val - min_val
                    if target_value < min_val:
                        distance = (min_val - target_value) / range_size
                    else:
                        distance = (target_value - max_val) / range_size
                    score = max(0, 1.0 - distance * 0.5)
                else:
                    score = 0.5
            
            # åº”ç”¨æƒé‡
            weight = core_features.get(feature_name, 1.0)
            total_score += score * weight
            total_weight += weight
        
        if total_weight > 0:
            return round(total_score / total_weight, 3)
        return 0
    
    def save_model(self, filepath: str):
        """ä¿å­˜æ¨¡å‹"""
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(self.model, f, ensure_ascii=False, indent=2)
        print(f"âœ… æ¨¡å‹å·²ä¿å­˜åˆ°: {filepath}")
    
    def load_model(self, filepath: str):
        """åŠ è½½æ¨¡å‹"""
        with open(filepath, 'r', encoding='utf-8') as f:
            self.model = json.load(f)
        self.feature_stats = self.model.get('feature_stats', {})
        self.sample_stocks = self.model.get('sample_stocks', [])
        print(f"âœ… æ¨¡å‹å·²åŠ è½½: {filepath}")


def train_enhanced_model():
    """è®­ç»ƒå¢å¼ºç‰ˆæ¨¡å‹"""
    print("=" * 80)
    print("ğŸš€ è®­ç»ƒå¢å¼ºç‰ˆå¤§ç‰›è‚¡æ¨¡å‹")
    print("=" * 80)
    
    # åŠ è½½åŸå§‹æ¨¡å‹è·å–æ ·æœ¬è‚¡ç¥¨
    with open('trained_model.json', 'r', encoding='utf-8') as f:
        old_model = json.load(f)
    
    sample_stocks = old_model['buy_features']['sample_stocks']
    analysis_results = old_model.get('analysis_results', {})
    
    print(f"ğŸ“Š æ ·æœ¬è‚¡ç¥¨: {len(sample_stocks)} åª")
    
    # å‡†å¤‡è®­ç»ƒæ•°æ®
    cache_dir = 'cache/weekly_kline'
    sample_data = []
    
    for code in sample_stocks:
        if code not in analysis_results:
            continue
        
        interval = analysis_results[code].get('interval', {})
        start_date = interval.get('èµ·ç‚¹æ—¥æœŸ', '')
        
        # åŠ è½½å‘¨Kçº¿
        csv_path = os.path.join(cache_dir, f'{code}.csv')
        json_path = os.path.join(cache_dir, f'{code}.json')
        
        weekly_df = None
        if os.path.exists(csv_path):
            weekly_df = pd.read_csv(csv_path)
        elif os.path.exists(json_path):
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            weekly_df = pd.DataFrame(data)
        
        if weekly_df is None or len(weekly_df) < 40:
            print(f"âš ï¸ {code} æ•°æ®ä¸è¶³")
            continue
        
        # æ‰¾åˆ°èµ·ç‚¹ç´¢å¼•
        start_ts = pd.to_datetime(start_date)
        weekly_df['__dt'] = pd.to_datetime(weekly_df['æ—¥æœŸ'], errors='coerce')
        weekly_df = weekly_df.dropna(subset=['__dt'])
        weekly_df = weekly_df.sort_values('__dt').reset_index(drop=True)
        
        start_idx = None
        for i, row in weekly_df.iterrows():
            if row['__dt'] <= start_ts:
                start_idx = i
        
        if start_idx is None or start_idx < 40:
            print(f"âš ï¸ {code} æ‰¾ä¸åˆ°èµ·ç‚¹æˆ–æ•°æ®ä¸è¶³")
            continue
        
        sample_data.append({
            'code': code,
            'weekly_df': weekly_df.drop(columns=['__dt']),
            'start_idx': start_idx
        })
    
    # è®­ç»ƒæ¨¡å‹
    model = EnhancedBullStockModel()
    result = model.train(sample_data)
    
    # ä¿å­˜æ¨¡å‹
    model.save_model('enhanced_model.json')
    
    # éªŒè¯åŒ¹é…åº¦
    print("\n" + "=" * 80)
    print("ğŸ“Š éªŒè¯è®­ç»ƒæ ·æœ¬åŒ¹é…åº¦")
    print("=" * 80)
    
    for sample in sample_data:
        df = sample['weekly_df']
        idx = sample['start_idx']
        code = sample['code']
        
        volume_col = 'å‘¨æˆäº¤é‡' if 'å‘¨æˆäº¤é‡' in df.columns else 'æˆäº¤é‡'
        features = model.feature_extractor.extract_enhanced_features(df, idx, volume_col)
        
        if features:
            score = model.calculate_match_score(features)
            status = 'âœ…' if score >= 0.95 else 'âš ï¸'
            print(f"{status} {code}: åŒ¹é…åº¦ {score:.3f}")
    
    return model


def backtest_enhanced_model():
    """ä½¿ç”¨å¢å¼ºç‰ˆæ¨¡å‹å›æµ‹"""
    print("\n" + "=" * 80)
    print("ğŸš€ å¢å¼ºç‰ˆæ¨¡å‹å›æµ‹ - 2025å¹´12æœˆ")
    print("=" * 80)
    
    # åŠ è½½æ¨¡å‹
    model = EnhancedBullStockModel()
    model.load_model('enhanced_model.json')
    
    # åŠ è½½è‚¡ç¥¨åˆ—è¡¨
    with open('cache/stock_list_all.json', 'r', encoding='utf-8') as f:
        stock_list = json.load(f)
    
    weeks = ['2025-12-05', '2025-12-12', '2025-12-19', '2025-12-26', '2025-12-31']
    cache_dir = 'cache/weekly_kline'
    
    all_results = []
    
    for week_date in weeks:
        print(f"\nğŸ“… æ‰«ææ—¥æœŸ: {week_date}")
        print("-" * 60)
        
        candidates = []
        scan_ts = pd.to_datetime(week_date)
        
        for stock_info in stock_list:
            code = stock_info.get('code', '')
            name = stock_info.get('name', '')
            
            # æ’é™¤STå’ŒåŒ—äº¤æ‰€
            if 'ST' in name.upper() or code.startswith('8') or code.startswith('9'):
                continue
            
            # åŠ è½½æ•°æ®
            csv_path = os.path.join(cache_dir, f'{code}.csv')
            json_path = os.path.join(cache_dir, f'{code}.json')
            
            weekly_df = None
            if os.path.exists(csv_path):
                weekly_df = pd.read_csv(csv_path)
            elif os.path.exists(json_path):
                with open(json_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                weekly_df = pd.DataFrame(data)
            
            if weekly_df is None or len(weekly_df) < 50:
                continue
            
            # æŒ‰æ—¥æœŸç­›é€‰
            weekly_df['__dt'] = pd.to_datetime(weekly_df['æ—¥æœŸ'], errors='coerce')
            weekly_df = weekly_df.dropna(subset=['__dt'])
            weekly_df = weekly_df[weekly_df['__dt'] <= scan_ts]
            weekly_df = weekly_df.sort_values('__dt').reset_index(drop=True)
            
            if len(weekly_df) < 50:
                continue
            
            idx = len(weekly_df) - 1
            volume_col = 'å‘¨æˆäº¤é‡' if 'å‘¨æˆäº¤é‡' in weekly_df.columns else 'æˆäº¤é‡'
            
            # æå–ç‰¹å¾å¹¶è®¡ç®—åŒ¹é…åº¦
            features = model.feature_extractor.extract_enhanced_features(
                weekly_df.drop(columns=['__dt']), idx, volume_col
            )
            
            if features:
                score = model.calculate_match_score(features)
                if score >= 0.95:
                    candidates.append({
                        'è‚¡ç¥¨ä»£ç ': code,
                        'è‚¡ç¥¨åç§°': name,
                        'åŒ¹é…åº¦': score,
                        'ä»·æ ¼': round(weekly_df['æ”¶ç›˜'].iloc[idx], 2),
                        'OBVè¶‹åŠ¿': features.get('OBVè¶‹åŠ¿', 0),
                        'MACDé‡‘å‰': features.get('MACDé‡‘å‰', 0),
                        'å‡çº¿å¤šå¤´': features.get('å‡çº¿å¤šå¤´', 0),
                        'é‡æ¯”5å‘¨': features.get('é‡æ¯”5å‘¨', 0),
                    })
        
        # æ’åºå¹¶å–å‰5
        candidates.sort(key=lambda x: x['åŒ¹é…åº¦'], reverse=True)
        top5 = candidates[:5]
        
        print(f"æ‰¾åˆ° {len(candidates)} åªå€™é€‰ï¼Œå‰5å:")
        for i, c in enumerate(top5, 1):
            print(f"  {i}. {c['è‚¡ç¥¨ä»£ç ']} {c['è‚¡ç¥¨åç§°']}: {c['åŒ¹é…åº¦']:.3f} | "
                  f"OBV={c['OBVè¶‹åŠ¿']:.1f} MACDé‡‘å‰={c['MACDé‡‘å‰']} å‡çº¿å¤šå¤´={c['å‡çº¿å¤šå¤´']}")
        
        for c in top5:
            c['æ‰«æå‘¨'] = week_date
            all_results.append(c)
    
    # ä¿å­˜ç»“æœ
    if all_results:
        df = pd.DataFrame(all_results)
        output_file = f'backtest_enhanced_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv'
        df.to_csv(output_file, index=False, encoding='utf-8-sig')
        print(f"\nâœ… ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    
    return all_results


if __name__ == '__main__':
    # è®­ç»ƒæ¨¡å‹
    model = train_enhanced_model()
    
    # å›æµ‹
    results = backtest_enhanced_model()
