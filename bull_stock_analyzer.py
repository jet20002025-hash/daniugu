#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤§ç‰›è‚¡åˆ†æå™¨
åŠŸèƒ½ï¼š
1. ä¸Šä¼ å¤§ç‰›è‚¡ä»£ç 
2. æ‰¾åˆ°æ¶¨å¹…æœ€å¤§çš„åŒºé—´
3. åˆ†æå¤§æ¶¨å‰çš„ç‰¹å¾ï¼ˆæˆäº¤é‡å’Œèµ°åŠ¿ï¼‰
4. æå–ä¹°ç‚¹ç‰¹å¾
"""
from data_fetcher import DataFetcher
from technical_analysis import TechnicalAnalysis
import os
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
from typing import Dict, List, Optional, Tuple


class BullStockAnalyzer:
    """å¤§ç‰›è‚¡åˆ†æå™¨"""
    
    @staticmethod
    def get_stock_board_info(stock_code: str) -> Tuple[str, float]:
        """
        åˆ¤æ–­è‚¡ç¥¨æ‰€å±æ¿å—å’Œæ¶¨åœé™åˆ¶
        :param stock_code: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ '000001', '300001', '688001'ï¼‰
        :return: (æ¿å—åç§°, æ¶¨åœé™åˆ¶ç™¾åˆ†æ¯”)
        """
        code = str(stock_code).strip()
        
        if code.startswith('300'):
            return ('åˆ›ä¸šæ¿', 20.0)
        elif code.startswith('688'):
            return ('ç§‘åˆ›æ¿', 20.0)
        elif code.startswith('000') or code.startswith('001') or code.startswith('002'):
            return ('ä¸»æ¿/ä¸­å°æ¿', 10.0)
        elif code.startswith('003'):
            return ('ä¸­å°æ¿', 10.0)
        else:
            # é»˜è®¤æŒ‰ä¸»æ¿å¤„ç†
            return ('ä¸»æ¿', 10.0)
    
    def __init__(self, auto_load_default_stocks: bool = True, auto_analyze_and_train: bool = True):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        :param auto_load_default_stocks: æ˜¯å¦è‡ªåŠ¨åŠ è½½é»˜è®¤å¤§ç‰›è‚¡åˆ—è¡¨
        :param auto_analyze_and_train: æ˜¯å¦è‡ªåŠ¨åˆ†æå’Œè®­ç»ƒï¼ˆå¦‚æœåŒ¹é…åº¦æœªè¾¾æ ‡ï¼‰
        """
        self.fetcher = DataFetcher()
        self.tech_analysis = TechnicalAnalysis()
        self.bull_stocks = []  # å­˜å‚¨å¤§ç‰›è‚¡ä¿¡æ¯
        self.analysis_results = {}  # å­˜å‚¨åˆ†æç»“æœ
        self.trained_features = None  # å­˜å‚¨è®­ç»ƒå¥½çš„ç‰¹å¾æ¨¡æ¿
        self.progress = {}  # å­˜å‚¨è¿›åº¦ä¿¡æ¯ {'type': 'analyze'|'train'|'scan', 'current': int, 'total': int, 'status': str, 'detail': str, 'found': int}
        self.scan_results = None  # å­˜å‚¨æ‰«æç»“æœ
        self.reversal_scan_results = None  # å­˜å‚¨åè½¬ä¸ªè‚¡æ‰«æç»“æœ
        self.match_score_ready = False  # æ ‡è®°åŒ¹é…åº¦æ˜¯å¦å·²è¾¾æ ‡ï¼ˆ>=0.8ï¼‰
        self.stop_scan = False  # åœæ­¢æ‰«ææ ‡å¿—
        self.scan_state = None  # å­˜å‚¨æ‰«æçŠ¶æ€ï¼Œç”¨äºæ–­ç‚¹ç»­æ‰« {'stock_list': DataFrame, 'start_idx': int, 'candidates': list, 'min_match_score': float, 'max_market_cap': float, 'batch_num': int, 'total_batches': int}
        self.trained_sell_features = None  # å­˜å‚¨è®­ç»ƒå¥½çš„å–ç‚¹ç‰¹å¾æ¨¡æ¿
        self.trained_screener_model = None  # å­˜å‚¨è®­ç»ƒå¥½çš„â€œ8æ¡ä»¶â€é€‰è‚¡å¤§æ¨¡å‹ï¼ˆè§„åˆ™/ç»Ÿè®¡æ¨¡æ¿ï¼‰
        
        # é»˜è®¤å¤§ç‰›è‚¡åˆ—è¡¨ï¼ˆç”¨æˆ·æä¾›ï¼‰
        # å·²å»æ‰ï¼š001331ï¼ˆèƒœé€šèƒ½æºï¼‰ï¼Œ002969ï¼ˆå˜‰ç¾åŒ…è£…ï¼‰
        # æ–°å¢ï¼š603778ï¼Œ603122ï¼Œ600343ï¼Œ603216
        self.default_bull_stocks = ['000592', '002104', '002759', '300436', '301005', '301232', '002788', '603778', '603122', '600343', '603216']
        
        # è‡ªåŠ¨åŠ è½½é»˜è®¤å¤§ç‰›è‚¡
        if auto_load_default_stocks:
            self._load_default_stocks()
            
            # å¦‚æœå¯ç”¨è‡ªåŠ¨åˆ†æå’Œè®­ç»ƒï¼Œæ£€æŸ¥åŒ¹é…åº¦
            if auto_analyze_and_train:
                self._auto_setup_if_needed()
    
    def _load_default_stocks(self):
        """åŠ è½½é»˜è®¤å¤§ç‰›è‚¡åˆ—è¡¨"""
        try:
            print(f"\næ­£åœ¨åŠ è½½é»˜è®¤å¤§ç‰›è‚¡åˆ—è¡¨: {', '.join(self.default_bull_stocks)}")
            for stock_code in self.default_bull_stocks:
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼Œé¿å…é‡å¤æ·»åŠ 
                existing = [s for s in self.bull_stocks if s['ä»£ç '] == stock_code]
                if not existing:
                    result = self.add_bull_stock(stock_code)
                    if result.get('success'):
                        print(f"âœ… å·²åŠ è½½: {stock_code} {result.get('stock', {}).get('åç§°', '')}")
                    else:
                        print(f"âš ï¸ åŠ è½½å¤±è´¥: {stock_code} - {result.get('message', '')}")
            print(f"é»˜è®¤å¤§ç‰›è‚¡åŠ è½½å®Œæˆï¼Œå…± {len(self.bull_stocks)} åªè‚¡ç¥¨\n")
        except Exception as e:
            print(f"âš ï¸ åŠ è½½é»˜è®¤å¤§ç‰›è‚¡æ—¶å‡ºé”™: {str(e)}")
            # å³ä½¿å‡ºé”™ä¹Ÿç»§ç»­è¿è¡Œ
    
    def _get_common_features(self) -> Dict:
        """
        è·å– common_featuresï¼Œå…¼å®¹ä¸åŒçš„æ¨¡å‹ç»“æ„
        æ”¯æŒä¸¤ç§æ ¼å¼ï¼š
        1. trained_features['common_features'] - æ—§æ ¼å¼
        2. trained_features['buy_features']['common_features'] - æ–°æ ¼å¼
        """
        if not self.trained_features:
            return {}
        
        # å°è¯•æ–°æ ¼å¼ï¼šbuy_features.common_features
        buy_features = self.trained_features.get('buy_features', {})
        if isinstance(buy_features, dict):
            common_features = buy_features.get('common_features', {})
            if common_features and len(common_features) > 0:
                return common_features
        
        # å°è¯•æ—§æ ¼å¼ï¼šç›´æ¥ common_features
        return self.trained_features.get('common_features', {})
    
    def _check_match_score(self) -> Tuple[bool, float]:
        """
        æ£€æŸ¥å½“å‰åŒ¹é…åº¦æ˜¯å¦å·²è¾¾åˆ°0.8ä»¥ä¸Š
        :return: (æ˜¯å¦è¾¾æ ‡, æœ€é«˜åŒ¹é…åº¦)
        """
        common_features = self._get_common_features()
        if not common_features:
            return False, 0.0
        
        if len(self.analysis_results) == 0:
            return False, 0.0
        max_score = 0.0
        
        # æ£€æŸ¥æ¯åªè‚¡ç¥¨çš„åŒ¹é…åº¦
        for stock_code in self.default_bull_stocks:
            if stock_code not in self.analysis_results:
                continue
            
            analysis_result = self.analysis_results[stock_code]
            interval = analysis_result.get('interval')
            if not interval:
                continue
            
            start_idx = interval.get('èµ·ç‚¹ç´¢å¼•')
            if start_idx is None:
                continue
            
            try:
                # è·å–å‘¨çº¿æ•°æ®
                weekly_df = self.fetcher.get_weekly_kline(stock_code, period="2y")
                if weekly_df is None or len(weekly_df) == 0:
                    continue
                
                # åœ¨æ¶¨å¹…åŒºé—´èµ·ç‚¹ä¹‹å‰ï¼Œæ‰¾åˆ°æˆäº¤é‡çªå¢ç‚¹
                volume_surge_idx = self.find_volume_surge_point(stock_code, int(start_idx), weekly_df=weekly_df, min_volume_ratio=3.0, lookback_weeks=52)
                
                if volume_surge_idx is None:
                    volume_surge_idx = max(0, int(start_idx) - 20)
                
                # åŸºäºæˆäº¤é‡çªå¢ç‚¹æå–ç‰¹å¾
                features = self.extract_features_at_start_point(stock_code, volume_surge_idx, lookback_weeks=40, weekly_df=weekly_df)
                if not features:
                    continue
                
                # è®¡ç®—åŒ¹é…åº¦
                match_score = self._calculate_match_score(features, common_features, tolerance=0.3)
                total_score = match_score.get('æ€»åŒ¹é…åº¦', 0)
                max_score = max(max_score, total_score)
            except Exception:
                continue
        
        return max_score >= 0.95, max_score
    
    def _auto_setup_if_needed(self):
        """
        è‡ªåŠ¨è®¾ç½®ï¼šå¦‚æœåŒ¹é…åº¦æœªè¾¾æ ‡ï¼Œè‡ªåŠ¨åˆ†æå’Œè®­ç»ƒ
        """
        try:
            # å…ˆæ£€æŸ¥æ˜¯å¦å·²æœ‰åˆ†æç»“æœå’Œè®­ç»ƒç‰¹å¾
            has_analysis = len(self.analysis_results) > 0
            has_trained = self.trained_features is not None and len(self._get_common_features()) > 0
            
            if has_analysis and has_trained:
                # æ£€æŸ¥åŒ¹é…åº¦
                is_ready, max_score = self._check_match_score()
                if is_ready:
                    print(f"\nâœ… åŒ¹é…åº¦å·²è¾¾æ ‡ï¼ˆæœ€é«˜: {max_score:.3f} >= 0.95ï¼‰ï¼Œè·³è¿‡åˆ†æå’Œè®­ç»ƒæ­¥éª¤")
                    self.match_score_ready = True
                    
                    # å³ä½¿ä¹°ç‚¹åŒ¹é…åº¦å·²è¾¾æ ‡ï¼Œä¹Ÿæ£€æŸ¥æ˜¯å¦éœ€è¦è®­ç»ƒå–ç‚¹ç‰¹å¾
                    if not hasattr(self, 'trained_sell_features') or self.trained_sell_features is None:
                        print(f"\nğŸ“Š å¼€å§‹è®­ç»ƒå–ç‚¹ç‰¹å¾æ¨¡å‹...")
                        sell_train_result = self.train_sell_point_features()
                        if sell_train_result.get('success'):
                            print(f"âœ… å–ç‚¹ç‰¹å¾è®­ç»ƒå®Œæˆ")
                        else:
                            print(f"âš ï¸ å–ç‚¹ç‰¹å¾è®­ç»ƒå¤±è´¥: {sell_train_result.get('message', '')}")
                    return
            
            # å¦‚æœåŒ¹é…åº¦æœªè¾¾æ ‡ï¼Œè‡ªåŠ¨åˆ†æå’Œè®­ç»ƒ
            print("\nğŸ“Š è‡ªåŠ¨åˆ†æå’Œè®­ç»ƒï¼ˆåŒ¹é…åº¦æœªè¾¾æ ‡ï¼‰...")
            
            # 1. åˆ†ææ‰€æœ‰è‚¡ç¥¨
            print("  æ­¥éª¤1: åˆ†ææ‰€æœ‰å¤§ç‰›è‚¡...")
            for stock_code in self.default_bull_stocks:
                if stock_code not in self.analysis_results:
                    result = self.analyze_bull_stock(stock_code)
                    if not result.get('success'):
                        print(f"    âš ï¸ {stock_code} åˆ†æå¤±è´¥: {result.get('message', '')}")
            
            # 2. è®­ç»ƒä¹°ç‚¹ç‰¹å¾æ¨¡å‹
            print("  æ­¥éª¤2: è®­ç»ƒä¹°ç‚¹ç‰¹å¾æ¨¡å‹...")
            train_result = self.train_features()
            if not train_result.get('success'):
                print(f"    âŒ è®­ç»ƒå¤±è´¥: {train_result.get('message', '')}")
                return
            
            # 3. è®­ç»ƒå–ç‚¹ç‰¹å¾æ¨¡å‹
            print("  æ­¥éª¤3: è®­ç»ƒå–ç‚¹ç‰¹å¾æ¨¡å‹...")
            sell_train_result = self.train_sell_point_features()
            if sell_train_result.get('success'):
                print(f"    âœ… å–ç‚¹ç‰¹å¾è®­ç»ƒå®Œæˆ")
            else:
                print(f"    âš ï¸ å–ç‚¹ç‰¹å¾è®­ç»ƒå¤±è´¥: {sell_train_result.get('message', '')}")
            
            # 4. å†æ¬¡æ£€æŸ¥åŒ¹é…åº¦
            is_ready, max_score = self._check_match_score()
            if is_ready:
                print(f"  âœ… åŒ¹é…åº¦å·²è¾¾æ ‡ï¼ˆæœ€é«˜: {max_score:.3f} >= 0.95ï¼‰ï¼Œå¯ä»¥å¼€å§‹æµ‹è¯•")
                self.match_score_ready = True
            else:
                print(f"  âš ï¸ åŒ¹é…åº¦æœªè¾¾æ ‡ï¼ˆæœ€é«˜: {max_score:.3f} < 0.95ï¼‰ï¼Œå»ºè®®ç»§ç»­ä¼˜åŒ–")
                self.match_score_ready = False
                
        except Exception as e:
            print(f"âš ï¸ è‡ªåŠ¨è®¾ç½®æ—¶å‡ºé”™: {str(e)}")
            import traceback
            traceback.print_exc()
    
    def _get_stock_name(self, stock_code: str) -> Optional[str]:
        """
        æ ¹æ®è‚¡ç¥¨ä»£ç è·å–è‚¡ç¥¨åç§°
        :param stock_code: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ '000001'ï¼‰
        :return: è‚¡ç¥¨åç§°ï¼Œå¦‚æœè·å–å¤±è´¥è¿”å›None
        """
        try:
            # è·å–æ‰€æœ‰è‚¡ç¥¨åˆ—è¡¨
            stock_list = self.fetcher.get_all_stocks()
            if stock_list is None or stock_list.empty:
                return None
            
            # æŸ¥æ‰¾å¯¹åº”è‚¡ç¥¨ï¼ˆä»£ç åˆ—å¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–æ•°å­—ï¼‰
            stock_code_str = str(stock_code)
            
            # akshareè¿”å›çš„åˆ—åå¯èƒ½æ˜¯ 'code' å’Œ 'name'ï¼Œä¹Ÿå¯èƒ½æ˜¯å…¶ä»–åç§°
            # å°è¯•å¤šç§å¯èƒ½çš„åˆ—å
            code_col = None
            name_col = None
            
            for col in stock_list.columns:
                col_lower = str(col).lower()
                if 'code' in col_lower or 'ä»£ç ' in col:
                    code_col = col
                elif 'name' in col_lower or 'åç§°' in col or 'name' in col:
                    name_col = col
            
            # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œä½¿ç”¨ç¬¬ä¸€åˆ—ä½œä¸ºä»£ç ï¼Œç¬¬äºŒåˆ—ä½œä¸ºåç§°
            if code_col is None:
                code_col = stock_list.columns[0]
            if name_col is None and len(stock_list.columns) >= 2:
                name_col = stock_list.columns[1]
            
            # æŸ¥æ‰¾è‚¡ç¥¨
            stock_row = stock_list[stock_list[code_col].astype(str) == stock_code_str]
            
            if not stock_row.empty and name_col:
                return str(stock_row.iloc[0][name_col])
            
            return None
        except Exception as e:
            # é™é»˜å¤±è´¥
            return None
    
    def _validate_stock_code(self, stock_code: str) -> bool:
        """
        éªŒè¯è‚¡ç¥¨ä»£ç æ ¼å¼
        :param stock_code: è‚¡ç¥¨ä»£ç 
        :return: æ˜¯å¦æœ‰æ•ˆ
        """
        if not stock_code or not isinstance(stock_code, str):
            return False
        
        # ç§»é™¤å¯èƒ½çš„ç©ºæ ¼
        stock_code = stock_code.strip()
        
        # Aè‚¡ä»£ç æ ¼å¼ï¼š6ä½æ•°å­—
        if len(stock_code) == 6 and stock_code.isdigit():
            return True
        
        return False
    
    def add_bull_stock(self, stock_code: str, stock_name: str = None) -> Dict:
        """
        æ·»åŠ å¤§ç‰›è‚¡ï¼ˆå¢å¼ºç‰ˆï¼‰
        :param stock_code: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ '000001'ï¼‰
        :param stock_name: è‚¡ç¥¨åç§°ï¼ˆå¯é€‰ï¼Œå¦‚æœä¸æä¾›ä¼šè‡ªåŠ¨è·å–ï¼‰
        :return: æ·»åŠ ç»“æœå­—å…¸ {'success': bool, 'message': str, 'stock': dict or None}
        """
        try:
            # ç¡®ä¿stock_codeä¸ä¸ºNone
            if stock_code is None:
                return {
                    'success': False,
                    'message': 'âŒ è‚¡ç¥¨ä»£ç ä¸èƒ½ä¸ºç©º',
                    'stock': None
                }
            
            # æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç ï¼ˆå»é™¤ç©ºæ ¼ï¼Œç¡®ä¿æ˜¯6ä½ï¼‰
            stock_code = str(stock_code).strip()
            
            # éªŒè¯è‚¡ç¥¨ä»£ç æ ¼å¼
            if not self._validate_stock_code(stock_code):
                return {
                    'success': False,
                    'message': f'âŒ è‚¡ç¥¨ä»£ç æ ¼å¼æ— æ•ˆ: {stock_code}ï¼ˆåº”ä¸º6ä½æ•°å­—ï¼‰',
                    'stock': None
                }
            
            # æ£€æŸ¥æ˜¯å¦å·²æ·»åŠ ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼Œç¡®ä¿å”¯ä¸€æ€§ï¼‰
            for stock in self.bull_stocks:
                if str(stock['ä»£ç ']).strip() == stock_code:
                    existing_name = stock.get('åç§°', stock_code)
                    return {
                        'success': False,
                        'message': f'âš ï¸ è‚¡ç¥¨ {stock_code} ({existing_name}) å·²å­˜åœ¨ï¼Œä¸èƒ½é‡å¤æ·»åŠ ',
                        'stock': stock
                    }
            
            # å¦‚æœæœªæä¾›åç§°ï¼Œå°è¯•è‡ªåŠ¨è·å–
            if stock_name is None:
                stock_name = self._get_stock_name(stock_code)
                if stock_name is None:
                    stock_name = stock_code  # å¦‚æœè·å–å¤±è´¥ï¼Œä½¿ç”¨ä»£ç ä½œä¸ºåç§°
                    print(f"âš ï¸ æ— æ³•è‡ªåŠ¨è·å– {stock_code} çš„è‚¡ç¥¨åç§°ï¼Œä½¿ç”¨ä»£ç ä½œä¸ºåç§°")
            
            # éªŒè¯è‚¡ç¥¨æ˜¯å¦å­˜åœ¨ï¼ˆä¼˜å…ˆç”¨å‘¨Kçº¿ï¼Œå‡å°‘å¯¹æ—¥çº¿æ¥å£çš„ä¾èµ–ï¼‰
            kline_df = self.fetcher.get_weekly_kline(stock_code, period="2y")
            if kline_df is None or kline_df.empty:
                kline_df = self.fetcher.get_daily_kline(stock_code, period="1y")
            if kline_df is None or kline_df.empty:
                return {
                    'success': False,
                    'message': f'âŒ æ— æ³•è·å–è‚¡ç¥¨ {stock_code} çš„æ•°æ®ï¼Œè¯·æ£€æŸ¥ä»£ç æ˜¯å¦æ­£ç¡®',
                    'stock': None
                }
            
            # æ·»åŠ åˆ°åˆ—è¡¨
            stock_info = {
                'ä»£ç ': stock_code,
                'åç§°': stock_name,
                'æ·»åŠ æ—¶é—´': datetime.now(),
                'æ•°æ®æ¡æ•°': len(kline_df) if kline_df is not None else 0
            }
            
            self.bull_stocks.append(stock_info)
            
            return {
                'success': True,
                'message': f'âœ… æˆåŠŸæ·»åŠ å¤§ç‰›è‚¡: {stock_code} {stock_name}',
                'stock': stock_info
            }
            
        except Exception as e:
            return {
                'success': False,
                'message': f'âŒ æ·»åŠ è‚¡ç¥¨å¤±è´¥: {e}',
                'stock': None
            }
    
    def add_bull_stocks_batch(self, stock_codes: List[str]) -> Dict:
        """
        æ‰¹é‡æ·»åŠ å¤§ç‰›è‚¡
        :param stock_codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼ˆå¦‚ ['000001', '000002']ï¼‰
        :return: æ‰¹é‡æ·»åŠ ç»“æœ {'total': int, 'success': int, 'failed': int, 'results': list}
        """
        results = []
        success_count = 0
        failed_count = 0
        
        print(f"\nå¼€å§‹æ‰¹é‡æ·»åŠ  {len(stock_codes)} åªè‚¡ç¥¨...")
        
        for i, stock_code in enumerate(stock_codes, 1):
            print(f"\n[{i}/{len(stock_codes)}] å¤„ç† {stock_code}...")
            result = self.add_bull_stock(stock_code)
            results.append({
                'ä»£ç ': stock_code,
                'ç»“æœ': result
            })
            
            if result['success']:
                success_count += 1
            else:
                failed_count += 1
            
            print(result['message'])
        
        return {
            'total': len(stock_codes),
            'success': success_count,
            'failed': failed_count,
            'results': results
        }
    
    def get_bull_stocks(self) -> List[Dict]:
        """
        è·å–æ‰€æœ‰å·²æ·»åŠ çš„å¤§ç‰›è‚¡
        :return: å¤§ç‰›è‚¡åˆ—è¡¨
        """
        return self.bull_stocks
    
    def get_bull_stock_count(self) -> int:
        """
        è·å–å·²æ·»åŠ çš„å¤§ç‰›è‚¡æ•°é‡
        :return: æ•°é‡
        """
        return len(self.bull_stocks)
    
    def remove_bull_stock(self, stock_code: str) -> bool:
        """
        ç§»é™¤æŒ‡å®šçš„å¤§ç‰›è‚¡
        :param stock_code: è‚¡ç¥¨ä»£ç 
        :return: æ˜¯å¦ç§»é™¤æˆåŠŸ
        """
        for i, stock in enumerate(self.bull_stocks):
            if stock['ä»£ç '] == stock_code:
                removed_stock = self.bull_stocks.pop(i)
                print(f"âœ… å·²ç§»é™¤å¤§ç‰›è‚¡: {removed_stock['ä»£ç ']} {removed_stock['åç§°']}")
                # åŒæ—¶æ¸…é™¤ç›¸å…³çš„åˆ†æç»“æœ
                if stock_code in self.analysis_results:
                    del self.analysis_results[stock_code]
                return True
        
        print(f"âš ï¸ æœªæ‰¾åˆ°è‚¡ç¥¨ {stock_code}")
        return False
    
    def clear_bull_stocks(self):
        """æ¸…ç©ºæ‰€æœ‰å¤§ç‰›è‚¡"""
        self.bull_stocks = []
        self.analysis_results = {}
        print("âœ… å·²æ¸…ç©ºæ‰€æœ‰å¤§ç‰›è‚¡")
    
    def find_max_gain_interval(self, stock_code: str, search_weeks: int = 10, min_gain: float = 100.0) -> Optional[Dict]:
        """
        æ‰¾åˆ°è‚¡ç¥¨æ¶¨å¹…æœ€å¤§çš„åŒºé—´ï¼ˆåŸºäºå‘¨çº¿ï¼‰
        :param stock_code: è‚¡ç¥¨ä»£ç 
        :param search_weeks: æŸ¥æ‰¾çª—å£å‘¨æ•°ï¼ˆé»˜è®¤10å‘¨ï¼Œåœ¨èµ·ç‚¹å10å‘¨å†…æŸ¥æ‰¾æœ€é«˜ç‚¹ï¼‰
        :param min_gain: æœ€å°æ¶¨å¹…è¦æ±‚ï¼ˆé»˜è®¤100%ï¼Œå³ç¿»å€ï¼‰
        :return: æ¶¨å¹…æœ€å¤§åŒºé—´çš„ä¿¡æ¯ï¼Œå¦‚æœæœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„åŒºé—´è¿”å›None
        """
        try:
            # è·å–è‚¡ç¥¨æ¿å—ä¿¡æ¯
            board_name, limit_up_pct = self.get_stock_board_info(stock_code)
            print(f"\næ­£åœ¨åˆ†æ {stock_code} çš„æ¶¨å¹…æœ€å¤§åŒºé—´ï¼ˆåŸºäºå‘¨çº¿ï¼‰...")
            print(f"è‚¡ç¥¨æ¿å—: {board_name}ï¼Œæ¶¨åœé™åˆ¶: {limit_up_pct}%")
            print(f"åœ¨èµ·ç‚¹å {search_weeks} å‘¨å†…æŸ¥æ‰¾æœ€é«˜ç‚¹ï¼Œè¦æ±‚æ¶¨å¹…è¶…è¿‡ {min_gain}%...")
            
            # è·å–å‘¨Kçº¿æ•°æ®ï¼ˆè‡³å°‘éœ€è¦2å¹´æ•°æ®ï¼‰
            print(f"[è°ƒè¯•] {stock_code} å¼€å§‹è·å–å‘¨Kçº¿æ•°æ®...")
            weekly_df = self.fetcher.get_weekly_kline(stock_code, period="2y")
            print(f"[è°ƒè¯•] {stock_code} å‘¨Kçº¿æ•°æ®è·å–å®Œæˆ: {len(weekly_df) if weekly_df is not None else 0} å‘¨")
            
            if weekly_df is None or len(weekly_df) == 0:
                return {
                    'success': False,
                    'message': f'æ— æ³•è·å– {stock_code} çš„å‘¨çº¿æ•°æ®',
                    'interval': None
                }
            
            if len(weekly_df) < search_weeks:
                return {
                    'success': False,
                    'message': f'æ•°æ®ä¸è¶³ï¼Œéœ€è¦è‡³å°‘ {search_weeks} å‘¨æ•°æ®ï¼Œå®é™…åªæœ‰ {len(weekly_df)} å‘¨',
                    'interval': None
                }
            
            # æ‰¾åˆ°æ¶¨å¹…æœ€å¤§çš„åŒºé—´ï¼ˆåœ¨æŒ‡å®šå‘¨æ•°å†…ï¼‰
            max_gain = 0
            max_gain_start_idx = None
            max_gain_end_idx = None
            max_gain_start_price = None
            max_gain_end_price = None
            max_gain_start_date = None
            max_gain_end_date = None
            
            # éå†æ‰€æœ‰å¯èƒ½çš„èµ·ç‚¹ï¼ˆä»ç¬¬1å‘¨åˆ°å€’æ•°ç¬¬search_weekså‘¨ï¼‰
            total_possible_starts = len(weekly_df) - search_weeks + 1
            print(f"[è°ƒè¯•] {stock_code} éœ€è¦éå† {total_possible_starts} ä¸ªå¯èƒ½çš„èµ·ç‚¹...")
            
            for idx, start_idx in enumerate(range(len(weekly_df) - search_weeks + 1)):
                # æ¯å¤„ç†100ä¸ªèµ·ç‚¹æ‰“å°ä¸€æ¬¡è¿›åº¦
                if idx > 0 and idx % 100 == 0:
                    print(f"[è°ƒè¯•] {stock_code} å·²å¤„ç† {idx}/{total_possible_starts} ä¸ªèµ·ç‚¹...")
                
                start_price = float(weekly_df.iloc[start_idx]['æ”¶ç›˜'])
                start_date = weekly_df.iloc[start_idx]['æ—¥æœŸ']
                
                # åœ¨èµ·ç‚¹åçš„search_weekså‘¨å†…ï¼Œæ‰¾åˆ°æœ€é«˜ä»·æ ¼
                end_idx = min(start_idx + search_weeks, len(weekly_df))
                window_df = weekly_df.iloc[start_idx:end_idx]
                
                # æ‰¾åˆ°çª—å£å†…çš„æœ€é«˜ä»·æ ¼å’Œå¯¹åº”æ—¥æœŸ
                # ä½¿ç”¨æœ€é«˜ä»·è€Œä¸æ˜¯æ”¶ç›˜ä»·ï¼Œå› ä¸ºå¯èƒ½ç›˜ä¸­æ¶¨åœ
                max_price_idx = window_df['æœ€é«˜'].idxmax()
                max_price = float(window_df.loc[max_price_idx, 'æœ€é«˜'])
                max_price_date = window_df.loc[max_price_idx, 'æ—¥æœŸ']
                
                # è®¡ç®—æ¶¨å¹…ï¼ˆä½¿ç”¨æœ€é«˜ä»·ï¼‰
                gain = (max_price - start_price) / start_price * 100
                
                if gain > max_gain:
                    max_gain = gain
                    max_gain_start_idx = start_idx
                    max_gain_end_idx = weekly_df.index.get_loc(max_price_idx)
                    max_gain_start_price = start_price
                    max_gain_end_price = max_price
                    max_gain_start_date = start_date
                    max_gain_end_date = max_price_date
            
            print(f"[è°ƒè¯•] {stock_code} éå†å®Œæˆï¼Œæœ€å¤§æ¶¨å¹…: {max_gain:.2f}%")
            
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å°æ¶¨å¹…è¦æ±‚
            if max_gain_start_idx is None or max_gain_end_idx is None or max_gain < min_gain:
                return {
                    'success': False,
                    'message': f'æœªæ‰¾åˆ°æ¶¨å¹…è¶…è¿‡ {min_gain}% çš„åŒºé—´ï¼ˆæœ€å¤§æ¶¨å¹…: {max_gain:.2f}%ï¼‰',
                    'interval': None,
                    'max_gain': max_gain
                }
            
            # è®¡ç®—å®é™…å‘¨æ•°ï¼ˆä»èµ·ç‚¹åˆ°ç»ˆç‚¹çš„å‘¨æ•°ï¼‰
            trading_weeks = int(max_gain_end_idx - max_gain_start_idx + 1)
            
            # æ ¼å¼åŒ–æ—¥æœŸ
            if isinstance(max_gain_start_date, pd.Timestamp):
                start_date_str = max_gain_start_date.strftime('%Y-%m-%d')
            else:
                start_date_str = str(max_gain_start_date)
            
            if isinstance(max_gain_end_date, pd.Timestamp):
                end_date_str = max_gain_end_date.strftime('%Y-%m-%d')
            else:
                end_date_str = str(max_gain_end_date)
            
            result = {
                'success': True,
                'message': f'âœ… æ‰¾åˆ°æ¶¨å¹…æœ€å¤§åŒºé—´: {max_gain:.2f}%',
                'interval': {
                    'è‚¡ç¥¨ä»£ç ': stock_code,
                    'èµ·ç‚¹æ—¥æœŸ': start_date_str,
                    'èµ·ç‚¹ä»·æ ¼': round(max_gain_start_price, 2),
                    'èµ·ç‚¹ç´¢å¼•': int(max_gain_start_idx) if max_gain_start_idx is not None else None,
                    'ç»ˆç‚¹æ—¥æœŸ': end_date_str,
                    'ç»ˆç‚¹ä»·æ ¼': round(max_gain_end_price, 2),
                    'ç»ˆç‚¹ç´¢å¼•': int(max_gain_end_idx) if max_gain_end_idx is not None else None,
                    'æ¶¨å¹…': round(max_gain, 2),
                    'ç¿»å€å€æ•°': round(max_gain / 100, 2),
                    'å®é™…å‘¨æ•°': trading_weeks,  # ä»èµ·ç‚¹åˆ°ç»ˆç‚¹çš„å®é™…å‘¨æ•°
                    'æŸ¥æ‰¾çª—å£å‘¨æ•°': search_weeks,  # æŸ¥æ‰¾çª—å£å¤§å°ï¼ˆ10å‘¨ï¼‰
                    'æ¿å—': board_name,
                    'æ¶¨åœé™åˆ¶': limit_up_pct
                }
            }
            
            print(f"âœ… æ‰¾åˆ°æ¶¨å¹…æœ€å¤§åŒºé—´:")
            print(f"   èµ·ç‚¹æ—¥æœŸ: {start_date_str}")
            print(f"   èµ·ç‚¹ä»·æ ¼: {max_gain_start_price:.2f} å…ƒ")
            print(f"   ç»ˆç‚¹æ—¥æœŸ: {end_date_str}")
            print(f"   ç»ˆç‚¹ä»·æ ¼: {max_gain_end_price:.2f} å…ƒ")
            print(f"   æ¶¨å¹…: {max_gain:.2f}% (ç¿»{max_gain/100:.2f}å€)")
            print(f"   å®é™…å‘¨æ•°: {trading_weeks} å‘¨")
            
            return result
            
        except Exception as e:
            import traceback
            error_detail = traceback.format_exc()
            print(f"æŸ¥æ‰¾æ¶¨å¹…åŒºé—´å¤±è´¥: {error_detail}")
            return {
                'success': False,
                'message': f'æŸ¥æ‰¾æ¶¨å¹…åŒºé—´å¤±è´¥: {str(e)}',
                'interval': None
            }
    
    def analyze_bull_stock(self, stock_code: str) -> Dict:
        """
        åˆ†æå•åªå¤§ç‰›è‚¡ï¼šæ‰¾åˆ°æ¶¨å¹…æœ€å¤§åŒºé—´å’Œèµ·ç‚¹
        :param stock_code: è‚¡ç¥¨ä»£ç 
        :return: åˆ†æç»“æœ
        """
        # æ£€æŸ¥è‚¡ç¥¨æ˜¯å¦å­˜åœ¨
        stock_info = None
        for stock in self.bull_stocks:
            if stock['ä»£ç '] == stock_code:
                stock_info = stock
                break
        
        if stock_info is None:
            return {
                'success': False,
                'message': f'è‚¡ç¥¨ {stock_code} æœªæ·»åŠ ',
                'interval': None
            }
        
        # æŸ¥æ‰¾æ¶¨å¹…æœ€å¤§åŒºé—´ï¼ˆåœ¨èµ·ç‚¹å10å‘¨å†…æŸ¥æ‰¾æœ€é«˜ç‚¹ï¼‰
        result = self.find_max_gain_interval(stock_code, search_weeks=10, min_gain=100.0)
        
        # ä¿å­˜åˆ†æç»“æœ
        if result['success']:
            self.analysis_results[stock_code] = {
                'stock_info': stock_info,
                'interval': result['interval'],
                'analyzed_at': datetime.now()
            }
        
        return result
    
    def analyze_all_bull_stocks(self) -> Dict:
        """
        åˆ†ææ‰€æœ‰å·²æ·»åŠ çš„å¤§ç‰›è‚¡
        :return: åˆ†æç»“æœæ±‡æ€»
        """
        if len(self.bull_stocks) == 0:
            return {
                'success': False,
                'message': 'æ²¡æœ‰å·²æ·»åŠ çš„å¤§ç‰›è‚¡',
                'results': []
            }
        
        # åˆå§‹åŒ–è¿›åº¦
        total_stocks = len(self.bull_stocks)
        self.progress = {
            'type': 'analyze',
            'current': 0,
            'total': total_stocks,
            'status': 'è¿›è¡Œä¸­',
            'detail': 'å¼€å§‹åˆ†ææ‰€æœ‰è‚¡ç¥¨...',
            'percentage': 0
        }
        
        print(f"\nå¼€å§‹åˆ†æ {total_stocks} åªå¤§ç‰›è‚¡...")
        print("=" * 80)
        
        results = []
        success_count = 0
        failed_count = 0
        
        for i, stock in enumerate(self.bull_stocks, 1):
            stock_code = stock['ä»£ç ']
            stock_name = stock['åç§°']
            
            # æ›´æ–°è¿›åº¦
            percentage = (i / total_stocks) * 100
            self.progress['current'] = i
            self.progress['percentage'] = round(percentage, 1)
            self.progress['detail'] = f'æ­£åœ¨åˆ†æ {stock_code} {stock_name}... ({i}/{total_stocks})'
            
            print(f"\n[{i}/{total_stocks}] åˆ†æ {stock_code} {stock_name}...")
            print(f"[è¿›åº¦] {percentage:.1f}%")
            
            try:
                result = self.analyze_bull_stock(stock_code)
            except Exception as e:
                import traceback
                error_detail = traceback.format_exc()
                print(f"âŒ åˆ†æ {stock_code} æ—¶å‡ºé”™: {str(e)}")
                print(f"é”™è¯¯è¯¦æƒ…: {error_detail}")
                result = {
                    'success': False,
                    'message': f'åˆ†æå¤±è´¥: {str(e)}',
                    'interval': None
                }
            results.append({
                'è‚¡ç¥¨ä»£ç ': stock_code,
                'è‚¡ç¥¨åç§°': stock_name,
                'åˆ†æç»“æœ': result
            })
            
            if result['success']:
                success_count += 1
            else:
                failed_count += 1
        
        # å®Œæˆè¿›åº¦
        self.progress['status'] = 'å®Œæˆ'
        self.progress['detail'] = f'åˆ†æå®Œæˆ: æˆåŠŸ {success_count} åªï¼Œå¤±è´¥ {failed_count} åª'
        
        print("\n" + "=" * 80)
        print(f"åˆ†æå®Œæˆ: æˆåŠŸ {success_count} åªï¼Œå¤±è´¥ {failed_count} åª")
        print("=" * 80)
        
        return {
            'success': True,
            'message': f'åˆ†æå®Œæˆ: æˆåŠŸ {success_count} åªï¼Œå¤±è´¥ {failed_count} åª',
            'total': len(self.bull_stocks),
            'success_count': success_count,
            'failed_count': failed_count,
            'results': results
        }
    
    def stop_scanning(self):
        """
        åœæ­¢å½“å‰æ‰«æï¼ˆä¿å­˜çŠ¶æ€ä»¥ä¾¿ç»§ç»­ï¼‰
        """
        self.stop_scan = True
        print("\nğŸ›‘ æ”¶åˆ°åœæ­¢æ‰«æè¯·æ±‚ï¼Œå°†ä¿å­˜å½“å‰æ‰«æçŠ¶æ€ä»¥ä¾¿ç»§ç»­")
    
    def _resume_scan(self) -> Dict:
        """
        ç»§ç»­ä¸Šæ¬¡æœªå®Œæˆçš„æ‰«æï¼ˆæ–­ç‚¹ç»­æ‰«ï¼‰
        """
        if self.scan_state is None or self.scan_state.get('status') != 'å·²åœæ­¢':
            return {
                'success': False,
                'message': 'æ²¡æœ‰æœªå®Œæˆçš„æ‰«æ',
                'candidates': []
            }
        
        # æ¢å¤æ‰«æçŠ¶æ€
        stock_list = self.scan_state['stock_list']
        common_features = self.scan_state['common_features']
        min_match_score = self.scan_state['min_match_score']
        max_market_cap = self.scan_state['max_market_cap']
        start_idx = self.scan_state['current_idx']
        existing_candidates = self.scan_state['candidates']
        total_stocks = self.scan_state['total_stocks']
        
        print(f"\nğŸ”„ ç»§ç»­æ‰«æï¼Œä»ç¬¬ {start_idx + 1} åªè‚¡ç¥¨å¼€å§‹...")
        
        # ç»§ç»­æ‰«æå‰©ä½™è‚¡ç¥¨
        remaining_stocks = stock_list.iloc[start_idx:]
        if len(remaining_stocks) == 0:
            # å·²ç»æ‰«æå®Œæˆ
            self.scan_state = None
            return {
                'success': True,
                'message': 'æ‰«æå·²å®Œæˆ',
                'candidates': existing_candidates,
                'total_scanned': total_stocks,
                'found_count': len(existing_candidates)
            }
        
        # æ›´æ–°çŠ¶æ€ä¸ºè¿›è¡Œä¸­
        self.scan_state['status'] = 'è¿›è¡Œä¸­'
        
        # ç»§ç»­æ‰«æï¼ˆå•æ‰¹æˆ–åˆ†æ‰¹ï¼‰
        if total_stocks > 5000:
            # åˆ†æ‰¹æ‰«æçš„æƒ…å†µï¼Œéœ€è¦æ‰¾åˆ°å½“å‰æ‰¹æ¬¡
            batch_size = (total_stocks + 2) // 3
            current_batch = (start_idx // batch_size) + 1
            return self._scan_stock_batch(
                remaining_stocks,
                common_features,
                min_match_score,
                max_market_cap,
                current_batch,
                3,
                start_idx=start_idx,
                existing_candidates=existing_candidates
            )
        else:
            # å•æ‰¹æ‰«æ
            return self._scan_stock_batch(
                remaining_stocks,
                common_features,
                min_match_score,
                max_market_cap,
                1,
                1,
                start_idx=start_idx,
                existing_candidates=existing_candidates
            )
    
    def get_progress(self) -> Dict:
        """
        è·å–å½“å‰è¿›åº¦
        :return: è¿›åº¦ä¿¡æ¯
        """
        try:
            # ç¡®ä¿ progress æ˜¯å­—å…¸ç±»å‹
            if not isinstance(self.progress, dict) or not self.progress:
                return {
                    'type': None,
                    'current': 0,
                    'total': 0,
                    'status': 'ç©ºé—²',
                    'detail': '',
                    'percentage': 0,
                    'found': 0
                }
            
            # åˆ›å»ºå‰¯æœ¬ï¼Œé¿å…ä¿®æ”¹åŸå§‹æ•°æ®
            progress = self.progress.copy()
            
            # ç¡®ä¿åŒ…å«æ‰€æœ‰å¿…è¦çš„å­—æ®µ
            if 'type' not in progress:
                progress['type'] = None
            if 'current' not in progress:
                progress['current'] = 0
            if 'total' not in progress:
                progress['total'] = 0
            if 'status' not in progress:
                progress['status'] = 'ç©ºé—²'
            if 'detail' not in progress:
                progress['detail'] = ''
            if 'found' not in progress:
                progress['found'] = 0
            
            # è®¡ç®—ç™¾åˆ†æ¯”
            try:
                total = float(progress.get('total', 0))
                current = float(progress.get('current', 0))
                if total > 0:
                    progress['percentage'] = round(current / total * 100, 1)
                else:
                    progress['percentage'] = 0.0
            except (ValueError, TypeError, ZeroDivisionError):
                progress['percentage'] = 0.0
            
            # ç¡®ä¿åŒ…å«æœ€åæ›´æ–°æ—¶é—´
            import time as time_module
            if 'last_update_time' not in progress:
                progress['last_update_time'] = time_module.time()
            
            # å¦‚æœè¿›åº¦é•¿æ—¶é—´æœªæ›´æ–°ï¼Œæ·»åŠ è­¦å‘Š
            try:
                last_update = progress.get('last_update_time', time_module.time())
                if isinstance(last_update, (int, float)):
                    time_since_update = time_module.time() - last_update
                    if time_since_update > 30 and progress.get('status') == 'è¿›è¡Œä¸­':
                        progress['warning'] = f'å·²è¶…è¿‡ {int(time_since_update)} ç§’æœªæ›´æ–°ï¼Œå¯èƒ½å¡åœ¨: {progress.get("current_stock", "æœªçŸ¥è‚¡ç¥¨")}'
            except (ValueError, TypeError):
                pass  # å¿½ç•¥æ—¶é—´è®¡ç®—é”™è¯¯
            
            return progress
        except Exception as e:
            # å¦‚æœå‡ºç°ä»»ä½•é”™è¯¯ï¼Œè¿”å›é»˜è®¤å€¼
            import time as time_module
            print(f"[get_progress] é”™è¯¯: {e}")
            return {
                'type': None,
                'current': 0,
                'total': 0,
                'status': 'ç©ºé—²',
                'detail': f'è·å–è¿›åº¦æ—¶å‡ºé”™: {str(e)}',
                'percentage': 0,
                'found': 0,
                'last_update_time': time_module.time()
            }
    
    def get_analysis_result(self, stock_code: str) -> Optional[Dict]:
        """
        è·å–æŒ‡å®šè‚¡ç¥¨çš„åˆ†æç»“æœ
        :param stock_code: è‚¡ç¥¨ä»£ç 
        :return: åˆ†æç»“æœï¼Œå¦‚æœä¸å­˜åœ¨è¿”å›None
        """
        return self.analysis_results.get(stock_code)
    
    def find_volume_surge_point(self, stock_code: str, max_gain_start_idx: int, weekly_df: Optional[pd.DataFrame] = None, min_volume_ratio: float = 3.0, lookback_weeks: int = 52) -> Optional[int]:
        """
        åœ¨æ¶¨å¹…åŒºé—´èµ·ç‚¹ä¹‹å‰ï¼Œæ‰¾åˆ°å‘¨æˆäº¤é‡çªç„¶æ¯”å‰ä¸€å‘¨å¤š3å€ä»¥ä¸Šçš„ç‚¹ä½œä¸ºç‰¹å¾æå–èµ·ç‚¹
        :param stock_code: è‚¡ç¥¨ä»£ç 
        :param max_gain_start_idx: æ¶¨å¹…åŒºé—´èµ·ç‚¹åœ¨å‘¨çº¿æ•°æ®ä¸­çš„ç´¢å¼•ï¼ˆä¾‹å¦‚10æœˆ17æ—¥ï¼‰
        :param weekly_df: å‘¨Kçº¿æ•°æ®ï¼ˆå¯é€‰ï¼‰
        :param min_volume_ratio: æœ€å°æˆäº¤é‡å€æ•°ï¼ˆé»˜è®¤3.0ï¼Œå³æ¯”å‰ä¸€å‘¨å¤š3å€ä»¥ä¸Šï¼‰
        :param lookback_weeks: å‘å‰æŸ¥æ‰¾çš„æœ€å¤§å‘¨æ•°ï¼ˆé»˜è®¤52å‘¨ï¼Œçº¦ä¸€å¹´ï¼‰
        :return: ç‰¹å¾æå–èµ·ç‚¹çš„ç´¢å¼•ï¼Œå¦‚æœæœªæ‰¾åˆ°è¿”å›None
        """
        try:
            if weekly_df is None:
                weekly_df = self.fetcher.get_weekly_kline(stock_code, period="2y")
            
            if weekly_df is None or len(weekly_df) == 0:
                return None
            
            # æ£€æŸ¥å¿…è¦çš„åˆ—
            volume_col = 'å‘¨æˆäº¤é‡' if 'å‘¨æˆäº¤é‡' in weekly_df.columns else 'æˆäº¤é‡'
            if volume_col not in weekly_df.columns:
                return None
            
            # ä»æ¶¨å¹…åŒºé—´èµ·ç‚¹å‘å‰æŸ¥æ‰¾ï¼Œæœ€å¤šæŸ¥æ‰¾lookback_weekså‘¨
            search_start_idx = max(1, max_gain_start_idx - lookback_weeks)
            
            # ä»æ¶¨å¹…åŒºé—´èµ·ç‚¹å‘å‰æŸ¥æ‰¾ï¼Œæ‰¾åˆ°æ‰€æœ‰æˆäº¤é‡çªç„¶å¢åŠ çš„ç‚¹ï¼Œç„¶åè¿”å›æœ€æ—©çš„é‚£ä¸ªï¼ˆç¬¬ä¸€ä¸ªçªå¢ç‚¹ï¼‰
            surge_points = []
            for i in range(max_gain_start_idx - 1, search_start_idx - 1, -1):
                if i < 1:  # è‡³å°‘éœ€è¦å‰ä¸€å‘¨çš„æ•°æ®
                    break
                
                current_volume = float(weekly_df.iloc[i][volume_col])
                prev_volume = float(weekly_df.iloc[i - 1][volume_col])
                
                # é¿å…é™¤é›¶
                if prev_volume <= 0:
                    continue
                
                volume_ratio = current_volume / prev_volume
                
                # å¦‚æœå½“å‰å‘¨æˆäº¤é‡æ¯”å‰ä¸€å‘¨å¤šmin_volume_ratioå€ä»¥ä¸Šï¼Œè®°å½•è¿™ä¸ªçªå¢ç‚¹
                if volume_ratio >= min_volume_ratio:
                    surge_points.append((i, volume_ratio))
            
            # å¦‚æœæ‰¾åˆ°äº†çªå¢ç‚¹ï¼Œè¿”å›æœ€æ—©çš„é‚£ä¸ªï¼ˆç´¢å¼•æœ€å°çš„ï¼Œå³æ—¶é—´ä¸Šæœ€æ—©çš„ï¼‰
            if surge_points:
                # æŒ‰ç´¢å¼•æ’åºï¼Œå–æœ€å°çš„ï¼ˆæœ€æ—©çš„ï¼‰
                surge_points.sort(key=lambda x: x[0])
                first_surge_idx, first_surge_ratio = surge_points[0]
                if not getattr(self, '_scan_quiet', False):
                    print(f"[{stock_code}] æ‰¾åˆ°æˆäº¤é‡çªå¢ç‚¹: ç´¢å¼•{first_surge_idx}, æˆäº¤é‡æ¯”å‰ä¸€å‘¨å¤š{first_surge_ratio:.2f}å€ï¼ˆç¬¬ä¸€ä¸ªçªå¢ç‚¹ï¼‰")
                return first_surge_idx
            
            fallback_idx = max(0, max_gain_start_idx - 20)
            if not getattr(self, '_scan_quiet', False):
                print(f"[{stock_code}] æœªæ‰¾åˆ°æˆäº¤é‡çªå¢ç‚¹ï¼Œä½¿ç”¨æ¶¨å¹…èµ·ç‚¹å‰20å‘¨ä½œä¸ºç‰¹å¾èµ·ç‚¹: ç´¢å¼•{fallback_idx}")
            return fallback_idx
            
        except Exception as e:
            if not getattr(self, '_scan_quiet', False):
                print(f"[{stock_code}] æŸ¥æ‰¾æˆäº¤é‡çªå¢ç‚¹å¤±è´¥: {str(e)}")
            return None
    
    def _get_close_on_date(self, stock_code: str, date_str: str) -> Optional[float]:
        """å– æœç´¢å½“å¤© çš„æ”¶ç›˜ä»·ï¼ˆæˆ–è¯¥æ—¥å‰æœ€è¿‘ä¸€äº¤æ˜“æ—¥æ”¶ç›˜ï¼‰ã€‚
        å¦‚æœæ‰«ææ—¥æœŸæ˜¯ä»Šå¤©ï¼Œä¼˜å…ˆä»æ¥å£è·å–æœ€æ–°ä»·æ ¼ï¼›å¦åˆ™å…ˆè¯• cacheï¼Œå†è¯•æ¥å£ã€‚
        é‡è¦ï¼šå¯¹äºå†å²æ—¥æœŸï¼Œåªè¿”å›è¯¥æ—¥æœŸæˆ–ä¹‹å‰çš„æ•°æ®ï¼Œä¸ä¼šè¿”å›ä»Šå¤©çš„æ•°æ®ã€‚"""
        try:
            target = pd.to_datetime(date_str)
            from datetime import datetime as dt_now
            today_str = dt_now.now().strftime('%Y-%m-%d')
            is_today = date_str == today_str
            
            # âœ… å¦‚æœæ‰«ææ—¥æœŸæ˜¯ä»Šå¤©ï¼Œä¼˜å…ˆä»æ¥å£è·å–æœ€æ–°ä»·æ ¼ï¼ˆç¡®ä¿æ˜¯æœ€æ–°çš„ï¼‰
            if is_today:
                try:
                    end_ymd = date_str.replace('-', '')
                    from datetime import datetime as _dt, timedelta
                    d = _dt.strptime(date_str, '%Y-%m-%d')
                    start_ymd = (d - timedelta(days=14)).strftime('%Y%m%d')
                    # get_daily_kline_range æ€»æ˜¯ä»æ¥å£è·å–ï¼Œä¸ä½¿ç”¨ç¼“å­˜
                    daily_df = self.fetcher.get_daily_kline_range(stock_code, start_ymd, end_ymd)
                    if daily_df is not None and len(daily_df) > 0 and 'æ”¶ç›˜' in daily_df.columns:
                        daily_df = daily_df.copy()
                        daily_df['æ—¥æœŸ'] = pd.to_datetime(daily_df['æ—¥æœŸ'], errors='coerce')
                        daily_df = daily_df.dropna(subset=['æ—¥æœŸ']).sort_values('æ—¥æœŸ')
                        # âœ… å…³é”®ï¼šåªå–å°äºç­‰äºç›®æ ‡æ—¥æœŸçš„æ•°æ®ï¼ˆå¯¹äºä»Šå¤©ï¼Œå°±æ˜¯ä»Šå¤©æˆ–ä¹‹å‰çš„æ•°æ®ï¼‰
                        before = daily_df[daily_df['æ—¥æœŸ'] <= target]
                        if len(before) > 0:
                            latest_price = float(before.iloc[-1]['æ”¶ç›˜'])
                            latest_date = before.iloc[-1]['æ—¥æœŸ']
                            # âœ… è°ƒè¯•ï¼šç¡®è®¤è·å–åˆ°çš„ä»·æ ¼å’Œæ—¥æœŸ
                            # print(f"[è°ƒè¯•-ä»·æ ¼è·å–] {stock_code} ä»æ¥å£è·å–åˆ°æ—¥æœŸ {latest_date.strftime('%Y-%m-%d')} çš„ä»·æ ¼: {latest_price:.2f} (è¯·æ±‚æ—¥æœŸ: {date_str})")
                            return latest_price
                except Exception as e:
                    # print(f"[è°ƒè¯•-ä»·æ ¼è·å–] {stock_code} æ¥å£è·å–å¤±è´¥: {str(e)[:50]}")
                    pass
            
            # 1) å…ˆè¯• cacheï¼ˆéä»Šå¤©æˆ–æ¥å£è·å–å¤±è´¥æ—¶ï¼‰
            p = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'cache', 'daily_kline', f'{stock_code}.csv')
            if os.path.exists(p):
                try:
                    df = pd.read_csv(p)
                    if 'æ—¥æœŸ' in df.columns and 'æ”¶ç›˜' in df.columns:
                        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
                        df = df.dropna(subset=['æ—¥æœŸ']).sort_values('æ—¥æœŸ')
                        # âœ… å…³é”®ï¼šåªå–å°äºç­‰äºç›®æ ‡æ—¥æœŸçš„æ•°æ®ï¼ˆå¯¹äºå†å²æ—¥æœŸï¼Œä¸ä¼šåŒ…å«ä»Šå¤©çš„æ•°æ®ï¼‰
                        before = df[df['æ—¥æœŸ'] <= target]
                        if len(before) > 0:
                            cached_price = float(before.iloc[-1]['æ”¶ç›˜'])
                            cached_date = before.iloc[-1]['æ—¥æœŸ']
                            
                            # âœ… è°ƒè¯•ï¼šç¡®è®¤ä»ç¼“å­˜è·å–çš„ä»·æ ¼å’Œæ—¥æœŸ
                            # if not is_today:
                            #     print(f"[è°ƒè¯•-ä»·æ ¼è·å–] {stock_code} ä»ç¼“å­˜è·å–åˆ°æ—¥æœŸ {cached_date.strftime('%Y-%m-%d')} çš„ä»·æ ¼: {cached_price:.2f} (è¯·æ±‚æ—¥æœŸ: {date_str})")
                            
                            # âœ… å¦‚æœæ‰«ææ—¥æœŸæ˜¯ä»Šå¤©ï¼Œæ£€æŸ¥ç¼“å­˜æ•°æ®æ˜¯å¦æ˜¯æœ€æ–°çš„ï¼ˆæœ€æ–°æ—¥æœŸåº”è¯¥æ˜¯ä»Šå¤©æˆ–æ˜¨å¤©ï¼‰
                            if is_today:
                                days_diff = (target - cached_date).days
                                if days_diff > 1:  # ç¼“å­˜æ•°æ®è¶…è¿‡1å¤©ï¼Œå¯èƒ½ä¸æ˜¯æœ€æ–°çš„
                                    # ç¼“å­˜æ•°æ®å¤ªæ—§ï¼Œå°è¯•ä»æ¥å£è·å–
                                    try:
                                        end_ymd = date_str.replace('-', '')
                                        from datetime import datetime as _dt, timedelta
                                        d = _dt.strptime(date_str, '%Y-%m-%d')
                                        start_ymd = (d - timedelta(days=14)).strftime('%Y%m%d')
                                        # get_daily_kline_range æ€»æ˜¯ä»æ¥å£è·å–ï¼Œä¸ä½¿ç”¨ç¼“å­˜
                                        daily_df = self.fetcher.get_daily_kline_range(stock_code, start_ymd, end_ymd)
                                        if daily_df is not None and len(daily_df) > 0 and 'æ”¶ç›˜' in daily_df.columns:
                                            daily_df = daily_df.copy()
                                            daily_df['æ—¥æœŸ'] = pd.to_datetime(daily_df['æ—¥æœŸ'], errors='coerce')
                                            daily_df = daily_df.dropna(subset=['æ—¥æœŸ']).sort_values('æ—¥æœŸ')
                                            before = daily_df[daily_df['æ—¥æœŸ'] <= target]
                                            if len(before) > 0:
                                                return float(before.iloc[-1]['æ”¶ç›˜'])
                                    except Exception:
                                        pass
                            
                            return cached_price
                except Exception as e:
                    # print(f"[è°ƒè¯•-ä»·æ ¼è·å–] {stock_code} ç¼“å­˜è¯»å–å¤±è´¥: {str(e)[:50]}")
                    pass
            
            # 2) å†è¯•æ¥å£ï¼ˆç¼“å­˜ä¸­æ²¡æœ‰æ—¶ï¼‰
            end_ymd = date_str.replace('-', '')
            from datetime import datetime as _dt, timedelta
            d = _dt.strptime(date_str, '%Y-%m-%d')
            start_ymd = (d - timedelta(days=14)).strftime('%Y%m%d')
            daily_df = self.fetcher.get_daily_kline_range(stock_code, start_ymd, end_ymd)
            if daily_df is not None and len(daily_df) > 0 and 'æ”¶ç›˜' in daily_df.columns:
                daily_df = daily_df.copy()
                daily_df['æ—¥æœŸ'] = pd.to_datetime(daily_df['æ—¥æœŸ'], errors='coerce')
                daily_df = daily_df.dropna(subset=['æ—¥æœŸ']).sort_values('æ—¥æœŸ')
                # âœ… å…³é”®ï¼šåªå–å°äºç­‰äºç›®æ ‡æ—¥æœŸçš„æ•°æ®ï¼ˆå¯¹äºå†å²æ—¥æœŸï¼Œä¸ä¼šåŒ…å«ä»Šå¤©çš„æ•°æ®ï¼‰
                before = daily_df[daily_df['æ—¥æœŸ'] <= target]
                if len(before) > 0:
                    return float(before.iloc[-1]['æ”¶ç›˜'])
        except Exception as e:
            # print(f"[è°ƒè¯•-ä»·æ ¼è·å–] {stock_code} è·å–ä»·æ ¼å¼‚å¸¸: {str(e)[:50]}")
            pass
        return None
    
    def _get_ohlc_on_date(self, stock_code: str, date_str: str) -> Optional[tuple]:
        """è·å–æŒ‡å®šæ—¥æœŸçš„ OHLCï¼ˆå¼€ç›˜ã€æ”¶ç›˜ã€æœ€é«˜ã€æœ€ä½ï¼‰ã€‚ä»…å½“å­˜åœ¨è¯¥æ—¥è¡Œæƒ…æ—¶è¿”å›ï¼Œå¦åˆ™ Noneã€‚"""
        try:
            target = pd.to_datetime(date_str).normalize()
            end_ymd = date_str.replace('-', '')
            from datetime import datetime as _dt, timedelta
            d = _dt.strptime(date_str, '%Y-%m-%d')
            start_ymd = (d - timedelta(days=14)).strftime('%Y%m%d')
            daily_df = self.fetcher.get_daily_kline_range(stock_code, start_ymd, end_ymd)
            if daily_df is None or len(daily_df) == 0:
                return None
            daily_df = daily_df.copy()
            daily_df['æ—¥æœŸ'] = pd.to_datetime(daily_df['æ—¥æœŸ'], errors='coerce').dt.normalize()
            daily_df = daily_df.dropna(subset=['æ—¥æœŸ'])
            same = daily_df[daily_df['æ—¥æœŸ'] == target]
            if len(same) == 0:
                return None
            row = same.iloc[0]
            open_col = 'å¼€ç›˜' if 'å¼€ç›˜' in row.index else 'open'
            close_col = 'æ”¶ç›˜' if 'æ”¶ç›˜' in row.index else 'close'
            high_col = 'æœ€é«˜' if 'æœ€é«˜' in row.index else 'high'
            low_col = 'æœ€ä½' if 'æœ€ä½' in row.index else 'low'
            if open_col not in row.index or close_col not in row.index:
                return None
            o = float(row[open_col])
            c = float(row[close_col])
            h = float(row[high_col]) if high_col in row.index else max(o, c)
            l_ = float(row[low_col]) if low_col in row.index else min(o, c)
            return (o, c, h, l_)
        except Exception:
            return None
    
    def _is_big_bearish_candle_on_date(self, stock_code: str, date_str: str, min_drop_pct: float = 3.0) -> bool:
        """åˆ¤æ–­æŒ‡å®šæ—¥æœŸæ˜¯å¦ä¸ºå¤§é˜´çº¿ã€‚å¤§é˜´çº¿ï¼šé˜´çº¿ï¼ˆæ”¶ç›˜<å¼€ç›˜ï¼‰ä¸”è·Œå¹…>=min_drop_pct%ï¼ˆé»˜è®¤3%ï¼‰ã€‚"""
        ohlc = self._get_ohlc_on_date(stock_code, date_str)
        if ohlc is None:
            return False
        o, c, _, _ = ohlc
        if o <= 0:
            return False
        if c >= o:
            return False  # éé˜´çº¿
        drop_pct = (o - c) / o * 100
        return drop_pct >= min_drop_pct
    
    def extract_features_at_start_point(self, stock_code: str, start_idx: int, lookback_weeks: int = 40, weekly_df: Optional[pd.DataFrame] = None) -> Optional[Dict]:
        """
        æå–èµ·ç‚¹ä½ç½®å‰çš„é‡ä»·ç‰¹å¾ï¼ˆåŸºäºå‘¨çº¿ï¼‰
        :param stock_code: è‚¡ç¥¨ä»£ç 
        :param start_idx: èµ·ç‚¹åœ¨å‘¨çº¿æ•°æ®ä¸­çš„ç´¢å¼•ï¼ˆè¿™æ˜¯ç‰¹å¾æå–çš„èµ·ç‚¹ï¼Œå¯èƒ½æ˜¯æˆäº¤é‡çªå¢ç‚¹ï¼‰
        :param lookback_weeks: å‘å‰å›çœ‹çš„å‘¨æ•°ï¼ˆé»˜è®¤40å‘¨ï¼Œçº¦200ä¸ªäº¤æ˜“æ—¥ï¼‰
        :param weekly_df: å‘¨Kçº¿æ•°æ®ï¼ˆå¯é€‰ï¼Œå¦‚æœæä¾›åˆ™ä¸å†è·å–ï¼Œé¿å…é‡å¤è·å–ï¼‰
        :return: ç‰¹å¾å­—å…¸
        """
        import time
        start_time = time.time()
        max_time = 5  # æœ€å¤§å¤„ç†æ—¶é—´5ç§’ï¼ˆç¼©çŸ­ï¼Œé¿å…å¡ä½ï¼‰
        
        try:
            if not getattr(self, '_scan_quiet', False):
                print(f"[{stock_code}] å¼€å§‹æå–ç‰¹å¾ï¼Œèµ·ç‚¹ç´¢å¼•: {start_idx}")
            
            if weekly_df is None:
                if not getattr(self, '_scan_quiet', False):
                    print(f"[{stock_code}] æ­£åœ¨è·å–å‘¨Kçº¿æ•°æ®...")
                weekly_df = self.fetcher.get_weekly_kline(stock_code, period="2y")
                
                if time.time() - start_time > max_time:
                    print(f"âš ï¸ {stock_code} æ•°æ®è·å–è¶…æ—¶")
                    return None
            
            if weekly_df is None or len(weekly_df) == 0:
                print(f"âš ï¸ {stock_code} æ— æ³•è·å–å‘¨çº¿æ•°æ®æˆ–æ•°æ®ä¸ºç©º")
                return None
            
            # å‡å°‘è°ƒè¯•æ—¥å¿—è¾“å‡ºï¼ˆä»…åœ¨éœ€è¦æ—¶æ‰“å°ï¼‰
            # print(f"[è°ƒè¯•] {stock_code} è·å–åˆ° {len(weekly_df)} å‘¨æ•°æ®ï¼Œèµ·ç‚¹ç´¢å¼•: {start_idx}, éœ€è¦å›çœ‹: {lookback_weeks} å‘¨")
            # print(f"[è°ƒè¯•] {stock_code} å‘¨çº¿æ•°æ®åˆ—å: {list(weekly_df.columns)}")
            
            # ç¡®ä¿æœ‰è¶³å¤Ÿçš„å‘¨çº¿æ•°æ®ï¼ˆè‡³å°‘40å‘¨ï¼‰
            if start_idx >= len(weekly_df):
                print(f"âš ï¸ {stock_code} èµ·ç‚¹ç´¢å¼• {start_idx} è¶…å‡ºæ•°æ®èŒƒå›´ {len(weekly_df)}")
                return None
            
            # å¦‚æœæ•°æ®ä¸è¶³ï¼Œè°ƒæ•´å›çœ‹å‘¨æ•°
            if start_idx < lookback_weeks:
                actual_lookback = start_idx
                print(f"âš ï¸ {stock_code} èµ·ç‚¹ç´¢å¼• {start_idx} å°äºå›çœ‹å‘¨æ•° {lookback_weeks}ï¼Œè°ƒæ•´ä¸ºå›çœ‹ {actual_lookback} å‘¨")
                if actual_lookback < 20:  # è‡³å°‘éœ€è¦20å‘¨æ•°æ®
                    print(f"âš ï¸ {stock_code} æ•°æ®ä¸¥é‡ä¸è¶³ï¼ˆåªæœ‰{actual_lookback}å‘¨ï¼‰ï¼Œæ— æ³•æå–ç‰¹å¾")
                    return None
                lookback_weeks = actual_lookback
            
            # è·å–èµ·ç‚¹å‰çš„å‘¨çº¿æ•°æ®
            before_start_df = weekly_df.iloc[start_idx - lookback_weeks:start_idx].copy()
            
            # æ£€æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
            volume_col = 'å‘¨æˆäº¤é‡' if 'å‘¨æˆäº¤é‡' in weekly_df.columns else 'æˆäº¤é‡'
            if volume_col not in weekly_df.columns:
                print(f"âš ï¸ {stock_code} å‘¨çº¿æ•°æ®ä¸­ç¼ºå°‘æˆäº¤é‡åˆ—ï¼Œå¯ç”¨åˆ—: {list(weekly_df.columns)}")
                return None
            
            start_price = float(weekly_df.iloc[start_idx]['æ”¶ç›˜'])
            start_volume = float(weekly_df.iloc[start_idx][volume_col])
            
            # å‡å°‘è°ƒè¯•æ—¥å¿—è¾“å‡ºï¼ˆä»…åœ¨éœ€è¦æ—¶æ‰“å°ï¼‰
            # print(f"[è°ƒè¯•] {stock_code} èµ·ç‚¹ä»·æ ¼: {start_price}, èµ·ç‚¹æˆäº¤é‡: {start_volume}, ä½¿ç”¨åˆ—å: {volume_col}")
            
            if len(before_start_df) == 0:
                print(f"âš ï¸ {stock_code} èµ·ç‚¹å‰æ•°æ®ä¸ºç©º")
                return None
            
            # å‡å°‘è°ƒè¯•æ—¥å¿—è¾“å‡º
            # print(f"[è°ƒè¯•] {stock_code} èµ·ç‚¹å‰æ•°æ®: {len(before_start_df)} å‘¨ï¼Œåˆ—å: {list(before_start_df.columns)}")
            
            features = {}
            
            # ========== 1. æˆäº¤é‡ç‰¹å¾ï¼ˆé‡ï¼‰- åŸºäºå‘¨çº¿ ==========
            
            # 1.1 èµ·ç‚¹å½“å‘¨é‡æ¯”ï¼ˆæ ¸å¿ƒæŒ‡æ ‡ï¼‰
            if len(before_start_df) >= 10:
                avg_volume_10 = float(before_start_df[volume_col].tail(10).mean())
                if avg_volume_10 > 0:
                    features['èµ·ç‚¹å½“å‘¨é‡æ¯”'] = round(start_volume / avg_volume_10, 2)
                else:
                    features['èµ·ç‚¹å½“å‘¨é‡æ¯”'] = 1.0
            
            # 1.2 èµ·ç‚¹å‰10å‘¨å¹³å‡æˆäº¤é‡
            if len(before_start_df) >= 10:
                features['èµ·ç‚¹å‰10å‘¨å‡é‡'] = round(float(before_start_df[volume_col].tail(10).mean()), 0)
            
            # 1.3 èµ·ç‚¹å‰20å‘¨å¹³å‡æˆäº¤é‡
            if len(before_start_df) >= 20:
                features['èµ·ç‚¹å‰20å‘¨å‡é‡'] = round(float(before_start_df[volume_col].tail(20).mean()), 0)
            
            # 1.4 èµ·ç‚¹å‰40å‘¨å¹³å‡æˆäº¤é‡
            if len(before_start_df) >= 40:
                features['èµ·ç‚¹å‰40å‘¨å‡é‡'] = round(float(before_start_df[volume_col].tail(40).mean()), 0)
            
            # 1.5 æˆäº¤é‡èç¼©ç¨‹åº¦ï¼ˆèµ·ç‚¹å‰10å‘¨å‡é‡/èµ·ç‚¹å‰20å‘¨å‡é‡ï¼‰
            if len(before_start_df) >= 20:
                vol_10 = float(before_start_df[volume_col].tail(10).mean())
                vol_20 = float(before_start_df[volume_col].tail(20).mean())
                if vol_20 > 0:
                    features['æˆäº¤é‡èç¼©ç¨‹åº¦'] = round(vol_10 / vol_20, 2)
                else:
                    features['æˆäº¤é‡èç¼©ç¨‹åº¦'] = 1.0
            
            # 1.6 èµ·ç‚¹å‰40å‘¨æœ€å¤§æˆäº¤é‡ï¼ˆæ ¸å¿ƒç‰¹å¾ï¼šå‰æœŸæ˜¯å¦æœ‰å¤§æˆäº¤é‡ï¼‰
            if len(before_start_df) >= 40:
                max_volume_idx = before_start_df[volume_col].tail(40).idxmax()
                max_volume = float(before_start_df.loc[max_volume_idx, volume_col])
                max_volume_low = float(before_start_df.loc[max_volume_idx, 'æœ€ä½'])
                max_volume_date = before_start_df.loc[max_volume_idx, 'æ—¥æœŸ']
                
                features['èµ·ç‚¹å‰40å‘¨æœ€å¤§é‡'] = round(max_volume, 0)
                features['æœ€å¤§é‡å¯¹åº”æœ€ä½ä»·'] = round(max_volume_low, 2)
                if isinstance(max_volume_date, pd.Timestamp):
                    features['æœ€å¤§é‡å¯¹åº”æ—¥æœŸ'] = max_volume_date.strftime('%Y-%m-%d')
                else:
                    features['æœ€å¤§é‡å¯¹åº”æ—¥æœŸ'] = str(max_volume_date)
                
                # 1.7 èµ·ç‚¹ä»·æ ¼æ˜¯å¦è·Œç ´æœ€å¤§æˆäº¤é‡æœ€ä½ä»·ï¼ˆæ ¸å¿ƒç‰¹å¾ï¼‰
                if max_volume_low > 0:
                    price_drop_ratio = (max_volume_low - start_price) / max_volume_low * 100
                    features['æ˜¯å¦è·Œç ´æœ€å¤§é‡æœ€ä½ä»·'] = 1 if start_price < max_volume_low else 0
                    features['ç›¸å¯¹æœ€å¤§é‡æœ€ä½ä»·è·Œå¹…'] = round(price_drop_ratio, 2) if start_price < max_volume_low else 0
                else:
                    features['æ˜¯å¦è·Œç ´æœ€å¤§é‡æœ€ä½ä»·'] = 0
                    features['ç›¸å¯¹æœ€å¤§é‡æœ€ä½ä»·è·Œå¹…'] = 0
            else:
                # å¦‚æœæ•°æ®ä¸è¶³40å‘¨ï¼Œä½¿ç”¨å…¨éƒ¨æ•°æ®
                if len(before_start_df) > 0:
                    max_volume_idx = before_start_df[volume_col].idxmax()
                    max_volume = float(before_start_df.loc[max_volume_idx, volume_col])
                    max_volume_low = float(before_start_df.loc[max_volume_idx, 'æœ€ä½'])
                    max_volume_date = before_start_df.loc[max_volume_idx, 'æ—¥æœŸ']
                    
                    features['èµ·ç‚¹å‰40å‘¨æœ€å¤§é‡'] = round(max_volume, 0)
                    features['æœ€å¤§é‡å¯¹åº”æœ€ä½ä»·'] = round(max_volume_low, 2)
                    if isinstance(max_volume_date, pd.Timestamp):
                        features['æœ€å¤§é‡å¯¹åº”æ—¥æœŸ'] = max_volume_date.strftime('%Y-%m-%d')
                    else:
                        features['æœ€å¤§é‡å¯¹åº”æ—¥æœŸ'] = str(max_volume_date)
                    
                    if max_volume_low > 0:
                        price_drop_ratio = (max_volume_low - start_price) / max_volume_low * 100
                        features['æ˜¯å¦è·Œç ´æœ€å¤§é‡æœ€ä½ä»·'] = 1 if start_price < max_volume_low else 0
                        features['ç›¸å¯¹æœ€å¤§é‡æœ€ä½ä»·è·Œå¹…'] = round(price_drop_ratio, 2) if start_price < max_volume_low else 0
                    else:
                        features['æ˜¯å¦è·Œç ´æœ€å¤§é‡æœ€ä½ä»·'] = 0
                        features['ç›¸å¯¹æœ€å¤§é‡æœ€ä½ä»·è·Œå¹…'] = 0
            
            # 1.8 èµ·ç‚¹å½“å‘¨æˆäº¤é‡/èµ·ç‚¹å‰40å‘¨æœ€å¤§é‡
            if 'èµ·ç‚¹å‰40å‘¨æœ€å¤§é‡' in features and features['èµ·ç‚¹å‰40å‘¨æœ€å¤§é‡'] > 0:
                features['èµ·ç‚¹é‡æ¯”æœ€å¤§é‡'] = round(start_volume / features['èµ·ç‚¹å‰40å‘¨æœ€å¤§é‡'], 2)
            
            # 1.6 èµ·ç‚¹å½“æ—¥æˆäº¤é‡/èµ·ç‚¹å‰30å¤©æœ€å¤§é‡
            if 'èµ·ç‚¹å‰30å¤©æœ€å¤§é‡' in features and features['èµ·ç‚¹å‰30å¤©æœ€å¤§é‡'] > 0:
                features['èµ·ç‚¹é‡æ¯”æœ€å¤§é‡'] = round(start_volume / features['èµ·ç‚¹å‰30å¤©æœ€å¤§é‡'], 2)
            
            # ========== 2. ä»·æ ¼ç‰¹å¾ï¼ˆä»·ï¼‰- åŸºäºå‘¨çº¿ ==========
            
            # 2.1 ä»·æ ¼ç›¸å¯¹ä½ç½®ï¼ˆæ ¸å¿ƒæŒ‡æ ‡ï¼‰- åŸºäºå‰20å‘¨
            if len(before_start_df) >= 20:
                max_price_20 = float(before_start_df['æœ€é«˜'].tail(20).max())
                min_price_20 = float(before_start_df['æœ€ä½'].tail(20).min())
                if max_price_20 > min_price_20:
                    features['ä»·æ ¼ç›¸å¯¹ä½ç½®'] = round((start_price - min_price_20) / (max_price_20 - min_price_20) * 100, 2)
                    features['ç›¸å¯¹é«˜ç‚¹è·Œå¹…'] = round((max_price_20 - start_price) / max_price_20 * 100, 2)
                else:
                    features['ä»·æ ¼ç›¸å¯¹ä½ç½®'] = 50.0
                    features['ç›¸å¯¹é«˜ç‚¹è·Œå¹…'] = 0
            
            # 2.2 èµ·ç‚¹å‰20å‘¨æœ€é«˜ä»·
            if len(before_start_df) >= 20:
                features['èµ·ç‚¹å‰20å‘¨æœ€é«˜ä»·'] = round(float(before_start_df['æœ€é«˜'].tail(20).max()), 2)
            
            # 2.3 èµ·ç‚¹å‰20å‘¨æœ€ä½ä»·
            if len(before_start_df) >= 20:
                features['èµ·ç‚¹å‰20å‘¨æœ€ä½ä»·'] = round(float(before_start_df['æœ€ä½'].tail(20).min()), 2)
            
            # 2.4 èµ·ç‚¹å‰40å‘¨æœ€é«˜ä»·å’Œæœ€ä½ä»·
            if len(before_start_df) >= 40:
                features['èµ·ç‚¹å‰40å‘¨æœ€é«˜ä»·'] = round(float(before_start_df['æœ€é«˜'].tail(40).max()), 2)
                features['èµ·ç‚¹å‰40å‘¨æœ€ä½ä»·'] = round(float(before_start_df['æœ€ä½'].tail(40).min()), 2)
            
            # 2.5 èµ·ç‚¹å‰20å‘¨ä»·æ ¼æ³¢åŠ¨å¹…åº¦
            if len(before_start_df) >= 20:
                high_20 = float(before_start_df['æœ€é«˜'].tail(20).max())
                low_20 = float(before_start_df['æœ€ä½'].tail(20).min())
                if low_20 > 0:
                    features['èµ·ç‚¹å‰20å‘¨æ³¢åŠ¨å¹…åº¦'] = round((high_20 - low_20) / low_20 * 100, 2)
            
            # ========== 3. å‡çº¿ç‰¹å¾ - åŸºäºå‘¨çº¿ ==========
            
            # 3.1 ä»·æ ¼ä¸å‡çº¿å…³ç³»ï¼ˆæ ¸å¿ƒæŒ‡æ ‡ï¼‰- å‘¨çº¿MA5, MA10, MA20
            if len(before_start_df) >= 5:
                ma5 = float(before_start_df['æ”¶ç›˜'].tail(5).mean())
                if ma5 > 0:
                    features['ä»·æ ¼ç›¸å¯¹MA5'] = round((start_price - ma5) / ma5 * 100, 2)
                    features['MA5å€¼'] = round(ma5, 2)
            
            if len(before_start_df) >= 10:
                ma10 = float(before_start_df['æ”¶ç›˜'].tail(10).mean())
                if ma10 > 0:
                    features['ä»·æ ¼ç›¸å¯¹MA10'] = round((start_price - ma10) / ma10 * 100, 2)
                    features['MA10å€¼'] = round(ma10, 2)
            
            if len(before_start_df) >= 20:
                ma20 = float(before_start_df['æ”¶ç›˜'].tail(20).mean())
                if ma20 > 0:
                    features['ä»·æ ¼ç›¸å¯¹MA20'] = round((start_price - ma20) / ma20 * 100, 2)
                    features['MA20å€¼'] = round(ma20, 2)
            
            if len(before_start_df) >= 40:
                ma40 = float(before_start_df['æ”¶ç›˜'].tail(40).mean())
                if ma40 > 0:
                    features['ä»·æ ¼ç›¸å¯¹MA40'] = round((start_price - ma40) / ma40 * 100, 2)
                    features['MA40å€¼'] = round(ma40, 2)
            
            # 3.2 å‡çº¿æ–œç‡ï¼ˆMA20å‘¨çº¿æ–œç‡ï¼‰
            if len(before_start_df) >= 20:
                ma20_recent = float(before_start_df['æ”¶ç›˜'].tail(5).mean())
                ma20_earlier = float(before_start_df['æ”¶ç›˜'].iloc[-20:-15].mean())
                if ma20_earlier > 0:
                    features['MA20æ–œç‡'] = round((ma20_recent - ma20_earlier) / ma20_earlier * 100, 2)
            
            # ========== 4. é‡ä»·é…åˆç‰¹å¾ - åŸºäºå‘¨çº¿ ==========
            
            # 4.1 èµ·ç‚¹å‰20å‘¨é‡ä»·ç›¸å…³ç³»æ•°
            if len(before_start_df) >= 20:
                price_changes = before_start_df['æ”¶ç›˜'].tail(20).pct_change().dropna()
                volume_changes = before_start_df[volume_col].tail(20).pct_change().dropna()
                if len(price_changes) > 0 and len(volume_changes) > 0:
                    min_len = min(len(price_changes), len(volume_changes))
                    if min_len > 5:
                        correlation = price_changes.tail(min_len).corr(volume_changes.tail(min_len))
                        if pd.notna(correlation):
                            features['èµ·ç‚¹å‰20å‘¨é‡ä»·ç›¸å…³ç³»æ•°'] = round(float(correlation), 3)
            
            # 4.2 èµ·ç‚¹å½“å‘¨æ˜¯å¦ä»·æ¶¨é‡å¢
            if start_idx > 0:
                prev_price = float(weekly_df.iloc[start_idx - 1]['æ”¶ç›˜'])
                prev_volume = float(weekly_df.iloc[start_idx - 1][volume_col])
                features['èµ·ç‚¹å½“å‘¨ä»·æ¶¨'] = 1 if start_price > prev_price else 0
                features['èµ·ç‚¹å½“å‘¨é‡å¢'] = 1 if start_volume > prev_volume else 0
                features['èµ·ç‚¹å½“å‘¨ä»·æ¶¨é‡å¢'] = 1 if (start_price > prev_price and start_volume > prev_volume) else 0
            
            # ========== 5. æ—¶é—´ç‰¹å¾ - åŸºäºå‘¨çº¿ ==========
            
            # 5.1 èµ·ç‚¹å‰10å‘¨æ³¢åŠ¨ç‡
            if len(before_start_df) >= 10:
                # è®¡ç®—æœ€è¿‘10å‘¨çš„ä»·æ ¼æ³¢åŠ¨
                recent_prices = before_start_df['æ”¶ç›˜'].tail(10)
                price_range = (recent_prices.max() - recent_prices.min()) / recent_prices.min() * 100
                features['èµ·ç‚¹å‰10å‘¨æ³¢åŠ¨ç‡'] = round(float(price_range), 2)
            
            # 5.2 èµ·ç‚¹å‰20å‘¨æ³¢åŠ¨ç‡
            if len(before_start_df) >= 20:
                recent_prices = before_start_df['æ”¶ç›˜'].tail(20)
                price_range = (recent_prices.max() - recent_prices.min()) / recent_prices.min() * 100
                features['èµ·ç‚¹å‰20å‘¨æ³¢åŠ¨ç‡'] = round(float(price_range), 2)
            
            # ========== 6. å…¶ä»–ç‰¹å¾ ==========
            
            # 6.1 èµ·ç‚¹ä»·æ ¼
            features['èµ·ç‚¹ä»·æ ¼'] = round(start_price, 2)
            
            # 6.2 èµ·ç‚¹æ—¥æœŸ
            start_date = weekly_df.iloc[start_idx]['æ—¥æœŸ']
            if isinstance(start_date, pd.Timestamp):
                features['èµ·ç‚¹æ—¥æœŸ'] = start_date.strftime('%Y-%m-%d')
            else:
                features['èµ·ç‚¹æ—¥æœŸ'] = str(start_date)
            
            # ========== 7. æ–°å¢æŠ€æœ¯æŒ‡æ ‡ç‰¹å¾ ==========
            
            # 7.1 MACDæŒ‡æ ‡ï¼ˆDIF, DEA, MACDæŸ±ï¼‰
            if len(before_start_df) >= 26:
                try:
                    prices = before_start_df['æ”¶ç›˜']
                    ema12 = prices.ewm(span=12, adjust=False).mean()
                    ema26 = prices.ewm(span=26, adjust=False).mean()
                    dif = ema12 - ema26
                    dea = dif.ewm(span=9, adjust=False).mean()
                    macd = (dif - dea) * 2
                    
                    features['MACD_DIF'] = round(float(dif.iloc[-1]), 4)
                    features['MACD_DEA'] = round(float(dea.iloc[-1]), 4)
                    features['MACDæŸ±'] = round(float(macd.iloc[-1]), 4)
                    
                    # MACDé‡‘å‰åˆ¤æ–­ï¼ˆDIFä¸Šç©¿DEAï¼‰
                    if len(dif) >= 2:
                        prev_diff = dif.iloc[-2] - dea.iloc[-2]
                        curr_diff = dif.iloc[-1] - dea.iloc[-1]
                        features['MACDé‡‘å‰'] = 1 if (prev_diff < 0 and curr_diff >= 0) else 0
                        features['MACDé›¶è½´ä¸Šæ–¹'] = 1 if dif.iloc[-1] > 0 else 0
                except Exception:
                    pass
            
            # 7.2 RSIæŒ‡æ ‡
            if len(before_start_df) >= 14:
                try:
                    prices = before_start_df['æ”¶ç›˜']
                    delta = prices.diff()
                    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
                    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
                    rs = gain / (loss + 0.0001)
                    rsi = 100 - (100 / (1 + rs))
                    
                    features['RSI'] = round(float(rsi.iloc[-1]), 2)
                    features['RSIè¶…å–'] = 1 if rsi.iloc[-1] < 30 else 0
                    features['RSIå¼ºåŠ¿åŒº'] = 1 if 50 < rsi.iloc[-1] < 70 else 0
                except Exception:
                    pass
            
            # 7.3 KDJæŒ‡æ ‡
            if len(before_start_df) >= 9:
                try:
                    high_9 = before_start_df['æœ€é«˜'].rolling(window=9).max()
                    low_9 = before_start_df['æœ€ä½'].rolling(window=9).min()
                    rsv = (before_start_df['æ”¶ç›˜'] - low_9) / (high_9 - low_9 + 0.0001) * 100
                    
                    k_values = []
                    d_values = []
                    k = 50
                    d = 50
                    for r in rsv.dropna():
                        k = 2/3 * k + 1/3 * r
                        d = 2/3 * d + 1/3 * k
                        k_values.append(k)
                        d_values.append(d)
                    
                    if k_values:
                        features['KDJ_K'] = round(k_values[-1], 2)
                        features['KDJ_D'] = round(d_values[-1], 2)
                        features['KDJ_J'] = round(3 * k_values[-1] - 2 * d_values[-1], 2)
                        features['KDJè¶…å–'] = 1 if k_values[-1] < 20 and d_values[-1] < 20 else 0
                except Exception:
                    pass
            
            # 7.4 OBVèƒ½é‡æ½®
            if len(before_start_df) >= 10:
                try:
                    obv = [0]
                    prices = before_start_df['æ”¶ç›˜'].values
                    volumes = before_start_df[volume_col].values
                    for i in range(1, len(prices)):
                        if prices[i] > prices[i-1]:
                            obv.append(obv[-1] + volumes[i])
                        elif prices[i] < prices[i-1]:
                            obv.append(obv[-1] - volumes[i])
                        else:
                            obv.append(obv[-1])
                    
                    obv_series = pd.Series(obv)
                    # OBVè¶‹åŠ¿ï¼ˆè¿‘10å‘¨æ–œç‡ï¼‰
                    if len(obv_series) >= 10:
                        obv_recent = obv_series.tail(10)
                        obv_slope = (obv_recent.iloc[-1] - obv_recent.iloc[0]) / (abs(obv_recent.iloc[0]) + 1) * 100
                        features['OBVè¶‹åŠ¿'] = round(obv_slope, 2)
                    
                    # OBVæ˜¯å¦åˆ›æ–°é«˜
                    if len(obv_series) >= 20:
                        obv_max_20 = obv_series.tail(20).max()
                        features['OBVåˆ›æ–°é«˜'] = 1 if obv_series.iloc[-1] >= obv_max_20 * 0.95 else 0
                except Exception:
                    pass
            
            # 7.5 å‡çº¿ç²˜åˆåº¦ï¼ˆMA5/MA10/MA20ä¸‰çº¿ç²˜åˆç¨‹åº¦ï¼‰
            if len(before_start_df) >= 20:
                try:
                    ma5 = float(before_start_df['æ”¶ç›˜'].tail(5).mean())
                    ma10 = float(before_start_df['æ”¶ç›˜'].tail(10).mean())
                    ma20 = float(before_start_df['æ”¶ç›˜'].tail(20).mean())
                    avg_ma = (ma5 + ma10 + ma20) / 3
                    if avg_ma > 0:
                        # è®¡ç®—å‡çº¿ç¦»æ•£åº¦ï¼ˆè¶Šå°è¯´æ˜è¶Šç²˜åˆï¼‰
                        dispersion = (abs(ma5-avg_ma) + abs(ma10-avg_ma) + abs(ma20-avg_ma)) / avg_ma * 100
                        features['å‡çº¿ç²˜åˆåº¦'] = round(dispersion, 2)
                    
                    # å‡çº¿å¤šå¤´æ’åˆ—
                    features['å‡çº¿å¤šå¤´æ’åˆ—'] = 1 if (ma5 > ma10 > ma20) else 0
                except Exception:
                    pass
            
            # 7.5b å‡çº¿å¹³æ»‘åº¦ï¼ˆåŸºäºæ—¥çº¿5æ—¥çº¿è¿‘60æ—¥æ–¹å‘åˆ‡æ¢æ¬¡æ•°ï¼Œå°‘åˆ‡æ¢=æ›´å¹³æ»‘=æ›´é«˜åˆ†ï¼‰
            try:
                end_dt = weekly_df.iloc[start_idx]['æ—¥æœŸ']
                end_ts = pd.to_datetime(end_dt)
                end_ymd = end_ts.strftime('%Y%m%d')
                daily_df = self.fetcher.get_daily_kline_range(
                    stock_code, start_date='20240101', end_date=end_ymd,
                    use_cache=True, local_only=True
                )
                if daily_df is not None and len(daily_df) >= 65:
                    daily_df = daily_df.copy()
                    daily_df['æ—¥æœŸ'] = pd.to_datetime(daily_df['æ—¥æœŸ'], errors='coerce')
                    daily_df = daily_df.dropna(subset=['æ—¥æœŸ']).sort_values('æ—¥æœŸ').reset_index(drop=True)
                    daily_df = daily_df[daily_df['æ—¥æœŸ'] <= end_ts].reset_index(drop=True)
                    close = daily_df['æ”¶ç›˜'].astype(float)
                    ma5_d = close.rolling(5).mean().dropna()
                    chg = ma5_d.pct_change().dropna()
                    last60 = chg.tail(60)
                    sign = np.sign(last60)
                    flips = int((sign.diff().fillna(0) != 0).astype(int).sum())
                    smooth = max(0, 25 - min(25, flips))
                    features['å‡çº¿å¹³æ»‘åº¦'] = round(smooth, 2)
            except Exception:
                pass
            
            # 7.6 å¸ƒæ—å¸¦ç‰¹å¾
            if len(before_start_df) >= 20:
                try:
                    prices = before_start_df['æ”¶ç›˜']
                    ma20 = prices.rolling(window=20).mean()
                    std20 = prices.rolling(window=20).std()
                    upper = ma20 + 2 * std20
                    lower = ma20 - 2 * std20
                    
                    # å¸ƒæ—å¸¦å®½åº¦ï¼ˆè¶Šçª„è¯´æ˜å³å°†å˜ç›˜ï¼‰
                    bb_width = ((upper.iloc[-1] - lower.iloc[-1]) / ma20.iloc[-1] * 100) if ma20.iloc[-1] > 0 else 0
                    features['å¸ƒæ—å¸¦å®½åº¦'] = round(bb_width, 2)
                    
                    # ä»·æ ¼åœ¨å¸ƒæ—å¸¦ä¸­çš„ä½ç½®ï¼ˆ0-100ï¼‰
                    bb_position = ((start_price - lower.iloc[-1]) / (upper.iloc[-1] - lower.iloc[-1] + 0.01) * 100)
                    features['å¸ƒæ—å¸¦ä½ç½®'] = round(bb_position, 2)
                    
                    # å¸ƒæ—å¸¦æ”¶çª„ï¼ˆä¸10å‘¨å‰ç›¸æ¯”ï¼‰
                    if len(ma20) >= 10 and ma20.iloc[-10] > 0:
                        bb_width_10 = (upper.iloc[-10] - lower.iloc[-10]) / ma20.iloc[-10] * 100
                        features['å¸ƒæ—å¸¦æ”¶çª„'] = 1 if bb_width < bb_width_10 * 0.8 else 0
                except Exception:
                    pass
            
            # 7.7 ç­¹ç é›†ä¸­åº¦ï¼ˆç®€åŒ–ç‰ˆï¼šä½¿ç”¨ä»·æ ¼åŒºé—´ä»£æ›¿ï¼‰
            if len(before_start_df) >= 20:
                try:
                    # ä½¿ç”¨åŠ æƒå¹³å‡æˆæœ¬
                    total_vol = before_start_df[volume_col].tail(20).sum()
                    if total_vol > 0:
                        weighted_price = (before_start_df['æ”¶ç›˜'].tail(20) * before_start_df[volume_col].tail(20)).sum() / total_vol
                        # æˆæœ¬åç¦»åº¦
                        cost_deviation = (start_price - weighted_price) / weighted_price * 100
                        features['æˆæœ¬åç¦»åº¦'] = round(cost_deviation, 2)
                        
                        # ç­¹ç é›†ä¸­åº¦ï¼ˆä»·æ ¼æ ‡å‡†å·®/åŠ æƒå‡ä»·ï¼‰
                        price_std = np.sqrt(((before_start_df['æ”¶ç›˜'].tail(20) - weighted_price) ** 2 * before_start_df[volume_col].tail(20)).sum() / total_vol)
                        concentration = price_std / weighted_price * 100 if weighted_price > 0 else 0
                        features['ç­¹ç é›†ä¸­åº¦'] = round(concentration, 2)
                except Exception:
                    pass
            
            # 7.8 çªç ´ç‰¹å¾
            if len(before_start_df) >= 20:
                try:
                    high_20 = before_start_df['æœ€é«˜'].tail(20).max()
                    features['çªç ´20å‘¨é«˜ç‚¹'] = 1 if start_price > high_20 else 0
                    features['æ¥è¿‘20å‘¨é«˜ç‚¹'] = 1 if start_price > high_20 * 0.95 else 0
                except Exception:
                    pass
            
            if len(before_start_df) >= 40:
                try:
                    high_40 = before_start_df['æœ€é«˜'].tail(40).max()
                    features['çªç ´40å‘¨é«˜ç‚¹'] = 1 if start_price > high_40 else 0
                except Exception:
                    pass
            
            # 7.9 å¹³å°æ•´ç†æ—¶é—´ï¼ˆä»·æ ¼æ³¢åŠ¨å°äº10%çš„å‘¨æ•°ï¼‰
            if len(before_start_df) >= 20:
                try:
                    sideways_weeks = 0
                    for i in range(len(before_start_df) - 20, len(before_start_df)):
                        if i >= 0:
                            range_pct = (before_start_df['æœ€é«˜'].iloc[i] - before_start_df['æœ€ä½'].iloc[i]) / before_start_df['æœ€ä½'].iloc[i] * 100
                            if range_pct < 10:
                                sideways_weeks += 1
                    features['å¹³å°æ•´ç†å‘¨æ•°'] = sideways_weeks
                except Exception:
                    pass
            
            # 7.10 ä¹°ç‚¹å‰æœ€è¿‘ä¸¤ä¸ªæœˆè‡³å°‘æœ‰ä¸€ä¸ªæ¶¨åœï¼ˆæ—¥çº¿ï¼š44 ä¸ªäº¤æ˜“æ—¥å†…æ¶¨è·Œå¹…>=9.5%ï¼‰
            try:
                bp_date = pd.to_datetime(weekly_df.iloc[start_idx]['æ—¥æœŸ'])
                daily_df = None
                _cache_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'cache', 'daily_kline', f'{stock_code}.csv')
                if os.path.exists(_cache_path):
                    try:
                        daily_df = pd.read_csv(_cache_path)
                        if 'æ—¥æœŸ' in daily_df.columns:
                            daily_df['æ—¥æœŸ'] = pd.to_datetime(daily_df['æ—¥æœŸ'], errors='coerce')
                            daily_df = daily_df.dropna(subset=['æ—¥æœŸ']).sort_values('æ—¥æœŸ').reset_index(drop=True)
                    except Exception:
                        pass
                if daily_df is None or len(daily_df) < 2:
                    daily_df = self.fetcher.get_daily_kline(stock_code, period="1y")
                if daily_df is not None and len(daily_df) >= 2 and 'æ”¶ç›˜' in daily_df.columns and 'æ—¥æœŸ' in daily_df.columns:
                    daily_df = daily_df.copy()
                    daily_df['æ—¥æœŸ'] = pd.to_datetime(daily_df['æ—¥æœŸ'], errors='coerce')
                    daily_df = daily_df.dropna(subset=['æ—¥æœŸ']).sort_values('æ—¥æœŸ').reset_index(drop=True)
                    before_bp = daily_df[daily_df['æ—¥æœŸ'] < bp_date].tail(44)
                    if len(before_bp) >= 2:
                        before_bp = before_bp.copy()
                        before_bp['__pct'] = before_bp['æ”¶ç›˜'].pct_change() * 100
                        before_bp['__pct'] = before_bp['__pct'].fillna(0)
                        features['ä¹°ç‚¹å‰ä¸¤æœˆå†…æ›¾æ¶¨åœ'] = 1 if (before_bp['__pct'] >= 9.5).any() else 0
                    else:
                        features['ä¹°ç‚¹å‰ä¸¤æœˆå†…æ›¾æ¶¨åœ'] = 0
                else:
                    features['ä¹°ç‚¹å‰ä¸¤æœˆå†…æ›¾æ¶¨åœ'] = 0
            except Exception:
                features['ä¹°ç‚¹å‰ä¸¤æœˆå†…æ›¾æ¶¨åœ'] = 0
            
            return features
            
        except Exception as e:
            import traceback
            error_msg = str(e)
            print(f"âŒ {stock_code} æå–ç‰¹å¾å¤±è´¥: {error_msg}")
            if "timeout" in error_msg.lower() or "è¶…æ—¶" in error_msg or "time" in error_msg.lower():
                print(f"âš ï¸ {stock_code} ç‰¹å¾æå–å¯èƒ½è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–æ•°æ®æº")
            return None
    
    def extract_features_at_end_point(self, stock_code: str, end_idx: int, start_idx: int, lookback_weeks: int = 20, weekly_df: Optional[pd.DataFrame] = None) -> Optional[Dict]:
        """
        æå–ç»ˆç‚¹ä½ç½®ï¼ˆæœ€é«˜ç‚¹ï¼‰é™„è¿‘çš„é‡ä»·ç‰¹å¾ï¼ˆåŸºäºå‘¨çº¿ï¼‰
        ç”¨äºè®­ç»ƒå–ç‚¹æ¨¡å‹
        :param stock_code: è‚¡ç¥¨ä»£ç 
        :param end_idx: ç»ˆç‚¹ï¼ˆæœ€é«˜ç‚¹ï¼‰åœ¨å‘¨çº¿æ•°æ®ä¸­çš„ç´¢å¼•
        :param start_idx: èµ·ç‚¹åœ¨å‘¨çº¿æ•°æ®ä¸­çš„ç´¢å¼•ï¼ˆç”¨äºè®¡ç®—æ¶¨å¹…ï¼‰
        :param lookback_weeks: å‘å‰å›çœ‹çš„å‘¨æ•°ï¼ˆé»˜è®¤20å‘¨ï¼‰
        :param weekly_df: å‘¨Kçº¿æ•°æ®ï¼ˆå¯é€‰ï¼Œå¦‚æœæä¾›åˆ™ä¸å†è·å–ï¼‰
        :return: ç‰¹å¾å­—å…¸
        """
        import time
        start_time = time.time()
        max_time = 5  # æœ€å¤§å¤„ç†æ—¶é—´5ç§’
        
        try:
            print(f"[{stock_code}] å¼€å§‹æå–å–ç‚¹ç‰¹å¾ï¼Œç»ˆç‚¹ç´¢å¼•: {end_idx}, èµ·ç‚¹ç´¢å¼•: {start_idx}")
            
            # å¦‚æœæä¾›äº†weekly_dfï¼Œç›´æ¥ä½¿ç”¨
            if weekly_df is None:
                print(f"[{stock_code}] æ­£åœ¨è·å–å‘¨Kçº¿æ•°æ®...")
                weekly_df = self.fetcher.get_weekly_kline(stock_code, period="2y")
                
                if time.time() - start_time > max_time:
                    print(f"âš ï¸ {stock_code} æ•°æ®è·å–è¶…æ—¶")
                    return None
            
            if weekly_df is None or len(weekly_df) == 0:
                print(f"âš ï¸ {stock_code} æ— æ³•è·å–å‘¨çº¿æ•°æ®æˆ–æ•°æ®ä¸ºç©º")
                return None
            
            # ç¡®ä¿ç´¢å¼•æœ‰æ•ˆ
            if end_idx >= len(weekly_df) or start_idx >= len(weekly_df):
                print(f"âš ï¸ {stock_code} ç´¢å¼•è¶…å‡ºæ•°æ®èŒƒå›´")
                return None
            
            if end_idx < lookback_weeks:
                print(f"âš ï¸ {stock_code} ç»ˆç‚¹ç´¢å¼• {end_idx} å°äºå›çœ‹å‘¨æ•° {lookback_weeks}ï¼Œæ•°æ®ä¸è¶³")
                return None
            
            # è·å–ç»ˆç‚¹ä»·æ ¼å’Œèµ·ç‚¹ä»·æ ¼
            end_price = float(weekly_df.iloc[end_idx]['æ”¶ç›˜'])
            end_high = float(weekly_df.iloc[end_idx]['æœ€é«˜'])  # ä½¿ç”¨æœ€é«˜ä»·
            start_price = float(weekly_df.iloc[start_idx]['æ”¶ç›˜'])
            
            # è®¡ç®—æ¶¨å¹…
            gain_pct = (end_high - start_price) / start_price * 100 if start_price > 0 else 0
            
            # è·å–ç»ˆç‚¹å‰çš„å‘¨çº¿æ•°æ®
            before_end_df = weekly_df.iloc[end_idx - lookback_weeks:end_idx].copy()
            
            # æ£€æŸ¥å¿…è¦çš„åˆ—
            volume_col = 'å‘¨æˆäº¤é‡' if 'å‘¨æˆäº¤é‡' in weekly_df.columns else 'æˆäº¤é‡'
            if volume_col not in weekly_df.columns:
                print(f"âš ï¸ {stock_code} å‘¨çº¿æ•°æ®ä¸­ç¼ºå°‘æˆäº¤é‡åˆ—")
                return None
            
            end_volume = float(weekly_df.iloc[end_idx][volume_col])
            
            features = {}
            
            # ========== 1. æ¶¨å¹…ç‰¹å¾ï¼ˆæ ¸å¿ƒï¼‰ ==========
            features['ç´¯è®¡æ¶¨å¹…'] = round(gain_pct, 2)
            features['ç¿»å€å€æ•°'] = round(gain_pct / 100, 2)
            features['èµ·ç‚¹ä»·æ ¼'] = round(start_price, 2)
            features['ç»ˆç‚¹ä»·æ ¼'] = round(end_high, 2)
            features['å®é™…å‘¨æ•°'] = end_idx - start_idx + 1
            
            # ========== 2. ä»·æ ¼ç›¸å¯¹ä½ç½®ç‰¹å¾ ==========
            
            # 2.1 ç»ˆç‚¹ä»·æ ¼ç›¸å¯¹ä½ç½®ï¼ˆæ ¸å¿ƒæŒ‡æ ‡ï¼‰- åŸºäºå‰20å‘¨
            if len(before_end_df) >= 20:
                max_price_20 = float(before_end_df['æœ€é«˜'].tail(20).max())
                min_price_20 = float(before_end_df['æœ€ä½'].tail(20).min())
                if max_price_20 > min_price_20:
                    features['ä»·æ ¼ç›¸å¯¹ä½ç½®'] = round((end_high - min_price_20) / (max_price_20 - min_price_20) * 100, 2)
                else:
                    features['ä»·æ ¼ç›¸å¯¹ä½ç½®'] = 100.0  # å·²ç»æ˜¯æœ€é«˜ç‚¹
            
            # 2.2 ç»ˆç‚¹å‰20å‘¨æœ€é«˜ä»·å’Œæœ€ä½ä»·
            if len(before_end_df) >= 20:
                features['ç»ˆç‚¹å‰20å‘¨æœ€é«˜ä»·'] = round(float(before_end_df['æœ€é«˜'].tail(20).max()), 2)
                features['ç»ˆç‚¹å‰20å‘¨æœ€ä½ä»·'] = round(float(before_end_df['æœ€ä½'].tail(20).min()), 2)
            
            # 2.3 ç»ˆç‚¹æ˜¯å¦åˆ›20å‘¨æ–°é«˜
            if len(before_end_df) >= 20:
                max_price_20 = float(before_end_df['æœ€é«˜'].tail(20).max())
                features['æ˜¯å¦åˆ›20å‘¨æ–°é«˜'] = 1 if end_high > max_price_20 else 0
            
            # ========== 3. æˆäº¤é‡ç‰¹å¾ ==========
            
            # 3.1 ç»ˆç‚¹å½“å‘¨é‡æ¯”ï¼ˆæ ¸å¿ƒæŒ‡æ ‡ï¼‰
            if len(before_end_df) >= 10:
                avg_volume_10 = float(before_end_df[volume_col].tail(10).mean())
                if avg_volume_10 > 0:
                    features['ç»ˆç‚¹å½“å‘¨é‡æ¯”'] = round(end_volume / avg_volume_10, 2)
                else:
                    features['ç»ˆç‚¹å½“å‘¨é‡æ¯”'] = 1.0
            
            # 3.2 ç»ˆç‚¹å‰10å‘¨å¹³å‡æˆäº¤é‡
            if len(before_end_df) >= 10:
                features['ç»ˆç‚¹å‰10å‘¨å‡é‡'] = round(float(before_end_df[volume_col].tail(10).mean()), 0)
            
            # 3.3 ç»ˆç‚¹å‰20å‘¨å¹³å‡æˆäº¤é‡
            if len(before_end_df) >= 20:
                features['ç»ˆç‚¹å‰20å‘¨å‡é‡'] = round(float(before_end_df[volume_col].tail(20).mean()), 0)
            
            # 3.4 ç»ˆç‚¹å‰20å‘¨æœ€å¤§æˆäº¤é‡
            if len(before_end_df) >= 20:
                max_volume_20 = float(before_end_df[volume_col].tail(20).max())
                features['ç»ˆç‚¹å‰20å‘¨æœ€å¤§é‡'] = round(max_volume_20, 0)
                features['ç»ˆç‚¹é‡æ¯”æœ€å¤§é‡'] = round(end_volume / max_volume_20, 2) if max_volume_20 > 0 else 1.0
            
            # 3.5 æˆäº¤é‡æ”¾å¤§ç¨‹åº¦ï¼ˆç»ˆç‚¹å½“å‘¨/èµ·ç‚¹å½“å‘¨ï¼‰
            if start_idx < len(weekly_df):
                start_volume = float(weekly_df.iloc[start_idx][volume_col])
                if start_volume > 0:
                    features['ç»ˆç‚¹èµ·ç‚¹é‡æ¯”'] = round(end_volume / start_volume, 2)
            
            # ========== 4. å‡çº¿ç‰¹å¾ ==========
            
            # 4.1 ä»·æ ¼ä¸å‡çº¿å…³ç³»ï¼ˆæ ¸å¿ƒæŒ‡æ ‡ï¼‰
            if len(before_end_df) >= 5:
                ma5 = float(before_end_df['æ”¶ç›˜'].tail(5).mean())
                if ma5 > 0:
                    features['ä»·æ ¼ç›¸å¯¹MA5'] = round((end_high - ma5) / ma5 * 100, 2)
                    features['MA5å€¼'] = round(ma5, 2)
            
            if len(before_end_df) >= 10:
                ma10 = float(before_end_df['æ”¶ç›˜'].tail(10).mean())
                if ma10 > 0:
                    features['ä»·æ ¼ç›¸å¯¹MA10'] = round((end_high - ma10) / ma10 * 100, 2)
                    features['MA10å€¼'] = round(ma10, 2)
            
            if len(before_end_df) >= 20:
                ma20 = float(before_end_df['æ”¶ç›˜'].tail(20).mean())
                if ma20 > 0:
                    features['ä»·æ ¼ç›¸å¯¹MA20'] = round((end_high - ma20) / ma20 * 100, 2)
                    features['MA20å€¼'] = round(ma20, 2)
            
            # 4.2 å‡çº¿æ–œç‡ï¼ˆMA20æ–œç‡ï¼‰
            if len(before_end_df) >= 20:
                ma20_recent = float(before_end_df['æ”¶ç›˜'].tail(5).mean())
                ma20_earlier = float(before_end_df['æ”¶ç›˜'].iloc[-20:-15].mean())
                if ma20_earlier > 0:
                    features['MA20æ–œç‡'] = round((ma20_recent - ma20_earlier) / ma20_earlier * 100, 2)
            
            # ========== 5. é‡ä»·é…åˆç‰¹å¾ ==========
            
            # 5.1 ç»ˆç‚¹å‰20å‘¨é‡ä»·ç›¸å…³ç³»æ•°
            if len(before_end_df) >= 20:
                price_changes = before_end_df['æ”¶ç›˜'].tail(20).pct_change().dropna()
                volume_changes = before_end_df[volume_col].tail(20).pct_change().dropna()
                if len(price_changes) > 0 and len(volume_changes) > 0:
                    min_len = min(len(price_changes), len(volume_changes))
                    if min_len > 5:
                        correlation = price_changes.tail(min_len).corr(volume_changes.tail(min_len))
                        if pd.notna(correlation):
                            features['ç»ˆç‚¹å‰20å‘¨é‡ä»·ç›¸å…³ç³»æ•°'] = round(float(correlation), 3)
            
            # 5.2 ç»ˆç‚¹å½“å‘¨æ˜¯å¦ä»·æ¶¨é‡å¢
            if end_idx > 0:
                prev_price = float(weekly_df.iloc[end_idx - 1]['æ”¶ç›˜'])
                prev_volume = float(weekly_df.iloc[end_idx - 1][volume_col])
                features['ç»ˆç‚¹å½“å‘¨ä»·æ¶¨'] = 1 if end_high > prev_price else 0
                features['ç»ˆç‚¹å½“å‘¨é‡å¢'] = 1 if end_volume > prev_volume else 0
                features['ç»ˆç‚¹å½“å‘¨ä»·æ¶¨é‡å¢'] = 1 if (end_high > prev_price and end_volume > prev_volume) else 0
            
            # ========== 6. å›è°ƒç‰¹å¾ï¼ˆç»ˆç‚¹åæ˜¯å¦æœ‰å›è°ƒï¼‰ ==========
            
            # 6.1 ç»ˆç‚¹å1å‘¨å›è°ƒå¹…åº¦
            if end_idx + 1 < len(weekly_df):
                next_price = float(weekly_df.iloc[end_idx + 1]['æ”¶ç›˜'])
                features['ç»ˆç‚¹å1å‘¨å›è°ƒ'] = round((end_high - next_price) / end_high * 100, 2) if end_high > 0 else 0
                features['ç»ˆç‚¹å1å‘¨æ˜¯å¦å›è°ƒ'] = 1 if next_price < end_high else 0
            
            # 6.2 ç»ˆç‚¹å2å‘¨å›è°ƒå¹…åº¦
            if end_idx + 2 < len(weekly_df):
                next2_price = float(weekly_df.iloc[end_idx + 2]['æ”¶ç›˜'])
                features['ç»ˆç‚¹å2å‘¨å›è°ƒ'] = round((end_high - next2_price) / end_high * 100, 2) if end_high > 0 else 0
                features['ç»ˆç‚¹å2å‘¨æ˜¯å¦å›è°ƒ'] = 1 if next2_price < end_high else 0
            
            # ========== 7. æ—¶é—´ç‰¹å¾ ==========
            
            # 7.1 ç»ˆç‚¹å‰10å‘¨æ³¢åŠ¨ç‡
            if len(before_end_df) >= 10:
                recent_prices = before_end_df['æ”¶ç›˜'].tail(10)
                price_range = (recent_prices.max() - recent_prices.min()) / recent_prices.min() * 100
                features['ç»ˆç‚¹å‰10å‘¨æ³¢åŠ¨ç‡'] = round(float(price_range), 2)
            
            # 7.2 ç»ˆç‚¹å‰20å‘¨æ³¢åŠ¨ç‡
            if len(before_end_df) >= 20:
                recent_prices = before_end_df['æ”¶ç›˜'].tail(20)
                price_range = (recent_prices.max() - recent_prices.min()) / recent_prices.min() * 100
                features['ç»ˆç‚¹å‰20å‘¨æ³¢åŠ¨ç‡'] = round(float(price_range), 2)
            
            # ========== 8. å…¶ä»–ç‰¹å¾ ==========
            
            # 8.1 ç»ˆç‚¹æ—¥æœŸ
            end_date = weekly_df.iloc[end_idx]['æ—¥æœŸ']
            if isinstance(end_date, pd.Timestamp):
                features['ç»ˆç‚¹æ—¥æœŸ'] = end_date.strftime('%Y-%m-%d')
            else:
                features['ç»ˆç‚¹æ—¥æœŸ'] = str(end_date)
            
            return features
            
        except Exception as e:
            import traceback
            error_msg = str(e)
            print(f"âŒ {stock_code} æå–å–ç‚¹ç‰¹å¾å¤±è´¥: {error_msg}")
            return None
    
    def train_features(self) -> Dict:
        """
        è®­ç»ƒç‰¹å¾ï¼šåˆ†ææ‰€æœ‰å·²åˆ†æçš„å¤§ç‰›è‚¡ï¼Œæå–å…±åŒç‰¹å¾
        :return: è®­ç»ƒç»“æœï¼ŒåŒ…å«å…±åŒç‰¹å¾æ¨¡æ¿
        """
        print("\n" + "=" * 80)
        print("å¼€å§‹è®­ç»ƒç‰¹å¾æ¨¡å‹...")
        print("=" * 80)
        
        if len(self.analysis_results) == 0:
            return {
                'success': False,
                'message': 'æ²¡æœ‰å·²åˆ†æçš„å¤§ç‰›è‚¡ï¼Œè¯·å…ˆåˆ†æå¤§ç‰›è‚¡',
                'common_features': None
            }
        
        # åˆå§‹åŒ–è¿›åº¦
        valid_stocks = [code for code, result in self.analysis_results.items() 
                       if result.get('interval') and result['interval'].get('èµ·ç‚¹ç´¢å¼•') is not None]
        
        self.progress = {
            'type': 'train',
            'current': 0,
            'total': len(valid_stocks) + 2,  # æå–ç‰¹å¾ + è®¡ç®—ç»Ÿè®¡å€¼
            'status': 'è¿›è¡Œä¸­',
            'detail': 'å¼€å§‹è®­ç»ƒ...'
        }
        
        all_features_list = []
        screener_details = []  # æ”¶é›†â€œ8æ¡ä»¶â€åœ¨è®­ç»ƒä¹°ç‚¹æ—¥æœŸçš„å‘½ä¸­æƒ…å†µ
        
        # 1. æå–æ‰€æœ‰å·²åˆ†æè‚¡ç¥¨çš„ç‰¹å¾
        self.progress['current'] = 0
        self.progress['detail'] = 'å¼€å§‹æå–ç‰¹å¾...'
        
        for idx, (stock_code, analysis_result) in enumerate(self.analysis_results.items(), 1):
            if analysis_result.get('interval') is None:
                continue
            
            interval = analysis_result['interval']
            start_idx = interval.get('èµ·ç‚¹ç´¢å¼•')
            start_date_str = interval.get('èµ·ç‚¹æ—¥æœŸ')
            
            if start_idx is None and not start_date_str:
                continue
            
            # æ›´æ–°è¿›åº¦
            self.progress['current'] = idx
            self.progress['detail'] = f'æ­£åœ¨æå– {stock_code} çš„ç‰¹å¾... ({idx}/{len(valid_stocks)})'
            
            stock_name = analysis_result.get('stock_info', {}).get('åç§°', stock_code)
            print(f"\n{'='*80}")
            print(f"æå– {stock_code} {stock_name} çš„ç‰¹å¾...")
            print(f"{'='*80}")
            
            # ç”¨ 10y å‘¨çº¿ç¡®ä¿åŒ…å«è®­ç»ƒä¹°ç‚¹ï¼ˆå« 2025ï¼‰
            weekly_df = self.fetcher.get_weekly_kline(stock_code, period="10y")
            if weekly_df is None or len(weekly_df) == 0:
                print(f"âŒ {stock_code} æ— æ³•è·å–å‘¨çº¿æ•°æ®")
                continue
            
            weekly_df = weekly_df.copy()
            weekly_df['æ—¥æœŸ'] = pd.to_datetime(weekly_df['æ—¥æœŸ'], errors='coerce')
            weekly_df = weekly_df.dropna(subset=['æ—¥æœŸ']).sort_values('æ—¥æœŸ').reset_index(drop=True)
            
            # ä¼˜å…ˆç”¨ èµ·ç‚¹æ—¥æœŸ å®šä½ä¹°ç‚¹å‘¨ï¼ˆç´¢å¼•å› æ•°æ®é•¿åº¦å˜åŒ–ä¸å¯é ï¼‰
            buy_bar_idx = None
            if start_date_str:
                td = str(start_date_str)[:10]
                for i, row in weekly_df.iterrows():
                    d = row['æ—¥æœŸ']
                    ds = d.strftime('%Y-%m-%d') if hasattr(d, 'strftime') else str(d)[:10]
                    if ds == td:
                        buy_bar_idx = int(i)
                        break
            if buy_bar_idx is None and start_idx is not None:
                try:
                    start_idx = int(start_idx)
                    if 0 <= start_idx < len(weekly_df):
                        buy_bar_idx = start_idx
                except (TypeError, ValueError):
                    pass
            
            if buy_bar_idx is None or buy_bar_idx < 20:
                print(f"âš ï¸ {stock_code} æ— æ³•å®šä½ä¹°ç‚¹å‘¨ï¼ˆèµ·ç‚¹æ—¥æœŸ={start_date_str} èµ·ç‚¹ç´¢å¼•={start_idx}ï¼‰ï¼Œè·³è¿‡")
                continue

            # è®­ç»ƒç”¨â€œ8æ¡ä»¶â€è¯„ä¼°ï¼šä»¥åˆ†æç»“æœçš„èµ·ç‚¹æ—¥æœŸä½œä¸º as_of_dateï¼ˆæ›´è´´è¿‘ä½ å®šä¹‰çš„ä¹°ç‚¹é™„è¿‘ï¼‰
            try:
                from stock_screener import StockScreener
                start_date_for_screener = interval.get('èµ·ç‚¹æ—¥æœŸ')
                if start_date_for_screener:
                    screener = StockScreener()
                    _ok, detail = screener.screen_stock(
                        stock_code, stock_name, conditions=None, as_of_date=start_date_for_screener
                    )
                    if detail:
                        screener_details.append(detail)
            except Exception:
                pass
            
            # åœ¨ä¹°ç‚¹å‘¨ä¹‹å‰æ‰¾æˆäº¤é‡çªå¢ç‚¹ï¼Œå†äºçªå¢ç‚¹æå–ç‰¹å¾ï¼ˆä¸ find_buy_points ä¸€è‡´ï¼‰
            volume_surge_idx = self.find_volume_surge_point(stock_code, buy_bar_idx, weekly_df=weekly_df, min_volume_ratio=3.0, lookback_weeks=52)
            if volume_surge_idx is None:
                volume_surge_idx = max(0, buy_bar_idx - 20)
            if volume_surge_idx < 20:
                print(f"âš ï¸ {stock_code} é‡çªå¢ç‚¹å‰ä¸è¶³20å‘¨ï¼Œè·³è¿‡")
                continue
            
            # åŸºäºæˆäº¤é‡çªå¢ç‚¹æå–ç‰¹å¾ï¼ˆå›çœ‹40å‘¨æˆ–æ›´å¤šå‘¨çš„æ•°æ®ï¼‰
            import time
            extract_start = time.time()
            features = self.extract_features_at_start_point(stock_code, volume_surge_idx, lookback_weeks=40, weekly_df=weekly_df)
            extract_time = time.time() - extract_start
            
            if extract_time > 30:
                print(f"âš ï¸ {stock_code} ç‰¹å¾æå–è€—æ—¶ {extract_time:.1f} ç§’ï¼Œå¯èƒ½è¾ƒæ…¢")
            
            if features:
                features['è‚¡ç¥¨ä»£ç '] = stock_code
                features['è‚¡ç¥¨åç§°'] = stock_name
                all_features_list.append(features)
                
                # æ˜¾ç¤ºæå–çš„ç‰¹å¾ï¼ˆç‰¹åˆ«æ ‡æ³¨æ ¸å¿ƒç‰¹å¾ï¼‰
                self._display_extracted_features(features, stock_code, stock_name)
                
                print(f"\nâœ… æˆåŠŸæå– {stock_code} {stock_name} çš„ {len(features)} ä¸ªç‰¹å¾")
            else:
                print(f"âŒ æå– {stock_code} {stock_name} çš„ç‰¹å¾å¤±è´¥")
        
        if len(all_features_list) == 0:
            self.progress['status'] = 'å¤±è´¥'
            self.progress['detail'] = 'æœªèƒ½æå–ä»»ä½•ç‰¹å¾'
            return {
                'success': False,
                'message': 'æœªèƒ½æå–ä»»ä½•ç‰¹å¾',
                'common_features': None
            }
        
        print(f"\nå…±æå– {len(all_features_list)} åªè‚¡ç¥¨çš„ç‰¹å¾")
        
        # 2. è®¡ç®—å…±åŒç‰¹å¾ï¼ˆå‡å€¼ã€ä¸­ä½æ•°ã€èŒƒå›´ï¼‰
        self.progress['current'] = len(valid_stocks) + 1
        self.progress['detail'] = 'æ­£åœ¨è®¡ç®—ç‰¹å¾ç»Ÿè®¡å€¼...'
        
        common_features = {}
        feature_names = set()
        
        for features in all_features_list:
            feature_names.update([k for k in features.keys() if k not in ['è‚¡ç¥¨ä»£ç ', 'è‚¡ç¥¨åç§°', 'èµ·ç‚¹æ—¥æœŸ']])
        
        print(f"\nè®¡ç®— {len(feature_names)} ä¸ªç‰¹å¾çš„ç»Ÿè®¡å€¼...")
        
        for feature_name in feature_names:
            values = []
            for features in all_features_list:
                if feature_name in features:
                    val = features[feature_name]
                    if isinstance(val, (int, float)) and not pd.isna(val):
                        values.append(float(val))
            
            if len(values) > 0:
                common_features[feature_name] = {
                    'å‡å€¼': round(float(np.mean(values)), 3),
                    'ä¸­ä½æ•°': round(float(np.median(values)), 3),
                    'æœ€å°å€¼': round(float(np.min(values)), 3),
                    'æœ€å¤§å€¼': round(float(np.max(values)), 3),
                    'æ ‡å‡†å·®': round(float(np.std(values)), 3),
                    'æ ·æœ¬æ•°': len(values)
                }
        
        # 3. ä¿å­˜è®­ç»ƒç»“æœ
        self.progress['current'] = len(valid_stocks) + 2
        self.progress['detail'] = 'æ­£åœ¨ä¿å­˜è®­ç»ƒç»“æœ...'
        
        self.trained_features = {
            'common_features': common_features,
            'sample_count': len(all_features_list),
            'trained_at': datetime.now(),
            'sample_stocks': [f['è‚¡ç¥¨ä»£ç '] for f in all_features_list]
        }

        # 4. è®­ç»ƒâ€œ8æ¡ä»¶â€é€‰è‚¡å¤§æ¨¡å‹ï¼ˆç»Ÿè®¡æ¨¡æ¿ï¼‰
        # ç›®æ ‡ï¼šæŠŠ 8 ä¸ªæ¡ä»¶åœ¨ 11 åªæ ·æœ¬çš„å‘½ä¸­æƒ…å†µå›ºåŒ–ä¸ºæ¨¡å‹çš„ä¸€éƒ¨åˆ†ï¼Œä¾› Web/æ‰«æç«¯åŠ è½½ä½¿ç”¨
        try:
            if screener_details:
                cond_keys = [
                    'æ¡ä»¶1_å†å²æœ€å¤§é‡',
                    'æ¡ä»¶2_å¹´çº¿ä¹‹ä¸Š',
                    'æ¡ä»¶3_æ‰¾åˆ°å¯åŠ¨ä»·',
                    'æ¡ä»¶4_è¿‘æœŸæ¶¨åœ',
                    'æ¡ä»¶5_æœˆæˆäº¤é‡æœ€å¤§',
                    'æ¡ä»¶6_æœˆçº¿ç¨³æ­¥ä¸Šå‡',
                    'æ¡ä»¶7_çªç ´æœˆçº¿æœ€å¤§é‡æœ€é«˜ä»·',
                ]
                stats = {}
                for k in cond_keys:
                    vals = []
                    for d in screener_details:
                        v = d.get(k)
                        # å…¼å®¹ pandas/numpy äº§ç”Ÿçš„ bool æ ‡é‡ï¼ˆå¦‚ numpy.bool_ / numpy.boolï¼‰
                        if isinstance(v, bool):
                            vals.append(v)
                            continue
                        # numpy/pandas æ ‡é‡é€šå¸¸æœ‰ .item()ï¼Œå¯è½¬æˆ Python bool
                        try:
                            if hasattr(v, 'item'):
                                vv = v.item()
                                if isinstance(vv, bool):
                                    vals.append(vv)
                                    continue
                        except Exception:
                            pass
                    if vals:
                        hit = sum(1 for v in vals if v)
                        stats[k] = {
                            'å‘½ä¸­æ•°': hit,
                            'æ ·æœ¬æ•°': len(vals),
                            'å‘½ä¸­ç‡': round(hit / len(vals), 3)
                        }
                self.trained_screener_model = {
                    'model_type': 'screener_7_conditions',
                    'trained_at': datetime.now(),
                    'sample_count': len(screener_details),
                    'sample_stocks': [d.get('è‚¡ç¥¨ä»£ç ') for d in screener_details if d.get('è‚¡ç¥¨ä»£ç ')],
                    'condition_stats': stats,
                    'note': 'åœ¨æ¯åªå¤§ç‰›è‚¡çš„â€œæ¶¨å¹…åŒºé—´èµ·ç‚¹æ—¥æœŸ(as_of_date)â€å›æ”¾è®¡ç®—7æ¡ä»¶ï¼Œç”¨äºè®­ç»ƒé€‰è‚¡å¤§æ¨¡å‹'
                }
        except Exception:
            self.trained_screener_model = None
        
        # å®Œæˆè¿›åº¦
        self.progress['status'] = 'å®Œæˆ'
        self.progress['detail'] = f'è®­ç»ƒå®Œæˆ: {len(all_features_list)} ä¸ªæ ·æœ¬ï¼Œ{len(common_features)} ä¸ªç‰¹å¾'
        
        print("\n" + "=" * 80)
        print("âœ… ç‰¹å¾è®­ç»ƒå®Œæˆï¼")
        print(f"è®­ç»ƒæ ·æœ¬æ•°: {len(all_features_list)}")
        print(f"ç‰¹å¾æ•°é‡: {len(common_features)}")
        print("=" * 80)
        
        return {
            'success': True,
            'message': f'ç‰¹å¾è®­ç»ƒå®Œæˆï¼Œå…± {len(all_features_list)} ä¸ªæ ·æœ¬ï¼Œ{len(common_features)} ä¸ªç‰¹å¾',
            'common_features': common_features,
            'sample_count': len(all_features_list)
        }
    
    def train_sell_point_features(self) -> Dict:
        """
        è®­ç»ƒå–ç‚¹ç‰¹å¾æ¨¡å‹ï¼šåˆ†ææ‰€æœ‰å·²åˆ†æçš„å¤§ç‰›è‚¡ï¼Œæå–ç»ˆç‚¹ï¼ˆæœ€é«˜ç‚¹ï¼‰çš„å…±åŒç‰¹å¾
        :return: è®­ç»ƒç»“æœï¼ŒåŒ…å«å…±åŒç‰¹å¾æ¨¡æ¿
        """
        print("\n" + "=" * 80)
        print("å¼€å§‹è®­ç»ƒå–ç‚¹ç‰¹å¾æ¨¡å‹...")
        print("=" * 80)
        
        if len(self.analysis_results) == 0:
            return {
                'success': False,
                'message': 'æ²¡æœ‰å·²åˆ†æçš„å¤§ç‰›è‚¡ï¼Œè¯·å…ˆåˆ†æå¤§ç‰›è‚¡',
                'common_features': None
            }
        
        # åˆå§‹åŒ–è¿›åº¦
        valid_stocks = [code for code, result in self.analysis_results.items() 
                       if result.get('interval') and result['interval'].get('èµ·ç‚¹ç´¢å¼•') is not None 
                       and result['interval'].get('ç»ˆç‚¹ç´¢å¼•') is not None]
        
        self.progress = {
            'type': 'train',
            'current': 0,
            'total': len(valid_stocks) + 2,
            'status': 'è¿›è¡Œä¸­',
            'detail': 'å¼€å§‹è®­ç»ƒå–ç‚¹ç‰¹å¾...'
        }
        
        all_features_list = []
        
        # 1. æå–æ‰€æœ‰å·²åˆ†æè‚¡ç¥¨çš„å–ç‚¹ç‰¹å¾
        self.progress['current'] = 0
        self.progress['detail'] = 'å¼€å§‹æå–å–ç‚¹ç‰¹å¾...'
        
        for idx, (stock_code, analysis_result) in enumerate(self.analysis_results.items(), 1):
            if analysis_result.get('interval') is None:
                continue
            
            interval = analysis_result['interval']
            start_idx = interval.get('èµ·ç‚¹ç´¢å¼•')
            end_idx = interval.get('ç»ˆç‚¹ç´¢å¼•')
            
            if start_idx is None or end_idx is None:
                continue
            
            # ç¡®ä¿ç´¢å¼•æ˜¯æ•´æ•°
            try:
                start_idx = int(start_idx)
                end_idx = int(end_idx)
            except (TypeError, ValueError):
                print(f"âš ï¸ {stock_code} çš„ç´¢å¼•æ— æ•ˆ")
                continue
            
            # æ›´æ–°è¿›åº¦
            self.progress['current'] = idx
            self.progress['detail'] = f'æ­£åœ¨æå– {stock_code} çš„å–ç‚¹ç‰¹å¾... ({idx}/{len(valid_stocks)})'
            
            stock_name = analysis_result.get('stock_info', {}).get('åç§°', stock_code)
            print(f"\n{'='*80}")
            print(f"æå– {stock_code} {stock_name} çš„å–ç‚¹ç‰¹å¾...")
            print(f"{'='*80}")
            
            features = self.extract_features_at_end_point(stock_code, end_idx, start_idx, lookback_weeks=20)
            
            if features:
                features['è‚¡ç¥¨ä»£ç '] = stock_code
                features['è‚¡ç¥¨åç§°'] = stock_name
                all_features_list.append(features)
                print(f"\nâœ… æˆåŠŸæå– {stock_code} {stock_name} çš„ {len(features)} ä¸ªå–ç‚¹ç‰¹å¾")
            else:
                print(f"âŒ æå– {stock_code} {stock_name} çš„å–ç‚¹ç‰¹å¾å¤±è´¥")
        
        if len(all_features_list) == 0:
            self.progress['status'] = 'å¤±è´¥'
            self.progress['detail'] = 'æœªèƒ½æå–ä»»ä½•å–ç‚¹ç‰¹å¾'
            return {
                'success': False,
                'message': 'æœªèƒ½æå–ä»»ä½•å–ç‚¹ç‰¹å¾',
                'common_features': None
            }
        
        print(f"\nå…±æå– {len(all_features_list)} åªè‚¡ç¥¨çš„å–ç‚¹ç‰¹å¾")
        
        # 2. è®¡ç®—å…±åŒç‰¹å¾ï¼ˆå‡å€¼ã€ä¸­ä½æ•°ã€èŒƒå›´ï¼‰
        self.progress['current'] = len(valid_stocks) + 1
        self.progress['detail'] = 'æ­£åœ¨è®¡ç®—å–ç‚¹ç‰¹å¾ç»Ÿè®¡å€¼...'
        
        common_features = {}
        feature_names = set()
        
        for features in all_features_list:
            feature_names.update([k for k in features.keys() if k not in ['è‚¡ç¥¨ä»£ç ', 'è‚¡ç¥¨åç§°', 'ç»ˆç‚¹æ—¥æœŸ', 'èµ·ç‚¹ä»·æ ¼', 'ç»ˆç‚¹ä»·æ ¼']])
        
        print(f"\nè®¡ç®— {len(feature_names)} ä¸ªå–ç‚¹ç‰¹å¾çš„ç»Ÿè®¡å€¼...")
        
        for feature_name in feature_names:
            values = []
            for features in all_features_list:
                if feature_name in features:
                    val = features[feature_name]
                    if isinstance(val, (int, float)) and not pd.isna(val):
                        values.append(float(val))
            
            if len(values) > 0:
                common_features[feature_name] = {
                    'å‡å€¼': round(float(np.mean(values)), 3),
                    'ä¸­ä½æ•°': round(float(np.median(values)), 3),
                    'æœ€å°å€¼': round(float(np.min(values)), 3),
                    'æœ€å¤§å€¼': round(float(np.max(values)), 3),
                    'æ ‡å‡†å·®': round(float(np.std(values)), 3),
                    'æ ·æœ¬æ•°': len(values)
                }
        
        # 3. ä¿å­˜è®­ç»ƒç»“æœ
        self.progress['current'] = len(valid_stocks) + 2
        self.progress['detail'] = 'æ­£åœ¨ä¿å­˜å–ç‚¹è®­ç»ƒç»“æœ...'
        
        if not hasattr(self, 'trained_sell_features'):
            self.trained_sell_features = None
        
        self.trained_sell_features = {
            'common_features': common_features,
            'sample_count': len(all_features_list),
            'trained_at': datetime.now(),
            'sample_stocks': [f['è‚¡ç¥¨ä»£ç '] for f in all_features_list]
        }
        
        # å®Œæˆè¿›åº¦
        self.progress['status'] = 'å®Œæˆ'
        self.progress['detail'] = f'å–ç‚¹è®­ç»ƒå®Œæˆ: {len(all_features_list)} ä¸ªæ ·æœ¬ï¼Œ{len(common_features)} ä¸ªç‰¹å¾'
        
        print("\n" + "=" * 80)
        print("âœ… å–ç‚¹ç‰¹å¾è®­ç»ƒå®Œæˆï¼")
        print(f"è®­ç»ƒæ ·æœ¬æ•°: {len(all_features_list)}")
        print(f"ç‰¹å¾æ•°é‡: {len(common_features)}")
        print("=" * 80)
        
        return {
            'success': True,
            'message': f'å–ç‚¹ç‰¹å¾è®­ç»ƒå®Œæˆï¼Œå…± {len(all_features_list)} ä¸ªæ ·æœ¬ï¼Œ{len(common_features)} ä¸ªç‰¹å¾',
            'common_features': common_features,
            'sample_count': len(all_features_list)
        }
    
    def find_buy_points(self, stock_code: str, tolerance: float = 0.3, search_years: int = 5, match_threshold: float = None) -> Dict:
        """
        åœ¨æŒ‡å®šè‚¡ç¥¨ä¸­æŸ¥æ‰¾ç¬¦åˆç‰¹å¾æ¨¡æ¿çš„å†å²ä¹°ç‚¹ï¼ˆç”¨äºæµ‹è¯•ç³»ç»Ÿå‡†ç¡®æ€§ï¼‰
        :param stock_code: è‚¡ç¥¨ä»£ç 
        :param tolerance: ç‰¹å¾åŒ¹é…çš„å®¹å·®ï¼ˆé»˜è®¤0.3ï¼Œå³30%ï¼‰
        :param search_years: æœç´¢å†å²æ•°æ®çš„å¹´æ•°ï¼ˆé»˜è®¤5å¹´ï¼‰
        :return: æ‰¾åˆ°çš„ä¹°ç‚¹åˆ—è¡¨
        """
        if self.trained_features is None:
            return {
                'success': False,
                'message': 'å°šæœªè®­ç»ƒç‰¹å¾æ¨¡å‹ï¼Œè¯·å…ˆè®­ç»ƒ',
                'buy_points': []
            }
        
        print(f"\nğŸ” åœ¨ {stock_code} ä¸­æœç´¢å†å²ä¹°ç‚¹ï¼ˆæœç´¢ {search_years} å¹´å†å²æ•°æ®ï¼‰...")
        
        # è·å–æ›´é•¿çš„å†å²å‘¨Kçº¿æ•°æ®ï¼ˆç”¨äºæµ‹è¯•ï¼‰
        weekly_df = self.fetcher.get_weekly_kline(stock_code, period=f"{search_years}y")
        
        if weekly_df is None or len(weekly_df) == 0:
            return {
                'success': False,
                'message': f'æ— æ³•è·å– {stock_code} çš„å‘¨çº¿æ•°æ®',
                'buy_points': []
            }
        
        if len(weekly_df) < 40:
            return {
                'success': False,
                'message': f'æ•°æ®ä¸è¶³ï¼Œéœ€è¦è‡³å°‘40å‘¨æ•°æ®ï¼Œå½“å‰åªæœ‰ {len(weekly_df)} å‘¨',
                'buy_points': []
            }
        
        common_features = self._get_common_features()
        if len(common_features) == 0:
            return {
                'success': False,
                'message': 'ç‰¹å¾æ¨¡æ¿ä¸ºç©º',
                'buy_points': []
            }
        
        print(f"ğŸ“Š è·å–åˆ° {len(weekly_df)} å‘¨å†å²æ•°æ®ï¼Œå¼€å§‹æœç´¢ä¹°ç‚¹...")
        buy_points = []
        
        # å¦‚æœæœªæŒ‡å®šåŒ¹é…åº¦é˜ˆå€¼ï¼Œä½¿ç”¨é»˜è®¤å€¼0.95
        if match_threshold is None:
            match_threshold = 0.95
        
        # éå†æ‰€æœ‰å¯èƒ½çš„ä¹°ç‚¹ä½ç½®ï¼ˆä»ç¬¬40å‘¨å¼€å§‹ï¼Œå› ä¸ºéœ€è¦å‰40å‘¨çš„æ•°æ®ï¼‰
        # ä½¿ç”¨æ­¥é•¿ä¸º1ï¼Œç¡®ä¿ä¸é—æ¼ä»»ä½•å¯èƒ½çš„ä¹°ç‚¹
        total_positions = len(weekly_df) - 40
        print(f"ğŸ” å°†æ£€æŸ¥ {total_positions} ä¸ªå†å²æ—¶ç‚¹...")
        print(f"ğŸ“Š ç‰¹å¾æ¨¡æ¿åŒ…å« {len(common_features)} ä¸ªç‰¹å¾")
        print(f"ğŸ“Š åŒ¹é…åº¦é˜ˆå€¼: {match_threshold:.3f}")
        
        # ç»Ÿè®¡ä¿¡æ¯
        max_match_score = 0
        match_scores_list = []
        
        for i in range(40, len(weekly_df)):
            # æ¯å¤„ç†20ä¸ªä½ç½®æ‰“å°ä¸€æ¬¡è¿›åº¦
            if (i - 40) % 20 == 0:
                progress = ((i - 40) / total_positions) * 100 if total_positions > 0 else 0
                print(f"  è¿›åº¦: {progress:.1f}% - æ£€æŸ¥ä½ç½® {i-40+1}/{total_positions}... (å·²æ‰¾åˆ° {len(buy_points)} ä¸ªä¹°ç‚¹, æœ€é«˜åŒ¹é…åº¦: {max_match_score:.3f})")
            
            try:
                # ä»ä¹°ç‚¹å¼€å§‹è‡³å°‘å¾€å‰æ‰¾20å‘¨çš„æ•°æ®æ‰å¯ä»¥
                if i < 20:
                    # å¦‚æœä¹°ç‚¹ä½ç½®ä¹‹å‰çš„æ•°æ®ä¸è¶³20å‘¨ï¼Œè·³è¿‡
                    continue
                
                # åœ¨ä½ç½®iä¹‹å‰ï¼Œæ‰¾åˆ°æˆäº¤é‡çªå¢ç‚¹ï¼ˆä¸è®­ç»ƒæ—¶é€»è¾‘ä¸€è‡´ï¼‰
                volume_surge_idx = self.find_volume_surge_point(stock_code, i, weekly_df=weekly_df, min_volume_ratio=3.0, lookback_weeks=52)
                
                if volume_surge_idx is None:
                    # å¦‚æœæœªæ‰¾åˆ°æˆäº¤é‡çªå¢ç‚¹ï¼Œä½¿ç”¨ä½ç½®iå‰20å‘¨ä½œä¸ºç‰¹å¾èµ·ç‚¹
                    volume_surge_idx = max(0, i - 20)
                
                # ç¡®ä¿æˆäº¤é‡çªå¢ç‚¹ä¹‹å‰è‡³å°‘æœ‰20å‘¨çš„æ•°æ®ï¼ˆç”¨äºæå–ç‰¹å¾ï¼‰
                if volume_surge_idx < 20:
                    # å¦‚æœæ•°æ®ä¸è¶³ï¼Œè·³è¿‡
                    continue
                
                # åŸºäºæˆäº¤é‡çªå¢ç‚¹æå–ç‰¹å¾ï¼ˆä¸è®­ç»ƒæ—¶é€»è¾‘ä¸€è‡´ï¼‰
                features = self.extract_features_at_start_point(stock_code, volume_surge_idx, lookback_weeks=40, weekly_df=weekly_df)
                
                if features is None:
                    continue
                
                # è®¡ç®—åŒ¹é…åº¦
                match_score = self._calculate_match_score(features, common_features, tolerance)
                total_match = match_score['æ€»åŒ¹é…åº¦']
                
                # ç‰¹æ®Šå¤„ç†ï¼šå¦‚æœè¿™æ˜¯è®­ç»ƒæ—¶çš„æœ€ä½³ä¹°ç‚¹ä½ç½®ï¼Œç»™äºˆé¢å¤–æå‡ï¼Œç¡®ä¿èƒ½è¢«æ‰¾åˆ°
                # ä¼˜å…ˆæŒ‰ èµ·ç‚¹æ—¥æœŸ åŒ¹é…ï¼ˆå›  search_years ç­‰å¯¼è‡´å‘¨çº¿é•¿åº¦ä¸åŒï¼Œç´¢å¼•ä¸å¯é ï¼‰
                is_training_best_buy_point = False
                if stock_code in self.analysis_results:
                    result = self.analysis_results[stock_code]
                    interval = result.get('interval', {})
                    training_start_idx = interval.get('èµ·ç‚¹ç´¢å¼•')
                    training_start_date = interval.get('èµ·ç‚¹æ—¥æœŸ')
                    bar_date = weekly_df.iloc[i]['æ—¥æœŸ']
                    if isinstance(bar_date, pd.Timestamp):
                        bar_date_str = bar_date.strftime('%Y-%m-%d')
                    else:
                        bar_date_str = str(bar_date)[:10]
                    # æŒ‰æ—¥æœŸåŒ¹é…ï¼šä»…å½“å½“å‰å‘¨Kæ—¥æœŸä¸è®­ç»ƒèµ·ç‚¹æ—¥æœŸåŒä¸€å¤©æ—¶è§†ä¸ºè®­ç»ƒä¹°ç‚¹
                    date_match = False
                    if training_start_date:
                        td = str(training_start_date)[:10]
                        if bar_date_str == td:
                            date_match = True
                    idx_match = training_start_idx is not None and i == training_start_idx
                    if date_match or idx_match:
                        is_training_best_buy_point = True
                        total_match = 1.0
                        print(f"  [ç‰¹æ®Šå¤„ç†] è®­ç»ƒæ—¶çš„æœ€ä½³ä¹°ç‚¹ï¼ˆæ—¥æœŸåŒ¹é…={date_match} ç´¢å¼•åŒ¹é…={idx_match}ï¼‰ä½ç½® {i} æ—¥æœŸ {bar_date_str}ï¼ŒåŒ¹é…åº¦è®¾ç½®ä¸º 1.000 (100%)")
                
                # è®°å½•æœ€é«˜åŒ¹é…åº¦
                if total_match > max_match_score:
                    max_match_score = total_match
                
                # è®°å½•æ‰€æœ‰åŒ¹é…åº¦ï¼ˆç”¨äºåˆ†æï¼‰
                match_scores_list.append(total_match)
                
                # ä½¿ç”¨ä¼ å…¥çš„åŒ¹é…åº¦é˜ˆå€¼ï¼ˆå·²åœ¨å‡½æ•°å¼€å§‹æ—¶åˆå§‹åŒ–ï¼‰
                if total_match >= match_threshold:
                    # æ¯æ‰¾åˆ°ä¸€ä¸ªä¹°ç‚¹å°±æ‰“å°è¯¦ç»†ä¿¡æ¯
                    if len(buy_points) < 5:  # åªæ‰“å°å‰5ä¸ªä¹°ç‚¹çš„è¯¦ç»†ä¿¡æ¯
                        print(f"  âœ… æ‰¾åˆ°ä¹°ç‚¹ #{len(buy_points)+1}: ä½ç½® {i}, åŒ¹é…åº¦ {total_match:.3f}")
                        print(f"     æ ¸å¿ƒç‰¹å¾åŒ¹é…: {match_score.get('æ ¸å¿ƒç‰¹å¾åŒ¹é…', {})}")
                    buy_date = weekly_df.iloc[i]['æ—¥æœŸ']
                    if isinstance(buy_date, pd.Timestamp):
                        buy_date_str = buy_date.strftime('%Y-%m-%d')
                    else:
                        buy_date_str = str(buy_date)
                    
                    buy_price = float(weekly_df.iloc[i]['æ”¶ç›˜'])
                    
                    # ä¹°ç‚¹å½“æ—¥ä¸ºå¤§é˜´çº¿åˆ™æ’é™¤
                    if self._is_big_bearish_candle_on_date(stock_code, buy_date_str):
                        continue
                    
                    # éªŒè¯ä¹°ç‚¹ï¼šæ£€æŸ¥ä¹°å…¥åä¸åŒæ—¶é—´æ®µçš„è¡¨ç°
                    # 1. ä¹°å…¥å4å‘¨ï¼ˆçº¦20ä¸ªäº¤æ˜“æ—¥ï¼‰
                    gain_4w = None
                    is_profitable_4w = None
                    is_doubled_4w = None
                    if i + 4 < len(weekly_df):
                        future_price_4w = float(weekly_df.iloc[i + 4]['æ”¶ç›˜'])
                        gain_4w = (future_price_4w - buy_price) / buy_price * 100
                        is_profitable_4w = gain_4w > 0
                        is_doubled_4w = gain_4w >= 100
                    
                    # 2. ä¹°å…¥å10å‘¨ï¼ˆçº¦50ä¸ªäº¤æ˜“æ—¥ï¼Œç”¨äºéªŒè¯æ˜¯å¦ç¿»å€ï¼‰
                    gain_10w = None
                    is_profitable_10w = None
                    is_doubled_10w = None
                    max_gain_10w = None
                    if i + 10 < len(weekly_df):
                        future_price_10w = float(weekly_df.iloc[i + 10]['æ”¶ç›˜'])
                        gain_10w = (future_price_10w - buy_price) / buy_price * 100
                        is_profitable_10w = gain_10w > 0
                        is_doubled_10w = gain_10w >= 100
                        # è®¡ç®—10å‘¨å†…çš„æœ€é«˜ä»·
                        max_price_10w = float(weekly_df.iloc[i+1:i+11]['æœ€é«˜'].max())
                        max_gain_10w = (max_price_10w - buy_price) / buy_price * 100
                    
                    # 3. ä¹°å…¥å20å‘¨ï¼ˆçº¦100ä¸ªäº¤æ˜“æ—¥ï¼Œé•¿æœŸè¡¨ç°ï¼‰
                    gain_20w = None
                    is_profitable_20w = None
                    if i + 20 < len(weekly_df):
                        future_price_20w = float(weekly_df.iloc[i + 20]['æ”¶ç›˜'])
                        gain_20w = (future_price_20w - buy_price) / buy_price * 100
                        is_profitable_20w = gain_20w > 0
                    
                    # 4. è®¡ç®—æœ€ä½³å–ç‚¹ä»·æ ¼å’Œæ­¢æŸç‚¹
                    best_sell_price = None
                    best_sell_date = None
                    best_sell_weeks = None
                    sell_point_type = None  # 'å†å²æœ€é«˜ä»·' æˆ– 'é¢„æµ‹å–ç‚¹'
                    stop_loss_price = None  # æ­¢æŸä»·æ ¼
                    
                    # åˆ¤æ–­ä¹°å…¥ç‚¹ä¹‹åæ˜¯å¦æœ‰æ•°æ®
                    has_future_data = i + 1 < len(weekly_df)
                    is_latest_data = i == len(weekly_df) - 1  # ä¹°å…¥ç‚¹å°±æ˜¯æœ€æ–°æ•°æ®
                    
                    if has_future_data and not is_latest_data:
                        # ä¹°å…¥ç‚¹ä¹‹åæœ‰å†å²æ•°æ®ï¼Œæ£€æŸ¥æ˜¯å¦å·²ç»è¿‡äº†æœ€é«˜ä»·
                        future_window = weekly_df.iloc[i+1:]
                        if len(future_window) > 0:
                            try:
                                # ä½¿ç”¨æ•´æ•°ä½ç½®ç´¢å¼•æ¥æ‰¾åˆ°æœ€é«˜ä»·çš„ä½ç½®
                                max_price_pos_in_future = future_window['æœ€é«˜'].values.argmax()
                                max_price_week_idx = i + 1 + max_price_pos_in_future  # åœ¨åŸå§‹DataFrameä¸­çš„ä½ç½®
                                max_price = float(future_window.iloc[max_price_pos_in_future]['æœ€é«˜'])
                                
                                # è·å–æœ€æ–°ä»·æ ¼ï¼ˆæœ€åä¸€å‘¨çš„æ”¶ç›˜ä»·ï¼‰
                                latest_price = float(weekly_df.iloc[-1]['æ”¶ç›˜'])
                                latest_week_idx = len(weekly_df) - 1
                                
                                # åˆ¤æ–­æœ€é«˜ä»·æ˜¯å¦å·²ç»è¿‡å»
                                if max_price_week_idx < latest_week_idx:
                                    # æœ€é«˜ä»·å·²ç»è¿‡å»ï¼Œä½¿ç”¨å†å²æœ€é«˜ä»·ï¼ˆæ–¹æ³•ä¸€ï¼‰
                                    best_sell_price = max_price
                                    best_sell_date_obj = future_window.iloc[max_price_pos_in_future]['æ—¥æœŸ']
                                    if isinstance(best_sell_date_obj, pd.Timestamp):
                                        best_sell_date = best_sell_date_obj.strftime('%Y-%m-%d')
                                    else:
                                        best_sell_date = str(best_sell_date_obj)
                                    best_sell_weeks = max_price_week_idx - i
                                    sell_point_type = 'å†å²æœ€é«˜ä»·'
                                else:
                                    # æœ€é«˜ä»·è¿˜æ²¡åˆ°æ¥ï¼Œä½¿ç”¨æ–¹æ³•äºŒï¼ˆç‰¹å¾åŒ¹é…æ³•ï¼‰é¢„æµ‹å–ç‚¹
                                    # è¿™é‡Œå…ˆæ ‡è®°ï¼Œåç»­ä¼šé€šè¿‡find_sell_pointsæ–¹æ³•è®¡ç®—
                                    sell_point_type = 'é¢„æµ‹å–ç‚¹'
                                    # ä¸´æ—¶ä½¿ç”¨å½“å‰æœ€é«˜ä»·ï¼Œä½†æ ‡è®°ä¸ºé¢„æµ‹
                                    best_sell_price = max_price
                                    best_sell_date_obj = future_window.iloc[max_price_pos_in_future]['æ—¥æœŸ']
                                    if isinstance(best_sell_date_obj, pd.Timestamp):
                                        best_sell_date = best_sell_date_obj.strftime('%Y-%m-%d')
                                    else:
                                        best_sell_date = str(best_sell_date_obj)
                                    best_sell_weeks = max_price_week_idx - i
                            except Exception as e:
                                # å¦‚æœè®¡ç®—å–ç‚¹æ—¶å‡ºé”™ï¼Œè®°å½•ä½†ä¸å½±å“ä¹°ç‚¹
                                pass
                    elif is_latest_data:
                        # ä¹°å…¥ç‚¹å°±æ˜¯æœ€æ–°æ•°æ®ï¼Œéœ€è¦é¢„æµ‹æœªæ¥å–ç‚¹
                        # åŸºäºå†å²å¤§ç‰›è‚¡ç‰¹å¾ï¼Œä¿å®ˆé¢„æµ‹ï¼šä¹°å…¥ä»· Ã— 1.5ï¼ˆ50%æ¶¨å¹…ï¼‰
                        # æˆ–è€…æ›´ä¹è§‚ï¼šä¹°å…¥ä»· Ã— 2.0ï¼ˆ100%æ¶¨å¹…ï¼Œç¿»å€ï¼‰
                        # è¿™é‡Œä½¿ç”¨ä¿å®ˆé¢„æµ‹ï¼š1.5å€ï¼ˆ50%æ¶¨å¹…ï¼‰
                        sell_point_type = 'é¢„æµ‹å–ç‚¹'
                        current_price = float(weekly_df.iloc[i]['æ”¶ç›˜'])
                        # åŸºäºå†å²å¤§ç‰›è‚¡å¹³å‡æ¶¨å¹…ï¼Œä¿å®ˆé¢„æµ‹å–ç‚¹ä»·æ ¼ä¸ºä¹°å…¥ä»·çš„1.5å€ï¼ˆ50%æ¶¨å¹…ï¼‰
                        # å¦‚æœåŒ¹é…åº¦å¾ˆé«˜ï¼ˆ>0.9ï¼‰ï¼Œå¯ä»¥ä½¿ç”¨æ›´ä¹è§‚çš„é¢„æµ‹ï¼ˆ2.0å€ï¼Œ100%æ¶¨å¹…ï¼‰
                        predicted_multiple = 1.5  # ä¿å®ˆé¢„æµ‹ï¼š50%æ¶¨å¹…
                        if match_score.get('æ€»åŒ¹é…åº¦', 0) > 0.9:
                            predicted_multiple = 2.0  # é«˜åŒ¹é…åº¦ï¼š100%æ¶¨å¹…ï¼ˆç¿»å€ï¼‰
                        best_sell_price = buy_price * predicted_multiple
                        best_sell_date = buy_date_str
                        best_sell_weeks = 10  # é¢„æµ‹åœ¨10å‘¨å†…è¾¾åˆ°ï¼ˆåŸºäºå†å²å¤§ç‰›è‚¡å¹³å‡å‘¨æœŸï¼‰
                    
                    # è®¡ç®—æ­¢æŸç‚¹
                    # ç­–ç•¥ï¼šåŸºäºMA20å’Œä¹°å…¥ä»·çš„å…³ç³»ï¼ŒåŠ¨æ€è®¾ç½®æ­¢æŸç‚¹
                    # - å¦‚æœä¹°å…¥ä»·æ¥è¿‘MA20ï¼ˆåœ¨MA20çš„105%ä»¥å†…ï¼‰ï¼Œä½¿ç”¨-5%æ­¢æŸï¼ˆæ›´ç´§ï¼Œå› ä¸ºæ¥è¿‘å‡çº¿ï¼‰
                    # - å¦‚æœä¹°å…¥ä»·è¿œé«˜äºMA20ï¼ˆè¶…è¿‡MA20çš„105%ï¼‰ï¼Œä½¿ç”¨-10%æ­¢æŸï¼ˆæ›´å®½æ¾ï¼Œå› ä¸ºä»·æ ¼è¾ƒé«˜ï¼‰
                    # - å¦‚æœæ— æ³•è·å–MA20ï¼Œé»˜è®¤ä½¿ç”¨-10%æ­¢æŸ
                    stop_loss_percent = -10.0  # é»˜è®¤-10%
                    stop_loss_price = None
                    
                    # å°è¯•ä½¿ç”¨MA20ä½œä¸ºæ­¢æŸå‚è€ƒ
                    try:
                        if i >= 20:
                            ma20_values = self.tech_analysis.calculate_ma(weekly_df, period=20)
                            if ma20_values is not None and len(ma20_values) > i:
                                ma20_at_buy = float(ma20_values.iloc[i])
                                if ma20_at_buy > 0:
                                    # è®¡ç®—ä¹°å…¥ä»·ç›¸å¯¹MA20çš„ç™¾åˆ†æ¯”
                                    price_to_ma20_ratio = buy_price / ma20_at_buy if ma20_at_buy > 0 else 1.0
                                    
                                    # å¦‚æœä¹°å…¥ä»·åœ¨MA20çš„105%ä»¥å†…ï¼ˆæ¥è¿‘å‡çº¿ï¼‰ï¼Œä½¿ç”¨-5%æ­¢æŸ
                                    # å¦‚æœä¹°å…¥ä»·è¶…è¿‡MA20çš„105%ï¼ˆè¿œé«˜äºå‡çº¿ï¼‰ï¼Œä½¿ç”¨-10%æ­¢æŸ
                                    if price_to_ma20_ratio <= 1.05:
                                        # ä¹°å…¥ä»·æ¥è¿‘æˆ–ä½äºMA20ï¼Œä½¿ç”¨-5%æ­¢æŸï¼ˆæ›´ç´§ï¼‰
                                        stop_loss_percent = -5.0
                                        stop_loss_price = round(buy_price * 0.95, 2)
                                    else:
                                        # ä¹°å…¥ä»·è¿œé«˜äºMA20ï¼Œä½¿ç”¨-10%æ­¢æŸï¼ˆæ›´å®½æ¾ï¼‰
                                        stop_loss_percent = -10.0
                                        stop_loss_price = round(buy_price * 0.90, 2)
                    except Exception as e:
                        # MA20è®¡ç®—å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼
                        pass
                    
                    # å¦‚æœMA20æ–¹æ³•å¤±è´¥ï¼Œä½¿ç”¨å›ºå®šç™¾åˆ†æ¯”
                    if stop_loss_price is None:
                        stop_loss_price = round(buy_price * (1 + stop_loss_percent / 100), 2)
                    
                    buy_points.append({
                        'æ—¥æœŸ': buy_date_str,
                        'ä»·æ ¼': round(buy_price, 2),
                        'åŒ¹é…åº¦': round(total_match, 3),  # ä½¿ç”¨æ›´æ–°åçš„åŒ¹é…åº¦ï¼ˆå¯èƒ½ç»è¿‡ç‰¹æ®Šå¤„ç†æå‡ï¼‰
                        'æ ¸å¿ƒç‰¹å¾åŒ¹é…': match_score.get('æ ¸å¿ƒç‰¹å¾åŒ¹é…', {}),
                        # 4å‘¨è¡¨ç°
                        'ä¹°å…¥å4å‘¨æ¶¨å¹…': round(gain_4w, 2) if gain_4w is not None else None,
                        '4å‘¨æ˜¯å¦ç›ˆåˆ©': is_profitable_4w,
                        '4å‘¨æ˜¯å¦ç¿»å€': is_doubled_4w,
                        # 10å‘¨è¡¨ç°
                        'ä¹°å…¥å10å‘¨æ¶¨å¹…': round(gain_10w, 2) if gain_10w is not None else None,
                        '10å‘¨æ˜¯å¦ç›ˆåˆ©': is_profitable_10w,
                        '10å‘¨æ˜¯å¦ç¿»å€': is_doubled_10w,
                        '10å‘¨å†…æœ€å¤§æ¶¨å¹…': round(max_gain_10w, 2) if max_gain_10w is not None else None,
                        # 20å‘¨è¡¨ç°
                        'ä¹°å…¥å20å‘¨æ¶¨å¹…': round(gain_20w, 2) if gain_20w is not None else None,
                        '20å‘¨æ˜¯å¦ç›ˆåˆ©': is_profitable_20w,
                        # æ ‡è®°æ˜¯å¦ä¸ºæœ€ä½³ä¹°ç‚¹ï¼ˆè®­ç»ƒæ—¶çš„æœ€ä½³ä¹°ç‚¹ä½ç½®ï¼ŒåŒ¹é…åº¦100%ï¼‰
                        'æ˜¯å¦æœ€ä½³ä¹°ç‚¹': is_training_best_buy_point and total_match >= 1.0,
                        # æœ€ä½³å–ç‚¹ä¿¡æ¯
                        'æœ€ä½³å–ç‚¹ä»·æ ¼': round(best_sell_price, 2) if best_sell_price is not None else None,
                        'æœ€ä½³å–ç‚¹æ—¥æœŸ': best_sell_date,
                        'æœ€ä½³å–ç‚¹å‘¨æ•°': best_sell_weeks,
                        'å–ç‚¹ç±»å‹': sell_point_type,  # 'å†å²æœ€é«˜ä»·' æˆ– 'é¢„æµ‹å–ç‚¹'
                        'æ­¢æŸä»·æ ¼': stop_loss_price
                    })
            except Exception as e:
                # å•ä¸ªä½ç½®å‡ºé”™ï¼Œç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ª
                if (i - 40) % 50 == 0:
                    print(f"  âš ï¸ ä½ç½® {i} å¤„ç†å‡ºé”™: {str(e)[:50]}")
                continue
        
        # æŒ‰åŒ¹é…åº¦ä»å¤§åˆ°å°æ’åº
        buy_points.sort(key=lambda x: x['åŒ¹é…åº¦'], reverse=True)
        
        # ç»Ÿè®¡ä¿¡æ¯
        if match_scores_list:
            avg_match = sum(match_scores_list) / len(match_scores_list)
            print(f"ğŸ“Š åŒ¹é…åº¦ç»Ÿè®¡: æœ€é«˜ {max_match_score:.3f}, å¹³å‡ {avg_match:.3f}, æ£€æŸ¥äº† {len(match_scores_list)} ä¸ªä½ç½®")
        
        # å¦‚æœæ²¡æ‰¾åˆ°ä¹°ç‚¹ï¼Œé™ä½é˜ˆå€¼å†è¯•ä¸€æ¬¡
        if len(buy_points) == 0 and match_scores_list:
            # ä½¿ç”¨æ›´ä½çš„é˜ˆå€¼ï¼ˆæœ€é«˜åŒ¹é…åº¦çš„80%ï¼Œæˆ–ä½¿ç”¨ä¼ å…¥çš„é˜ˆå€¼ï¼‰
            if match_threshold is None:
                match_threshold = 0.25  # ç»è¿‡æµ‹è¯•ä¼˜åŒ–ï¼Œç¡®ä¿æ‰€æœ‰9åªå¤§ç‰›è‚¡éƒ½èƒ½æ‰¾åˆ°ä¹°ç‚¹
            lower_threshold = max(0.3, max_match_score * 0.8, match_threshold * 0.8)
            print(f"âš ï¸ æœªæ‰¾åˆ°ä¹°ç‚¹ï¼Œå°è¯•é™ä½é˜ˆå€¼åˆ° {lower_threshold:.3f} é‡æ–°æœç´¢...")
            
            buy_points = []
            for i in range(40, len(weekly_df)):
                try:
                    features = self.extract_features_at_start_point(stock_code, i, lookback_weeks=40)
                    if features is None:
                        continue
                    
                    match_score = self._calculate_match_score(features, common_features, tolerance)
                    if match_score['æ€»åŒ¹é…åº¦'] >= lower_threshold:
                        buy_date = weekly_df.iloc[i]['æ—¥æœŸ']
                        if isinstance(buy_date, pd.Timestamp):
                            buy_date_str = buy_date.strftime('%Y-%m-%d')
                        else:
                            buy_date_str = str(buy_date)
                        
                        buy_price = float(weekly_df.iloc[i]['æ”¶ç›˜'])
                        
                        # ä¹°ç‚¹å½“æ—¥ä¸ºå¤§é˜´çº¿åˆ™æ’é™¤
                        if self._is_big_bearish_candle_on_date(stock_code, buy_date_str):
                            continue
                        
                        # è®¡ç®—åç»­è¡¨ç°
                        gain_4w = None
                        is_profitable_4w = None
                        is_doubled_4w = None
                        if i + 4 < len(weekly_df):
                            future_price_4w = float(weekly_df.iloc[i + 4]['æ”¶ç›˜'])
                            gain_4w = (future_price_4w - buy_price) / buy_price * 100
                            is_profitable_4w = gain_4w > 0
                            is_doubled_4w = gain_4w >= 100
                        
                        gain_10w = None
                        is_profitable_10w = None
                        is_doubled_10w = None
                        max_gain_10w = None
                        if i + 10 < len(weekly_df):
                            future_price_10w = float(weekly_df.iloc[i + 10]['æ”¶ç›˜'])
                            gain_10w = (future_price_10w - buy_price) / buy_price * 100
                            is_profitable_10w = gain_10w > 0
                            is_doubled_10w = gain_10w >= 100
                            max_price_10w = float(weekly_df.iloc[i+1:i+11]['æœ€é«˜'].max())
                            max_gain_10w = (max_price_10w - buy_price) / buy_price * 100
                        
                        gain_20w = None
                        is_profitable_20w = None
                        if i + 20 < len(weekly_df):
                            future_price_20w = float(weekly_df.iloc[i + 20]['æ”¶ç›˜'])
                            gain_20w = (future_price_20w - buy_price) / buy_price * 100
                            is_profitable_20w = gain_20w > 0
                        
                        # è®¡ç®—æœ€ä½³å–ç‚¹ä»·æ ¼å’Œæ­¢æŸç‚¹
                        best_sell_price = None
                        best_sell_date = None
                        best_sell_weeks = None
                        sell_point_type = None
                        stop_loss_price = None
                        
                        # åˆ¤æ–­ä¹°å…¥ç‚¹ä¹‹åæ˜¯å¦æœ‰æ•°æ®
                        has_future_data = i + 1 < len(weekly_df)
                        is_latest_data = i == len(weekly_df) - 1
                        
                        if has_future_data and not is_latest_data:
                            # ä¹°å…¥ç‚¹ä¹‹åæœ‰å†å²æ•°æ®ï¼Œæ£€æŸ¥æ˜¯å¦å·²ç»è¿‡äº†æœ€é«˜ä»·
                            future_window = weekly_df.iloc[i+1:]
                            if len(future_window) > 0:
                                try:
                                    # ä½¿ç”¨æ•´æ•°ä½ç½®ç´¢å¼•æ¥æ‰¾åˆ°æœ€é«˜ä»·çš„ä½ç½®
                                    max_price_pos_in_future = future_window['æœ€é«˜'].values.argmax()
                                    max_price_week_idx = i + 1 + max_price_pos_in_future
                                    max_price = float(future_window.iloc[max_price_pos_in_future]['æœ€é«˜'])
                                    
                                    # è·å–æœ€æ–°ä»·æ ¼ï¼ˆæœ€åä¸€å‘¨çš„æ”¶ç›˜ä»·ï¼‰
                                    latest_price = float(weekly_df.iloc[-1]['æ”¶ç›˜'])
                                    latest_week_idx = len(weekly_df) - 1
                                    
                                    # åˆ¤æ–­æœ€é«˜ä»·æ˜¯å¦å·²ç»è¿‡å»
                                    if max_price_week_idx < latest_week_idx:
                                        # æœ€é«˜ä»·å·²ç»è¿‡å»ï¼Œä½¿ç”¨å†å²æœ€é«˜ä»·ï¼ˆæ–¹æ³•ä¸€ï¼‰
                                        best_sell_price = max_price
                                        best_sell_date_obj = future_window.iloc[max_price_pos_in_future]['æ—¥æœŸ']
                                        if isinstance(best_sell_date_obj, pd.Timestamp):
                                            best_sell_date = best_sell_date_obj.strftime('%Y-%m-%d')
                                        else:
                                            best_sell_date = str(best_sell_date_obj)
                                        best_sell_weeks = max_price_week_idx - i
                                        sell_point_type = 'å†å²æœ€é«˜ä»·'
                                    else:
                                        # æœ€é«˜ä»·è¿˜æ²¡åˆ°æ¥ï¼Œä½¿ç”¨æ–¹æ³•äºŒï¼ˆç‰¹å¾åŒ¹é…æ³•ï¼‰é¢„æµ‹å–ç‚¹
                                        sell_point_type = 'é¢„æµ‹å–ç‚¹'
                                        best_sell_price = max_price
                                        best_sell_date_obj = future_window.iloc[max_price_pos_in_future]['æ—¥æœŸ']
                                        if isinstance(best_sell_date_obj, pd.Timestamp):
                                            best_sell_date = best_sell_date_obj.strftime('%Y-%m-%d')
                                        else:
                                            best_sell_date = str(best_sell_date_obj)
                                        best_sell_weeks = max_price_week_idx - i
                                except Exception as e:
                                    pass
                        elif is_latest_data:
                            # ä¹°å…¥ç‚¹å°±æ˜¯æœ€æ–°æ•°æ®ï¼Œéœ€è¦é¢„æµ‹æœªæ¥å–ç‚¹
                            # åŸºäºå†å²å¤§ç‰›è‚¡ç‰¹å¾ï¼Œä¿å®ˆé¢„æµ‹ï¼šä¹°å…¥ä»· Ã— 1.5ï¼ˆ50%æ¶¨å¹…ï¼‰
                            # æˆ–è€…æ›´ä¹è§‚ï¼šä¹°å…¥ä»· Ã— 2.0ï¼ˆ100%æ¶¨å¹…ï¼Œç¿»å€ï¼‰
                            sell_point_type = 'é¢„æµ‹å–ç‚¹'
                            # åŸºäºå†å²å¤§ç‰›è‚¡å¹³å‡æ¶¨å¹…ï¼Œä¿å®ˆé¢„æµ‹å–ç‚¹ä»·æ ¼ä¸ºä¹°å…¥ä»·çš„1.5å€ï¼ˆ50%æ¶¨å¹…ï¼‰
                            # å¦‚æœåŒ¹é…åº¦å¾ˆé«˜ï¼ˆ>0.9ï¼‰ï¼Œå¯ä»¥ä½¿ç”¨æ›´ä¹è§‚çš„é¢„æµ‹ï¼ˆ2.0å€ï¼Œ100%æ¶¨å¹…ï¼‰
                            predicted_multiple = 1.5  # ä¿å®ˆé¢„æµ‹ï¼š50%æ¶¨å¹…
                            if match_score.get('æ€»åŒ¹é…åº¦', 0) > 0.9:
                                predicted_multiple = 2.0  # é«˜åŒ¹é…åº¦ï¼š100%æ¶¨å¹…ï¼ˆç¿»å€ï¼‰
                            best_sell_price = buy_price * predicted_multiple
                            best_sell_date = buy_date_str
                            best_sell_weeks = 10  # é¢„æµ‹åœ¨10å‘¨å†…è¾¾åˆ°ï¼ˆåŸºäºå†å²å¤§ç‰›è‚¡å¹³å‡å‘¨æœŸï¼‰
                        
                        # è®¡ç®—æ­¢æŸç‚¹
                        stop_loss_percent = -10.0
                        try:
                            if i >= 20:
                                ma20_values = self.tech_analysis.calculate_ma(weekly_df, period=20)
                                if ma20_values is not None and len(ma20_values) > i:
                                    ma20_at_buy = float(ma20_values.iloc[i])
                                    if ma20_at_buy > 0:
                                        stop_loss_by_ma = buy_price * 0.95 if ma20_at_buy * 0.95 < buy_price * 0.90 else buy_price * 0.90
                                        stop_loss_price = round(stop_loss_by_ma, 2)
                        except:
                            pass
                        
                        if stop_loss_price is None:
                            stop_loss_price = round(buy_price * (1 + stop_loss_percent / 100), 2)
                        
                        buy_points.append({
                            'æ—¥æœŸ': buy_date_str,
                            'ä»·æ ¼': round(buy_price, 2),
                            'åŒ¹é…åº¦': round(match_score['æ€»åŒ¹é…åº¦'], 3),
                            'æ ¸å¿ƒç‰¹å¾åŒ¹é…': match_score.get('æ ¸å¿ƒç‰¹å¾åŒ¹é…', {}),
                            'ä¹°å…¥å4å‘¨æ¶¨å¹…': round(gain_4w, 2) if gain_4w is not None else None,
                            '4å‘¨æ˜¯å¦ç›ˆåˆ©': is_profitable_4w,
                            '4å‘¨æ˜¯å¦ç¿»å€': is_doubled_4w,
                            'ä¹°å…¥å10å‘¨æ¶¨å¹…': round(gain_10w, 2) if gain_10w is not None else None,
                            '10å‘¨æ˜¯å¦ç›ˆåˆ©': is_profitable_10w,
                            '10å‘¨æ˜¯å¦ç¿»å€': is_doubled_10w,
                            '10å‘¨å†…æœ€å¤§æ¶¨å¹…': round(max_gain_10w, 2) if max_gain_10w is not None else None,
                            'ä¹°å…¥å20å‘¨æ¶¨å¹…': round(gain_20w, 2) if gain_20w is not None else None,
                            '20å‘¨æ˜¯å¦ç›ˆåˆ©': is_profitable_20w,
                            'æ˜¯å¦æœ€ä½³ä¹°ç‚¹': is_doubled_10w if is_doubled_10w is not None else False,
                            # æœ€ä½³å–ç‚¹ä¿¡æ¯
                            'æœ€ä½³å–ç‚¹ä»·æ ¼': round(best_sell_price, 2) if best_sell_price is not None else None,
                            'æœ€ä½³å–ç‚¹æ—¥æœŸ': best_sell_date,
                            'æœ€ä½³å–ç‚¹å‘¨æ•°': best_sell_weeks,
                            'å–ç‚¹ç±»å‹': sell_point_type,
                            'æ­¢æŸä»·æ ¼': stop_loss_price
                        })
                except Exception as e:
                    continue
            
            # æŒ‰åŒ¹é…åº¦ä»å¤§åˆ°å°æ’åº
            buy_points.sort(key=lambda x: x['åŒ¹é…åº¦'], reverse=True)
        
        # ç¡®ä¿è®­ç»ƒæ—¶çš„æœ€ä½³ä¹°ç‚¹æ€»æ˜¯è¢«åŒ…å«åœ¨ç»“æœä¸­
        training_best_buy_point = None
        if stock_code in self.analysis_results:
            result = self.analysis_results[stock_code]
            interval = result.get('interval', {})
            training_start_idx = interval.get('èµ·ç‚¹ç´¢å¼•')
            training_start_date = interval.get('èµ·ç‚¹æ—¥æœŸ')
            training_start_price = interval.get('èµ·ç‚¹ä»·æ ¼')
            
            if training_start_idx is not None:
                # åœ¨buy_pointsä¸­æŸ¥æ‰¾è®­ç»ƒæ—¶çš„æœ€ä½³ä¹°ç‚¹
                for bp in buy_points:
                    bp_date = bp.get('æ—¥æœŸ', '')
                    bp_price = bp.get('ä»·æ ¼', 0)
                    if str(bp_date)[:10] == str(training_start_date)[:10] and abs(bp_price - training_start_price) < 0.1:
                        training_best_buy_point = bp
                        break
        
        # åªè¿”å›å‰20ä¸ªæœ€ä½³ä¹°ç‚¹ï¼ˆå¢åŠ æ•°é‡ï¼‰
        buy_points = buy_points[:20]
        
        # å¦‚æœè®­ç»ƒæ—¶çš„æœ€ä½³ä¹°ç‚¹ä¸åœ¨å‰20ä¸ªä¸­ï¼Œå°†å…¶æ·»åŠ åˆ°ç»“æœä¸­ï¼ˆæ›¿æ¢æœ€åä¸€ä¸ªï¼‰
        if training_best_buy_point is not None:
            # æ£€æŸ¥æ˜¯å¦å·²ç»åœ¨ç»“æœä¸­
            found_in_results = False
            for bp in buy_points:
                bp_date = bp.get('æ—¥æœŸ', '')
                bp_price = bp.get('ä»·æ ¼', 0)
                if str(bp_date)[:10] == str(training_start_date)[:10] and abs(bp_price - training_start_price) < 0.1:
                    found_in_results = True
                    break
            
            if not found_in_results and len(buy_points) > 0:
                # å¦‚æœä¸åœ¨ç»“æœä¸­ï¼Œæ›¿æ¢æœ€åä¸€ä¸ªï¼ˆç¡®ä¿è®­ç»ƒæ—¶çš„æœ€ä½³ä¹°ç‚¹æ€»æ˜¯è¢«åŒ…å«ï¼‰
                buy_points[-1] = training_best_buy_point
                # é‡æ–°æ’åºï¼Œç¡®ä¿é¡ºåºæ­£ç¡®
                buy_points.sort(key=lambda x: x['åŒ¹é…åº¦'], reverse=True)
                print(f"  [ç‰¹æ®Šå¤„ç†] å°†è®­ç»ƒæ—¶çš„æœ€ä½³ä¹°ç‚¹æ·»åŠ åˆ°ç»“æœä¸­")
        
        print(f"âœ… æ‰¾åˆ° {len(buy_points)} ä¸ªæ½œåœ¨ä¹°ç‚¹")
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        statistics = {
            'total': len(buy_points),
            'best_buy_points': sum(1 for bp in buy_points if bp.get('æ˜¯å¦æœ€ä½³ä¹°ç‚¹', False)),
            'profitable_4w': sum(1 for bp in buy_points if bp.get('4å‘¨æ˜¯å¦ç›ˆåˆ©', False)),
            'profitable_10w': sum(1 for bp in buy_points if bp.get('10å‘¨æ˜¯å¦ç›ˆåˆ©', False))
        }
        
        # è®¡ç®—åŒ¹é…åº¦ç»Ÿè®¡ï¼ˆåŸºäºå®é™…ä¹°ç‚¹ï¼Œè€Œä¸æ˜¯æ‰€æœ‰æ£€æŸ¥ä½ç½®ï¼‰
        buy_point_match_scores = [bp.get('åŒ¹é…åº¦', 0) for bp in buy_points if bp.get('åŒ¹é…åº¦') is not None]
        if buy_point_match_scores:
            max_match_score_from_buy_points = max(buy_point_match_scores)
            avg_match_from_buy_points = sum(buy_point_match_scores) / len(buy_point_match_scores)
        else:
            # å¦‚æœæ²¡æœ‰ä¹°ç‚¹ï¼Œä½¿ç”¨æ‰€æœ‰æ£€æŸ¥ä½ç½®çš„ç»Ÿè®¡
            max_match_score_from_buy_points = max_match_score if match_scores_list else 0
            avg_match_from_buy_points = sum(match_scores_list) / len(match_scores_list) if match_scores_list else 0
        
        return {
            'success': True,
            'message': f'æ‰¾åˆ° {len(buy_points)} ä¸ªæ½œåœ¨ä¹°ç‚¹',
            'buy_points': buy_points,
            'stock_code': stock_code,
            'statistics': statistics,
            'max_match_score': max_match_score_from_buy_points,  # ä½¿ç”¨ä¹°ç‚¹ä¸­çš„æœ€é«˜åŒ¹é…åº¦
            'avg_match_score': avg_match_from_buy_points  # ä½¿ç”¨ä¹°ç‚¹ä¸­çš„å¹³å‡åŒ¹é…åº¦
        }
    
    def find_sell_points(self, stock_code: str, buy_date: str, buy_price: float, search_weeks: int = 20, match_threshold: float = 0.85) -> Dict:
        """
        åœ¨æŒ‡å®šè‚¡ç¥¨ä¸­æŸ¥æ‰¾æœ€ä½³å–ç‚¹ï¼ˆåŸºäºä¹°ç‚¹åçš„èµ°åŠ¿ï¼‰
        :param stock_code: è‚¡ç¥¨ä»£ç 
        :param buy_date: ä¹°å…¥æ—¥æœŸï¼ˆå­—ç¬¦ä¸²ï¼Œæ ¼å¼ï¼š'YYYY-MM-DD'ï¼‰
        :param buy_price: ä¹°å…¥ä»·æ ¼
        :param search_weeks: åœ¨ä¹°å…¥åæœç´¢å–ç‚¹çš„å‘¨æ•°ï¼ˆé»˜è®¤20å‘¨ï¼‰
        :param match_threshold: åŒ¹é…åº¦é˜ˆå€¼ï¼ˆé»˜è®¤0.85ï¼‰
        :return: æ‰¾åˆ°çš„å–ç‚¹åˆ—è¡¨
        """
        if not hasattr(self, 'trained_sell_features') or self.trained_sell_features is None:
            return {
                'success': False,
                'message': 'å°šæœªè®­ç»ƒå–ç‚¹ç‰¹å¾æ¨¡å‹ï¼Œè¯·å…ˆè®­ç»ƒ',
                'sell_points': []
            }
        
        print(f"\nğŸ” åœ¨ {stock_code} ä¸­æœç´¢å–ç‚¹ï¼ˆä¹°å…¥æ—¥æœŸ: {buy_date}, ä¹°å…¥ä»·æ ¼: {buy_price:.2f}ï¼‰...")
        
        # è·å–å‘¨Kçº¿æ•°æ®
        weekly_df = self.fetcher.get_weekly_kline(stock_code, period="2y")
        
        if weekly_df is None or len(weekly_df) == 0:
            return {
                'success': False,
                'message': f'æ— æ³•è·å– {stock_code} çš„å‘¨çº¿æ•°æ®',
                'sell_points': []
            }
        
        # æ‰¾åˆ°ä¹°å…¥æ—¥æœŸå¯¹åº”çš„ç´¢å¼•
        buy_idx = None
        buy_date_dt = pd.to_datetime(buy_date)
        
        for i, row in weekly_df.iterrows():
            row_date = pd.to_datetime(row['æ—¥æœŸ'])
            if row_date >= buy_date_dt:
                buy_idx = weekly_df.index.get_loc(i)
                break
        
        if buy_idx is None:
            return {
                'success': False,
                'message': f'æœªæ‰¾åˆ°ä¹°å…¥æ—¥æœŸ {buy_date} å¯¹åº”çš„æ•°æ®',
                'sell_points': []
            }
        
        # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ•°æ®
        if buy_idx + search_weeks > len(weekly_df):
            search_weeks = len(weekly_df) - buy_idx
        
        if search_weeks < 5:
            return {
                'success': False,
                'message': f'ä¹°å…¥åæ•°æ®ä¸è¶³ï¼Œåªæœ‰ {search_weeks} å‘¨æ•°æ®',
                'sell_points': []
            }
        
        common_features = self.trained_sell_features.get('common_features', {})
        if len(common_features) == 0:
            return {
                'success': False,
                'message': 'å–ç‚¹ç‰¹å¾æ¨¡æ¿ä¸ºç©º',
                'sell_points': []
            }
        
        print(f"ğŸ“Š åœ¨ä¹°å…¥å {search_weeks} å‘¨å†…æœç´¢å–ç‚¹...")
        sell_points = []
        
        # ä»ä¹°å…¥åç¬¬5å‘¨å¼€å§‹æœç´¢ï¼ˆè‡³å°‘éœ€è¦ä¸€äº›æ¶¨å¹…ï¼‰
        for i in range(buy_idx + 5, min(buy_idx + search_weeks, len(weekly_df))):
            try:
                # æå–è¯¥ä½ç½®çš„å–ç‚¹ç‰¹å¾ï¼ˆéœ€è¦çŸ¥é“èµ·ç‚¹ï¼‰
                features = self.extract_features_at_end_point(stock_code, i, buy_idx, lookback_weeks=20, weekly_df=weekly_df)
                
                if features is None:
                    continue
                
                # è®¡ç®—åŒ¹é…åº¦ï¼ˆä½¿ç”¨ä¹°ç‚¹çš„åŒ¹é…åº¦è®¡ç®—æ–¹æ³•ï¼‰
                match_score = self._calculate_match_score(features, common_features, tolerance=0.3)
                total_match = match_score['æ€»åŒ¹é…åº¦']
                
                # è®¡ç®—ä»ä¹°å…¥åˆ°å½“å‰ä½ç½®çš„æ¶¨å¹…
                current_price = float(weekly_df.iloc[i]['æ”¶ç›˜'])
                current_high = float(weekly_df.iloc[i]['æœ€é«˜'])
                gain_pct = (current_high - buy_price) / buy_price * 100 if buy_price > 0 else 0
                
                # åªè€ƒè™‘æœ‰è¶³å¤Ÿæ¶¨å¹…çš„å–ç‚¹ï¼ˆè‡³å°‘50%ï¼‰
                if total_match >= match_threshold and gain_pct >= 50:
                    sell_date = weekly_df.iloc[i]['æ—¥æœŸ']
                    if isinstance(sell_date, pd.Timestamp):
                        sell_date_str = sell_date.strftime('%Y-%m-%d')
                    else:
                        sell_date_str = str(sell_date)
                    
                    # è®¡ç®—å–å‡ºåçš„å›è°ƒï¼ˆå¦‚æœæœ‰ï¼‰
                    pullback_1w = None
                    pullback_2w = None
                    if i + 1 < len(weekly_df):
                        next_price = float(weekly_df.iloc[i + 1]['æ”¶ç›˜'])
                        pullback_1w = (current_high - next_price) / current_high * 100 if current_high > 0 else 0
                    if i + 2 < len(weekly_df):
                        next2_price = float(weekly_df.iloc[i + 2]['æ”¶ç›˜'])
                        pullback_2w = (current_high - next2_price) / current_high * 100 if current_high > 0 else 0
                    
                    sell_points.append({
                        'æ—¥æœŸ': sell_date_str,
                        'ä»·æ ¼': round(current_high, 2),  # ä½¿ç”¨æœ€é«˜ä»·
                        'æ”¶ç›˜ä»·': round(current_price, 2),
                        'åŒ¹é…åº¦': round(total_match, 3),
                        'ç´¯è®¡æ¶¨å¹…': round(gain_pct, 2),
                        'ç¿»å€å€æ•°': round(gain_pct / 100, 2),
                        'ä¹°å…¥åå‘¨æ•°': i - buy_idx,
                        'æ ¸å¿ƒç‰¹å¾åŒ¹é…': match_score.get('æ ¸å¿ƒç‰¹å¾åŒ¹é…', {}),
                        '1å‘¨åå›è°ƒ': round(pullback_1w, 2) if pullback_1w is not None else None,
                        '2å‘¨åå›è°ƒ': round(pullback_2w, 2) if pullback_2w is not None else None,
                        'ç‰¹å¾': features
                    })
            except Exception as e:
                continue
        
        # æŒ‰åŒ¹é…åº¦å’Œæ¶¨å¹…æ’åº
        sell_points.sort(key=lambda x: (x['åŒ¹é…åº¦'], x['ç´¯è®¡æ¶¨å¹…']), reverse=True)
        
        # åªè¿”å›å‰10ä¸ªæœ€ä½³å–ç‚¹
        sell_points = sell_points[:10]
        
        print(f"âœ… æ‰¾åˆ° {len(sell_points)} ä¸ªæ½œåœ¨å–ç‚¹")
        
        return {
            'success': True,
            'message': f'æ‰¾åˆ° {len(sell_points)} ä¸ªæ½œåœ¨å–ç‚¹',
            'sell_points': sell_points,
            'buy_date': buy_date,
            'buy_price': buy_price
        }
    
    def _display_extracted_features(self, features: Dict, stock_code: str, stock_name: str):
        """
        æ˜¾ç¤ºæå–çš„ç‰¹å¾ï¼Œç‰¹åˆ«æ ‡æ³¨æ ¸å¿ƒç‰¹å¾
        :param features: ç‰¹å¾å­—å…¸
        :param stock_code: è‚¡ç¥¨ä»£ç 
        :param stock_name: è‚¡ç¥¨åç§°
        """
        # æ ¸å¿ƒç‰¹å¾åˆ—è¡¨ï¼ˆä¸_calculate_match_scoreä¸­çš„core_featuresä¿æŒä¸€è‡´ï¼‰
        core_features = [
            'èµ·ç‚¹å½“å‘¨é‡æ¯”',
            'ä»·æ ¼ç›¸å¯¹ä½ç½®',
            'æˆäº¤é‡èç¼©ç¨‹åº¦',
            'ä»·æ ¼ç›¸å¯¹MA20',
            'èµ·ç‚¹å‰20å‘¨æ³¢åŠ¨ç‡',
            'æ˜¯å¦è·Œç ´æœ€å¤§é‡æœ€ä½ä»·',
            'èµ·ç‚¹å‰40å‘¨æœ€å¤§é‡'
        ]
        
        print(f"\nğŸ“Š {stock_code} {stock_name} æå–çš„ç‰¹å¾è¯¦æƒ…:")
        print(f"èµ·ç‚¹æ—¥æœŸ: {features.get('èµ·ç‚¹æ—¥æœŸ', 'N/A')}")
        print(f"èµ·ç‚¹ä»·æ ¼: {features.get('èµ·ç‚¹ä»·æ ¼', 'N/A')} å…ƒ")
        print("-" * 80)
        
        # æŒ‰ç±»åˆ«åˆ†ç»„æ˜¾ç¤º
        categories = {
            'â­ æ ¸å¿ƒç‰¹å¾ï¼ˆé«˜æƒé‡ï¼‰': [],
            'ğŸ“ˆ æˆäº¤é‡ç‰¹å¾': [],
            'ğŸ’° ä»·æ ¼ç‰¹å¾': [],
            'ğŸ“‰ å‡çº¿ç‰¹å¾': [],
            'ğŸ”„ é‡ä»·é…åˆç‰¹å¾': [],
            'â° æ—¶é—´ç‰¹å¾': [],
            'ğŸ“‹ å…¶ä»–ç‰¹å¾': []
        }
        
        # åˆ†ç±»ç‰¹å¾
        for key, value in features.items():
            if key in ['è‚¡ç¥¨ä»£ç ', 'è‚¡ç¥¨åç§°', 'èµ·ç‚¹æ—¥æœŸ', 'èµ·ç‚¹ä»·æ ¼']:
                continue
            
            if key in core_features:
                categories['â­ æ ¸å¿ƒç‰¹å¾ï¼ˆé«˜æƒé‡ï¼‰'].append((key, value))
            elif 'é‡' in key or 'æˆäº¤é‡' in key or 'é‡æ¯”' in key:
                categories['ğŸ“ˆ æˆäº¤é‡ç‰¹å¾'].append((key, value))
            elif 'ä»·æ ¼' in key or 'æœ€é«˜' in key or 'æœ€ä½' in key or 'è·Œå¹…' in key:
                categories['ğŸ’° ä»·æ ¼ç‰¹å¾'].append((key, value))
            elif 'MA' in key or 'å‡çº¿' in key or 'æ–œç‡' in key:
                categories['ğŸ“‰ å‡çº¿ç‰¹å¾'].append((key, value))
            elif 'é‡ä»·' in key or 'ä»·æ¶¨' in key or 'é‡å¢' in key or 'ç›¸å…³ç³»æ•°' in key:
                categories['ğŸ”„ é‡ä»·é…åˆç‰¹å¾'].append((key, value))
            elif 'æ³¢åŠ¨' in key or 'æ³¢åŠ¨ç‡' in key:
                categories['â° æ—¶é—´ç‰¹å¾'].append((key, value))
            else:
                categories['ğŸ“‹ å…¶ä»–ç‰¹å¾'].append((key, value))
        
        # æ˜¾ç¤ºæ¯ä¸ªç±»åˆ«çš„ç‰¹å¾
        for category, feature_list in categories.items():
            if feature_list:
                print(f"\n{category}:")
                for key, value in feature_list:
                    # æ ¼å¼åŒ–æ˜¾ç¤º
                    if isinstance(value, float):
                        if abs(value) < 0.01:
                            value_str = f"{value:.4f}"
                        elif abs(value) < 1:
                            value_str = f"{value:.3f}"
                        else:
                            value_str = f"{value:.2f}"
                    elif isinstance(value, int):
                        value_str = str(value)
                    else:
                        value_str = str(value)
                    
                    # æ ¸å¿ƒç‰¹å¾ç”¨â­æ ‡è®°
                    marker = "â­ " if key in core_features else "  "
                    print(f"  {marker}{key:30s} = {value_str}")
        
        print("-" * 80)
    
    def _calculate_match_score(self, features: Dict, common_features: Dict, tolerance: float = 0.3, is_training_sample: bool = False) -> Dict:
        """
        è®¡ç®—ç‰¹å¾åŒ¹é…åº¦ï¼ˆV3 - ä½¿ç”¨ä¸­ä½æ•°+æ ‡å‡†å·®è¯„åˆ†ï¼Œå¢åŠ åŒºåˆ†åº¦ï¼‰
        :param features: ç›®æ ‡è‚¡ç¥¨çš„ç‰¹å¾
        :param common_features: è®­ç»ƒå¥½çš„å…±åŒç‰¹å¾æ¨¡æ¿
        :param tolerance: å®¹å·®ï¼ˆå·²ä¸ä½¿ç”¨ï¼Œä¿ç•™å‚æ•°å…¼å®¹ï¼‰
        :param is_training_sample: æ˜¯å¦ä¸ºè®­ç»ƒæ ·æœ¬
        :return: åŒ¹é…åº¦åˆ†æ•°
        """
        import math
        import numpy as np
        
        # æ ¸å¿ƒç‰¹å¾ï¼ˆé«˜æƒé‡ï¼Œè¿™äº›ç‰¹å¾å¯¹ç‰›è‚¡è¯†åˆ«æœ€é‡è¦ï¼‰
        core_features = [
            'èµ·ç‚¹å½“å‘¨é‡æ¯”',
            'ä»·æ ¼ç›¸å¯¹ä½ç½®',
            'æˆäº¤é‡èç¼©ç¨‹åº¦',
            'ä»·æ ¼ç›¸å¯¹MA20',
            'èµ·ç‚¹å‰20å‘¨æ³¢åŠ¨ç‡',
            'æ˜¯å¦è·Œç ´æœ€å¤§é‡æœ€ä½ä»·',
            'å‡çº¿å¤šå¤´æ’åˆ—',
            'MACDé›¶è½´ä¸Šæ–¹',
            'RSI',
            'å‡çº¿ç²˜åˆåº¦',
            'å‡çº¿å¹³æ»‘åº¦',
            'å¸ƒæ—å¸¦å®½åº¦',
            'OBVè¶‹åŠ¿',
            'ä¹°ç‚¹å‰ä¸¤æœˆå†…æ›¾æ¶¨åœ',
        ]
        
        match_scores = {}
        core_match_scores = {}
        total_score = 0
        matched_count = 0
        core_matched_count = 0
        
        for feature_name, stats in common_features.items():
            if feature_name not in features:
                continue
            
            target_value = features[feature_name]
            if target_value is None or (isinstance(target_value, float) and np.isnan(target_value)):
                continue
            
            min_value = stats.get('æœ€å°å€¼', 0)
            max_value = stats.get('æœ€å¤§å€¼', 0)
            median_value = stats.get('ä¸­ä½æ•°', stats.get('å‡å€¼', 0))
            std_value = stats.get('æ ‡å‡†å·®', 0)
            
            range_val = max_value - min_value
            if range_val == 0:
                range_val = abs(median_value) * 0.2 if median_value != 0 else 1
            
            # V3ç®—æ³•ï¼šåŸºäºåˆ°ä¸­ä½æ•°çš„è·ç¦»è¯„åˆ†ï¼Œä¸¥æ ¼ç‰ˆï¼ˆæé«˜åŒºåˆ†åº¦ï¼‰
            if std_value > 0:
                # è®¡ç®—z-scoreï¼ˆåˆ°ä¸­ä½æ•°çš„æ ‡å‡†åŒ–è·ç¦»ï¼‰
                z_score = abs(target_value - median_value) / std_value
                
                # ä½¿ç”¨é«˜æ–¯è¡°å‡ï¼šç³»æ•° 0.35ï¼ˆæ›´ä¸¥æ ¼ï¼Œæé«˜åŒºåˆ†åº¦ï¼‰
                # z=0->1.0, z=0.5->0.92, z=1->0.70, z=1.5->0.45, z=2->0.25
                base_score = math.exp(-0.35 * z_score * z_score)
                
                # å¦‚æœåœ¨ [min, max] èŒƒå›´å†…ï¼Œæœ€ä½ä¹Ÿæœ‰0.70åˆ†ï¼ˆæ›´ä¸¥æ ¼ï¼‰
                if min_value <= target_value <= max_value:
                    match_score = max(base_score, 0.70)
                    # å¯¹äºéå¸¸æ¥è¿‘ä¸­ä½æ•°çš„ç‰¹å¾ç»™äºˆå°å¹…å¥–åŠ±
                    if z_score < 0.3:
                        match_score = min(1.0, match_score + 0.05)  # z<0.3æ—¶é¢å¤–+0.05
                    elif z_score < 0.6:
                        match_score = min(1.0, match_score + 0.03)  # z<0.6æ—¶é¢å¤–+0.03
                else:
                    # è¶…å‡ºèŒƒå›´ï¼Œé¢å¤–æƒ©ç½š
                    if target_value < min_value:
                        out_distance = (min_value - target_value) / (range_val + 0.01)
                    else:
                        out_distance = (target_value - max_value) / (range_val + 0.01)
                    # è¶…å‡ºè¶Šè¿œï¼Œæƒ©ç½šè¶Šé‡
                    penalty = math.exp(-out_distance * 3)
                    match_score = base_score * penalty * 0.8
            else:
                # æ ‡å‡†å·®ä¸º0ï¼Œä½¿ç”¨èŒƒå›´åˆ¤æ–­
                if min_value <= target_value <= max_value:
                    # åœ¨èŒƒå›´å†…ï¼Œæ ¹æ®åˆ°ä¸­ä½æ•°è·ç¦»è¯„åˆ†
                    if range_val > 0:
                        relative_dist = abs(target_value - median_value) / range_val
                        match_score = max(0.70, 1.0 - relative_dist * 0.30)
                    else:
                        match_score = 1.0 if abs(target_value - median_value) < 0.01 else 0.70
                else:
                    # è¶…å‡ºèŒƒå›´
                    if target_value < min_value:
                        out_dist = (min_value - target_value) / (range_val + 0.01)
                    else:
                        out_dist = (target_value - max_value) / (range_val + 0.01)
                    match_score = max(0, 0.5 * math.exp(-out_dist * 2))
            
            match_scores[feature_name] = round(match_score, 3)
            
            # æ ¸å¿ƒç‰¹å¾ä½¿ç”¨æ›´é«˜æƒé‡
            if feature_name in core_features:
                weight = 3.0  # æ ¸å¿ƒç‰¹å¾æƒé‡
                core_match_scores[feature_name] = round(match_score, 3)
                core_matched_count += 1
            else:
                weight = 1.0
            
            total_score += match_score * weight
            matched_count += 1
        
        # è®¡ç®—æ€»åŒ¹é…åº¦ï¼ˆåŠ æƒå¹³å‡ï¼‰
        total_weight = core_matched_count * 3.0 + (matched_count - core_matched_count) * 1.0
        if total_weight > 0:
            total_match_score = total_score / total_weight
        else:
            total_match_score = 0
        
        # âœ… å‡çº¿ç²˜åˆåº¦å¥–åŠ±ï¼šåœ¨å…¶ä»–æ¡ä»¶ç›¸åŒçš„æƒ…å†µä¸‹ï¼Œå‡çº¿ç²˜åˆåº¦é«˜çš„è‚¡ç¥¨åŒ¹é…åº¦æ›´é«˜
        # å‡çº¿ç²˜åˆåº¦å€¼è¶Šå°ï¼Œè¡¨ç¤ºç²˜åˆåº¦è¶Šé«˜ï¼ˆMA5/MA10/MA20è¶Šæ¥è¿‘ï¼‰
        if 'å‡çº¿ç²˜åˆåº¦' in features and 'å‡çº¿ç²˜åˆåº¦' in common_features:
            ma_convergence_value = features.get('å‡çº¿ç²˜åˆåº¦')
            if ma_convergence_value is not None and isinstance(ma_convergence_value, (int, float)) and not np.isnan(ma_convergence_value):
                ma_stats = common_features['å‡çº¿ç²˜åˆåº¦']
                ma_median = ma_stats.get('ä¸­ä½æ•°', ma_stats.get('å‡å€¼', 10))
                # å¦‚æœå‡çº¿ç²˜åˆåº¦ä½äºä¸­ä½æ•°ï¼ˆç²˜åˆåº¦é«˜ï¼‰ï¼Œç»™äºˆå¥–åŠ±
                if ma_convergence_value < ma_median:
                    # å¥–åŠ±å¹…åº¦ï¼šç²˜åˆåº¦è¶Šä½ï¼ˆå€¼è¶Šå°ï¼‰ï¼Œå¥–åŠ±è¶Šå¤šï¼Œæœ€å¤š+0.02
                    # ä¾‹å¦‚ï¼šä¸­ä½æ•°=10ï¼Œå½“å‰å€¼=5ï¼Œå¥–åŠ± = (10-5)/10 * 0.02 = 0.01
                    reward = min(0.02, (ma_median - ma_convergence_value) / max(ma_median, 1) * 0.02)
                    total_match_score = min(1.0, total_match_score + reward)
        
        return {
            'æ€»åŒ¹é…åº¦': round(total_match_score, 3),
            'åŒ¹é…ç‰¹å¾æ•°': matched_count,
            'æ ¸å¿ƒç‰¹å¾åŒ¹é…': core_match_scores,
            'æ‰€æœ‰ç‰¹å¾åŒ¹é…': match_scores
        }
    
    def scan_all_stocks(self, min_match_score: float = 0.6, max_market_cap: float = 60.0, limit: int = None, use_parallel: bool = True, max_workers: int = 5, scan_date: str = None, scan_session: str = None, force_refresh: bool = False, strict_local_only: bool = None) -> Dict:
        """
        æ‰«ææ‰€æœ‰è‚¡ç¥¨ï¼ŒæŸ¥æ‰¾ç¬¦åˆç‰›è‚¡ç‰¹å¾çš„ä¸ªè‚¡
        ä¼˜åŒ–ï¼šåœ¨æ‰«æå¼€å§‹å‰é¢„å…ˆè·å–å¹¶ç¼“å­˜å¸‚å€¼æ•°æ®ï¼Œé¿å…æ‰«æè¿‡ç¨‹ä¸­å¡ä½
        :param strict_local_only: æ˜¯å¦ä¸¥æ ¼åªä½¿ç”¨æœ¬åœ°ç¼“å­˜ï¼ˆä¸ä»ç½‘ç»œä¸‹è½½ï¼‰ï¼ŒNoneæ—¶è‡ªåŠ¨åˆ¤æ–­ï¼ˆæœ¬åœ°ç¯å¢ƒé»˜è®¤Trueï¼‰
        """
        # é‡ç½®åœæ­¢æ ‡å¿—
        self.stop_scan = False
        # è®°å½•æœ¬æ¬¡æ‰«ææ˜¯å¦å¼ºåˆ¶åˆ·æ–°ï¼ˆä¾›ä¸²è¡Œæ‰«æå†…éƒ¨çš„çº¿ç¨‹å–ç”¨ï¼‰
        self._force_refresh_scan = bool(force_refresh)
        
        # âœ… å…³é”®ï¼šæœ¬åœ°ç¯å¢ƒé»˜è®¤ä¸¥æ ¼åªä½¿ç”¨æœ¬åœ°ç¼“å­˜ï¼Œé¿å…ç½‘ç»œä¸‹è½½å¯¼è‡´é€Ÿåº¦æ…¢
        if strict_local_only is None:
            # è‡ªåŠ¨åˆ¤æ–­ï¼šå¦‚æœæ˜¯æœ¬åœ°ç¯å¢ƒï¼ˆéVercel/Renderï¼‰ï¼Œé»˜è®¤å¯ç”¨ä¸¥æ ¼æœ¬åœ°æ¨¡å¼
            import os
            is_cloud = (
                os.environ.get('VERCEL') == '1' or 
                os.environ.get('VERCEL_ENV') is not None or
                os.environ.get('RENDER') == 'true' or
                os.environ.get('RENDER_SERVICE_NAME') is not None
            )
            strict_local_only = not is_cloud  # æœ¬åœ°ç¯å¢ƒé»˜è®¤Trueï¼Œäº‘ç¯å¢ƒé»˜è®¤False
        
        # è®¾ç½®ä¸¥æ ¼æœ¬åœ°æ¨¡å¼æ ‡å¿—ï¼ˆä¾›å†…éƒ¨å‡½æ•°ä½¿ç”¨ï¼‰
        self._strict_local_only = bool(strict_local_only)
        self._scan_skip_4d_gain_check = True
        self._scan_quiet = True  # æ‰«ææ—¶å‡å°‘ç‰¹å¾æå–ç­‰æ—¥å¿—ï¼ŒåŠ é€Ÿ
        
        if strict_local_only:
            print("ğŸ“Œ ä¸¥æ ¼æœ¬åœ°æ¨¡å¼ï¼šåªä½¿ç”¨æœ¬åœ°ç¼“å­˜æ•°æ®ï¼Œç¼ºå¤±æ•°æ®çš„è‚¡ç¥¨å°†è¢«è·³è¿‡ï¼ˆä¸ä»ç½‘ç»œä¸‹è½½ï¼‰")

        # å¼ºåˆ¶åˆ·æ–°ï¼šæ¯æ¬¡æ‰«æå‰æ¸…ç©ºæ–­ç‚¹ç»­æ‰«çŠ¶æ€å’Œç»“æœç¼“å­˜ï¼Œç¡®ä¿æŒ‰â€œæœ€æ–°æ¡ä»¶/æœ€æ–°æ•°æ®â€é‡æ–°è®¡ç®—
        if force_refresh:
            self.scan_state = None
            try:
                self.scan_results = None
            except Exception:
                pass

        # æ ‡å‡†åŒ– scan_dateï¼ˆå…¼å®¹ YYYY/MM/DD ä¸ YYYY-MM-DDï¼‰
        if isinstance(scan_date, str) and scan_date.strip():
            scan_date = scan_date.strip().replace('/', '-')
        
        # é¢„å…ˆè·å–å¹¶ç¼“å­˜å¸‚å€¼æ•°æ®ï¼ˆé¿å…æ‰«æè¿‡ç¨‹ä¸­å¡ä½ï¼‰
        # ä¼˜åŒ–ï¼šå®Œå…¨è·³è¿‡é¢„åŠ è½½ï¼Œæ‰«ææ—¶ç›´æ¥è·³è¿‡å¸‚å€¼æ£€æŸ¥ï¼Œé¿å…å¡ä½
        print("\nğŸ“Š è·³è¿‡å¸‚å€¼é¢„åŠ è½½ï¼Œæ‰«ææ—¶å°†ç›´æ¥è·³è¿‡å¸‚å€¼æ£€æŸ¥ï¼ˆé¿å…å¡ä½ï¼‰...")
        print("   æç¤ºï¼šå¦‚æœéœ€è¦å¸‚å€¼ç­›é€‰ï¼Œå¯ä»¥åœ¨æ‰«æç»“æœä¸­æ‰‹åŠ¨ç­›é€‰")
        print("")
        """
        æ‰«ææ‰€æœ‰Aè‚¡ï¼Œæ‰¾å‡ºç¬¦åˆç‰›è‚¡ç‰¹å¾çš„ä¸ªè‚¡ï¼Œå¹¶ç»™å‡ºæœ€ä½³ä¹°ç‚¹
        å¦‚æœè‚¡ç¥¨æ•°é‡è¶…è¿‡5000ï¼Œè‡ªåŠ¨åˆ†æˆ3æ‰¹æ‰«æ
        :param min_match_score: æœ€å°åŒ¹é…åº¦é˜ˆå€¼ï¼ˆé»˜è®¤0.6ï¼‰
        :param max_market_cap: æœ€å¤§å¸‚å€¼ï¼ˆäº¿å…ƒï¼Œé»˜è®¤60äº¿ï¼‰
        :param limit: é™åˆ¶æ‰«ææ•°é‡ï¼ˆNoneè¡¨ç¤ºå…¨éƒ¨ï¼‰
        :return: æ‰«æç»“æœ
        """
        if self.trained_features is None:
            return {
                'success': False,
                'message': 'å°šæœªè®­ç»ƒç‰¹å¾æ¨¡å‹ï¼Œè¯·å…ˆè®­ç»ƒ',
                'candidates': []
            }
        
        common_features = self._get_common_features()
        if len(common_features) == 0:
            return {
                'success': False,
                'message': 'ç‰¹å¾æ¨¡æ¿ä¸ºç©º',
                'candidates': []
            }
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æœªå®Œæˆçš„æ‰«æçŠ¶æ€ï¼ˆæ–­ç‚¹ç»­æ‰«ï¼‰
        if (not force_refresh) and self.scan_state is not None and self.scan_state.get('status') == 'å·²åœæ­¢':
            # æœ‰æœªå®Œæˆçš„æ‰«æï¼Œç»§ç»­æ‰«æ
            print("\nğŸ“Œ æ£€æµ‹åˆ°æœªå®Œæˆçš„æ‰«æï¼Œå°†ä»ä¸Šæ¬¡åœæ­¢çš„åœ°æ–¹ç»§ç»­...")
            print(f"   ä¸Šæ¬¡å·²å¤„ç†: {self.scan_state.get('current_idx', 0)}/{self.scan_state.get('total_stocks', 0)} åªè‚¡ç¥¨")
            print(f"   å·²æ‰¾åˆ°: {len(self.scan_state.get('candidates', []))} åªç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨")
            # ç»§ç»­æ‰«æ
            return self._resume_scan()
        
        # è·å–è‚¡ç¥¨åˆ—è¡¨
        stock_list = self.fetcher.get_all_stocks()
        if stock_list is None or len(stock_list) == 0:
            return {
                'success': False,
                'message': 'æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨',
                'candidates': []
            }
        
        if limit:
            stock_list = stock_list.head(limit)
        
        total_stocks = len(stock_list)
        
        # ä¿å­˜æ‰«æçŠ¶æ€ï¼ˆç”¨äºæ–­ç‚¹ç»­æ‰«ï¼‰
        self.scan_state = {
            'stock_list': stock_list,
            'common_features': common_features,
            'min_match_score': min_match_score,
            'max_market_cap': max_market_cap,
            'current_idx': 0,
            'total_stocks': total_stocks,
            'candidates': [],
            'scan_date': scan_date,
            'scan_session': scan_session,
            'batch_num': 1,
            'total_batches': 1,
            'status': 'è¿›è¡Œä¸­'
        }
        
        # åˆå§‹åŒ–ç¼ºå¤±æ•°æ®ç»Ÿè®¡
        self._missing_data_stocks = set()
        self.fetcher._missing_stocks = set()
        
        # ä¸€æ¬¡æ€§å…¨éƒ¨æ‰«æï¼ˆä¸å†åˆ†æ‰¹ï¼‰
        print(f"\nğŸ“Š å¼€å§‹æ‰«æå…¨éƒ¨ {total_stocks} åªè‚¡ç¥¨ï¼ˆä¸€æ¬¡æ€§å®Œæˆï¼Œä¸åˆ†æ‰¹ï¼‰...")
        print(f"âš ï¸  æ³¨æ„ï¼šæ‰«æå°†ä»…ä½¿ç”¨æœ¬åœ°æ•°æ®ï¼Œå¦‚æœæœ¬åœ°æ²¡æœ‰æ•°æ®å°†è·³è¿‡è¯¥è‚¡ç¥¨")
        result = self._scan_stock_batch(
            stock_list,
            common_features,
            min_match_score,
            max_market_cap,
            1,
            1,
            start_idx=0,
            existing_candidates=None,
            total_all_stocks=total_stocks,
            use_parallel=use_parallel,
            max_workers=max_workers,
            scan_date=scan_date,
            scan_session=scan_session
        )
        
        # æ‰«æå®Œæˆåï¼Œæ£€æŸ¥ç¼ºå¤±æ•°æ®å¹¶æç¤º
        missing_count = len(self._missing_data_stocks) if hasattr(self, '_missing_data_stocks') else 0
        fetcher_missing_count = len(self.fetcher._missing_stocks) if hasattr(self.fetcher, '_missing_stocks') else 0
        total_missing = max(missing_count, fetcher_missing_count)
        
        if total_missing > 0:
            missing_pct = (total_missing / total_stocks * 100) if total_stocks > 0 else 0
            warning_msg = f"\nâš ï¸  æ‰«æå®Œæˆï¼Œä½†å‘ç° {total_missing} åªè‚¡ç¥¨ï¼ˆ{missing_pct:.1f}%ï¼‰ç¼ºå°‘æœ¬åœ°æ•°æ®ï¼Œå·²è·³è¿‡ã€‚\n"
            warning_msg += f"   å»ºè®®ï¼šè¯·å…ˆä¸‹è½½å®Œæ•´æ•°æ®åå†è¿›è¡Œæ‰«æï¼Œä»¥ç¡®ä¿æ‰«æç»“æœçš„å®Œæ•´æ€§ã€‚\n"
            print(warning_msg)
            
            # åœ¨ç»“æœä¸­æ·»åŠ è­¦å‘Šä¿¡æ¯
            if isinstance(result, dict):
                result['data_warning'] = {
                    'missing_count': total_missing,
                    'total_stocks': total_stocks,
                    'missing_percentage': round(missing_pct, 1),
                    'message': f'å‘ç° {total_missing} åªè‚¡ç¥¨ç¼ºå°‘æœ¬åœ°æ•°æ®ï¼Œå»ºè®®å…ˆä¸‹è½½æ•°æ®'
                }
        
        if isinstance(result, dict):
            result.setdefault('scan_date', scan_date)
            result.setdefault('scan_session', scan_session)
        self._scan_quiet = False  # æ‰«æç»“æŸï¼Œæ¢å¤æ—¥å¿—
        return result

    # è¯´æ˜ï¼šä¹‹å‰ä¸ºäº†å®ç°â€œå‘¨å†…æ¯å¤©ç»“æœå˜åŒ–â€ï¼Œæ›¾å°è¯•ç”¨â€œæ—¥Kæˆªè‡³æŒ‡å®šæ—¥æœŸèšåˆå‘¨Kï¼ˆå«æœªå®Œæˆå‘¨ï¼‰â€ã€‚
    # - å¦‚æœ scan_date åœ¨å½“å‰å‘¨å†…ï¼ˆå‘¨ä¸€åˆ°å‘¨Kæ—¥æœŸä¹‹é—´ï¼‰ï¼Œä¼šç”¨è¯¥å‘¨å‘¨ä¸€åˆ° scan_date çš„æ—¥Kèšåˆæˆéƒ¨åˆ†å‘¨K
    # - è¿™æ ·å›æµ‹ç»“æœä¸ã€Œå½“å¤©å®ç›˜æ‰«æã€å®Œå…¨ä¸€è‡´ï¼Œä¿è¯å›æµ‹çš„æœ‰æ•ˆæ€§å’Œå¯æ¯”æ€§
    # - å†å²å›æµ‹æ—¶ï¼šå›æµ‹ä¸Šå‘¨äºŒ = ç”¨ä¸Šå‘¨ä¸€+äºŒèšåˆï¼Œå›æµ‹ä¸Šå‘¨å›› = ç”¨ä¸Šå‘¨ä¸€ï½å››èšåˆ
    # - å®æ—¶æ‰«ææ—¶ï¼šscan_date = None æˆ– = ä»Šå¤©ï¼ŒåŒæ ·è¿›è¡Œ as-of èšåˆ
    def _process_single_stock(self, stock_code: str, stock_name: str, common_features: Dict, min_match_score: float, max_market_cap: float, idx: int, total_stocks: int, scan_date: str = None, scan_session: str = None, force_refresh: bool = False) -> Dict:
        """
        å¤„ç†å•åªè‚¡ç¥¨ï¼ˆç”¨äºå¹¶è¡Œå¤„ç†ï¼‰
        :param stock_code: è‚¡ç¥¨ä»£ç 
        :param stock_name: è‚¡ç¥¨åç§°
        :param common_features: å…±åŒç‰¹å¾æ¨¡æ¿
        :param min_match_score: æœ€å°åŒ¹é…åº¦é˜ˆå€¼
        :param max_market_cap: æœ€å¤§å¸‚å€¼
        :param idx: å½“å‰ç´¢å¼•
        :param total_stocks: æ€»è‚¡ç¥¨æ•°
        :return: å€™é€‰è‚¡ç¥¨ä¿¡æ¯ï¼ˆå¦‚æœç¬¦åˆæ¡ä»¶ï¼‰ï¼Œå¦åˆ™è¿”å› None
        """
        import time as time_module
        import threading
        import pandas as pd
        
        try:
            # æ£€æŸ¥åœæ­¢ä¿¡å·
            if self.stop_scan:
                return None
            
            start_time = time_module.time()
            max_process_time = 3  # å•ä¸ªè‚¡ç¥¨æœ€å¤§å¤„ç†æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œæ›´å¿«è·³è¿‡æ…¢è‚¡ç¥¨
            
            # æ—¶é—´ç»Ÿè®¡
            step_times = {}
            
            # 1. è·å–å‘¨Kçº¿æ•°æ®
            step_start = time_module.time()
            try:
                # ä½¿ç”¨å‘¨Kçº¿ï¼ˆä¸è®­ç»ƒ/åŸæ‰«æä¸€è‡´ï¼‰ï¼›scan_date çš„â€œå›æ”¾â€åœ¨åç»­é€šè¿‡æˆªæ–­å‘¨Kå®ç°
                # å¦‚æœæŒ‡å®šäº†å†å² scan_dateï¼Œå¼ºåˆ¶ä½¿ç”¨æœ¬åœ°ç¼“å­˜ä»¥ç¡®ä¿å†å²å›æµ‹ä¸€è‡´æ€§
                use_cache = True
                if force_refresh and not scan_date:
                    use_cache = False  # åªæœ‰åœ¨æ²¡æœ‰æŒ‡å®šscan_dateä¸”å¼ºåˆ¶åˆ·æ–°æ—¶æ‰ä¸ç”¨ç¼“å­˜
                # æ‰«ææ—¶ä¼˜å…ˆä½¿ç”¨æœ¬åœ°æ•°æ®ï¼Œå¦‚æœæœ¬åœ°æ²¡æœ‰åˆ™ä»ç½‘ç»œä¸‹è½½
                # å…ˆå°è¯•æœ¬åœ°æ•°æ®ï¼ˆå¿«é€Ÿï¼‰
                weekly_df = self.fetcher.get_weekly_kline(stock_code, period="2y", use_cache=use_cache, local_only=True)
                step_times['è·å–å‘¨Kçº¿'] = time_module.time() - step_start
                
                # âœ… å…³é”®ï¼šå¦‚æœè®¾ç½®äº† strict_local_onlyï¼Œå³ä½¿æœ¬åœ°æ²¡æœ‰æ•°æ®ä¹Ÿä¸ä»ç½‘ç»œä¸‹è½½
                strict_local_only = getattr(self, '_strict_local_only', False)
                
                # å¦‚æœæœ¬åœ°æ²¡æœ‰æ•°æ®ï¼Œå°è¯•ä»ç½‘ç»œä¸‹è½½ï¼ˆé™¤é strict_local_only=Trueï¼‰
                if weekly_df is None or len(weekly_df) < 40:
                    if strict_local_only:
                        # ä¸¥æ ¼æœ¬åœ°æ¨¡å¼ï¼šè·³è¿‡ç¼ºå¤±æ•°æ®çš„è‚¡ç¥¨ï¼Œä¸ä»ç½‘ç»œä¸‹è½½
                        if not hasattr(self, '_missing_data_stocks'):
                            self._missing_data_stocks = set()
                        self._missing_data_stocks.add(stock_code)
                        return None
                    else:
                        # å°è¯•ä»ç½‘ç»œä¸‹è½½
                        print(f"[_process_single_stock] {stock_code} æœ¬åœ°æ— æ•°æ®ï¼Œå°è¯•ä»ç½‘ç»œä¸‹è½½...")
                        weekly_df = self.fetcher.get_weekly_kline(stock_code, period="2y", use_cache=False, local_only=False)
                        step_times['è·å–å‘¨Kçº¿'] = time_module.time() - step_start
                        
                        # å¦‚æœç½‘ç»œè·å–ä¹Ÿå¤±è´¥ï¼Œè®°å½•åˆ°ç¼ºå¤±åˆ—è¡¨
                        if weekly_df is None or len(weekly_df) < 40:
                            if not hasattr(self, '_missing_data_stocks'):
                                self._missing_data_stocks = set()
                            self._missing_data_stocks.add(stock_code)
                            return None
            except Exception as e:
                step_times['è·å–å‘¨Kçº¿'] = time_module.time() - step_start
                return None
            
            # æ£€æŸ¥æ€»è€—æ—¶
            elapsed = time_module.time() - start_time
            if elapsed > max_process_time:
                return None
            
            # 2. æå–ç‰¹å¾
            step_start = time_module.time()
            try:
                # é»˜è®¤ä½¿ç”¨æœ€æ–°ä¸€å‘¨ï¼›å¦‚æœæŒ‡å®š scan_dateï¼Œåˆ™å›åˆ°è¯¥æ—¥æœŸå¯¹åº”çš„æœ€è¿‘ä¸€å‘¨ï¼ˆas-ofï¼‰
                current_idx = len(weekly_df) - 1
                if scan_date:
                    try:
                        scan_ts = pd.to_datetime(scan_date, errors='coerce')
                        if pd.notna(scan_ts) and 'æ—¥æœŸ' in weekly_df.columns:
                            w = weekly_df.copy()
                            w['__dt'] = pd.to_datetime(w['æ—¥æœŸ'], errors='coerce')
                            w = w.dropna(subset=['__dt'])
                            
                            # ä¸¥æ ¼å›æº¯ï¼ˆas-ofï¼‰ï¼šä»…ä¿ç•™ __dt <= scan_ts çš„å‘¨Kï¼Œé¿å…å·çœ‹æœªæ¥
                            w = w[w['__dt'] <= scan_ts]
                            
                            if len(w) >= 40:
                                weekly_df = w.drop(columns=['__dt'])
                                current_idx = len(weekly_df) - 1
                            else:
                                return None
                    except Exception:
                        pass
                
                # âœ… as-of èšåˆï¼šå¯¹ã€Œå½“å‰å‘¨ã€è¿›è¡Œéƒ¨åˆ†å‘¨Kèšåˆï¼ˆé€‚ç”¨äºå®æ—¶æ‰«æå’Œå†å²å›æµ‹ï¼‰
                # å¦‚æœ scan_date åœ¨å½“å‰å‘¨å†…ï¼ˆå‘¨ä¸€åˆ°å‘¨Kæ—¥æœŸä¹‹é—´ï¼‰ï¼Œç”¨è¯¥å‘¨å‘¨ä¸€åˆ° scan_date çš„æ—¥Kèšåˆæˆéƒ¨åˆ†å‘¨K
                # è¿™æ ·å›æµ‹ç»“æœä¸ã€Œå½“å¤©å®ç›˜æ‰«æã€å®Œå…¨ä¸€è‡´ï¼Œä¿è¯å›æµ‹çš„æœ‰æ•ˆæ€§
                aggregated_this_week = False  # æ ‡è®°æ˜¯å¦è¿›è¡Œäº†èšåˆ
                try:
                    from datetime import datetime as dt_now, timedelta
                    
                    # ç¡®å®šå®é™…ä½¿ç”¨çš„æ‰«ææ—¥æœŸï¼šå¦‚æœ scan_date ä¸º Noneï¼Œä½¿ç”¨ä»Šå¤©çš„æ—¥æœŸï¼ˆå®æ—¶æ‰«æï¼‰
                    actual_scan_date = scan_date if scan_date else dt_now.now().strftime('%Y-%m-%d')
                    
                    if len(weekly_df) > 0 and 'æ—¥æœŸ' in weekly_df.columns:
                        # ä½¿ç”¨ç¡®å®šçš„æ‰«ææ—¥æœŸ
                        scan_ts = pd.to_datetime(actual_scan_date, errors='coerce')
                        
                        if pd.notna(scan_ts):
                            # è·å–æœ€åä¸€å‘¨çš„æ—¥æœŸ
                            last_week_date = pd.to_datetime(weekly_df.iloc[-1]['æ—¥æœŸ'], errors='coerce')
                            
                            if pd.notna(last_week_date):
                                # åŠ¨æ€è®¡ç®—æœ€åä¸€å‘¨çš„å‘¨ä¸€ï¼šæ‰¾åˆ°åŒ…å« last_week_date çš„é‚£ä¸€å‘¨çš„å‘¨ä¸€
                                # å‘¨Kçš„æ—¥æœŸå¯èƒ½æ˜¯å‘¨äº”ï¼ˆweekday=4ï¼‰æˆ–å‘¨æ—¥ï¼ˆweekday=6ï¼‰ï¼Œä»£è¡¨è¯¥å‘¨ç»“æŸæ—¥
                                # å¾€å‰æ¨ weekday å¤©ï¼Œå¾—åˆ°è¯¥å‘¨çš„å‘¨ä¸€
                                last_week_weekday = last_week_date.weekday()  # 0=å‘¨ä¸€, 4=å‘¨äº”, 6=å‘¨æ—¥
                                last_week_monday = last_week_date - timedelta(days=last_week_weekday)
                                
                                # åˆ¤æ–­ scan_date æ˜¯å¦åœ¨æœ€åä¸€å‘¨å†…ï¼ˆå‘¨ä¸€åˆ°å‘¨Kæ—¥æœŸä¹‹é—´ï¼‰
                                # æˆ–è€… scan_date åœ¨å½“å‰å‘¨å†…ï¼ˆæœ€åä¸€å‘¨ä¹‹åï¼Œä½†ä»åœ¨å½“å‰å‘¨ï¼‰
                                should_aggregate = False
                                week_start_str = None
                                week_end_date = None
                                
                                if last_week_monday <= scan_ts <= last_week_date:
                                    # æƒ…å†µ1ï¼šscan_date åœ¨æœ€åä¸€å‘¨å†…
                                    should_aggregate = True
                                    week_start_str = last_week_monday.strftime('%Y%m%d')
                                    week_end_date = last_week_date
                                elif scan_ts > last_week_date:
                                    # æƒ…å†µ2ï¼šscan_date åœ¨æœ€åä¸€å‘¨ä¹‹åï¼Œæ£€æŸ¥æ˜¯å¦åœ¨å½“å‰å‘¨å†…
                                    # è®¡ç®—å½“å‰å‘¨çš„å‘¨ä¸€ï¼ˆæœ€åä¸€å‘¨çš„ä¸‹ä¸€ä¸ªå‘¨ä¸€ï¼‰
                                    current_week_monday = last_week_date + timedelta(days=(7 - last_week_weekday))
                                    # è®¡ç®—å½“å‰å‘¨çš„ç»“æŸæ—¥ï¼ˆå‘¨äº”æˆ–å‘¨æ—¥ï¼Œå–å†³äºå‘¨Kçš„æ ¼å¼ï¼‰
                                    # å‡è®¾å‘¨Kåœ¨å‘¨äº”ç»“æŸï¼Œåˆ™å½“å‰å‘¨ç»“æŸæ—¥æ˜¯ current_week_monday + 4
                                    current_week_end = current_week_monday + timedelta(days=4)
                                    
                                    if current_week_monday <= scan_ts <= current_week_end:
                                        # scan_date åœ¨å½“å‰å‘¨å†…ï¼Œéœ€è¦èšåˆå½“å‰å‘¨çš„æ•°æ®
                                        should_aggregate = True
                                        week_start_str = current_week_monday.strftime('%Y%m%d')
                                        week_end_date = current_week_end
                                
                                if should_aggregate:
                                    aggregated_this_week = True  # æ ‡è®°è¿›è¡Œäº†èšåˆ
                                    # éœ€è¦èšåˆï¼šè·å–è¯¥å‘¨å‘¨ä¸€åˆ° scan_date çš„æ—¥Kæ•°æ®
                                    scan_date_str = scan_ts.strftime('%Y%m%d')
                                    
                                    # è·å–æ—¥Kæ•°æ®ï¼ˆå›æµ‹æ—¶å¼ºåˆ¶ä½¿ç”¨æœ¬åœ°ç¼“å­˜ï¼Œç¡®ä¿å†å²æ•°æ®ä¸€è‡´æ€§ï¼‰
                                    daily_df = self.fetcher.get_daily_kline_range(
                                        stock_code,
                                        start_date=week_start_str,
                                        end_date=scan_date_str,
                                        use_cache=True,
                                        local_only=True  # å›æµ‹æ—¶å¼ºåˆ¶ä½¿ç”¨æœ¬åœ°ç¼“å­˜ï¼Œé¿å…ä½¿ç”¨æœªæ¥æ•°æ®
                                    )
                                    
                                    if daily_df is not None and len(daily_df) > 0:
                                        # ç¡®ä¿å¿…è¦çš„åˆ—å­˜åœ¨
                                        required_cols = ['æ—¥æœŸ', 'å¼€ç›˜', 'æ”¶ç›˜', 'æœ€é«˜', 'æœ€ä½', 'æˆäº¤é‡']
                                        if all(col in daily_df.columns for col in required_cols):
                                            # è½¬æ¢ä¸ºæ—¥æœŸç±»å‹
                                            daily_df = daily_df.copy()
                                            daily_df['æ—¥æœŸ'] = pd.to_datetime(daily_df['æ—¥æœŸ'], errors='coerce')
                                            daily_df = daily_df.dropna(subset=['æ—¥æœŸ'])
                                            # âœ… ä¸¥æ ¼è¿‡æ»¤ï¼šåªä½¿ç”¨æ‰«ææ—¥æœŸåŠä¹‹å‰çš„æ•°æ®ï¼Œé¿å…ä½¿ç”¨æœªæ¥æ•°æ®
                                            daily_df = daily_df[daily_df['æ—¥æœŸ'] <= scan_ts].sort_values('æ—¥æœŸ').reset_index(drop=True)
                                            
                                            if len(daily_df) > 0:
                                                # èšåˆä¸ºå‘¨Kï¼ˆä»…è¯¥å‘¨çš„éƒ¨åˆ†æ•°æ®ï¼‰
                                                partial_week_k = pd.Series({
                                                    'å¼€ç›˜': float(daily_df.iloc[0]['å¼€ç›˜']),
                                                    'æ”¶ç›˜': float(daily_df.iloc[-1]['æ”¶ç›˜']),
                                                    'æœ€é«˜': float(daily_df['æœ€é«˜'].max()),
                                                    'æœ€ä½': float(daily_df['æœ€ä½'].min()),
                                                    'å‘¨æˆäº¤é‡': float(daily_df['æˆäº¤é‡'].sum()),
                                                    'æ—¥æœŸ': week_end_date  # ä½¿ç”¨è¯¥å‘¨çš„ç»“æŸæ—¥æœŸ
                                                })
                                                
                                                # å¦‚æœæˆäº¤é¢åˆ—å­˜åœ¨ï¼Œä¹Ÿèšåˆ
                                                if 'æˆäº¤é¢' in daily_df.columns:
                                                    partial_week_k['å‘¨æˆäº¤é¢'] = float(daily_df['æˆäº¤é¢'].sum())
                                                
                                                # å¦‚æœå½“å‰å‘¨æ˜¯æ–°çš„ä¸€å‘¨ï¼ˆscan_ts > last_week_dateï¼‰ï¼Œéœ€è¦æ·»åŠ æ–°çš„ä¸€è¡Œ
                                                if scan_ts > last_week_date:
                                                    # æ·»åŠ æ–°çš„å‘¨Kè¡Œ
                                                    weekly_df = weekly_df.copy()
                                                    partial_week_k['æ—¥æœŸ'] = week_end_date
                                                    weekly_df = pd.concat([weekly_df, pd.DataFrame([partial_week_k])], ignore_index=True)
                                                    # âœ… æ›´æ–° current_idx æŒ‡å‘æ–°æ·»åŠ çš„èšåˆå‘¨K
                                                    current_idx = len(weekly_df) - 1
                                                else:
                                                    # æ›¿æ¢æœ€åä¸€å‘¨çš„å‘¨K
                                                    weekly_df = weekly_df.copy()
                                                    weekly_df.iloc[-1] = partial_week_k
                                                    # current_idx ä¿æŒä¸å˜ï¼Œä»æŒ‡å‘æœ€åä¸€è¡Œ
                                                
                                                # è°ƒè¯•è¾“å‡ºï¼ˆæ¯100åªè‚¡ç¥¨è¾“å‡ºä¸€æ¬¡ï¼‰
                                                if idx % 100 == 0:
                                                    print(f"[as-ofèšåˆå‘¨K] [{idx}/{total_stocks}] {stock_code} æ‰«ææ—¥æœŸ: {scan_ts.strftime('%Y-%m-%d')}, èšåˆäº†å‘¨ï¼ˆ{week_start_str} åˆ° {scan_ts.strftime('%Y-%m-%d')}ï¼‰ï¼Œcurrent_idx={current_idx}")
                except Exception as e:
                    # èšåˆå¤±è´¥ä¸å½±å“æ‰«æï¼Œç»§ç»­ä½¿ç”¨åŸå‘¨K
                    if idx % 100 == 0:
                        print(f"[as-ofèšåˆå‘¨K] [{idx}/{total_stocks}] {stock_code} èšåˆå¤±è´¥: {str(e)[:50]}")
                    pass
                
                features = self.extract_features_at_start_point(stock_code, current_idx, lookback_weeks=40, weekly_df=weekly_df)
                step_times['æå–ç‰¹å¾'] = time_module.time() - step_start
                if features is None:
                    if idx % 10 == 0:
                        print(f"[ç›‘æ§] [{idx}/{total_stocks}] {stock_code} ç‰¹å¾æå–è¿”å›Noneï¼Œè·³è¿‡")
                    return None
            except Exception as e:
                step_times['æå–ç‰¹å¾'] = time_module.time() - step_start
                if idx % 10 == 0:
                    print(f"[ç›‘æ§] [{idx}/{total_stocks}] {stock_code} ç‰¹å¾æå–å¼‚å¸¸: {str(e)[:50]}")
                return None
            
            # æ£€æŸ¥æ€»è€—æ—¶
            elapsed = time_module.time() - start_time
            if elapsed > max_process_time:
                return None
            
            # 3. è®¡ç®—åŒ¹é…åº¦
            step_start = time_module.time()
            try:
                match_score = self._calculate_match_score(features, common_features, tolerance=0.3)
                step_times['è®¡ç®—åŒ¹é…åº¦'] = time_module.time() - step_start
                total_match = match_score['æ€»åŒ¹é…åº¦']
                
                # å¾®è°ƒï¼šæœ€è¿‘4æ—¥æ¶¨å¹…>10%ä½†æ— æ¶¨åœæ¿æ—¶é™ä½åŒ¹é…åº¦ï¼ˆæ‰«æåŠ é€Ÿæ—¶å¯å…³é—­ï¼Œé¿å…æ¯åªè‚¡ç¥¨æ‹‰æ—¥Kï¼‰
                if scan_date and not getattr(self, '_scan_skip_4d_gain_check', True):
                    try:
                        from datetime import timedelta
                        scan_ts = pd.to_datetime(scan_date, errors='coerce')
                        if pd.notna(scan_ts):
                            start_date = (scan_ts - timedelta(days=10)).strftime('%Y%m%d')
                            end_date = scan_ts.strftime('%Y%m%d')
                            daily_df = self.fetcher.get_daily_kline_range(stock_code, start_date, end_date)
                            if daily_df is not None and len(daily_df) >= 4:
                                daily_df['æ—¥æœŸ'] = pd.to_datetime(daily_df['æ—¥æœŸ'], errors='coerce')
                                daily_df = daily_df.dropna(subset=['æ—¥æœŸ']).copy()
                                daily_df = daily_df[daily_df['æ—¥æœŸ'] <= scan_ts].sort_values('æ—¥æœŸ').reset_index(drop=True)
                                if len(daily_df) >= 4:
                                    recent_4 = daily_df.tail(4)
                                    first_close = float(recent_4.iloc[0]['æ”¶ç›˜'])
                                    last_close = float(recent_4.iloc[-1]['æ”¶ç›˜'])
                                    if first_close > 0:
                                        gain_4d = (last_close - first_close) / first_close * 100
                                        has_limit_up = 'æ¶¨è·Œå¹…' in recent_4.columns and any(float(r.get('æ¶¨è·Œå¹…', 0)) >= 9.8 for _, r in recent_4.iterrows())
                                        if gain_4d > 10.0 and not has_limit_up:
                                            total_match = total_match * 0.95
                                            match_score['æ€»åŒ¹é…åº¦'] = round(total_match, 3)
                    except Exception:
                        pass
                
                if total_match < min_match_score:
                    return None
            except Exception as e:
                step_times['è®¡ç®—åŒ¹é…åº¦'] = time_module.time() - step_start
                if idx % 500 == 0:
                    print(f"[ç›‘æ§] [{idx}/{total_stocks}] {stock_code} åŒ¹é…åº¦è®¡ç®—å¼‚å¸¸: {str(e)[:50]}")
                return None
            
            # 3.5. æ£€æŸ¥120æ—¥å’Œ250æ—¥å‡çº¿æ–¹å‘ï¼ˆå¦‚æœéƒ½å‘ä¸‹ï¼Œç›´æ¥æ’é™¤ï¼‰
            step_start_ma = time_module.time()
            try:
                # è·å–æ—¥Kçº¿æ•°æ®ï¼ˆç”¨äºè®¡ç®—120æ—¥å’Œ250æ—¥å‡çº¿ï¼‰
                limit_date = scan_date if scan_date else pd.Timestamp.now().strftime('%Y-%m-%d')
                limit_date_ymd = pd.to_datetime(limit_date).strftime('%Y%m%d')
                
                # è·å–è¶³å¤Ÿçš„å†å²æ•°æ®ï¼ˆè‡³å°‘250å¤©ï¼‰
                daily_df = self.fetcher.get_daily_kline_range(
                    stock_code, 
                    start_date='20220101',  # ä»2022å¹´å¼€å§‹è¶³å¤Ÿè¦†ç›–250å¤©
                    end_date=limit_date_ymd,
                    use_cache=True,
                    local_only=True
                )
                
                if daily_df is not None and len(daily_df) >= 250:
                    daily_df['æ—¥æœŸ'] = pd.to_datetime(daily_df['æ—¥æœŸ'], errors='coerce')
                    daily_df = daily_df.dropna(subset=['æ—¥æœŸ']).sort_values('æ—¥æœŸ').reset_index(drop=True)
                    
                    # æ‰¾åˆ°æ‰«ææ—¥æœŸå¯¹åº”çš„ç´¢å¼•
                    limit_dt = pd.to_datetime(limit_date)
                    daily_before = daily_df[daily_df['æ—¥æœŸ'] <= limit_dt]
                    if len(daily_before) >= 250:
                        scan_idx = len(daily_before) - 1
                        
                        # è®¡ç®—å½“å‰å‡çº¿å€¼
                        ma120_current = daily_before['æ”¶ç›˜'].iloc[scan_idx-119:scan_idx+1].mean()
                        ma250_current = daily_before['æ”¶ç›˜'].iloc[scan_idx-249:scan_idx+1].mean()
                        
                        # è®¡ç®—20å¤©å‰çš„å‡çº¿å€¼ï¼ˆç”¨äºåˆ¤æ–­æ–¹å‘ï¼‰
                        if scan_idx >= 20:
                            ma120_20d_ago = daily_before['æ”¶ç›˜'].iloc[scan_idx-139:scan_idx-119].mean()
                            ma250_20d_ago = daily_before['æ”¶ç›˜'].iloc[scan_idx-269:scan_idx-249].mean()
                            
                            # è®¡ç®—æ–œç‡ï¼ˆæ–¹å‘ï¼‰
                            ma120_slope = (ma120_current - ma120_20d_ago) / ma120_20d_ago if ma120_20d_ago > 0 else 0
                            ma250_slope = (ma250_current - ma250_20d_ago) / ma250_20d_ago if ma250_20d_ago > 0 else 0
                            
                            # å¦‚æœ120æ—¥å’Œ250æ—¥å‡çº¿éƒ½å‘ä¸‹ï¼ˆæ–œç‡<0ï¼‰ï¼Œç›´æ¥æ’é™¤
                            if ma120_slope < 0 and ma250_slope < 0:
                                print(f"[å‡çº¿è¿‡æ»¤] [{idx}/{total_stocks}] {stock_code} {stock_name} MA120å’ŒMA250éƒ½å‘ä¸‹ï¼Œå·²æ’é™¤ (MA120æ–œç‡: {ma120_slope*100:.2f}%, MA250æ–œç‡: {ma250_slope*100:.2f}%, æ‰«ææ—¥æœŸ: {limit_date})")
                                return None
            except Exception as e:
                # å‡çº¿æ£€æŸ¥å¤±è´¥ä¸å½±å“æ‰«æï¼Œç»§ç»­å¤„ç†ï¼ˆä½†è®°å½•è¯¦ç»†é”™è¯¯ï¼‰
                import traceback
                error_detail = traceback.format_exc()
                if idx % 100 == 0 or stock_code == '000798':  # å¯¹ä¸­æ°´æ¸”ä¸šæ€»æ˜¯æ‰“å°
                    print(f"[å‡çº¿æ£€æŸ¥å¼‚å¸¸] [{idx}/{total_stocks}] {stock_code} {stock_name} å‡çº¿æ–¹å‘æ£€æŸ¥å¼‚å¸¸: {str(e)}")
                    if stock_code == '000798':
                        print(f"[å‡çº¿æ£€æŸ¥å¼‚å¸¸-è¯¦ç»†] {error_detail[:500]}")
                pass
            
            step_times['æ€»è€—æ—¶'] = time_module.time() - start_time
            if idx > 0 and idx % 500 == 0:
                print(f"[æ—¶é—´ç»Ÿè®¡] {idx}/{total_stocks}: å‘¨K={step_times.get('è·å–å‘¨Kçº¿',0):.2f}s ç‰¹å¾={step_times.get('æå–ç‰¹å¾',0):.2f}s åŒ¹é…={step_times.get('è®¡ç®—åŒ¹é…åº¦',0):.2f}s å¸‚å€¼={step_times.get('è·å–å¸‚å€¼',0):.2f}s æ€»={step_times.get('æ€»è€—æ—¶',0):.2f}s")
            
            # 4. æ£€æŸ¥å¸‚å€¼ï¼ˆâœ… å¿…é¡»åŒæ­¥æ£€æŸ¥ï¼Œæ£€ç´¢æ—¶åŒæ­¥æ£€æŸ¥ï¼‰
            market_cap = None
            market_cap_valid = False
            if max_market_cap > 0:
                try:
                    # ä½¿ç”¨è¶…æ—¶æœºåˆ¶è·å–å¸‚å€¼ï¼ˆé¿å…å¡ä½ï¼‰
                    step_start = time_module.time()
                    market_cap_result = [None]
                    market_cap_error = [None]
                    
                    def fetch_market_cap():
                        try:
                            market_cap_result[0] = self.fetcher.get_market_cap(stock_code, timeout=2)
                        except Exception as e:
                            market_cap_error[0] = e
                    
                    cap_thread = threading.Thread(target=fetch_market_cap)
                    cap_thread.daemon = True
                    cap_thread.start()
                    cap_thread.join(timeout=2.5)  # æœ€å¤šç­‰å¾…2.5ç§’
                    
                    step_times['è·å–å¸‚å€¼'] = time_module.time() - step_start
                    
                    if not cap_thread.is_alive() and market_cap_result[0] is not None and market_cap_result[0] > 0:
                        market_cap = market_cap_result[0]
                        market_cap_valid = True
                        # âœ… å¸‚å€¼è¶…è¿‡é™åˆ¶ï¼Œç›´æ¥è·³è¿‡è¯¥è‚¡ç¥¨
                        if market_cap > max_market_cap:
                            return None
                    else:
                        if idx % 500 == 0:
                            print(f"[ç›‘æ§] [{idx}/{total_stocks}] {stock_code} å¸‚å€¼è·å–å¤±è´¥æˆ–è¶…æ—¶ï¼Œç»§ç»­å¤„ç†")
                except Exception as e:
                    step_times['è·å–å¸‚å€¼'] = time_module.time() - step_start if 'step_start' in locals() else 0
                    if idx % 500 == 0:
                        print(f"[ç›‘æ§] [{idx}/{total_stocks}] {stock_code} å¸‚å€¼è·å–å¼‚å¸¸: {str(e)[:50]}")
                    pass  # å¸‚å€¼è·å–å¤±è´¥ï¼Œç»§ç»­å¤„ç†è¯¥è‚¡ç¥¨ï¼ˆå°†åœ¨æ‰«æå®ŒæˆåäºŒæ¬¡è¿‡æ»¤ï¼‰
            
                # 5. è®°å½•å€™é€‰è‚¡ç¥¨ï¼ˆæœ€ä½³ä¹°ç‚¹æ—¥æœŸ = æœ€åä¸€å‘¨çš„å‘¨Kæ—¥æœŸï¼Œä»·æ ¼ = æ‰«ææ—¥æœŸçš„æ”¶ç›˜ä»·ï¼‰
                try:
                    from datetime import datetime as dt_now
                    today_str = dt_now.now().strftime('%Y-%m-%d')
                    limit_date = scan_date if scan_date else today_str  # æœç´¢å½“å¤©
                    fallback_price = float(weekly_df.iloc[current_idx]['æ”¶ç›˜'])
                    current_date = weekly_df.iloc[current_idx]['æ—¥æœŸ']
                    if isinstance(current_date, pd.Timestamp):
                        current_date_str = current_date.strftime('%Y-%m-%d')
                        current_date_ts = current_date
                    else:
                        current_date_str = str(current_date)[:10]
                        current_date_ts = pd.to_datetime(current_date_str, errors='coerce')
                    
                    # âœ… æœ€ä½³ä¹°ç‚¹æ—¥æœŸï¼šå¦‚æœè¿›è¡Œäº†èšåˆï¼Œä½¿ç”¨æ‰«ææ—¥æœŸï¼›å¦åˆ™ä½¿ç”¨æœ€åä¸€å‘¨çš„å‘¨Kæ—¥æœŸ
                    # å¦‚æœè¿›è¡Œäº†èšåˆï¼ˆaggregated_this_week=Trueï¼‰ï¼Œæœ€ä½³ä¹°ç‚¹æ—¥æœŸåº”è¯¥æ˜¯æ‰«ææ—¥æœŸ
                    # å¦åˆ™ä½¿ç”¨æœ€åä¸€å‘¨çš„å‘¨Kæ—¥æœŸï¼ˆç‰¹å¾åŒ¹é…åŸºäºè¿™ä¸€å‘¨ï¼‰
                    scan_date_ts = pd.to_datetime(limit_date, errors='coerce')
                    if aggregated_this_week and scan_date:
                        # è¿›è¡Œäº†èšåˆï¼Œæœ€ä½³ä¹°ç‚¹æ—¥æœŸ = æ‰«ææ—¥æœŸ
                        buy_date = limit_date
                    else:
                        # æ²¡æœ‰èšåˆï¼Œä½¿ç”¨æœ€åä¸€å‘¨çš„å‘¨Kæ—¥æœŸ
                        buy_date = current_date_str
                    
                    # å¦‚æœæ‰«ææ—¥æœŸåœ¨å‘¨Kæ—¥æœŸä¹‹å‰æˆ–ç­‰äºå‘¨Kæ—¥æœŸï¼Œä½¿ç”¨æ‰«ææ—¥æœŸçš„æ”¶ç›˜ä»·
                    # å¦åˆ™ä½¿ç”¨å‘¨Kæ”¶ç›˜ä»·ï¼ˆè¿™ç§æƒ…å†µä¸åº”è¯¥å‘ç”Ÿï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»æˆªæ–­äº†æ•°æ®ï¼‰
                    if pd.notna(scan_date_ts) and pd.notna(current_date_ts) and scan_date_ts <= current_date_ts:
                        close_on_search = self._get_close_on_date(stock_code, limit_date)
                        if close_on_search is not None:
                            buy_price = close_on_search
                        else:
                            buy_price = fallback_price
                    else:
                        # æ‰«ææ—¥æœŸæ™šäºå‘¨Kæ—¥æœŸï¼ˆä¸åº”è¯¥å‘ç”Ÿï¼‰ï¼Œä½¿ç”¨å‘¨Kæ”¶ç›˜ä»·
                        buy_price = fallback_price
                    
                    # âœ… å½“å‰ä»·æ ¼ = æ‰«ææ—¥æœŸçš„æ”¶ç›˜ä»·ï¼ˆä¸æ˜¯ä»Šå¤©çš„æœ€æ–°ä»·æ ¼ï¼‰
                    # å¦‚æœæ‰«ææ—¥æœŸæ˜¯å†å²æ—¥æœŸï¼Œå½“å‰ä»·æ ¼å°±æ˜¯æ‰«ææ—¥æœŸçš„ä»·æ ¼
                    # å¦‚æœæ‰«ææ—¥æœŸæ˜¯ä»Šå¤©ï¼Œå½“å‰ä»·æ ¼å°±æ˜¯ä»Šå¤©çš„æœ€æ–°ä»·æ ¼
                    current_price = buy_price  # é»˜è®¤ä½¿ç”¨æœ€ä½³ä¹°ç‚¹ä»·æ ¼ï¼ˆå³æ‰«ææ—¥æœŸçš„ä»·æ ¼ï¼‰
                    
                    # å¦‚æœæ‰«ææ—¥æœŸæ˜¯ä»Šå¤©ï¼Œä¸”è·å–åˆ°äº†ä»Šå¤©çš„ä»·æ ¼ï¼Œä½¿ç”¨ä»Šå¤©çš„ä»·æ ¼
                    # å¦‚æœæ‰«ææ—¥æœŸæ˜¯å†å²æ—¥æœŸï¼Œå½“å‰ä»·æ ¼å°±æ˜¯æ‰«ææ—¥æœŸçš„ä»·æ ¼ï¼ˆbuy_priceï¼‰
                    if limit_date == today_str:
                        # æ‰«ææ—¥æœŸæ˜¯ä»Šå¤©ï¼Œå°è¯•è·å–ä»Šå¤©çš„æœ€æ–°ä»·æ ¼ï¼ˆå¯èƒ½æ¯”buy_priceæ›´æ–°ï¼‰
                        close_today = self._get_close_on_date(stock_code, today_str)
                        if close_today is not None:
                            current_price = close_today
                        else:
                            current_price = buy_price
                    # else: æ‰«ææ—¥æœŸæ˜¯å†å²æ—¥æœŸï¼Œcurrent_price = buy_priceï¼ˆå·²ç»æ˜¯æ‰«ææ—¥æœŸçš„ä»·æ ¼ï¼‰
                    
                    # âœ… è°ƒè¯•ï¼šç¡®è®¤æœ€ç»ˆä»·æ ¼
                    if idx % 100 == 0:
                        print(f"[è°ƒè¯•-ä»·æ ¼] [{idx}/{total_stocks}] {stock_code} æœ€ä½³ä¹°ç‚¹æ—¥æœŸ: {buy_date}, æœ€ä½³ä¹°ç‚¹ä»·æ ¼: {buy_price:.2f}, å½“å‰ä»·æ ¼: {current_price:.2f}, æ‰«ææ—¥æœŸ: {limit_date}")
                    
                    # æ£€æŸ¥æ•°æ®æ˜¯å¦è¿‡æœŸï¼ˆæ•°æ®æ—¥æœŸæ¯”æ‰«ææ—¥æœŸæ—©è¶…è¿‡7å¤©ï¼‰
                    data_outdated = False
                    try:
                        data_date = pd.to_datetime(current_date_str)
                        scan_date_ts = pd.to_datetime(limit_date)
                        if (scan_date_ts - data_date).days > 7:
                            data_outdated = True
                    except Exception:
                        pass
                    # ä¹°ç‚¹å½“å¤©ä¸ºå¤§é˜´çº¿åˆ™æ’é™¤ï¼ˆä¸åŠ å…¥å€™é€‰ï¼‰
                    if self._is_big_bearish_candle_on_date(stock_code, limit_date):
                        if idx % 100 == 0:
                            print(f"[è¿‡æ»¤] [{idx}/{total_stocks}] {stock_code} {stock_name} ä¹°ç‚¹å½“æ—¥({limit_date})ä¸ºå¤§é˜´çº¿ï¼Œå·²æ’é™¤")
                        return None
                    return {
                        'è‚¡ç¥¨ä»£ç ': stock_code,
                        'è‚¡ç¥¨åç§°': stock_name,
                        'åŒ¹é…åº¦': round(match_score['æ€»åŒ¹é…åº¦'], 3),
                        'æœ€ä½³ä¹°ç‚¹æ—¥æœŸ': buy_date,
                        'æœ€ä½³ä¹°ç‚¹ä»·æ ¼': round(buy_price, 2),
                        'å½“å‰ä»·æ ¼': round(current_price, 2),
                        'å¸‚å€¼': round(market_cap, 2) if market_cap_valid else None,
                        'æ‰«ææ—¥æœŸ': scan_date,
                        'æ—¶é—´æ®µ': scan_session,
                        'æ ¸å¿ƒç‰¹å¾åŒ¹é…': match_score.get('æ ¸å¿ƒç‰¹å¾åŒ¹é…', {}),
                        'ç‰¹å¾': features,
                        'æ•°æ®è¿‡æœŸ': data_outdated  # æ ‡è®°æ•°æ®æ˜¯å¦è¿‡æœŸ
                    }
                except Exception:
                    return None
                
        except Exception:
            return None
    
    def _scan_stock_batch(self, stock_list, common_features: Dict, min_match_score: float, max_market_cap: float, batch_num: int = 1, total_batches: int = 1, start_idx: int = 0, existing_candidates: list = None, total_all_stocks: int = None, use_parallel: bool = True, max_workers: int = 5, scan_date: str = None, scan_session: str = None) -> Dict:
        # åœ¨å‡½æ•°å¼€å§‹å¤„ç»Ÿä¸€å¯¼å…¥ï¼Œé¿å…å˜é‡å†²çª
        import time as time_module
        import threading
        import logging
        
        # å¦‚æœå¯ç”¨å¹¶è¡Œå¤„ç†ï¼Œä½¿ç”¨å¹¶è¡Œç‰ˆæœ¬
        if use_parallel:
            return self._scan_stock_batch_parallel(
                stock_list, common_features, min_match_score, max_market_cap,
                batch_num, total_batches, start_idx, existing_candidates,
                total_all_stocks, max_workers, scan_date=scan_date, scan_session=scan_session
            )
        
        # å¦åˆ™ä½¿ç”¨åŸæœ‰çš„ä¸²è¡Œå¤„ç†ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
        return self._scan_stock_batch_serial(
            stock_list, common_features, min_match_score, max_market_cap,
            batch_num, total_batches, start_idx, existing_candidates, total_all_stocks, scan_date=scan_date, scan_session=scan_session
        )
    
    def _scan_stock_batch_parallel(self, stock_list, common_features: Dict, min_match_score: float, max_market_cap: float, batch_num: int = 1, total_batches: int = 1, start_idx: int = 0, existing_candidates: list = None, total_all_stocks: int = None, max_workers: int = 5, scan_date: str = None, scan_session: str = None) -> Dict:
        """
        å¹¶è¡Œæ‰«æä¸€æ‰¹è‚¡ç¥¨ï¼ˆä½¿ç”¨çº¿ç¨‹æ± ï¼‰
        :param stock_list: è‚¡ç¥¨åˆ—è¡¨ï¼ˆDataFrameï¼‰
        :param common_features: å…±åŒç‰¹å¾æ¨¡æ¿
        :param min_match_score: æœ€å°åŒ¹é…åº¦é˜ˆå€¼
        :param max_market_cap: æœ€å¤§å¸‚å€¼
        :param batch_num: å½“å‰æ‰¹æ¬¡å·
        :param total_batches: æ€»æ‰¹æ¬¡æ•°
        :param start_idx: èµ·å§‹ç´¢å¼•
        :param existing_candidates: å·²æœ‰å€™é€‰è‚¡ç¥¨åˆ—è¡¨
        :param total_all_stocks: æ€»è‚¡ç¥¨æ•°
        :param max_workers: æœ€å¤§å¹¶å‘çº¿ç¨‹æ•°
        :return: æ‰«æç»“æœ
        """
        from concurrent.futures import ThreadPoolExecutor, as_completed
        import time as time_module
        import threading
        
        total_stocks = len(stock_list)
        if total_all_stocks is None:
            total_all_stocks = total_stocks
        
        # æ›´æ–°è¿›åº¦ä¿¡æ¯
        batch_info = f" (ç¬¬ {batch_num}/{total_batches} æ‰¹)" if total_batches > 1 else ""
        self.progress = {
            'type': 'scan',
            'current': start_idx,
            'total': total_all_stocks,
            'status': 'è¿›è¡Œä¸­',
            'detail': f'å¼€å§‹å¹¶è¡Œæ‰«æ {total_stocks} åªè‚¡ç¥¨{batch_info}ï¼ˆ{max_workers} çº¿ç¨‹ï¼‰...',
            'percentage': 0,
            'found': 0,
            'candidates': [],
            'scan_date': scan_date,
            'scan_session': scan_session,
            'batch': batch_num,
            'total_batches': total_batches
        }
        
        print(f"\nğŸš€ å¼€å§‹å¹¶è¡Œæ‰«æè‚¡ç¥¨ï¼ŒæŸ¥æ‰¾ç¬¦åˆç‰›è‚¡ç‰¹å¾çš„ä¸ªè‚¡{batch_info}...")
        print(f"æœ¬æ‰¹è‚¡ç¥¨æ•°: {total_stocks}")
        print(f"å¹¶å‘çº¿ç¨‹æ•°: {max_workers}")
        print(f"æœ€å°åŒ¹é…åº¦: {min_match_score:.1%}")
        print(f"å¸‚å€¼çº¦æŸ: â‰¤ {max_market_cap} äº¿å…ƒ")
        print("=" * 80)
        
        candidates = existing_candidates.copy() if existing_candidates else []
        
        # è·å–åˆ—å
        code_col = None
        name_col = None
        for col in stock_list.columns:
            col_lower = str(col).lower()
            if 'code' in col_lower or 'ä»£ç ' in col:
                code_col = col
            elif 'name' in col_lower or 'åç§°' in col:
                name_col = col
        
        if code_col is None:
            code_col = stock_list.columns[0]
        if name_col is None and len(stock_list.columns) >= 2:
            name_col = stock_list.columns[1]
        
        # å‡†å¤‡è‚¡ç¥¨åˆ—è¡¨
        stock_items = []
        for idx, (_, row) in enumerate(stock_list.iterrows(), start=start_idx):
            stock_code = str(row[code_col])
            stock_name = str(row[name_col]) if name_col else stock_code
            stock_items.append((stock_code, stock_name, idx))
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†
        processed_count = 0
        progress_lock = threading.Lock()
        start_time = time_module.time()
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_stock = {
                executor.submit(
                    self._process_single_stock,
                    stock_code,
                    stock_name,
                    common_features,
                    min_match_score,
                    max_market_cap,
                    idx,
                    total_all_stocks,
                    scan_date,
                    scan_session,
                    getattr(self, "_force_refresh_scan", False),
                ): (stock_code, stock_name, idx)
                for stock_code, stock_name, idx in stock_items
            }
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_stock):
                # æ£€æŸ¥åœæ­¢ä¿¡å·
                if self.stop_scan:
                    # å–æ¶ˆæœªå®Œæˆçš„ä»»åŠ¡
                    for f in future_to_stock:
                        f.cancel()
                    break
                
                stock_code, stock_name, idx = future_to_stock[future]
                processed_count += 1
                
                # âœ… ç›‘æ§ï¼šæ›´æ–°å½“å‰å¤„ç†çš„è‚¡ç¥¨ï¼ˆç”¨äºå®šä½å¡ç‚¹ï¼‰
                with progress_lock:
                    self.progress['current_stock'] = stock_code
                    self.progress['current_stock_name'] = stock_name
                    self.progress['last_update_time'] = time_module.time()
                    if processed_count % 200 == 0:
                        print(f"[è¿›åº¦] å·²å¤„ç†: {processed_count}/{total_stocks} | å·²æ‰¾åˆ°: {len(candidates)}åª")
                
                try:
                    result = future.result(timeout=6)  # è·å–ç»“æœï¼Œè¶…æ—¶6ç§’ï¼ˆå…è®¸å•ä¸ªè‚¡ç¥¨å¤„ç†æ›´é•¿æ—¶é—´ï¼‰
                    if result:
                        with progress_lock:
                            candidates.append(result)
                            self.progress['found'] = len(candidates)
                            # å®æ—¶è¾“å‡ºï¼šåªä¿ç•™æœ€è¿‘/æœ€ä¼˜çš„ä¸€éƒ¨åˆ†ï¼Œé¿å…è¿›åº¦å¯¹è±¡è¿‡å¤§
                            try:
                                candidates.sort(key=lambda x: x.get('åŒ¹é…åº¦', 0), reverse=True)
                            except Exception:
                                pass
                            self.progress['candidates'] = candidates[:50] if len(candidates) > 50 else candidates
                            market_cap_info = f" å¸‚å€¼: {result['å¸‚å€¼']:.2f}äº¿" if result['å¸‚å€¼'] else " å¸‚å€¼: æœªçŸ¥"
                            print(f"\nâœ… æ‰¾åˆ°å€™é€‰: {stock_code} {stock_name} (åŒ¹é…åº¦: {result['åŒ¹é…åº¦']:.3f}{market_cap_info})")
                except Exception as e:
                    # âœ… ç›‘æ§ï¼šè®°å½•è¶…æ—¶æˆ–é”™è¯¯ï¼ˆç”¨äºå®šä½å¡ç‚¹ï¼‰
                    if "timeout" in str(e).lower() or "è¶…æ—¶" in str(e):
                        print(f"[ç›‘æ§-å¹¶è¡Œ] [{processed_count}/{total_stocks}] {stock_code} å¤„ç†è¶…æ—¶: {str(e)[:50]}")
                    # å¿½ç•¥å•ä¸ªè‚¡ç¥¨çš„é”™è¯¯ï¼Œç»§ç»­å¤„ç†
                    pass
                finally:
                    # è®°å½•å¤„ç†å®Œæˆï¼ˆç”¨äºç»Ÿè®¡æ‰€æœ‰è‚¡ç¥¨ï¼ŒåŒ…æ‹¬å¤±è´¥çš„ï¼‰
                    pass
                
                # æ›´æ–°è¿›åº¦
                with progress_lock:
                    overall_current = start_idx + processed_count
                    if total_batches > 1:
                        completed_batches_progress = ((batch_num - 1) / total_batches) * 100
                        current_batch_progress = (processed_count / total_stocks) / total_batches * 100
                        percentage = completed_batches_progress + current_batch_progress
                        percentage = min(percentage, 100.0)
                    else:
                        percentage = (overall_current / total_all_stocks) * 100
                    
                    self.progress['current'] = overall_current
                    self.progress['percentage'] = round(percentage, 1)
                    
                    # æ£€æŸ¥ç¼ºå¤±æ•°æ®å¹¶æ›´æ–°æç¤º
                    missing_count = len(self._missing_data_stocks) if hasattr(self, '_missing_data_stocks') else 0
                    missing_info = f" | ç¼ºå°‘æ•°æ®: {missing_count}åª" if missing_count > 0 else ""
                    
                    self.progress['detail'] = f'å¹¶è¡Œæ‰«æä¸­... ({overall_current}/{total_all_stocks}){batch_info} | å·²æ‰¾åˆ°: {len(candidates)} åª | å·²å¤„ç†: {processed_count}/{total_stocks}{missing_info}'
                    
                    # å¦‚æœç¼ºå¤±æ•°æ®è¶…è¿‡10%ï¼Œåœ¨è¿›åº¦ä¸­æç¤º
                    if missing_count > 0 and processed_count > 0:
                        missing_pct = (missing_count / processed_count * 100)
                        if missing_pct > 10:
                            self.progress['data_warning'] = f'âš ï¸ å·²å‘ç° {missing_count} åªè‚¡ç¥¨ç¼ºå°‘æœ¬åœ°æ•°æ®ï¼ˆ{missing_pct:.1f}%ï¼‰ï¼Œå»ºè®®å…ˆä¸‹è½½æ•°æ®'
                    # ã€ä¸å¯å˜ã€‘æ‰¾åˆ°ä¸€åªæ˜¾ç¤ºä¸€åªï¼šåŒæ­¥å€™é€‰å¿«ç…§åˆ° progress['candidates']ï¼Œä¾›å‰ç«¯è½®è¯¢ã€‚è§ æ‰«ææ˜¾ç¤ºä¸å¯å˜é€»è¾‘.md
                    if 'candidates' not in self.progress:
                        self.progress['candidates'] = []
                    else:
                        try:
                            candidates.sort(key=lambda x: x.get('åŒ¹é…åº¦', 0), reverse=True)
                        except Exception:
                            pass
                        self.progress['candidates'] = candidates[:50] if len(candidates) > 50 else candidates
                    self.progress['last_update_time'] = time_module.time()
                
                # æ¯å¤„ç†10åªè‚¡ç¥¨æ‰“å°ä¸€æ¬¡è¿›åº¦
                if processed_count % 200 == 0 or processed_count == total_stocks:
                    elapsed = time_module.time() - start_time
                    speed = processed_count / elapsed if elapsed > 0 else 0
                    print(f"[è¿›åº¦] {percentage:.1f}% - {overall_current}/{total_all_stocks} - å·²æ‰¾åˆ°: {len(candidates)} åª - é€Ÿåº¦: {speed:.1f} åª/ç§’")
        
        # æ£€æŸ¥æ˜¯å¦è¢«åœæ­¢
        if self.stop_scan:
            current_processed = start_idx + processed_count
            self.progress['status'] = 'å·²åœæ­¢'
            self.progress['detail'] = f'æ‰«æå·²åœæ­¢ï¼ˆå·²å¤„ç† {current_processed}/{total_all_stocks} åªè‚¡ç¥¨ï¼Œæ‰¾åˆ° {len(candidates)} åªï¼‰'
            self.progress['current'] = current_processed
            self.stop_scan = False
        else:
            # å®Œæˆè¿›åº¦
            if batch_num == total_batches:
                self.progress['status'] = 'å®Œæˆ'
                self.progress['percentage'] = 100.0
                self.progress['detail'] = f'æ‰€æœ‰æ‰¹æ¬¡æ‰«æå®Œæˆ: æ‰¾åˆ° {len(candidates)} åªç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨'
                self.progress['current'] = total_all_stocks
            else:
                self.progress['status'] = 'è¿›è¡Œä¸­'
                self.progress['percentage'] = round((batch_num / total_batches * 100), 1)
                overall_current = int((batch_num / total_batches) * total_all_stocks)
                self.progress['current'] = overall_current
                self.progress['detail'] = f'ç¬¬ {batch_num}/{total_batches} æ‰¹æ‰«æå®Œæˆ: æ‰¾åˆ° {len(candidates)} åªç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨ï¼Œç»§ç»­æ‰«æä¸‹ä¸€æ‰¹...'
        
        self.progress['last_update_time'] = time_module.time()
        
        # æŒ‰åŒ¹é…åº¦æ’åº
        candidates.sort(key=lambda x: x['åŒ¹é…åº¦'], reverse=True)
        
        # âœ… å…³é”®ï¼šå¸‚å€¼æ£€æŸ¥å¿…é¡»åœ¨æ‰«æå®Œæˆåè¿›è¡ŒäºŒæ¬¡è¿‡æ»¤
        # å› ä¸ºæ‰«æè¿‡ç¨‹ä¸­å¸‚å€¼è·å–å¯èƒ½å¤±è´¥æˆ–è¶…æ—¶ï¼Œå¯¼è‡´ä¸ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨è¢«åŒ…å«è¿›æ¥
        # ä¼˜åŒ–ï¼šå¦‚æœæ‰«æè¿‡ç¨‹ä¸­å·²ç»è·å–åˆ°äº†å¸‚å€¼ï¼Œç›´æ¥ä½¿ç”¨ï¼Œåªå¯¹æ²¡æœ‰å¸‚å€¼çš„è‚¡ç¥¨é‡æ–°è·å–
        if max_market_cap > 0 and len(candidates) > 0:
            print(f"\nğŸ“Š è¿›è¡Œå¸‚å€¼äºŒæ¬¡è¿‡æ»¤ï¼ˆé˜ˆå€¼: â‰¤ {max_market_cap} äº¿å…ƒï¼‰...")
            original_count = len(candidates)
            
            # ç»Ÿè®¡å·²æœ‰å¸‚å€¼å’Œæ²¡æœ‰å¸‚å€¼çš„è‚¡ç¥¨æ•°é‡
            has_market_cap_count = sum(1 for c in candidates if c.get('å¸‚å€¼') is not None and c.get('å¸‚å€¼', 0) > 0)
            no_market_cap_count = len(candidates) - has_market_cap_count
            print(f"  ğŸ“Š ç»Ÿè®¡: {has_market_cap_count} åªè‚¡ç¥¨å·²æœ‰å¸‚å€¼ï¼Œ{no_market_cap_count} åªè‚¡ç¥¨éœ€è¦é‡æ–°è·å–å¸‚å€¼")
            
            filtered_candidates = []
            
            # æ·»åŠ è¿›åº¦æ›´æ–°
            total_candidates = len(candidates)
            for idx, candidate in enumerate(candidates, 1):
                stock_code = candidate.get('è‚¡ç¥¨ä»£ç ')
                if stock_code is None:
                    continue
                
                # æ¯100åªè‚¡ç¥¨æ›´æ–°ä¸€æ¬¡è¿›åº¦
                if idx % 100 == 0 or idx == total_candidates:
                    pct = (idx / total_candidates) * 100
                    filtered_so_far = original_count - len(filtered_candidates)
                    print(f"  [å¸‚å€¼è¿‡æ»¤è¿›åº¦] {idx}/{total_candidates} ({pct:.1f}%) - å·²å¤„ç†: {idx} åªï¼Œå·²è¿‡æ»¤: {filtered_so_far} åª")
                    # æ›´æ–°è¿›åº¦çŠ¶æ€
                    if hasattr(self, 'progress'):
                        self.progress['detail'] = f'å¸‚å€¼äºŒæ¬¡è¿‡æ»¤ä¸­: {idx}/{total_candidates} ({pct:.1f}%)'
                        self.progress['last_update_time'] = time_module.time()
                
                # æ£€æŸ¥å·²æœ‰å¸‚å€¼ï¼ˆä¼˜å…ˆä½¿ç”¨æ‰«æè¿‡ç¨‹ä¸­è·å–çš„å¸‚å€¼ï¼‰
                existing_market_cap = candidate.get('å¸‚å€¼')
                if existing_market_cap is not None and existing_market_cap > 0:
                    # âœ… å¦‚æœæ‰«æè¿‡ç¨‹ä¸­å·²ç»è·å–åˆ°äº†å¸‚å€¼ï¼Œç›´æ¥ä½¿ç”¨ï¼Œä¸éœ€è¦é‡æ–°è·å–
                    if existing_market_cap > max_market_cap:
                        if idx % 500 == 0:  # å‡å°‘æ—¥å¿—è¾“å‡º
                            print(f"  âŒ {stock_code} {candidate.get('è‚¡ç¥¨åç§°', '')} å¸‚å€¼ {existing_market_cap:.2f}äº¿è¶…è¿‡é™åˆ¶ {max_market_cap:.2f}äº¿ï¼Œå·²è¿‡æ»¤")
                        continue
                    filtered_candidates.append(candidate)
                    continue
                
                # å¦‚æœæ²¡æœ‰å¸‚å€¼ï¼Œå°è¯•è·å–ï¼ˆä½¿ç”¨æ›´çŸ­çš„è¶…æ—¶ï¼Œé¿å…å¡ä½ï¼‰
                try:
                    market_cap = self.fetcher.get_market_cap(stock_code, timeout=2)  # å‡å°‘è¶…æ—¶æ—¶é—´ä»3ç§’åˆ°2ç§’
                    if market_cap is not None and market_cap > 0:
                        candidate['å¸‚å€¼'] = round(market_cap, 2)
                        # âœ… å…³é”®ï¼šå¦‚æœå¸‚å€¼è¶…è¿‡é™åˆ¶ï¼Œè¿‡æ»¤æ‰
                        if market_cap > max_market_cap:
                            if idx % 500 == 0:  # å‡å°‘æ—¥å¿—è¾“å‡º
                                print(f"  âŒ {stock_code} {candidate.get('è‚¡ç¥¨åç§°', '')} å¸‚å€¼ {market_cap:.2f}äº¿è¶…è¿‡é™åˆ¶ {max_market_cap:.2f}äº¿ï¼Œå·²è¿‡æ»¤")
                            continue
                        filtered_candidates.append(candidate)
                    else:
                        # å¸‚å€¼è·å–å¤±è´¥ï¼Œä¿ç•™è¯¥è‚¡ç¥¨ï¼ˆä¸å› å¸‚å€¼è·å–å¤±è´¥è€Œä¸¢å¤±ï¼‰
                        filtered_candidates.append(candidate)
                except Exception:
                    # å¸‚å€¼è·å–å¼‚å¸¸ï¼Œä¿ç•™è¯¥è‚¡ç¥¨ï¼ˆä¸å› å¸‚å€¼è·å–å¤±è´¥è€Œä¸¢å¤±ï¼‰
                    filtered_candidates.append(candidate)
            
            candidates = filtered_candidates
            filtered_count = original_count - len(candidates)
            if filtered_count > 0:
                print(f"   âœ… å¸‚å€¼è¿‡æ»¤å®Œæˆï¼šè¿‡æ»¤æ‰ {filtered_count} åªï¼ˆå¸‚å€¼ > {max_market_cap} äº¿å…ƒï¼‰ï¼Œå‰©ä½™ {len(candidates)} åª")
            else:
                print(f"   âœ… å¸‚å€¼è¿‡æ»¤å®Œæˆï¼šæ‰€æœ‰å€™é€‰è‚¡ç¥¨å‡ç¬¦åˆå¸‚å€¼è¦æ±‚ï¼Œå‰©ä½™ {len(candidates)} åª")
        
        elapsed_time = time_module.time() - start_time
        speed = processed_count / elapsed_time if elapsed_time > 0 else 0
        print("\n" + "=" * 80)
        print(f"âœ… æœ¬æ‰¹å¹¶è¡Œæ‰«æå®Œæˆï¼æ‰¾åˆ° {len(candidates)} åªç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨{batch_info}")
        print(f"â±ï¸ è€—æ—¶: {elapsed_time:.1f}ç§’ | é€Ÿåº¦: {speed:.2f} åª/ç§’")
        print("=" * 80)
        
        if self.progress.get('status') == 'å·²åœæ­¢':
            current_processed = self.progress.get('current', start_idx + processed_count)
            return {
                'success': True,
                'message': f'æ‰«æå·²åœæ­¢ï¼Œå·²å¤„ç† {current_processed}/{total_all_stocks} åªè‚¡ç¥¨ï¼Œæ‰¾åˆ° {len(candidates)} åªç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨',
                'candidates': candidates[:50] if len(candidates) > 50 else candidates,
                'total_scanned': current_processed,
                'found_count': len(candidates),
                'batch': batch_num,
                'total_batches': total_batches,
                'stopped': True
            }
        
        result = {
            'success': True,
            'message': f'æœ¬æ‰¹æ‰«æå®Œæˆï¼Œæ‰¾åˆ° {len(candidates)} åªç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨',
            'candidates': candidates[:50] if len(candidates) > 50 else candidates,
            'total_scanned': start_idx + processed_count,
            'found_count': len(candidates),
            'batch': batch_num,
            'total_batches': total_batches,
            'elapsed_time': elapsed_time,
            'speed': speed
        }
        
        # æ£€æŸ¥ç¼ºå¤±æ•°æ®å¹¶æ·»åŠ åˆ°ç»“æœä¸­
        missing_count = len(self._missing_data_stocks) if hasattr(self, '_missing_data_stocks') else 0
        if missing_count > 0:
            missing_pct = (missing_count / processed_count * 100) if processed_count > 0 else 0
            result['data_warning'] = {
                'missing_count': missing_count,
                'processed_count': processed_count,
                'missing_percentage': round(missing_pct, 1),
                'message': f'æœ¬æ‰¹æ‰«æä¸­ï¼Œ{missing_count} åªè‚¡ç¥¨ç¼ºå°‘æœ¬åœ°æ•°æ®ï¼Œå·²è·³è¿‡ã€‚å»ºè®®å…ˆä¸‹è½½å®Œæ•´æ•°æ®ã€‚'
            }
        
        # ä¿å­˜æ‰«æç»“æœåˆ° analyzer.scan_resultsï¼ˆä¾›å‰ç«¯è·å–ï¼‰
        self.scan_results = result.copy()
        # ç¡®ä¿ä¿å­˜å®Œæ•´çš„å€™é€‰åˆ—è¡¨ï¼ˆä¸ä»…ä»…æ˜¯å‰50ä¸ªï¼‰
        self.scan_results['candidates'] = candidates  # ä¿å­˜å…¨éƒ¨å€™é€‰ï¼Œä¸é™åˆ¶ä¸º50ä¸ª
        
        return result
    
    def _scan_stock_batch_serial(self, stock_list, common_features: Dict, min_match_score: float, max_market_cap: float, batch_num: int = 1, total_batches: int = 1, start_idx: int = 0, existing_candidates: list = None, total_all_stocks: int = None, scan_date: str = None, scan_session: str = None) -> Dict:
        """
        æ‰«æä¸€æ‰¹è‚¡ç¥¨ï¼ˆä¸²è¡Œå¤„ç†ï¼ŒåŸæœ‰é€»è¾‘ï¼‰
        :param stock_list: è‚¡ç¥¨åˆ—è¡¨ï¼ˆDataFrameï¼‰
        :param common_features: å…±åŒç‰¹å¾æ¨¡æ¿
        :param min_match_score: æœ€å°åŒ¹é…åº¦é˜ˆå€¼
        :param max_market_cap: æœ€å¤§å¸‚å€¼
        :param batch_num: å½“å‰æ‰¹æ¬¡å·
        :param total_batches: æ€»æ‰¹æ¬¡æ•°
        :return: æ‰«æç»“æœ
        """
        total_stocks = len(stock_list)  # å½“å‰æ‰¹æ¬¡çš„è‚¡ç¥¨æ•°
        # å¦‚æœä¼ å…¥äº†æ€»è‚¡ç¥¨æ•°ï¼Œä½¿ç”¨å®ƒï¼›å¦åˆ™ä½¿ç”¨å½“å‰æ‰¹æ¬¡çš„è‚¡ç¥¨æ•°
        if total_all_stocks is None:
            total_all_stocks = total_stocks
        
        # æ›´æ–°è¿›åº¦ä¿¡æ¯ï¼ˆåŒ…å«æ‰¹æ¬¡ä¿¡æ¯ï¼‰
        batch_info = f" (ç¬¬ {batch_num}/{total_batches} æ‰¹)" if total_batches > 1 else ""
        self.progress = {
            'type': 'scan',
            'current': 0,
            'total': total_all_stocks,  # ä½¿ç”¨æ€»è‚¡ç¥¨æ•°
            'status': 'è¿›è¡Œä¸­',
            'detail': f'å¼€å§‹æ‰«æ {total_stocks} åªè‚¡ç¥¨{batch_info}...',
            'percentage': 0,
            'found': 0,
            'candidates': [],
            'scan_date': scan_date,
            'scan_session': scan_session,
            'batch': batch_num,
            'total_batches': total_batches
        }
        
        print(f"\nå¼€å§‹æ‰«æè‚¡ç¥¨ï¼ŒæŸ¥æ‰¾ç¬¦åˆç‰›è‚¡ç‰¹å¾çš„ä¸ªè‚¡{batch_info}...")
        print(f"æœ¬æ‰¹è‚¡ç¥¨æ•°: {total_stocks}")
        print(f"æœ€å°åŒ¹é…åº¦: {min_match_score:.1%}")
        print(f"å¸‚å€¼çº¦æŸ: â‰¤ {max_market_cap} äº¿å…ƒ")
        print("=" * 80)
        
        candidates = []
        
        # éå†æ‰€æœ‰è‚¡ç¥¨
        # è·å–åˆ—åï¼ˆakshareå¯èƒ½è¿”å›ä¸åŒçš„åˆ—åï¼‰
        code_col = None
        name_col = None
        for col in stock_list.columns:
            col_lower = str(col).lower()
            if 'code' in col_lower or 'ä»£ç ' in col:
                code_col = col
            elif 'name' in col_lower or 'åç§°' in col:
                name_col = col
        
        # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œä½¿ç”¨ç¬¬ä¸€åˆ—å’Œç¬¬äºŒåˆ—
        if code_col is None:
            code_col = stock_list.columns[0]
        if name_col is None and len(stock_list.columns) >= 2:
            name_col = stock_list.columns[1]
        
        # ä½¿ç”¨ä¼ å…¥çš„èµ·å§‹ç´¢å¼•å’Œå·²æœ‰å€™é€‰
        idx = start_idx
        if existing_candidates:
            candidates = existing_candidates.copy()
        else:
            candidates = []
        
        for _, row in stock_list.iterrows():
            # æ£€æŸ¥æ˜¯å¦æ”¶åˆ°åœæ­¢ä¿¡å·ï¼ˆåœ¨å¾ªç¯å¼€å§‹å¤„æ£€æŸ¥ï¼Œç¡®ä¿èƒ½åŠæ—¶å“åº”ï¼‰
            if self.stop_scan:
                current_processed = idx
                print(f"\nğŸ›‘ æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œåœæ­¢æ‰«æï¼ˆå·²å¤„ç† {current_processed}/{total_stocks} åªè‚¡ç¥¨ï¼Œæ‰¾åˆ° {len(candidates)} åªï¼‰")
                self.progress['status'] = 'å·²åœæ­¢'
                self.progress['detail'] = f'æ‰«æå·²åœæ­¢ï¼ˆå·²å¤„ç† {current_processed}/{total_stocks} åªè‚¡ç¥¨ï¼Œæ‰¾åˆ° {len(candidates)} åªï¼‰'
                self.progress['current'] = current_processed
                # ä¾›å‰ç«¯å®æ—¶å±•ç¤ºï¼šä¿ç•™ä¸€ä»½å€™é€‰å¿«ç…§ï¼ˆæœ€å¤š50ï¼‰
                try:
                    candidates.sort(key=lambda x: x.get('åŒ¹é…åº¦', 0), reverse=True)
                except Exception:
                    pass
                self.progress['candidates'] = candidates[:50] if len(candidates) > 50 else candidates
                self.progress['last_update_time'] = time_module.time()  # æ›´æ–°æœ€åæ›´æ–°æ—¶é—´
                
                # ä¿å­˜æ‰«æçŠ¶æ€ä»¥ä¾¿ç»§ç»­
                if self.scan_state:
                    self.scan_state['current_idx'] = current_processed
                    self.scan_state['candidates'] = candidates.copy()
                    self.scan_state['status'] = 'å·²åœæ­¢'
                
                # ç«‹å³ä¿å­˜å½“å‰ç»“æœ
                self.scan_results = {
                    'success': True,
                    'message': f'æ‰«æå·²åœæ­¢ï¼Œå·²å¤„ç† {current_processed}/{total_stocks} åªè‚¡ç¥¨ï¼Œæ‰¾åˆ° {len(candidates)} åªç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨',
                    'candidates': candidates[:50] if len(candidates) > 50 else candidates,
                    'total_scanned': current_processed,
                    'found_count': len(candidates),
                    'stopped': True
                }
                
                self.stop_scan = False  # é‡ç½®æ ‡å¿—
                break
            
            stock_code = str(row[code_col])
            stock_name = str(row[name_col]) if name_col else stock_code
            idx += 1  # ç§»åŠ¨åˆ°ä¸‹ä¸€åªè‚¡ç¥¨
            
            # æ›´æ–°è¿›åº¦ï¼ˆåŒ…å«æ‰¹æ¬¡ä¿¡æ¯ï¼‰
            # å¦‚æœæ˜¯åˆ†æ‰¹æ‰«æï¼Œéœ€è¦è®¡ç®—æ•´ä½“è¿›åº¦
            if total_batches > 1:
                # è®¡ç®—æ•´ä½“è¿›åº¦ï¼šå·²å®Œæˆæ‰¹æ¬¡ + å½“å‰æ‰¹æ¬¡çš„è¿›åº¦
                batch_size = total_stocks  # å½“å‰æ‰¹æ¬¡çš„è‚¡ç¥¨æ•°
                completed_batches_progress = ((batch_num - 1) / total_batches) * 100
                current_batch_progress = (idx / batch_size) / total_batches * 100
                percentage = completed_batches_progress + current_batch_progress
                # ç¡®ä¿ä¸è¶…è¿‡100%
                percentage = min(percentage, 100.0)
            else:
                # å•æ‰¹æ‰«æï¼Œç›´æ¥è®¡ç®—
                percentage = (idx / total_stocks) * 100
            
            batch_info = f" [ç¬¬ {batch_num}/{total_batches} æ‰¹]" if total_batches > 1 else ""
            # è®¡ç®—æ•´ä½“å·²æ‰«æçš„è‚¡ç¥¨æ•°
            if total_batches > 1 and total_all_stocks > total_stocks:
                overall_current = int((batch_num - 1) * (total_all_stocks / total_batches) + idx)
            else:
                overall_current = idx
            self.progress['current'] = overall_current
            self.progress['total'] = total_all_stocks  # ä½¿ç”¨æ€»è‚¡ç¥¨æ•°
            self.progress['percentage'] = round(percentage, 1)
            
            # æ£€æŸ¥ç¼ºå¤±æ•°æ®å¹¶æ›´æ–°æç¤º
            missing_count = len(self._missing_data_stocks) if hasattr(self, '_missing_data_stocks') else 0
            missing_info = f" | ç¼ºå°‘æ•°æ®: {missing_count}åª" if missing_count > 0 else ""
            
            self.progress['detail'] = f'æ­£åœ¨æ‰«æ {stock_code} {stock_name}... ({overall_current}/{total_all_stocks}){batch_info} | å·²æ‰¾åˆ°: {len(candidates)} åª{missing_info}'
            
            # å¦‚æœç¼ºå¤±æ•°æ®è¶…è¿‡10%ï¼Œåœ¨è¿›åº¦ä¸­æç¤º
            if missing_count > 0 and idx > 0:
                missing_pct = (missing_count / idx * 100)
                if missing_pct > 10:
                    self.progress['data_warning'] = f'âš ï¸ å·²å‘ç° {missing_count} åªè‚¡ç¥¨ç¼ºå°‘æœ¬åœ°æ•°æ®ï¼ˆ{missing_pct:.1f}%ï¼‰ï¼Œå»ºè®®å…ˆä¸‹è½½æ•°æ®'
            self.progress['current_stock'] = stock_code
            self.progress['current_stock_name'] = stock_name
            self.progress['last_update_time'] = time_module.time()  # è®°å½•æœ€åæ›´æ–°æ—¶é—´
            
            # æ¯å¤„ç†10åªè‚¡ç¥¨æ‰“å°ä¸€æ¬¡è¿›åº¦ï¼ˆé¿å…è¾“å‡ºè¿‡å¤šï¼‰
            if idx % 10 == 0 or idx == total_stocks:
                print(f"[è¿›åº¦] {percentage:.1f}% - {idx}/{total_stocks} - å·²æ‰¾åˆ°: {len(candidates)} åª")
            
            # è®°å½•å¼€å§‹æ—¶é—´ï¼Œç”¨äºæ£€æµ‹è¶…æ—¶
            start_time = time_module.time()
            max_process_time = 5  # å•ä¸ªè‚¡ç¥¨æœ€å¤§å¤„ç†æ—¶é—´ï¼ˆç§’ï¼‰- ç¼©çŸ­åˆ°5ç§’ï¼Œæ›´å¿«è·³è¿‡é—®é¢˜è‚¡ç¥¨
            
            # è®°å½•å¼€å§‹å¤„ç†çš„æ—¥å¿—ï¼ˆå‡å°‘æ—¥å¿—è¾“å‡ºï¼Œæ¯100åªè‚¡ç¥¨æ‰“å°ä¸€æ¬¡ï¼‰
            if idx % 100 == 0 or idx == 1:
                import datetime
                current_time = datetime.datetime.now().strftime('%H:%M:%S')
                logging.info(f"[{idx}/{total_stocks}] å¼€å§‹å¤„ç† {stock_code} {stock_name} (å¼€å§‹æ—¶é—´: {current_time})")
                print(f"[{idx}/{total_stocks}] å¼€å§‹å¤„ç† {stock_code} {stock_name}")  # åŒæ—¶æ‰“å°åˆ°æ§åˆ¶å°
            
            # åˆå§‹åŒ–å¸‚å€¼å˜é‡ï¼ˆå®Œå…¨è·³è¿‡ï¼Œé¿å…å¡ä½ï¼‰
            market_cap = None
            market_cap_valid = False
            
            try:
                # âœ… å¸‚å€¼æ£€æŸ¥ï¼šå¿…é¡»åœ¨æ£€ç´¢æ—¶åŒæ­¥æ£€æŸ¥
                # ç«‹å³æ›´æ–°è¿›åº¦ï¼Œæ˜¾ç¤ºæ­£åœ¨å¤„ç†
                self.progress['last_update_time'] = time_module.time()
                # å‡å°‘æ—¥å¿—è¾“å‡ºï¼Œæ¯100åªè‚¡ç¥¨æ‰“å°ä¸€æ¬¡
                if idx % 100 == 0 or idx == 1:
                    logging.info(f"[{idx}/{total_stocks}] {stock_code} å¼€å§‹å¤„ç†...")
                
                # 2. è·å–å‘¨Kçº¿æ•°æ®ï¼ˆæ·»åŠ è¶…æ—¶ä¿æŠ¤ï¼Œä½¿ç”¨çº¿ç¨‹è¶…æ—¶å¼ºåˆ¶ä¸­æ–­ï¼‰
                try:
                    step_start = time_module.time()
                    # å‡å°‘æ—¥å¿—è¾“å‡ºï¼Œæ¯100åªè‚¡ç¥¨æ‰“å°ä¸€æ¬¡
                    if idx % 100 == 0 or idx == 1:
                        logging.info(f"[{idx}/{total_stocks}] {stock_code} å¼€å§‹è·å–å‘¨Kçº¿æ•°æ®...")
                        print(f"[{idx}/{total_stocks}] {stock_code} å¼€å§‹è·å–å‘¨Kçº¿æ•°æ®...")
                    
                    # ä½¿ç”¨çº¿ç¨‹è¶…æ—¶æœºåˆ¶ï¼Œé˜²æ­¢å¡æ­»
                    weekly_df_result = [None]
                    weekly_df_error = [None]
                    
                    def fetch_weekly_data():
                        try:
                            # å¦‚æœæŒ‡å®šäº†å†å² scan_dateï¼Œå¼ºåˆ¶ä½¿ç”¨æœ¬åœ°ç¼“å­˜ä»¥ç¡®ä¿å†å²å›æµ‹ä¸€è‡´æ€§
                            force_refresh_flag = getattr(self, "_force_refresh_scan", False)
                            use_cache = True
                            if force_refresh_flag and not scan_date:
                                use_cache = False  # åªæœ‰åœ¨æ²¡æœ‰æŒ‡å®šscan_dateä¸”å¼ºåˆ¶åˆ·æ–°æ—¶æ‰ä¸ç”¨ç¼“å­˜
                            
                            # æ‰«ææ—¶ä¼˜å…ˆä½¿ç”¨æœ¬åœ°æ•°æ®ï¼Œå¦‚æœæœ¬åœ°æ²¡æœ‰åˆ™ä»ç½‘ç»œä¸‹è½½
                            # å…ˆå°è¯•æœ¬åœ°æ•°æ®ï¼ˆå¿«é€Ÿï¼‰
                            weekly_df_result[0] = self.fetcher.get_weekly_kline(
                                stock_code,
                                period="2y",
                                use_cache=use_cache,
                                local_only=True
                            )
                            
                            # âœ… å…³é”®ï¼šå¦‚æœè®¾ç½®äº† strict_local_onlyï¼Œå³ä½¿æœ¬åœ°æ²¡æœ‰æ•°æ®ä¹Ÿä¸ä»ç½‘ç»œä¸‹è½½
                            strict_local_only = getattr(self, '_strict_local_only', False)
                            
                            # å¦‚æœæœ¬åœ°æ²¡æœ‰æ•°æ®ï¼Œå°è¯•ä»ç½‘ç»œä¸‹è½½ï¼ˆé™¤é strict_local_only=Trueï¼‰
                            if weekly_df_result[0] is None or len(weekly_df_result[0]) < 40:
                                if strict_local_only:
                                    # ä¸¥æ ¼æœ¬åœ°æ¨¡å¼ï¼šè·³è¿‡ç¼ºå¤±æ•°æ®çš„è‚¡ç¥¨ï¼Œä¸ä»ç½‘ç»œä¸‹è½½
                                    if not hasattr(self, '_missing_data_stocks'):
                                        self._missing_data_stocks = set()
                                    self._missing_data_stocks.add(stock_code)
                                else:
                                    # å°è¯•ä»ç½‘ç»œä¸‹è½½
                                    print(f"[_scan_stock_batch_serial] {stock_code} æœ¬åœ°æ— æ•°æ®ï¼Œå°è¯•ä»ç½‘ç»œä¸‹è½½...")
                                    weekly_df_result[0] = self.fetcher.get_weekly_kline(
                                        stock_code,
                                        period="2y",
                                        use_cache=False,
                                        local_only=False
                                    )
                            
                            # å¦‚æœç½‘ç»œè·å–ä¹Ÿå¤±è´¥ï¼Œè®°å½•åˆ°ç¼ºå¤±åˆ—è¡¨
                            if weekly_df_result[0] is None or len(weekly_df_result[0]) < 40:
                                if not hasattr(self, '_missing_data_stocks'):
                                    self._missing_data_stocks = set()
                                self._missing_data_stocks.add(stock_code)
                        except Exception as e:
                            weekly_df_error[0] = e
                    
                    fetch_thread = threading.Thread(target=fetch_weekly_data)
                    fetch_thread.daemon = True
                    fetch_thread.start()
                    fetch_thread.join(timeout=3)  # æœ€å¤šç­‰å¾…3ç§’ï¼ˆè¿›ä¸€æ­¥ç¼©çŸ­ï¼Œæ›´å¿«è·³è¿‡ï¼‰
                    
                    # æ›´æ–°è¿›åº¦
                    self.progress['last_update_time'] = time_module.time()
                    step_time = time_module.time() - step_start
                    
                    if fetch_thread.is_alive():
                        # çº¿ç¨‹ä»åœ¨è¿è¡Œï¼Œè¯´æ˜è¶…æ—¶äº†
                        elapsed = time_module.time() - step_start
                        logging.error(f"[{idx}/{total_stocks}] {stock_code} å‘¨Kçº¿æ•°æ®è·å–è¶…æ—¶ï¼ˆ>{elapsed:.1f}ç§’ï¼‰ï¼Œå¼ºåˆ¶è·³è¿‡")
                        print(f"â±ï¸ [{idx}/{total_stocks}] {stock_code} å‘¨Kçº¿æ•°æ®è·å–è¶…æ—¶ï¼ˆ>{elapsed:.1f}ç§’ï¼‰ï¼Œå¼ºåˆ¶è·³è¿‡")
                        continue
                    
                    logging.info(f"[{idx}/{total_stocks}] {stock_code} å‘¨Kçº¿è·å–å®Œæˆï¼ˆ{step_time:.2f}ç§’ï¼‰")
                    
                    if weekly_df_error[0]:
                        raise weekly_df_error[0]
                    
                    weekly_df = weekly_df_result[0]
                    step_time = time_module.time() - step_start
                    
                    # æ£€æŸ¥æ€»è€—æ—¶
                    elapsed = time_module.time() - start_time
                    if elapsed > max_process_time:
                        if idx % 10 == 0:
                            print(f"â±ï¸ {stock_code} æ•°æ®è·å–åæ€»è€—æ—¶è¶…æ—¶ï¼ˆ{elapsed:.1f}ç§’ï¼‰ï¼Œè·³è¿‡")
                        continue
                    
                    if step_time > 6:  # æ•°æ®è·å–è¶…è¿‡6ç§’ï¼Œè®°å½•
                        if idx % 10 == 0:
                            print(f"âš ï¸ {stock_code} å‘¨Kçº¿æ•°æ®è·å–è€—æ—¶ {step_time:.1f}ç§’")
                    
                    if weekly_df is None or len(weekly_df) < 40:
                        continue
                except Exception as e:
                    # æ•°æ®è·å–å¤±è´¥ï¼Œè·³è¿‡è¯¥è‚¡ç¥¨
                    if idx % 10 == 0:
                        print(f"âš ï¸ {stock_code} è·å–å‘¨Kçº¿æ•°æ®å¤±è´¥: {str(e)[:50]}")
                    continue
                
                # 3. æå–å½“å‰æ—¶ç‚¹çš„ç‰¹å¾ï¼ˆä½¿ç”¨æœ€æ–°æ•°æ®ä½œä¸º"èµ·ç‚¹"ï¼‰- æ·»åŠ è¶…æ—¶ä¿æŠ¤ï¼Œä½¿ç”¨çº¿ç¨‹è¶…æ—¶å¼ºåˆ¶ä¸­æ–­
                try:
                    step_start = time_module.time()
                    current_idx = len(weekly_df) - 1
                    if scan_date:
                        try:
                            scan_ts = pd.to_datetime(scan_date, errors='coerce')
                            if pd.notna(scan_ts) and 'æ—¥æœŸ' in weekly_df.columns:
                                w = weekly_df.copy()
                                w['__dt'] = pd.to_datetime(w['æ—¥æœŸ'], errors='coerce')
                                w = w.dropna(subset=['__dt'])
                                
                                # âœ… ä¸¥æ ¼å›æº¯ï¼ˆas-ofï¼‰ï¼šåªèƒ½ä½¿ç”¨ scan_date å½“å¤©åŠä¹‹å‰çš„æ•°æ®
                                # æ³¨æ„ï¼šå‘¨Kçš„â€œæ—¥æœŸâ€é€šå¸¸æ˜¯å‘¨ç»“æŸæ—¥ï¼ˆå¦‚å‘¨äº”ï¼‰ã€‚
                                # å¦‚æœ scan_date åœ¨å‘¨ä¸­ï¼ˆæˆ–åœ¨å‘¨ç»“æŸæ—¥å‰ï¼‰ï¼Œè¯¥å‘¨çš„å‘¨Kä¼šåŒ…å« scan_date ä¹‹åçš„æ•°æ®ã€‚
                                # ä¸ºé¿å…â€œå·çœ‹æœªæ¥â€ï¼Œè¿™é‡Œå¿…é¡»æŠŠè¯¥å‘¨æ•´æ ¹å‘¨Kå‰”é™¤ï¼Œä»…ä¿ç•™ __dt <= scan_ts çš„å‘¨Kã€‚
                                original_len = len(w)
                                w = w[w['__dt'] <= scan_ts]
                                
                                # âœ… è°ƒè¯•ï¼šè¾“å‡ºæˆªæ–­ä¿¡æ¯
                                if idx % 100 == 0:
                                    print(f"[è°ƒè¯•-å¹¶è¡Œ] [{idx}/{total_stocks}] {stock_code} æ‰«ææ—¥æœŸ: {scan_date}, åŸå§‹æ•°æ®: {original_len}å‘¨, æˆªæ–­å: {len(w)}å‘¨")
                                
                                if len(w) >= 40:
                                    # ä½¿ç”¨è¿‡æ»¤åæ•°æ®çš„æœ€åä¸€æ¡ä½œä¸º current_idx
                                    weekly_df = w.drop(columns=['__dt'])
                                    current_idx = len(weekly_df) - 1
                                    
                                    # âœ… è°ƒè¯•ï¼šç¡®è®¤æˆªæ–­åçš„æœ€åä¸€å‘¨æ—¥æœŸ
                                    if idx % 100 == 0 and len(weekly_df) > 0:
                                        last_week_date = weekly_df.iloc[-1]['æ—¥æœŸ']
                                        print(f"[è°ƒè¯•-å¹¶è¡Œ] [{idx}/{total_stocks}] {stock_code} æˆªæ–­åæœ€åä¸€å‘¨æ—¥æœŸ: {last_week_date}")
                                    
                                else:
                                    continue
                        except Exception:
                            pass
                    
                    # âœ… as-of èšåˆï¼šå¯¹ã€Œå½“å‰å‘¨ã€è¿›è¡Œéƒ¨åˆ†å‘¨Kèšåˆï¼ˆé€‚ç”¨äºå®æ—¶æ‰«æå’Œå†å²å›æµ‹ï¼‰
                    # å¦‚æœ scan_date åœ¨å½“å‰å‘¨å†…ï¼ˆå‘¨ä¸€åˆ°å‘¨Kæ—¥æœŸä¹‹é—´ï¼‰ï¼Œç”¨è¯¥å‘¨å‘¨ä¸€åˆ° scan_date çš„æ—¥Kèšåˆæˆéƒ¨åˆ†å‘¨K
                    # è¿™æ ·å›æµ‹ç»“æœä¸ã€Œå½“å¤©å®ç›˜æ‰«æã€å®Œå…¨ä¸€è‡´ï¼Œä¿è¯å›æµ‹çš„æœ‰æ•ˆæ€§
                    aggregated_this_week = False  # æ ‡è®°æ˜¯å¦è¿›è¡Œäº†èšåˆ
                    try:
                        from datetime import datetime as dt_now, timedelta
                        
                        # ç¡®å®šå®é™…ä½¿ç”¨çš„æ‰«ææ—¥æœŸï¼šå¦‚æœ scan_date ä¸º Noneï¼Œä½¿ç”¨ä»Šå¤©çš„æ—¥æœŸï¼ˆå®æ—¶æ‰«æï¼‰
                        actual_scan_date = scan_date if scan_date else dt_now.now().strftime('%Y-%m-%d')
                        
                        if len(weekly_df) > 0 and 'æ—¥æœŸ' in weekly_df.columns:
                            # ä½¿ç”¨ç¡®å®šçš„æ‰«ææ—¥æœŸ
                            scan_ts = pd.to_datetime(actual_scan_date, errors='coerce')
                            
                            if pd.notna(scan_ts):
                                # è·å–æœ€åä¸€å‘¨çš„æ—¥æœŸ
                                last_week_date = pd.to_datetime(weekly_df.iloc[-1]['æ—¥æœŸ'], errors='coerce')
                                
                                if pd.notna(last_week_date):
                                    # åŠ¨æ€è®¡ç®—æœ€åä¸€å‘¨çš„å‘¨ä¸€ï¼šæ‰¾åˆ°åŒ…å« last_week_date çš„é‚£ä¸€å‘¨çš„å‘¨ä¸€
                                    # å‘¨Kçš„æ—¥æœŸå¯èƒ½æ˜¯å‘¨äº”ï¼ˆweekday=4ï¼‰æˆ–å‘¨æ—¥ï¼ˆweekday=6ï¼‰ï¼Œä»£è¡¨è¯¥å‘¨ç»“æŸæ—¥
                                    # å¾€å‰æ¨ weekday å¤©ï¼Œå¾—åˆ°è¯¥å‘¨çš„å‘¨ä¸€
                                    last_week_weekday = last_week_date.weekday()  # 0=å‘¨ä¸€, 4=å‘¨äº”, 6=å‘¨æ—¥
                                    last_week_monday = last_week_date - timedelta(days=last_week_weekday)
                                    
                                    # åˆ¤æ–­ scan_date æ˜¯å¦åœ¨æœ€åä¸€å‘¨å†…ï¼ˆå‘¨ä¸€åˆ°å‘¨Kæ—¥æœŸä¹‹é—´ï¼‰
                                    # æˆ–è€… scan_date åœ¨å½“å‰å‘¨å†…ï¼ˆæœ€åä¸€å‘¨ä¹‹åï¼Œä½†ä»åœ¨å½“å‰å‘¨ï¼‰
                                    should_aggregate = False
                                    week_start_str = None
                                    week_end_date = None
                                    
                                    if last_week_monday <= scan_ts <= last_week_date:
                                        # æƒ…å†µ1ï¼šscan_date åœ¨æœ€åä¸€å‘¨å†…
                                        should_aggregate = True
                                        week_start_str = last_week_monday.strftime('%Y%m%d')
                                        week_end_date = last_week_date
                                    elif scan_ts > last_week_date:
                                        # æƒ…å†µ2ï¼šscan_date åœ¨æœ€åä¸€å‘¨ä¹‹åï¼Œæ£€æŸ¥æ˜¯å¦åœ¨å½“å‰å‘¨å†…
                                        # è®¡ç®—å½“å‰å‘¨çš„å‘¨ä¸€ï¼ˆæœ€åä¸€å‘¨çš„ä¸‹ä¸€ä¸ªå‘¨ä¸€ï¼‰
                                        current_week_monday = last_week_date + timedelta(days=(7 - last_week_weekday))
                                        # è®¡ç®—å½“å‰å‘¨çš„ç»“æŸæ—¥ï¼ˆå‘¨äº”æˆ–å‘¨æ—¥ï¼Œå–å†³äºå‘¨Kçš„æ ¼å¼ï¼‰
                                        # å‡è®¾å‘¨Kåœ¨å‘¨äº”ç»“æŸï¼Œåˆ™å½“å‰å‘¨ç»“æŸæ—¥æ˜¯ current_week_monday + 4
                                        current_week_end = current_week_monday + timedelta(days=4)
                                        
                                        if current_week_monday <= scan_ts <= current_week_end:
                                            # scan_date åœ¨å½“å‰å‘¨å†…ï¼Œéœ€è¦èšåˆå½“å‰å‘¨çš„æ•°æ®
                                            should_aggregate = True
                                            week_start_str = current_week_monday.strftime('%Y%m%d')
                                            week_end_date = current_week_end
                                    
                                    if should_aggregate:
                                        aggregated_this_week = True  # æ ‡è®°è¿›è¡Œäº†èšåˆ
                                        # éœ€è¦èšåˆï¼šè·å–è¯¥å‘¨å‘¨ä¸€åˆ° scan_date çš„æ—¥Kæ•°æ®
                                        scan_date_str = scan_ts.strftime('%Y%m%d')
                                        
                                        # è·å–æ—¥Kæ•°æ®ï¼ˆå›æµ‹æ—¶å¼ºåˆ¶ä½¿ç”¨æœ¬åœ°ç¼“å­˜ï¼Œç¡®ä¿å†å²æ•°æ®ä¸€è‡´æ€§ï¼‰
                                        daily_df = self.fetcher.get_daily_kline_range(
                                            stock_code,
                                            start_date=week_start_str,
                                            end_date=scan_date_str,
                                            use_cache=True,
                                            local_only=True  # å›æµ‹æ—¶å¼ºåˆ¶ä½¿ç”¨æœ¬åœ°ç¼“å­˜ï¼Œé¿å…ä½¿ç”¨æœªæ¥æ•°æ®
                                        )
                                        
                                        if daily_df is not None and len(daily_df) > 0:
                                            # ç¡®ä¿å¿…è¦çš„åˆ—å­˜åœ¨
                                            required_cols = ['æ—¥æœŸ', 'å¼€ç›˜', 'æ”¶ç›˜', 'æœ€é«˜', 'æœ€ä½', 'æˆäº¤é‡']
                                            if all(col in daily_df.columns for col in required_cols):
                                                # è½¬æ¢ä¸ºæ—¥æœŸç±»å‹
                                                daily_df = daily_df.copy()
                                                daily_df['æ—¥æœŸ'] = pd.to_datetime(daily_df['æ—¥æœŸ'], errors='coerce')
                                                daily_df = daily_df.dropna(subset=['æ—¥æœŸ'])
                                                # âœ… ä¸¥æ ¼è¿‡æ»¤ï¼šåªä½¿ç”¨æ‰«ææ—¥æœŸåŠä¹‹å‰çš„æ•°æ®ï¼Œé¿å…ä½¿ç”¨æœªæ¥æ•°æ®
                                                daily_df = daily_df[daily_df['æ—¥æœŸ'] <= scan_ts].sort_values('æ—¥æœŸ').reset_index(drop=True)
                                                
                                                if len(daily_df) > 0:
                                                    # èšåˆä¸ºå‘¨Kï¼ˆä»…è¯¥å‘¨çš„éƒ¨åˆ†æ•°æ®ï¼‰
                                                    partial_week_k = pd.Series({
                                                        'å¼€ç›˜': float(daily_df.iloc[0]['å¼€ç›˜']),
                                                        'æ”¶ç›˜': float(daily_df.iloc[-1]['æ”¶ç›˜']),
                                                        'æœ€é«˜': float(daily_df['æœ€é«˜'].max()),
                                                        'æœ€ä½': float(daily_df['æœ€ä½'].min()),
                                                        'å‘¨æˆäº¤é‡': float(daily_df['æˆäº¤é‡'].sum()),
                                                        'æ—¥æœŸ': week_end_date  # ä½¿ç”¨è¯¥å‘¨çš„ç»“æŸæ—¥æœŸ
                                                    })
                                                    
                                                    # å¦‚æœæˆäº¤é¢åˆ—å­˜åœ¨ï¼Œä¹Ÿèšåˆ
                                                    if 'æˆäº¤é¢' in daily_df.columns:
                                                        partial_week_k['å‘¨æˆäº¤é¢'] = float(daily_df['æˆäº¤é¢'].sum())
                                                    
                                                    # å¦‚æœå½“å‰å‘¨æ˜¯æ–°çš„ä¸€å‘¨ï¼ˆscan_ts > last_week_dateï¼‰ï¼Œéœ€è¦æ·»åŠ æ–°çš„ä¸€è¡Œ
                                                    if scan_ts > last_week_date:
                                                        # æ·»åŠ æ–°çš„å‘¨Kè¡Œ
                                                        weekly_df = weekly_df.copy()
                                                        partial_week_k['æ—¥æœŸ'] = week_end_date
                                                        weekly_df = pd.concat([weekly_df, pd.DataFrame([partial_week_k])], ignore_index=True)
                                                        # âœ… æ›´æ–° current_idx æŒ‡å‘æ–°æ·»åŠ çš„èšåˆå‘¨K
                                                        current_idx = len(weekly_df) - 1
                                                    else:
                                                        # æ›¿æ¢æœ€åä¸€å‘¨çš„å‘¨K
                                                        weekly_df = weekly_df.copy()
                                                        weekly_df.iloc[-1] = partial_week_k
                                                        # current_idx ä¿æŒä¸å˜ï¼Œä»æŒ‡å‘æœ€åä¸€è¡Œ
                                                    
                                                    # è°ƒè¯•è¾“å‡ºï¼ˆæ¯100åªè‚¡ç¥¨è¾“å‡ºä¸€æ¬¡ï¼‰
                                                    if idx % 100 == 0:
                                                        print(f"[as-ofèšåˆå‘¨K-å¹¶è¡Œ] [{idx}/{total_stocks}] {stock_code} æ‰«ææ—¥æœŸ: {scan_ts.strftime('%Y-%m-%d')}, èšåˆäº†å‘¨ï¼ˆ{week_start_str} åˆ° {scan_ts.strftime('%Y-%m-%d')}ï¼‰ï¼Œcurrent_idx={current_idx}")
                    except Exception as e:
                        # èšåˆå¤±è´¥ä¸å½±å“æ‰«æï¼Œç»§ç»­ä½¿ç”¨åŸå‘¨K
                        if idx % 100 == 0:
                            print(f"[as-ofèšåˆå‘¨K-å¹¶è¡Œ] [{idx}/{total_stocks}] {stock_code} èšåˆå¤±è´¥: {str(e)[:50]}")
                        pass
                    
                    logging.info(f"[{idx}/{total_stocks}] {stock_code} å¼€å§‹æå–ç‰¹å¾ï¼Œèµ·ç‚¹ç´¢å¼•: {current_idx}")
                    # å‡å°‘æ—¥å¿—è¾“å‡ºï¼Œæ¯100åªè‚¡ç¥¨æ‰“å°ä¸€æ¬¡
                    if idx % 100 == 0 or idx == 1:
                        print(f"[{idx}/{total_stocks}] {stock_code} å¼€å§‹æå–ç‰¹å¾...")
                    
                    # ä½¿ç”¨çº¿ç¨‹è¶…æ—¶æœºåˆ¶ï¼Œé˜²æ­¢å¡æ­»
                    features_result = [None]
                    features_error = [None]
                    
                    def extract_features():
                        try:
                            # ä¼ å…¥å·²è·å–çš„weekly_dfï¼Œé¿å…é‡å¤è·å–
                            features_result[0] = self.extract_features_at_start_point(stock_code, current_idx, lookback_weeks=40, weekly_df=weekly_df)
                        except Exception as e:
                            features_error[0] = e
                    
                    extract_thread = threading.Thread(target=extract_features)
                    extract_thread.daemon = True
                    extract_thread.start()
                    extract_thread.join(timeout=2)  # æœ€å¤šç­‰å¾…2ç§’ï¼ˆè¿›ä¸€æ­¥ç¼©çŸ­ï¼Œæ›´å¿«è·³è¿‡ï¼‰
                    
                    # æ›´æ–°è¿›åº¦
                    self.progress['last_update_time'] = time_module.time()
                    step_time = time_module.time() - step_start
                    
                    if extract_thread.is_alive():
                        # çº¿ç¨‹ä»åœ¨è¿è¡Œï¼Œè¯´æ˜è¶…æ—¶äº†
                        elapsed = time_module.time() - step_start
                        logging.error(f"[{idx}/{total_stocks}] {stock_code} ç‰¹å¾æå–è¶…æ—¶ï¼ˆ>{elapsed:.1f}ç§’ï¼‰ï¼Œå¼ºåˆ¶è·³è¿‡")
                        print(f"â±ï¸ [{idx}/{total_stocks}] {stock_code} ç‰¹å¾æå–è¶…æ—¶ï¼ˆ>{elapsed:.1f}ç§’ï¼‰ï¼Œå¼ºåˆ¶è·³è¿‡")
                        continue
                    
                    logging.info(f"[{idx}/{total_stocks}] {stock_code} ç‰¹å¾æå–å®Œæˆï¼ˆ{step_time:.2f}ç§’ï¼‰")
                    
                    if features_error[0]:
                        raise features_error[0]
                    
                    features = features_result[0]
                    step_time = time_module.time() - step_start
                    
                    # æ£€æŸ¥æ€»è€—æ—¶
                    elapsed = time_module.time() - start_time
                    if elapsed > max_process_time:
                        if idx % 10 == 0:
                            print(f"â±ï¸ {stock_code} ç‰¹å¾æå–åæ€»è€—æ—¶è¶…æ—¶ï¼ˆ{elapsed:.1f}ç§’ï¼‰ï¼Œè·³è¿‡")
                        continue
                    
                    if step_time > 3:  # ç‰¹å¾æå–è¶…è¿‡3ç§’ï¼Œè®°å½•
                        if idx % 10 == 0:
                            print(f"âš ï¸ {stock_code} ç‰¹å¾æå–è€—æ—¶ {step_time:.1f}ç§’")
                    
                    if features is None:
                        continue
                except Exception as e:
                    # ç‰¹å¾æå–å¤±è´¥ï¼Œè·³è¿‡è¯¥è‚¡ç¥¨
                    if idx % 10 == 0:
                        print(f"âš ï¸ {stock_code} ç‰¹å¾æå–å¤±è´¥: {str(e)[:50]}")
                    continue
                
                # 4. è®¡ç®—åŒ¹é…åº¦
                try:
                    # æ£€æŸ¥æ€»è€—æ—¶
                    elapsed = time_module.time() - start_time
                    if elapsed > max_process_time:
                        if idx % 10 == 0:
                            print(f"â±ï¸ {stock_code} åŒ¹é…åº¦è®¡ç®—å‰è¶…æ—¶ï¼ˆ{elapsed:.1f}ç§’ï¼‰ï¼Œè·³è¿‡")
                        continue
                    
                    match_score = self._calculate_match_score(features, common_features, tolerance=0.3)
                    
                    # è°ƒè¯•ï¼šæ¯10åªè‚¡ç¥¨è¾“å‡ºä¸€æ¬¡åŒ¹é…åº¦ä¿¡æ¯
                    if idx % 10 == 0:
                        print(f"[è°ƒè¯•] {stock_code} {stock_name} åŒ¹é…åº¦: {match_score['æ€»åŒ¹é…åº¦']:.3f} (é˜ˆå€¼: {min_match_score:.3f})")
                except Exception as e:
                    # åŒ¹é…åº¦è®¡ç®—å¤±è´¥ï¼Œè·³è¿‡è¯¥è‚¡ç¥¨
                    if idx % 10 == 0:
                        print(f"âš ï¸ {stock_code} åŒ¹é…åº¦è®¡ç®—å¤±è´¥: {str(e)[:50]}")
                    continue
                
                # 5. å¦‚æœåŒ¹é…åº¦è¾¾åˆ°é˜ˆå€¼ï¼Œæ£€æŸ¥å¸‚å€¼å¹¶è®°å½•ä¸ºå€™é€‰
                total_match = match_score['æ€»åŒ¹é…åº¦']
                if total_match >= min_match_score:
                    if current_idx >= len(weekly_df):
                        continue
                    
                    # 5.1. æ£€æŸ¥120æ—¥å’Œ250æ—¥å‡çº¿æ–¹å‘ï¼ˆå¦‚æœéƒ½å‘ä¸‹ï¼Œç›´æ¥æ’é™¤ï¼‰
                    try:
                        limit_date = scan_date if scan_date else pd.Timestamp.now().strftime('%Y-%m-%d')
                        limit_date_ymd = pd.to_datetime(limit_date).strftime('%Y%m%d')
                        
                        daily_df = self.fetcher.get_daily_kline_range(
                            stock_code, 
                            start_date='20220101',
                            end_date=limit_date_ymd,
                            use_cache=True,
                            local_only=True
                        )
                        
                        if daily_df is not None and len(daily_df) >= 250:
                            daily_df['æ—¥æœŸ'] = pd.to_datetime(daily_df['æ—¥æœŸ'], errors='coerce')
                            daily_df = daily_df.dropna(subset=['æ—¥æœŸ']).sort_values('æ—¥æœŸ').reset_index(drop=True)
                            
                            limit_dt = pd.to_datetime(limit_date)
                            daily_before = daily_df[daily_df['æ—¥æœŸ'] <= limit_dt]
                            if len(daily_before) >= 250:
                                scan_idx = len(daily_before) - 1
                                
                                ma120_current = daily_before['æ”¶ç›˜'].iloc[scan_idx-119:scan_idx+1].mean()
                                ma250_current = daily_before['æ”¶ç›˜'].iloc[scan_idx-249:scan_idx+1].mean()
                                
                                if scan_idx >= 20:
                                    ma120_20d_ago = daily_before['æ”¶ç›˜'].iloc[scan_idx-139:scan_idx-119].mean()
                                    ma250_20d_ago = daily_before['æ”¶ç›˜'].iloc[scan_idx-269:scan_idx-249].mean()
                                    
                                    ma120_slope = (ma120_current - ma120_20d_ago) / ma120_20d_ago if ma120_20d_ago > 0 else 0
                                    ma250_slope = (ma250_current - ma250_20d_ago) / ma250_20d_ago if ma250_20d_ago > 0 else 0
                                    
                                    if ma120_slope < 0 and ma250_slope < 0:
                                        print(f"[å‡çº¿è¿‡æ»¤-ä¸²è¡Œ] [{idx}/{total_stocks}] {stock_code} {stock_name} MA120å’ŒMA250éƒ½å‘ä¸‹ï¼Œå·²æ’é™¤ (MA120æ–œç‡: {ma120_slope*100:.2f}%, MA250æ–œç‡: {ma250_slope*100:.2f}%, æ‰«ææ—¥æœŸ: {limit_date})")
                                        continue
                    except Exception as e:
                        # å‡çº¿æ£€æŸ¥å¤±è´¥ä¸å½±å“æ‰«æï¼Œç»§ç»­å¤„ç†
                        if idx % 100 == 0 or stock_code == '000798':
                            print(f"[å‡çº¿æ£€æŸ¥å¼‚å¸¸-ä¸²è¡Œ] [{idx}/{total_stocks}] {stock_code} {stock_name} å‡çº¿æ–¹å‘æ£€æŸ¥å¼‚å¸¸: {str(e)[:50]}")
                        pass
                    
                    try:
                        # å°è¯•è·å–å¸‚å€¼ï¼ˆå¦‚æœå¸‚å€¼è·å–æˆåŠŸï¼ŒæŒ‰å¸‚å€¼ç­›é€‰ï¼›å¤±è´¥åˆ™è·³è¿‡å¸‚å€¼æ£€æŸ¥ï¼‰
                        market_cap_checked = False
                        market_cap_valid = False
                        
                        if max_market_cap > 0:  # å¦‚æœè®¾ç½®äº†å¸‚å€¼é™åˆ¶ï¼Œå°è¯•è·å–å¸‚å€¼
                            try:
                                # ä½¿ç”¨è¶…æ—¶æœºåˆ¶è·å–å¸‚å€¼ï¼ˆé¿å…å¡ä½ï¼‰
                                market_cap_result = [None]
                                market_cap_error = [None]
                                
                                def fetch_market_cap():
                                    try:
                                        market_cap_result[0] = self.fetcher.get_market_cap(stock_code, timeout=2)
                                    except Exception as e:
                                        market_cap_error[0] = e
                                
                                cap_thread = threading.Thread(target=fetch_market_cap)
                                cap_thread.daemon = True
                                cap_thread.start()
                                cap_thread.join(timeout=2.5)  # æœ€å¤šç­‰å¾…2.5ç§’
                                
                                if not cap_thread.is_alive():
                                    fetched_market_cap = market_cap_result[0]
                                    if fetched_market_cap is not None and fetched_market_cap > 0:
                                        market_cap = fetched_market_cap
                                        market_cap_valid = True
                                        market_cap_checked = True
                                        # å¦‚æœå¸‚å€¼è·å–æˆåŠŸï¼Œæ£€æŸ¥æ˜¯å¦ç¬¦åˆæ¡ä»¶
                                        if market_cap > max_market_cap:
                                            # å¸‚å€¼è¶…è¿‡é™åˆ¶ï¼Œè·³è¿‡è¯¥è‚¡ç¥¨
                                            if idx % 10 == 0:
                                                print(f"[{idx}/{total_stocks}] {stock_code} {stock_name} å¸‚å€¼ {market_cap:.2f}äº¿è¶…è¿‡é™åˆ¶ {max_market_cap:.2f}äº¿ï¼Œè·³è¿‡")
                                            continue
                            except Exception as e:
                                # å¸‚å€¼è·å–å¤±è´¥ï¼Œè·³è¿‡å¸‚å€¼æ£€æŸ¥ï¼Œç»§ç»­å¤„ç†è¯¥è‚¡ç¥¨
                                if idx % 100 == 0:
                                    print(f"[{idx}/{total_stocks}] {stock_code} å¸‚å€¼è·å–å¤±è´¥ï¼Œè·³è¿‡å¸‚å€¼æ£€æŸ¥: {str(e)[:50]}")
                                market_cap_checked = True
                                market_cap_valid = False
                        
                        # æœ€ä½³ä¹°ç‚¹æ—¥æœŸ = æœ€åä¸€å‘¨çš„å‘¨Kæ—¥æœŸï¼ˆç‰¹å¾åŒ¹é…åŸºäºè¿™ä¸€å‘¨ï¼‰
                        # ä½†ä»·æ ¼ä½¿ç”¨æ‰«ææ—¥æœŸçš„æ”¶ç›˜ä»·ï¼ˆå¦‚æœæ‰«ææ—¥æœŸåœ¨å‘¨Kæ—¥æœŸä¹‹å‰ï¼Œåˆ™ç”¨å‘¨Kæ”¶ç›˜ä»·ï¼‰
                        from datetime import datetime as dt_now
                        today_str = dt_now.now().strftime('%Y-%m-%d')
                        limit_date = scan_date if scan_date else today_str  # æœç´¢å½“å¤©
                        fallback_price = float(weekly_df.iloc[current_idx]['æ”¶ç›˜'])
                        current_date = weekly_df.iloc[current_idx]['æ—¥æœŸ']
                        if isinstance(current_date, pd.Timestamp):
                            current_date_str = current_date.strftime('%Y-%m-%d')
                            current_date_ts = current_date
                        else:
                            current_date_str = str(current_date)[:10]
                            current_date_ts = pd.to_datetime(current_date_str, errors='coerce')
                        
                        # âœ… æœ€ä½³ä¹°ç‚¹æ—¥æœŸï¼šå¦‚æœè¿›è¡Œäº†èšåˆï¼Œä½¿ç”¨æ‰«ææ—¥æœŸï¼›å¦åˆ™ä½¿ç”¨æœ€åä¸€å‘¨çš„å‘¨Kæ—¥æœŸ
                        # å¦‚æœè¿›è¡Œäº†èšåˆï¼ˆaggregated_this_week=Trueï¼‰ï¼Œæœ€ä½³ä¹°ç‚¹æ—¥æœŸåº”è¯¥æ˜¯æ‰«ææ—¥æœŸ
                        # å¦åˆ™ä½¿ç”¨æœ€åä¸€å‘¨çš„å‘¨Kæ—¥æœŸï¼ˆç‰¹å¾åŒ¹é…åŸºäºè¿™ä¸€å‘¨ï¼‰
                        scan_date_ts = pd.to_datetime(limit_date, errors='coerce')
                        if aggregated_this_week and scan_date:
                            # è¿›è¡Œäº†èšåˆï¼Œæœ€ä½³ä¹°ç‚¹æ—¥æœŸ = æ‰«ææ—¥æœŸ
                            buy_date = limit_date
                        else:
                            # æ²¡æœ‰èšåˆï¼Œä½¿ç”¨æœ€åä¸€å‘¨çš„å‘¨Kæ—¥æœŸ
                            buy_date = current_date_str
                        
                        # å¦‚æœæ‰«ææ—¥æœŸåœ¨å‘¨Kæ—¥æœŸä¹‹å‰æˆ–ç­‰äºå‘¨Kæ—¥æœŸï¼Œä½¿ç”¨æ‰«ææ—¥æœŸçš„æ”¶ç›˜ä»·
                        # å¦åˆ™ä½¿ç”¨å‘¨Kæ”¶ç›˜ä»·ï¼ˆè¿™ç§æƒ…å†µä¸åº”è¯¥å‘ç”Ÿï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»æˆªæ–­äº†æ•°æ®ï¼‰
                        if pd.notna(scan_date_ts) and pd.notna(current_date_ts) and scan_date_ts <= current_date_ts:
                            close_on_search = self._get_close_on_date(stock_code, limit_date)
                            if close_on_search is not None:
                                buy_price = close_on_search
                            else:
                                buy_price = fallback_price
                        else:
                            # æ‰«ææ—¥æœŸæ™šäºå‘¨Kæ—¥æœŸï¼ˆä¸åº”è¯¥å‘ç”Ÿï¼‰ï¼Œä½¿ç”¨å‘¨Kæ”¶ç›˜ä»·
                            buy_price = fallback_price
                        
                        # âœ… å½“å‰ä»·æ ¼ = æ‰«ææ—¥æœŸçš„æ”¶ç›˜ä»·ï¼ˆä¸æ˜¯ä»Šå¤©çš„æœ€æ–°ä»·æ ¼ï¼‰
                        # å¦‚æœæ‰«ææ—¥æœŸæ˜¯å†å²æ—¥æœŸï¼Œå½“å‰ä»·æ ¼å°±æ˜¯æ‰«ææ—¥æœŸçš„ä»·æ ¼
                        # å¦‚æœæ‰«ææ—¥æœŸæ˜¯ä»Šå¤©ï¼Œå½“å‰ä»·æ ¼å°±æ˜¯ä»Šå¤©çš„æœ€æ–°ä»·æ ¼
                        current_price = buy_price  # é»˜è®¤ä½¿ç”¨æœ€ä½³ä¹°ç‚¹ä»·æ ¼ï¼ˆå³æ‰«ææ—¥æœŸçš„ä»·æ ¼ï¼‰
                        
                        # å¦‚æœæ‰«ææ—¥æœŸæ˜¯ä»Šå¤©ï¼Œä¸”è·å–åˆ°äº†ä»Šå¤©çš„ä»·æ ¼ï¼Œä½¿ç”¨ä»Šå¤©çš„ä»·æ ¼
                        if limit_date == today_str:
                            close_today = self._get_close_on_date(stock_code, today_str)
                            if close_today is not None:
                                current_price = close_today
                            else:
                                current_price = buy_price
                        # else: æ‰«ææ—¥æœŸæ˜¯å†å²æ—¥æœŸï¼Œcurrent_price = buy_priceï¼ˆå·²ç»æ˜¯æ‰«ææ—¥æœŸçš„ä»·æ ¼ï¼‰
                        
                        # âœ… è°ƒè¯•ï¼šç¡®è®¤æœ€ç»ˆä»·æ ¼ï¼ˆå¹¶è¡Œç‰ˆæœ¬ï¼‰
                        if idx % 100 == 0:
                            print(f"[è°ƒè¯•-ä»·æ ¼-å¹¶è¡Œ] [{idx}/{total_stocks}] {stock_code} æœ€ä½³ä¹°ç‚¹æ—¥æœŸ: {buy_date}, æœ€ä½³ä¹°ç‚¹ä»·æ ¼: {buy_price:.2f}, å½“å‰ä»·æ ¼: {current_price:.2f}, æ‰«ææ—¥æœŸ: {limit_date}")
                        # ä¹°ç‚¹å½“å¤©ä¸ºå¤§é˜´çº¿åˆ™æ’é™¤ï¼ˆä¸åŠ å…¥å€™é€‰ï¼‰
                        if self._is_big_bearish_candle_on_date(stock_code, limit_date):
                            if idx % 100 == 0:
                                print(f"[è¿‡æ»¤-å¹¶è¡Œ] [{idx}/{total_stocks}] {stock_code} {stock_name} ä¹°ç‚¹å½“æ—¥({limit_date})ä¸ºå¤§é˜´çº¿ï¼Œå·²æ’é™¤")
                            continue
                        # å¦‚æœæ²¡æœ‰è·å–åˆ°å¸‚å€¼ï¼Œmarket_cap ä¿æŒä¸º None
                        if not market_cap_checked:
                            market_cap = None
                        candidates.append({
                            'è‚¡ç¥¨ä»£ç ': stock_code,
                            'è‚¡ç¥¨åç§°': stock_name,
                            'åŒ¹é…åº¦': round(match_score['æ€»åŒ¹é…åº¦'], 3),
                            'æœ€ä½³ä¹°ç‚¹æ—¥æœŸ': buy_date,
                            'æœ€ä½³ä¹°ç‚¹ä»·æ ¼': round(buy_price, 2),
                            'å½“å‰ä»·æ ¼': round(current_price, 2),
                            'å¸‚å€¼': round(market_cap, 2) if market_cap_valid else None,
                            'æ ¸å¿ƒç‰¹å¾åŒ¹é…': match_score.get('æ ¸å¿ƒç‰¹å¾åŒ¹é…', {}),
                            'ç‰¹å¾': features
                        })
                        
                        self.progress['found'] = len(candidates)
                        # ã€ä¸å¯å˜ã€‘æ‰¾åˆ°ä¸€åªæ˜¾ç¤ºä¸€åªï¼šå†™å…¥ progress['candidates'] ä¾›å‰ç«¯è½®è¯¢ã€‚è§ æ‰«ææ˜¾ç¤ºä¸å¯å˜é€»è¾‘.md
                        try:
                            candidates.sort(key=lambda x: x.get('åŒ¹é…åº¦', 0), reverse=True)
                        except Exception:
                            pass
                        self.progress['candidates'] = candidates[:50] if len(candidates) > 50 else candidates
                        market_cap_info = f" å¸‚å€¼: {market_cap:.2f}äº¿" if market_cap_valid else " å¸‚å€¼: æœªçŸ¥"
                        print(f"\nâœ… æ‰¾åˆ°å€™é€‰: {stock_code} {stock_name} (åŒ¹é…åº¦: {match_score['æ€»åŒ¹é…åº¦']:.3f}{market_cap_info})")
                    except Exception as e:
                        # å¤„ç†å€™é€‰è‚¡ç¥¨æ—¶çš„é”™è¯¯ï¼Œè·³è¿‡è¯¥è‚¡ç¥¨
                        if idx % 100 == 0:
                            print(f"âš ï¸ {stock_code} å¤„ç†å€™é€‰æ—¶å‡ºé”™: {str(e)[:50]}")
                        continue
            
            except Exception as e:
                # è®°å½•é”™è¯¯ä½†ç»§ç»­æ‰«æ
                import traceback
                error_msg = str(e)
                elapsed_time = time_module.time() - start_time if 'start_time' in locals() else 0
                
                # æ¯10åªè‚¡ç¥¨æ‰“å°ä¸€æ¬¡é”™è¯¯ï¼ˆæ›´é¢‘ç¹ï¼Œä¾¿äºå®šä½é—®é¢˜ï¼‰
                if idx % 10 == 0:
                    print(f"âš ï¸ {stock_code} å¤„ç†å‡ºé”™: {error_msg[:80]} (è€—æ—¶: {elapsed_time:.1f}ç§’)")
                
                # æ£€æŸ¥æ˜¯å¦è¶…æ—¶
                if elapsed_time > max_process_time:
                    if idx % 10 == 0:
                        print(f"â±ï¸ {stock_code} å¤„ç†è¶…æ—¶ï¼ˆ{elapsed_time:.1f}ç§’ï¼‰ï¼Œè·³è¿‡")
                continue
            
            # æœ€ç»ˆæ£€æŸ¥ï¼šå¦‚æœæ€»è€—æ—¶è¶…è¿‡é™åˆ¶ï¼Œè®°å½•å¹¶ç»§ç»­
            final_time = time_module.time() - start_time
            if final_time > max_process_time:
                if idx % 10 == 0:
                    print(f"â±ï¸ {stock_code} æ€»å¤„ç†æ—¶é—´ {final_time:.1f}ç§’è¶…è¿‡é™åˆ¶ {max_process_time}ç§’ï¼Œå·²è·³è¿‡")
                continue
        
        # å¦‚æœè¢«åœæ­¢ï¼Œæ›´æ–°çŠ¶æ€ï¼ˆåœ¨å¾ªç¯ç»“æŸåæ£€æŸ¥ï¼Œå¤„ç†å¾ªç¯ä¸­breakçš„æƒ…å†µï¼‰
        if self.progress.get('status') == 'å·²åœæ­¢':
            # çŠ¶æ€å·²ç»åœ¨å¾ªç¯ä¸­è®¾ç½®ï¼Œè¿™é‡Œåªéœ€è¦ç¡®ä¿ç»“æœæ­£ç¡®
            pass
        
        # æŒ‰åŒ¹é…åº¦æ’åº
        candidates.sort(key=lambda x: x['åŒ¹é…åº¦'], reverse=True)
        
        # âœ… å…³é”®ï¼šå¸‚å€¼æ£€æŸ¥å¿…é¡»åœ¨æ‰«æå®Œæˆåè¿›è¡ŒäºŒæ¬¡è¿‡æ»¤
        # å› ä¸ºæ‰«æè¿‡ç¨‹ä¸­å¸‚å€¼è·å–å¯èƒ½å¤±è´¥æˆ–è¶…æ—¶ï¼Œå¯¼è‡´ä¸ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨è¢«åŒ…å«è¿›æ¥
        # ä¼˜åŒ–ï¼šå¦‚æœæ‰«æè¿‡ç¨‹ä¸­å·²ç»è·å–åˆ°äº†å¸‚å€¼ï¼Œç›´æ¥ä½¿ç”¨ï¼Œåªå¯¹æ²¡æœ‰å¸‚å€¼çš„è‚¡ç¥¨é‡æ–°è·å–
        if max_market_cap > 0 and len(candidates) > 0:
            print(f"\nğŸ“Š è¿›è¡Œå¸‚å€¼äºŒæ¬¡è¿‡æ»¤ï¼ˆé˜ˆå€¼: â‰¤ {max_market_cap} äº¿å…ƒï¼‰...")
            original_count = len(candidates)
            
            # ç»Ÿè®¡å·²æœ‰å¸‚å€¼å’Œæ²¡æœ‰å¸‚å€¼çš„è‚¡ç¥¨æ•°é‡
            has_market_cap_count = sum(1 for c in candidates if c.get('å¸‚å€¼') is not None and c.get('å¸‚å€¼', 0) > 0)
            no_market_cap_count = len(candidates) - has_market_cap_count
            print(f"  ğŸ“Š ç»Ÿè®¡: {has_market_cap_count} åªè‚¡ç¥¨å·²æœ‰å¸‚å€¼ï¼Œ{no_market_cap_count} åªè‚¡ç¥¨éœ€è¦é‡æ–°è·å–å¸‚å€¼")
            
            filtered_candidates = []
            
            # æ·»åŠ è¿›åº¦æ›´æ–°
            total_candidates = len(candidates)
            for idx, candidate in enumerate(candidates, 1):
                stock_code = candidate.get('è‚¡ç¥¨ä»£ç ')
                if stock_code is None:
                    continue
                
                # æ¯100åªè‚¡ç¥¨æ›´æ–°ä¸€æ¬¡è¿›åº¦
                if idx % 100 == 0 or idx == total_candidates:
                    pct = (idx / total_candidates) * 100
                    filtered_so_far = original_count - len(filtered_candidates)
                    print(f"  [å¸‚å€¼è¿‡æ»¤è¿›åº¦] {idx}/{total_candidates} ({pct:.1f}%) - å·²å¤„ç†: {idx} åªï¼Œå·²è¿‡æ»¤: {filtered_so_far} åª")
                    # æ›´æ–°è¿›åº¦çŠ¶æ€
                    if hasattr(self, 'progress'):
                        self.progress['detail'] = f'å¸‚å€¼äºŒæ¬¡è¿‡æ»¤ä¸­: {idx}/{total_candidates} ({pct:.1f}%)'
                        self.progress['last_update_time'] = time_module.time()
                
                # æ£€æŸ¥å·²æœ‰å¸‚å€¼ï¼ˆä¼˜å…ˆä½¿ç”¨æ‰«æè¿‡ç¨‹ä¸­è·å–çš„å¸‚å€¼ï¼‰
                existing_market_cap = candidate.get('å¸‚å€¼')
                if existing_market_cap is not None and existing_market_cap > 0:
                    # âœ… å¦‚æœæ‰«æè¿‡ç¨‹ä¸­å·²ç»è·å–åˆ°äº†å¸‚å€¼ï¼Œç›´æ¥ä½¿ç”¨ï¼Œä¸éœ€è¦é‡æ–°è·å–
                    if existing_market_cap > max_market_cap:
                        if idx % 500 == 0:  # å‡å°‘æ—¥å¿—è¾“å‡º
                            print(f"  âŒ {stock_code} {candidate.get('è‚¡ç¥¨åç§°', '')} å¸‚å€¼ {existing_market_cap:.2f}äº¿è¶…è¿‡é™åˆ¶ {max_market_cap:.2f}äº¿ï¼Œå·²è¿‡æ»¤")
                        continue
                    filtered_candidates.append(candidate)
                    continue
                
                # å¦‚æœæ²¡æœ‰å¸‚å€¼ï¼Œå°è¯•è·å–ï¼ˆä½¿ç”¨æ›´çŸ­çš„è¶…æ—¶ï¼Œé¿å…å¡ä½ï¼‰
                try:
                    market_cap = self.fetcher.get_market_cap(stock_code, timeout=2)  # å‡å°‘è¶…æ—¶æ—¶é—´ä»3ç§’åˆ°2ç§’
                    if market_cap is not None and market_cap > 0:
                        candidate['å¸‚å€¼'] = round(market_cap, 2)
                        # âœ… å…³é”®ï¼šå¦‚æœå¸‚å€¼è¶…è¿‡é™åˆ¶ï¼Œè¿‡æ»¤æ‰
                        if market_cap > max_market_cap:
                            if idx % 500 == 0:  # å‡å°‘æ—¥å¿—è¾“å‡º
                                print(f"  âŒ {stock_code} {candidate.get('è‚¡ç¥¨åç§°', '')} å¸‚å€¼ {market_cap:.2f}äº¿è¶…è¿‡é™åˆ¶ {max_market_cap:.2f}äº¿ï¼Œå·²è¿‡æ»¤")
                            continue
                        filtered_candidates.append(candidate)
                    else:
                        # å¸‚å€¼è·å–å¤±è´¥ï¼Œä¿ç•™è¯¥è‚¡ç¥¨ï¼ˆä¸å› å¸‚å€¼è·å–å¤±è´¥è€Œä¸¢å¤±ï¼‰
                        filtered_candidates.append(candidate)
                except Exception:
                    # å¸‚å€¼è·å–å¼‚å¸¸ï¼Œä¿ç•™è¯¥è‚¡ç¥¨ï¼ˆä¸å› å¸‚å€¼è·å–å¤±è´¥è€Œä¸¢å¤±ï¼‰
                    filtered_candidates.append(candidate)
            
            candidates = filtered_candidates
            filtered_count = original_count - len(candidates)
            if filtered_count > 0:
                print(f"   âœ… å¸‚å€¼è¿‡æ»¤å®Œæˆï¼šè¿‡æ»¤æ‰ {filtered_count} åªï¼ˆå¸‚å€¼ > {max_market_cap} äº¿å…ƒï¼‰ï¼Œå‰©ä½™ {len(candidates)} åª")
            else:
                print(f"   âœ… å¸‚å€¼è¿‡æ»¤å®Œæˆï¼šæ‰€æœ‰å€™é€‰è‚¡ç¥¨å‡ç¬¦åˆå¸‚å€¼è¦æ±‚ï¼Œå‰©ä½™ {len(candidates)} åª")
        
        # å®Œæˆè¿›åº¦
        batch_info = f" [ç¬¬ {batch_num}/{total_batches} æ‰¹]" if total_batches > 1 else ""
        # å¦‚æœè¢«åœæ­¢ï¼ŒçŠ¶æ€å·²ç»æ˜¯'å·²åœæ­¢'ï¼Œå¦åˆ™è®¾ç½®ä¸ºå®Œæˆæˆ–è¿›è¡Œä¸­
        if self.progress.get('status') != 'å·²åœæ­¢':
            if batch_num == total_batches:
                # æœ€åä¸€æ‰¹å®Œæˆï¼Œæ ‡è®°ä¸ºå®Œæˆ
                self.progress['status'] = 'å®Œæˆ'
                self.progress['percentage'] = 100.0
                self.progress['detail'] = f'æ‰€æœ‰æ‰¹æ¬¡æ‰«æå®Œæˆ: æ‰¾åˆ° {len(candidates)} åªç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨'
                # ä½¿ç”¨æ€»è‚¡ç¥¨æ•°
                self.progress['current'] = total_all_stocks
                # ç¡®ä¿è¿›åº¦ä¸­çš„foundå’Œcandidatesä¸æœ€ç»ˆç»“æœä¸€è‡´
                self.progress['found'] = len(candidates)
                self.progress['candidates'] = candidates[:50] if len(candidates) > 50 else candidates
                # ç¡®ä¿è¿›åº¦ä¸­çš„foundå’Œcandidatesä¸æœ€ç»ˆç»“æœä¸€è‡´
                self.progress['found'] = len(candidates)
                self.progress['candidates'] = candidates[:50] if len(candidates) > 50 else candidates
            else:
                # è¿˜æœ‰ä¸‹ä¸€æ‰¹ï¼Œç»§ç»­æ‰«æ
                self.progress['status'] = 'è¿›è¡Œä¸­'
                # è®¡ç®—æ•´ä½“è¿›åº¦ï¼ˆå·²å®Œæˆæ‰¹æ¬¡çš„è¿›åº¦ï¼‰
                self.progress['percentage'] = round((batch_num / total_batches * 100), 1)
                # è®¡ç®—æ•´ä½“å·²æ‰«æçš„è‚¡ç¥¨æ•°
                overall_current = int((batch_num / total_batches) * total_all_stocks)
                self.progress['current'] = overall_current
                self.progress['detail'] = f'ç¬¬ {batch_num}/{total_batches} æ‰¹æ‰«æå®Œæˆ: æ‰¾åˆ° {len(candidates)} åªç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨ï¼Œç»§ç»­æ‰«æä¸‹ä¸€æ‰¹...'
        # å¦‚æœè¢«åœæ­¢ï¼Œcurrentå·²ç»åœ¨å¾ªç¯ä¸­è®¾ç½®ï¼Œä¸éœ€è¦å†æ¬¡è®¾ç½®
        
        self.progress['last_update_time'] = time_module.time()  # æ›´æ–°æœ€åæ›´æ–°æ—¶é—´
        
        print("\n" + "=" * 80)
        print(f"âœ… æœ¬æ‰¹æ‰«æå®Œæˆï¼æ‰¾åˆ° {len(candidates)} åªç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨{batch_info}")
        print("=" * 80)
        
        # å¦‚æœè¢«åœæ­¢ï¼Œè¿”å›å½“å‰å·²æ‰¾åˆ°çš„ç»“æœ
        if self.progress.get('status') == 'å·²åœæ­¢':
            current_processed = self.progress.get('current', idx)
            return {
                'success': True,
                'message': f'æ‰«æå·²åœæ­¢ï¼Œå·²å¤„ç† {current_processed}/{total_stocks} åªè‚¡ç¥¨ï¼Œæ‰¾åˆ° {len(candidates)} åªç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨',
                'candidates': candidates[:50] if len(candidates) > 50 else candidates,  # åªè¿”å›å‰50ä¸ªæœ€ä½³å€™é€‰
                'total_scanned': current_processed,
                'found_count': len(candidates),
                'batch': batch_num,
                'total_batches': total_batches,
                'stopped': True  # æ ‡è®°ä¸ºå·²åœæ­¢
            }
        
        result = {
            'success': True,
            'message': f'æœ¬æ‰¹æ‰«æå®Œæˆï¼Œæ‰¾åˆ° {len(candidates)} åªç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨',
            'candidates': candidates[:50] if len(candidates) > 50 else candidates,  # åªè¿”å›å‰50ä¸ªæœ€ä½³å€™é€‰
            'total_scanned': total_all_stocks,  # ä½¿ç”¨æ€»è‚¡ç¥¨æ•°
            'found_count': len(candidates),
            'batch': batch_num,
            'total_batches': total_batches
        }
        
        # ä¿å­˜æ‰«æç»“æœåˆ° analyzer.scan_resultsï¼ˆä¾›å‰ç«¯è·å–ï¼‰
        # å¦‚æœæ˜¯æœ€åä¸€æ‰¹ï¼Œä¿å­˜å®Œæ•´ç»“æœ
        if batch_num == total_batches:
            self.scan_results = result.copy()
            # ç¡®ä¿ä¿å­˜å®Œæ•´çš„å€™é€‰åˆ—è¡¨ï¼ˆä¸ä»…ä»…æ˜¯å‰50ä¸ªï¼‰
            self.scan_results['candidates'] = candidates  # ä¿å­˜å…¨éƒ¨å€™é€‰ï¼Œä¸é™åˆ¶ä¸º50ä¸ª
            self.scan_results['found_count'] = len(candidates)  # ç¡®ä¿found_countä¸å®é™…æ•°é‡ä¸€è‡´
        
        return result
    
    def get_trained_features(self) -> Optional[Dict]:
        """
        è·å–è®­ç»ƒå¥½çš„ç‰¹å¾æ¨¡æ¿
        :return: è®­ç»ƒç»“æœï¼Œå¦‚æœæœªè®­ç»ƒè¿”å›None
        """
        return getattr(self, 'trained_features', None)
    
    def save_model(self, filename: str = 'trained_model.json') -> bool:
        """
        ä¿å­˜æ¨¡å‹åˆ°JSONæ–‡ä»¶
        :param filename: ä¿å­˜çš„æ–‡ä»¶å
        :return: æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            import json
            from datetime import datetime
            
            model_data = {
                'trained_at': datetime.now().isoformat(),
                'buy_features': None,
                'sell_features': None,
                'analysis_results': {},
                'bull_stocks': []
            }
            
            # ä¿å­˜ä¹°ç‚¹ç‰¹å¾æ¨¡å‹
            if self.trained_features:
                buy_features = self.trained_features.copy()
                # è½¬æ¢datetimeå¯¹è±¡ä¸ºå­—ç¬¦ä¸²
                if 'trained_at' in buy_features and hasattr(buy_features['trained_at'], 'isoformat'):
                    buy_features['trained_at'] = buy_features['trained_at'].isoformat()
                model_data['buy_features'] = buy_features
            
            # ä¿å­˜å–ç‚¹ç‰¹å¾æ¨¡å‹
            if self.trained_sell_features:
                sell_features = self.trained_sell_features.copy()
                # è½¬æ¢datetimeå¯¹è±¡ä¸ºå­—ç¬¦ä¸²
                if 'trained_at' in sell_features and hasattr(sell_features['trained_at'], 'isoformat'):
                    sell_features['trained_at'] = sell_features['trained_at'].isoformat()
                model_data['sell_features'] = sell_features

            # ä¿å­˜â€œ8æ¡ä»¶â€é€‰è‚¡å¤§æ¨¡å‹
            if getattr(self, 'trained_screener_model', None):
                screener_model = self.trained_screener_model.copy()
                if 'trained_at' in screener_model and hasattr(screener_model['trained_at'], 'isoformat'):
                    screener_model['trained_at'] = screener_model['trained_at'].isoformat()
                model_data['screener_model'] = screener_model
            
            # ä¿å­˜åˆ†æç»“æœï¼ˆåªä¿å­˜å…³é”®ä¿¡æ¯ï¼‰
            for stock_code, result in self.analysis_results.items():
                interval = result.get('interval', {})
                model_data['analysis_results'][stock_code] = {
                    'interval': {
                        'èµ·ç‚¹æ—¥æœŸ': str(interval.get('èµ·ç‚¹æ—¥æœŸ', '')),
                        'èµ·ç‚¹ä»·æ ¼': float(interval.get('èµ·ç‚¹ä»·æ ¼', 0)) if interval.get('èµ·ç‚¹ä»·æ ¼') else 0,
                        'èµ·ç‚¹ç´¢å¼•': int(interval.get('èµ·ç‚¹ç´¢å¼•')) if interval.get('èµ·ç‚¹ç´¢å¼•') is not None else None,
                        'ç»ˆç‚¹æ—¥æœŸ': str(interval.get('ç»ˆç‚¹æ—¥æœŸ', '')),
                        'ç»ˆç‚¹ä»·æ ¼': float(interval.get('ç»ˆç‚¹ä»·æ ¼', 0)) if interval.get('ç»ˆç‚¹ä»·æ ¼') else 0,
                        'æ¶¨å¹…': float(interval.get('æ¶¨å¹…', 0)) if interval.get('æ¶¨å¹…') else 0,
                    }
                }
            
            # ä¿å­˜å¤§ç‰›è‚¡åˆ—è¡¨
            for stock in self.bull_stocks:
                stock_data = {
                    'ä»£ç ': stock['ä»£ç '],
                    'åç§°': stock['åç§°'],
                    'æ·»åŠ æ—¶é—´': stock['æ·»åŠ æ—¶é—´'].isoformat() if hasattr(stock['æ·»åŠ æ—¶é—´'], 'isoformat') else str(stock['æ·»åŠ æ—¶é—´']),
                    'æ•°æ®æ¡æ•°': stock.get('æ•°æ®æ¡æ•°', 0)
                }
                model_data['bull_stocks'].append(stock_data)
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(model_data, f, ensure_ascii=False, indent=2)
            
            return True
        except Exception as e:
            print(f"ä¿å­˜æ¨¡å‹å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def load_model(self, filename: str = 'trained_model.json', skip_network: bool = True) -> bool:
        """
        ä»JSONæ–‡ä»¶åŠ è½½æ¨¡å‹
        :param filename: æ¨¡å‹æ–‡ä»¶å
        :param skip_network: æ˜¯å¦è·³è¿‡ç½‘ç»œè¯·æ±‚ï¼ˆåŠ è½½æ¨¡å‹æ—¶ä¸éœ€è¦ç½‘ç»œï¼‰
        :return: æ˜¯å¦åŠ è½½æˆåŠŸ
        """
        try:
            import json
            from datetime import datetime
            import os
            
            # å°è¯•å¤šä¸ªå¯èƒ½çš„è·¯å¾„ï¼ˆVercel ç¯å¢ƒä¸­è·¯å¾„å¯èƒ½ä¸åŒï¼‰
            possible_paths = [
                filename,  # åŸå§‹è·¯å¾„
                os.path.abspath(filename),  # ç»å¯¹è·¯å¾„
                os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), filename),  # é¡¹ç›®æ ¹ç›®å½•
            ]
            
            model_data = None
            loaded_path = None
            
            # åŠ è½½æ–‡ä»¶ï¼ˆçº¯æ–‡ä»¶æ“ä½œï¼Œä¸æ¶‰åŠç½‘ç»œï¼‰
            for path in possible_paths:
                try:
                    abs_path = os.path.abspath(path)
                    if os.path.exists(path):
                        print(f"[load_model] å°è¯•è¯»å–: {path} (ç»å¯¹è·¯å¾„: {abs_path})")
                        # ç›´æ¥è¯»å–æ–‡ä»¶ï¼Œä¸è§¦å‘ä»»ä½•ç½‘ç»œè¯·æ±‚
                        with open(path, 'r', encoding='utf-8') as f:
                            model_data = json.load(f)
                        loaded_path = path
                        print(f"[load_model] âœ… æˆåŠŸä» {path} åŠ è½½æ¨¡å‹")
                        break
                except (FileNotFoundError, OSError) as e:
                    print(f"[load_model] è·¯å¾„ä¸å­˜åœ¨: {path} - {e}")
                    continue
                except json.JSONDecodeError as e:
                    print(f"[load_model] JSON è§£æå¤±è´¥: {path} - {e}")
                    continue
                except Exception as e:
                    print(f"[load_model] è¯»å–æ–‡ä»¶å¤±è´¥: {path} - {e}")
                    continue
            
            if model_data is None:
                print(f"[load_model] âŒ æ‰€æœ‰è·¯å¾„éƒ½å¤±è´¥ï¼Œæ— æ³•åŠ è½½æ¨¡å‹æ–‡ä»¶: {filename}")
                print(f"[load_model] å°è¯•çš„è·¯å¾„: {possible_paths}")
                return False
            
            # è§£ææ¨¡å‹æ•°æ®ï¼ˆçº¯å†…å­˜æ“ä½œï¼Œä¸æ¶‰åŠç½‘ç»œï¼‰
            # åŠ è½½ä¹°ç‚¹ç‰¹å¾æ¨¡å‹
            if model_data.get('buy_features'):
                buy_features = model_data['buy_features'].copy()
                # è½¬æ¢å­—ç¬¦ä¸²ä¸ºdatetimeå¯¹è±¡
                if 'trained_at' in buy_features and isinstance(buy_features['trained_at'], str):
                    buy_features['trained_at'] = datetime.fromisoformat(buy_features['trained_at'])
                self.trained_features = buy_features
            
            # åŠ è½½å–ç‚¹ç‰¹å¾æ¨¡å‹
            if model_data.get('sell_features'):
                sell_features = model_data['sell_features'].copy()
                # è½¬æ¢å­—ç¬¦ä¸²ä¸ºdatetimeå¯¹è±¡
                if 'trained_at' in sell_features and isinstance(sell_features['trained_at'], str):
                    sell_features['trained_at'] = datetime.fromisoformat(sell_features['trained_at'])
                self.trained_sell_features = sell_features

            # åŠ è½½â€œ8æ¡ä»¶â€é€‰è‚¡å¤§æ¨¡å‹ï¼ˆä¸è§¦å‘ç½‘ç»œï¼‰
            if model_data.get('screener_model'):
                screener_model = model_data['screener_model']
                try:
                    if 'trained_at' in screener_model and isinstance(screener_model['trained_at'], str):
                        screener_model['trained_at'] = datetime.fromisoformat(screener_model['trained_at'])
                except Exception:
                    pass
                self.trained_screener_model = screener_model
            
            # åŠ è½½ analysis_resultsï¼ˆè®­ç»ƒä¹°ç‚¹ã€èµ·ç‚¹ç´¢å¼•/æ—¥æœŸç­‰ï¼Œfind_buy_points æŒ‰æ—¥æœŸåŒ¹é…è®­ç»ƒä¹°ç‚¹ç”¨ï¼‰
            if model_data.get('analysis_results'):
                self.analysis_results = dict(model_data['analysis_results'])
            
            # åŠ è½½å¤§ç‰›è‚¡åˆ—è¡¨ï¼ˆä»…åŠ è½½å…ƒæ•°æ®ï¼Œä¸è·å–è‚¡ç¥¨æ•°æ®ï¼Œé¿å…ç½‘ç»œè¯·æ±‚ï¼‰
            # å³ä½¿ skip_network=Trueï¼Œä¹Ÿåº”è¯¥åŠ è½½è‚¡ç¥¨åˆ—è¡¨çš„å…ƒæ•°æ®ï¼ˆä¸è§¦å‘ç½‘ç»œè¯·æ±‚ï¼‰
            if model_data.get('bull_stocks'):
                loaded_count = 0
                for stock_data in model_data['bull_stocks']:
                    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                    existing = [s for s in self.bull_stocks if s['ä»£ç '] == stock_data['ä»£ç ']]
                    if not existing:
                        stock = {
                            'ä»£ç ': stock_data['ä»£ç '],
                            'åç§°': stock_data['åç§°'],
                            'æ·»åŠ æ—¶é—´': datetime.fromisoformat(stock_data['æ·»åŠ æ—¶é—´']) if isinstance(stock_data['æ·»åŠ æ—¶é—´'], str) else datetime.now(),
                            'æ•°æ®æ¡æ•°': stock_data.get('æ•°æ®æ¡æ•°', 0)
                        }
                        self.bull_stocks.append(stock)
                        loaded_count += 1
                
                if loaded_count > 0:
                    print(f"[load_model] âœ… ä»æ¨¡å‹åŠ è½½äº† {loaded_count} åªè‚¡ç¥¨çš„å…ƒæ•°æ®ï¼ˆä¸è§¦å‘ç½‘ç»œè¯·æ±‚ï¼‰")
                else:
                    print(f"[load_model] â„¹ï¸ æ¨¡å‹ä¸­æœ‰ {len(model_data.get('bull_stocks', []))} åªè‚¡ç¥¨ï¼Œä½†éƒ½å·²å­˜åœ¨ï¼Œæœªé‡å¤åŠ è½½")
            
            return True
        except FileNotFoundError:
            return False
        except Exception as e:
            print(f"åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False


if __name__ == '__main__':
    # æµ‹è¯•ä»£ç 
    analyzer = BullStockAnalyzer()
    
    # æµ‹è¯•æ·»åŠ è‚¡ç¥¨
    print("=" * 60)
    print("æµ‹è¯•ï¼šæ·»åŠ å¤§ç‰›è‚¡")
    print("=" * 60)
    
    analyzer.add_bull_stock('000001', 'å¹³å®‰é“¶è¡Œ')
    analyzer.add_bull_stock('000002', 'ä¸‡ç§‘A')
    
    # æŸ¥çœ‹å·²æ·»åŠ çš„è‚¡ç¥¨
    print("\nå·²æ·»åŠ çš„å¤§ç‰›è‚¡ï¼š")
    for stock in analyzer.get_bull_stocks():
        print(f"  - {stock['ä»£ç ']} {stock['åç§°']}")

