# 🚀 扫描速度优化方案

## 📊 当前性能

**当前速度**：约 1 秒/只股票
**全市场扫描**：约 5000 只股票 × 1 秒 = 约 83 分钟（1.4 小时）

---

## 🎯 优化目标

**目标速度**：提升到 **5-10 倍**（使用并行处理）

**预期效果**：
- 串行处理：1 秒/只
- 并行处理（5-10 线程）：0.1-0.2 秒/只
- **全市场扫描**：约 5000 只股票 × 0.15 秒 ≈ **12.5 分钟**

---

## 🔍 性能瓶颈分析

### 1. 数据获取（周K线）

**当前实现**：
- 串行获取：一只一只股票获取数据
- 如果有缓存：很快（< 0.1 秒）
- 如果没有缓存：需要从 API 获取（0.5-1 秒）

**优化点**：
- ✅ 并行获取：同时获取多只股票的数据
- ✅ 预加载缓存：扫描前预先加载常用股票的数据

### 2. 特征提取

**当前实现**：
- 串行计算：一只一只股票计算特征
- CPU 密集型操作（约 0.1-0.2 秒/只）

**优化点**：
- ✅ 并行计算：同时计算多只股票的特征

### 3. 匹配度计算

**当前实现**：
- 串行计算：一只一只股票计算匹配度
- CPU 密集型操作（约 0.05-0.1 秒/只）

**优化点**：
- ✅ 并行计算：同时计算多只股票的匹配度

---

## 💡 优化方案

### 方案一：并行处理（推荐，最快）

**原理**：使用 `ThreadPoolExecutor` 并行处理多只股票

**优势**：
- ✅ **速度快**：5-10 倍提升
- ✅ **实现简单**：只需修改扫描循环
- ✅ **适合 I/O 密集型**：数据获取主要是网络 I/O

**注意事项**：
- ⚠️ 需要控制并发数量（建议 5-10 个线程）
- ⚠️ 需要确保线程安全（共享变量需要加锁）
- ⚠️ 需要处理进度更新（多线程共享进度）

**实现方式**：
```python
from concurrent.futures import ThreadPoolExecutor, as_completed

def _scan_stock_parallel(self, stock_list, common_features, min_match_score, max_market_cap, max_workers=5):
    """并行扫描股票"""
    candidates = []
    
    # 使用线程池并行处理
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # 提交所有任务
        future_to_stock = {
            executor.submit(self._process_single_stock, stock_code, stock_name, common_features, min_match_score, max_market_cap): (stock_code, stock_name)
            for _, row in stock_list.iterrows()
            for stock_code, stock_name in [(row[code_col], row[name_col])]
        }
        
        # 收集结果
        for future in as_completed(future_to_stock):
            stock_code, stock_name = future_to_stock[future]
            try:
                result = future.result()
                if result:
                    candidates.append(result)
            except Exception as e:
                print(f"处理 {stock_code} 失败: {e}")
    
    return candidates
```

---

### 方案二：预加载缓存（辅助，减少网络请求）

**原理**：在扫描前预先加载常用股票的周K线数据到缓存

**优势**：
- ✅ **减少网络请求**：缓存命中率提高
- ✅ **加快数据获取**：从缓存读取更快

**实现方式**：
```python
def preload_stock_cache(self, stock_list, max_workers=10):
    """预加载股票数据到缓存"""
    from concurrent.futures import ThreadPoolExecutor
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = [
            executor.submit(self.fetcher.get_weekly_kline, stock_code, period="2y", use_cache=True)
            for stock_code in stock_list['代码']
        ]
        
        # 等待所有任务完成
        for future in futures:
            try:
                future.result(timeout=5)  # 5秒超时
            except Exception as e:
                pass  # 忽略失败的任务
```

---

### 方案三：批量处理（中等优化）

**原理**：将股票列表分成多个批次，每批次并行处理

**优势**：
- ✅ **平衡速度和资源**：避免过多并发
- ✅ **更好的进度跟踪**：分批处理，进度更清晰

**实现方式**：
```python
def _scan_stock_batch_parallel(self, stock_list, batch_size=50, max_workers=5):
    """批量并行扫描"""
    candidates = []
    total_stocks = len(stock_list)
    
    # 分批处理
    for i in range(0, total_stocks, batch_size):
        batch = stock_list.iloc[i:i+batch_size]
        
        # 并行处理当前批次
        batch_candidates = self._scan_stock_parallel(batch, common_features, min_match_score, max_market_cap, max_workers)
        candidates.extend(batch_candidates)
        
        # 更新进度
        self.progress['current'] = min(i + batch_size, total_stocks)
        self.progress['percentage'] = (self.progress['current'] / total_stocks) * 100
    
    return candidates
```

---

## 🚀 推荐实施方案

### 步骤 1：添加并行处理函数

在 `bull_stock_analyzer.py` 中添加并行处理函数：

```python
from concurrent.futures import ThreadPoolExecutor, as_completed

def _process_single_stock(self, stock_code, stock_name, common_features, min_match_score, max_market_cap):
    """处理单只股票（用于并行处理）"""
    try:
        # 获取周K线数据
        weekly_df = self.fetcher.get_weekly_kline(stock_code, period="2y", use_cache=True)
        if weekly_df is None or len(weekly_df) < 40:
            return None
        
        # 提取特征
        current_idx = len(weekly_df) - 1
        features = self.extract_features_at_start_point(stock_code, current_idx, lookback_weeks=40, weekly_df=weekly_df)
        
        # 计算匹配度
        match_score = self.calculate_match_score(features, common_features)
        
        # 检查是否符合条件
        if match_score >= min_match_score:
            return {
                'code': stock_code,
                'name': stock_name,
                'match_score': match_score,
                'features': features
            }
        
        return None
    except Exception as e:
        return None
```

### 步骤 2：修改扫描函数

在 `_scan_stock_batch` 方法中添加并行处理选项：

```python
def _scan_stock_batch(self, stock_list, common_features, min_match_score, max_market_cap, 
                     batch_num=1, total_batches=1, start_idx=0, existing_candidates=None, 
                     total_all_stocks=None, use_parallel=True, max_workers=5):
    """扫描一批股票（支持并行处理）"""
    
    if use_parallel:
        # 使用并行处理
        return self._scan_stock_batch_parallel(stock_list, common_features, min_match_score, 
                                              max_market_cap, max_workers=max_workers)
    else:
        # 使用串行处理（原有逻辑）
        return self._scan_stock_batch_serial(stock_list, common_features, min_match_score, 
                                            max_market_cap, batch_num, total_batches, 
                                            start_idx, existing_candidates, total_all_stocks)
```

### 步骤 3：在 API 中添加配置选项

在 `bull_stock_web.py` 的 `scan_all_stocks` API 中添加参数：

```python
data = request.get_json() or {}
use_parallel = data.get('use_parallel', True)  # 默认启用并行处理
max_workers = int(data.get('max_workers', 5))  # 默认5个线程
```

---

## ⚙️ 配置建议

### Render 环境

**推荐配置**：
- `max_workers=5`：5 个线程（平衡速度和资源）
- `use_parallel=True`：启用并行处理

**原因**：
- Render 免费版有资源限制
- 5 个线程通常足够，不会过载
- 如果速度仍然不够，可以增加到 10 个线程

### 本地环境

**推荐配置**：
- `max_workers=10`：10 个线程（本地资源充足）
- `use_parallel=True`：启用并行处理

---

## 📊 预期效果

### 串行处理（当前）

- **速度**：1 秒/只
- **全市场扫描**：5000 只 × 1 秒 = **83 分钟**

### 并行处理（5 线程）

- **速度**：约 0.2 秒/只（5 倍提升）
- **全市场扫描**：5000 只 × 0.2 秒 = **16.7 分钟**

### 并行处理（10 线程）

- **速度**：约 0.1 秒/只（10 倍提升）
- **全市场扫描**：5000 只 × 0.1 秒 = **8.3 分钟**

---

## ⚠️ 注意事项

### 1. 线程安全

- 进度更新需要加锁（`threading.Lock`）
- 共享变量需要同步

### 2. 资源限制

- Render 免费版有资源限制，不要使用过多线程
- 建议从 5 个线程开始，逐步增加

### 3. 错误处理

- 单个股票处理失败不应该影响其他股票
- 需要捕获并记录错误

### 4. 进度更新

- 多线程环境下进度更新需要同步
- 可以使用队列或锁来同步进度

---

## ✅ 实施检查清单

- [ ] 添加 `_process_single_stock` 函数
- [ ] 添加 `_scan_stock_batch_parallel` 函数
- [ ] 修改 `_scan_stock_batch` 函数支持并行处理
- [ ] 在 API 中添加并行处理配置选项
- [ ] 测试并行处理功能
- [ ] 测试进度更新是否正确
- [ ] 测试错误处理是否正常
- [ ] 性能测试（对比串行和并行速度）

---

## 🎉 总结

**推荐方案**：使用 **并行处理（方案一）**

**优势**：
- ✅ 速度提升明显（5-10 倍）
- ✅ 实现相对简单
- ✅ 适合 Render 环境

**预期效果**：
- 从 1 秒/只 → 0.1-0.2 秒/只
- 全市场扫描从 83 分钟 → 8-17 分钟

如果还有其他问题或需要进一步优化，请告诉我！

