#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä½¿ç”¨æ–°æµªè´¢ç»APIå¢é‡æ›´æ–°æœ¬åœ°Kçº¿æ•°æ®åˆ°æœ€æ–°æ—¥æœŸ
"""
import os
import sys
import json
import time
import requests
import pandas as pd
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor, as_completed

# é…ç½®
CACHE_DIR = 'cache'
DAILY_DIR = os.path.join(CACHE_DIR, 'daily_kline')
WEEKLY_DIR = os.path.join(CACHE_DIR, 'weekly_kline')
MAX_WORKERS = 10  # å¹¶å‘æ•°ï¼ˆæ–°æµªAPIç›¸å¯¹å®½æ¾ï¼‰
RETRY_TIMES = 3  # é‡è¯•æ¬¡æ•°

# åˆ›å»ºå…¨å±€session
session = requests.Session()
session.trust_env = False  # ä¸ä½¿ç”¨ç³»ç»Ÿä»£ç†
session.headers.update({'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)'})


def get_stock_list():
    """è·å–è‚¡ç¥¨åˆ—è¡¨"""
    stock_list_path = os.path.join(CACHE_DIR, 'stock_list_all.json')
    if os.path.exists(stock_list_path):
        with open(stock_list_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return None


def get_sina_daily_kline(code, datalen=60):
    """
    é€šè¿‡æ–°æµªè´¢ç»è·å–æ—¥Kçº¿æ•°æ®
    :param code: è‚¡ç¥¨ä»£ç 
    :param datalen: è·å–æ•°æ®æ¡æ•°
    """
    # è½¬æ¢ä»£ç æ ¼å¼
    if code.startswith('6'):
        symbol = f'sh{code}'
    else:
        symbol = f'sz{code}'
    
    url = f'https://quotes.sina.cn/cn/api/jsonp_v2.php/data/CN_MarketDataService.getKLineData?symbol={symbol}&scale=240&datalen={datalen}'
    
    for attempt in range(RETRY_TIMES):
        try:
            resp = session.get(url, timeout=10)
            if resp.status_code == 200:
                text = resp.text
                if 'data(' in text:
                    json_str = text.split('data(')[1].rsplit(')', 1)[0]
                    data = json.loads(json_str)
                    if data:
                        df = pd.DataFrame(data)
                        df = df.rename(columns={
                            'day': 'æ—¥æœŸ',
                            'open': 'å¼€ç›˜',
                            'close': 'æ”¶ç›˜',
                            'high': 'æœ€é«˜',
                            'low': 'æœ€ä½',
                            'volume': 'æˆäº¤é‡'
                        })
                        df = df[['æ—¥æœŸ', 'å¼€ç›˜', 'æ”¶ç›˜', 'æœ€é«˜', 'æœ€ä½', 'æˆäº¤é‡']]
                        df['å¼€ç›˜'] = df['å¼€ç›˜'].astype(float)
                        df['æ”¶ç›˜'] = df['æ”¶ç›˜'].astype(float)
                        df['æœ€é«˜'] = df['æœ€é«˜'].astype(float)
                        df['æœ€ä½'] = df['æœ€ä½'].astype(float)
                        df['æˆäº¤é‡'] = df['æˆäº¤é‡'].astype(int)
                        return df
        except Exception as e:
            if attempt < RETRY_TIMES - 1:
                time.sleep(0.3 * (attempt + 1))
    return None


def get_sina_weekly_kline(code, datalen=30):
    """
    é€šè¿‡æ–°æµªè´¢ç»è·å–å‘¨Kçº¿æ•°æ®
    :param code: è‚¡ç¥¨ä»£ç 
    :param datalen: è·å–æ•°æ®æ¡æ•°
    """
    # è½¬æ¢ä»£ç æ ¼å¼
    if code.startswith('6'):
        symbol = f'sh{code}'
    else:
        symbol = f'sz{code}'
    
    # scale=1200 æ˜¯å‘¨Kçº¿
    url = f'https://quotes.sina.cn/cn/api/jsonp_v2.php/data/CN_MarketDataService.getKLineData?symbol={symbol}&scale=1200&datalen={datalen}'
    
    for attempt in range(RETRY_TIMES):
        try:
            resp = session.get(url, timeout=10)
            if resp.status_code == 200:
                text = resp.text
                if 'data(' in text:
                    json_str = text.split('data(')[1].rsplit(')', 1)[0]
                    data = json.loads(json_str)
                    if data:
                        df = pd.DataFrame(data)
                        df = df.rename(columns={
                            'day': 'æ—¥æœŸ',
                            'open': 'å¼€ç›˜',
                            'close': 'æ”¶ç›˜',
                            'high': 'æœ€é«˜',
                            'low': 'æœ€ä½',
                            'volume': 'å‘¨æˆäº¤é‡'
                        })
                        df = df[['æ—¥æœŸ', 'å¼€ç›˜', 'æ”¶ç›˜', 'æœ€é«˜', 'æœ€ä½', 'å‘¨æˆäº¤é‡']]
                        df['å¼€ç›˜'] = df['å¼€ç›˜'].astype(float)
                        df['æ”¶ç›˜'] = df['æ”¶ç›˜'].astype(float)
                        df['æœ€é«˜'] = df['æœ€é«˜'].astype(float)
                        df['æœ€ä½'] = df['æœ€ä½'].astype(float)
                        df['å‘¨æˆäº¤é‡'] = df['å‘¨æˆäº¤é‡'].astype(int)
                        return df
        except Exception as e:
            if attempt < RETRY_TIMES - 1:
                time.sleep(0.3 * (attempt + 1))
    return None


def process_single_stock(code, name, target_date):
    """å¤„ç†å•åªè‚¡ç¥¨çš„æ•°æ®æ›´æ–°"""
    result = {'code': code, 'name': name, 'daily_updated': 0, 'weekly_updated': 0, 'error': None}
    
    try:
        # æ›´æ–°æ—¥Kçº¿
        daily_path = os.path.join(DAILY_DIR, f'{code}.csv')
        if os.path.exists(daily_path):
            existing_daily = pd.read_csv(daily_path)
            last_date = existing_daily['æ—¥æœŸ'].iloc[-1] if len(existing_daily) > 0 else '2000-01-01'
            
            # å¦‚æœæ•°æ®å·²ç»æ˜¯æœ€æ–°çš„ï¼Œè·³è¿‡
            if last_date >= target_date:
                pass
            else:
                # è·å–æœ€è¿‘çš„æ•°æ®
                new_daily = get_sina_daily_kline(code, datalen=30)
                if new_daily is not None and len(new_daily) > 0:
                    # åªä¿ç•™æ¯”ç°æœ‰æ•°æ®æ–°çš„è®°å½•
                    new_daily = new_daily[new_daily['æ—¥æœŸ'] > last_date]
                    if len(new_daily) > 0:
                        # åˆå¹¶æ•°æ®
                        combined = pd.concat([existing_daily, new_daily], ignore_index=True)
                        combined = combined.drop_duplicates(subset=['æ—¥æœŸ'], keep='last')
                        combined = combined.sort_values('æ—¥æœŸ').reset_index(drop=True)
                        combined.to_csv(daily_path, index=False, encoding='utf-8')
                        result['daily_updated'] = len(new_daily)
        
        # æ›´æ–°å‘¨Kçº¿
        weekly_path = os.path.join(WEEKLY_DIR, f'{code}.csv')
        if os.path.exists(weekly_path):
            existing_weekly = pd.read_csv(weekly_path)
            last_date = existing_weekly['æ—¥æœŸ'].iloc[-1] if len(existing_weekly) > 0 else '2000-01-01'
            
            # è·å–æœ€è¿‘çš„å‘¨Kçº¿æ•°æ®
            new_weekly = get_sina_weekly_kline(code, datalen=10)
            if new_weekly is not None and len(new_weekly) > 0:
                # åªä¿ç•™æ¯”ç°æœ‰æ•°æ®æ–°çš„è®°å½•ï¼ˆå‘¨Kçº¿ç”¨æ—¥æœŸåšæ¯”è¾ƒï¼Œå–æœ€åä¸€å‘¨ï¼‰
                new_weekly = new_weekly[new_weekly['æ—¥æœŸ'] > last_date]
                if len(new_weekly) > 0:
                    # åˆå¹¶æ•°æ®
                    combined = pd.concat([existing_weekly, new_weekly], ignore_index=True)
                    combined = combined.drop_duplicates(subset=['æ—¥æœŸ'], keep='last')
                    combined = combined.sort_values('æ—¥æœŸ').reset_index(drop=True)
                    combined.to_csv(weekly_path, index=False, encoding='utf-8')
                    result['weekly_updated'] = len(new_weekly)
        
    except Exception as e:
        result['error'] = str(e)
    
    return result


def main():
    print("=" * 60)
    print("ğŸ“Š å¢é‡æ›´æ–°æœ¬åœ°Kçº¿æ•°æ®ï¼ˆä½¿ç”¨æ–°æµªè´¢ç»APIï¼‰")
    print("=" * 60)
    print(flush=True)
    
    # è·å–è‚¡ç¥¨åˆ—è¡¨
    stock_list = get_stock_list()
    if not stock_list:
        print("âŒ æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨")
        return
    
    # ç›®æ ‡æ—¥æœŸï¼ˆä»Šå¤©ï¼‰
    target_date = datetime.now().strftime('%Y-%m-%d')
    
    print(f"ğŸ“… ç›®æ ‡æ—¥æœŸ: {target_date}")
    print(f"ğŸ“ˆ è‚¡ç¥¨æ€»æ•°: {len(stock_list)}")
    print(flush=True)
    
    # ä¸è¿‡æ»¤ï¼šSTã€åŒ—äº¤æ‰€ç­‰å…¨éƒ¨å‚ä¸è¿½åŠ æ›´æ–°
    valid_stocks = []
    for stock in stock_list:
        code = stock.get('code', stock.get('è‚¡ç¥¨ä»£ç ', ''))
        name = stock.get('name', stock.get('è‚¡ç¥¨åç§°', ''))
        if code:
            valid_stocks.append({'code': str(code).strip(), 'name': name or ''})
    
    print(f"ğŸ“Š å‚ä¸æ›´æ–°è‚¡ç¥¨æ•°: {len(valid_stocks)}ï¼ˆå…¨éƒ¨ï¼‰")
    print()
    print(flush=True)
    
    # å¹¶è¡Œæ›´æ–°
    total = len(valid_stocks)
    completed = 0
    daily_total = 0
    weekly_total = 0
    errors = 0
    
    start_time = time.time()
    
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = {
            executor.submit(process_single_stock, s['code'], s['name'], target_date): s
            for s in valid_stocks
        }
        
        for future in as_completed(futures):
            completed += 1
            result = future.result()
            
            if result['error']:
                errors += 1
            else:
                daily_total += result['daily_updated']
                weekly_total += result['weekly_updated']
            
            # æ¯200åªè‚¡ç¥¨æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
            if completed % 200 == 0 or completed == total:
                elapsed = time.time() - start_time
                speed = completed / elapsed if elapsed > 0 else 0
                eta = (total - completed) / speed if speed > 0 else 0
                print(f"è¿›åº¦: {completed}/{total} ({completed/total*100:.1f}%) | "
                      f"æ—¥Kæ–°å¢: {daily_total} | å‘¨Kæ–°å¢: {weekly_total} | "
                      f"é”™è¯¯: {errors} | é€Ÿåº¦: {speed:.1f}åª/ç§’ | é¢„è®¡å‰©ä½™: {eta:.0f}ç§’", flush=True)
    
    elapsed = time.time() - start_time
    print()
    print("=" * 60)
    print(f"âœ… æ›´æ–°å®Œæˆ!")
    print(f"   è€—æ—¶: {elapsed:.1f}ç§’")
    print(f"   æ—¥Kçº¿æ–°å¢è®°å½•: {daily_total}")
    print(f"   å‘¨Kçº¿æ–°å¢è®°å½•: {weekly_total}")
    print(f"   é”™è¯¯æ•°: {errors}")
    print("=" * 60)
    print(flush=True)


if __name__ == '__main__':
    main()
