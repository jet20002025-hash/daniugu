#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä»¥90%çš„ç­¹ç é›†ä¸­åº¦ä¸ºæ ¸å¿ƒæŒ‡æ ‡ï¼Œä»¥ç­¹ç ç›ˆåˆ©95%ä»¥ä¸Šçš„ä¹°ç‚¹ä¸ºæŒ‡æ ‡ï¼Œå†æ¬¡è®­ç»ƒç³»ç»Ÿ
"""
import sys
sys.path.insert(0, '.')
from bull_stock_analyzer import BullStockAnalyzer
import json
import os
from datetime import datetime

def main():
    print("=" * 80)
    print("ğŸš€ ä»¥90%ç­¹ç é›†ä¸­åº¦ä¸ºæ ¸å¿ƒæŒ‡æ ‡ï¼Œç›ˆåˆ©ç­¹ç æ¯”ä¾‹>=95%é‡æ–°è®­ç»ƒæ¨¡å‹")
    print("=" * 80)
    
    # 1. è¯»å–å½“å‰è®­ç»ƒæ¨¡å‹ï¼Œè·å–è‚¡ç¥¨åˆ—è¡¨
    print("\nğŸ“– è¯»å–å½“å‰è®­ç»ƒæ¨¡å‹...")
    trained_model_path = 'trained_model.json'
    if not os.path.exists(trained_model_path):
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶ {trained_model_path}")
        return
    
    with open(trained_model_path, 'r', encoding='utf-8') as f:
        model_data = json.load(f)
    
    buy_features = model_data.get('buy_features', {})
    training_stocks = buy_features.get('training_stocks', [])
    
    print(f"å½“å‰è®­ç»ƒè‚¡ç¥¨æ•°: {len(training_stocks)} åª")
    
    # 2. åˆ›å»ºåˆ†æå™¨
    print("\nğŸ”§ åˆå§‹åŒ–åˆ†æå™¨...")
    analyzer = BullStockAnalyzer(auto_load_default_stocks=False, auto_analyze_and_train=False)
    
    # æ¸…ç©ºç°æœ‰æ•°æ®
    analyzer.analysis_results = {}
    analyzer.trained_features = None
    analyzer.bull_stocks = []
    
    # 3. åˆ†ææ‰€æœ‰è‚¡ç¥¨ï¼Œæ‰¾åˆ°æœ€ä½³ä¹°ç‚¹ï¼ˆç›ˆåˆ©ç­¹ç æ¯”ä¾‹>=95%ï¼‰
    print("\n" + "=" * 80)
    print("ğŸ“Š æ­¥éª¤1: åˆ†ææ‰€æœ‰å¤§ç‰›è‚¡ï¼Œç­›é€‰ç›ˆåˆ©ç­¹ç æ¯”ä¾‹>=95%çš„ä¹°ç‚¹")
    print("=" * 80)
    
    valid_stocks = []
    
    for i, stock_code in enumerate(training_stocks, 1):
        print(f"\n[{i}/{len(training_stocks)}] å¤„ç† {stock_code}...")
        
        try:
            # è·å–å‘¨Kçº¿æ•°æ®
            weekly_df = analyzer.fetcher.get_weekly_kline(stock_code, period="3y")
            
            if weekly_df is None or len(weekly_df) < 8:
                print(f"  âš ï¸ æ— æ³•è·å–è¶³å¤Ÿçš„å‘¨çº¿æ•°æ®")
                continue
            
            # æŸ¥æ‰¾æ¶¨å¹…æœ€å¤§åŒºé—´ï¼ˆ8å‘¨å†…æ¶¨å¹…è¾¾åˆ°300%ï¼‰
            valid_intervals = []
            for start_idx in range(len(weekly_df) - 8):
                for end_idx in range(start_idx + 1, min(start_idx + 9, len(weekly_df))):
                    start_price = float(weekly_df.iloc[start_idx]['æ”¶ç›˜'])
                    interval_df = weekly_df.iloc[start_idx:end_idx]
                    max_price = float(interval_df['æœ€é«˜'].max())
                    gain = (max_price - start_price) / start_price * 100
                    
                    if gain >= 300.0:
                        valid_intervals.append({
                            'èµ·ç‚¹ç´¢å¼•': start_idx,
                            'ç»ˆç‚¹ç´¢å¼•': end_idx,
                            'æ¶¨å¹…': gain,
                            'å‘¨æ•°': end_idx - start_idx
                        })
            
            if not valid_intervals:
                print(f"  âš ï¸ æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„ä¹°ç‚¹ï¼ˆ8å‘¨å†…æ¶¨å¹…>=300%ï¼‰")
                continue
            
            # æ‰¾åˆ°æ¶¨å¹…æœ€å¤§çš„åŒºé—´
            best_interval = max(valid_intervals, key=lambda x: x['æ¶¨å¹…'])
            best_start_idx = best_interval['èµ·ç‚¹ç´¢å¼•']
            
            # æå–ç‰¹å¾
            features = analyzer.extract_features_at_start_point(
                stock_code, best_start_idx, lookback_weeks=40, weekly_df=weekly_df
            )
            
            if not features:
                print(f"  âš ï¸ æ— æ³•æå–ç‰¹å¾")
                continue
            
            # æ£€æŸ¥ç›ˆåˆ©ç­¹ç æ¯”ä¾‹æ˜¯å¦>=95%
            profit_chips = features.get('ç›ˆåˆ©ç­¹ç æ¯”ä¾‹')
            chip_concentration_90 = features.get('90%æˆæœ¬é›†ä¸­åº¦')
            
            if profit_chips is not None and profit_chips >= 95.0:
                # æ·»åŠ åˆ°åˆ†æç»“æœ
                analyzer.analysis_results[stock_code] = {
                    'features': features,
                    'start_idx': best_start_idx,
                    'interval': best_interval,
                    'profit_chips': profit_chips,
                    'chip_concentration_90': chip_concentration_90
                }
                valid_stocks.append(stock_code)
                print(f"  âœ… æˆåŠŸï¼šç›ˆåˆ©ç­¹ç æ¯”ä¾‹={profit_chips:.2f}%, 90%æˆæœ¬é›†ä¸­åº¦={chip_concentration_90 if chip_concentration_90 else 'N/A'}")
            else:
                print(f"  âš ï¸ ç›ˆåˆ©ç­¹ç æ¯”ä¾‹ä¸è¶³95%ï¼ˆå½“å‰: {profit_chips if profit_chips else 'N/A'}ï¼‰")
        except Exception as e:
            print(f"  âŒ å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    print(f"\nâœ… ç­›é€‰å®Œæˆï¼šæ‰¾åˆ° {len(valid_stocks)}/{len(training_stocks)} åªç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨ï¼ˆç›ˆåˆ©ç­¹ç æ¯”ä¾‹>=95%ï¼‰")
    
    if len(valid_stocks) == 0:
        print("âŒ é”™è¯¯ï¼šæ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨ï¼ˆç›ˆåˆ©ç­¹ç æ¯”ä¾‹>=95%ï¼‰")
        print("ğŸ’¡ æç¤ºï¼šå¯ä»¥é™ä½ç›ˆåˆ©ç­¹ç æ¯”ä¾‹é˜ˆå€¼ï¼Œæˆ–è€…æ£€æŸ¥æ•°æ®")
        return
    
    # 4. è®­ç»ƒç‰¹å¾æ¨¡å‹
    print("\n" + "=" * 80)
    print("ğŸ“Š æ­¥éª¤2: è®­ç»ƒç‰¹å¾æ¨¡å‹ï¼ˆä»¥90%æˆæœ¬é›†ä¸­åº¦ä¸ºæ ¸å¿ƒæŒ‡æ ‡ï¼‰")
    print("=" * 80)
    print("ğŸ“ æ³¨æ„ï¼š90%æˆæœ¬é›†ä¸­åº¦å·²æ·»åŠ åˆ°æ ¸å¿ƒç‰¹å¾åˆ—è¡¨")
    
    train_result = analyzer.train_features()
    
    if not train_result.get('success'):
        print(f"\nâŒ è®­ç»ƒå¤±è´¥: {train_result.get('message', 'æœªçŸ¥é”™è¯¯')}")
        return
    
    print(f"\nâœ… è®­ç»ƒå®Œæˆï¼")
    print(f"è®­ç»ƒæ ·æœ¬æ•°: {train_result.get('sample_count', 0)}")
    print(f"ç‰¹å¾æ•°é‡: {len(train_result.get('common_features', {}))}")
    
    # 5. ä¿å­˜æ¨¡å‹
    print("\n" + "=" * 80)
    print("ğŸ’¾ æ­¥éª¤3: ä¿å­˜æ¨¡å‹")
    print("=" * 80)
    
    output_file = 'trained_model_chip.json'
    
    # æ„å»ºæ¨¡å‹æ•°æ®ç»“æ„ï¼ˆä¸trained_model.jsonæ ¼å¼ä¸€è‡´ï¼‰
    model_data = {
        'trained_at': datetime.now().isoformat(),
        'buy_features': analyzer.trained_features
    }
    
    # ä¿å­˜è®­ç»ƒç»“æœ
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(model_data, f, ensure_ascii=False, indent=2, default=str)
    
    print(f"âœ… æ¨¡å‹å·²ä¿å­˜åˆ°: {output_file}")
    
    # 6. æµ‹è¯•åŒ¹é…åº¦
    print("\n" + "=" * 80)
    print("ğŸ“Š æ­¥éª¤4: æµ‹è¯•è®­ç»ƒæ ·æœ¬çš„åŒ¹é…åº¦")
    print("=" * 80)
    
    common_features = analyzer.trained_features.get('common_features', {})
    match_scores = {}
    
    for stock_code in valid_stocks:
        if stock_code in analyzer.analysis_results:
            features = analyzer.analysis_results[stock_code].get('features')
            if features:
                match_score = analyzer._calculate_match_score(
                    features, common_features, tolerance=0.3, stock_code=stock_code
                )
                total_match = match_score.get('æ€»åŒ¹é…åº¦', 0)
                match_scores[stock_code] = total_match
                print(f"  {stock_code}: {total_match:.3f}")
    
    if match_scores:
        avg_score = sum(match_scores.values()) / len(match_scores)
        min_score = min(match_scores.values())
        max_score = max(match_scores.values())
        print(f"\nğŸ“Š åŒ¹é…åº¦ç»Ÿè®¡:")
        print(f"   å¹³å‡åŒ¹é…åº¦: {avg_score:.3f}")
        print(f"   æœ€ä½åŒ¹é…åº¦: {min_score:.3f}")
        print(f"   æœ€é«˜åŒ¹é…åº¦: {max_score:.3f}")
    
    print("\n" + "=" * 80)
    print("âœ… è®­ç»ƒå®Œæˆï¼")
    print("=" * 80)
    print(f"\nğŸ“‹ æ€»ç»“:")
    print(f"   - è®­ç»ƒè‚¡ç¥¨æ•°: {len(valid_stocks)} åªï¼ˆç›ˆåˆ©ç­¹ç æ¯”ä¾‹>=95%ï¼‰")
    print(f"   - æ ¸å¿ƒç‰¹å¾: å·²æ·»åŠ '90%æˆæœ¬é›†ä¸­åº¦'")
    print(f"   - æ¨¡å‹æ–‡ä»¶: {output_file}")

if __name__ == '__main__':
    main()
