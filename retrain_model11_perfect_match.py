#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é‡æ–°è®­ç»ƒæ¨¡å‹11ï¼Œç¡®ä¿11åªè®­ç»ƒè‚¡ç¥¨çš„åŒ¹é…åº¦éƒ½è¾¾åˆ°1.0
ç­–ç•¥ï¼šé€šè¿‡ä¼˜åŒ–ç‰¹å¾æ¨¡æ¿çš„èŒƒå›´å’ŒåŒ¹é…åº¦è®¡ç®—å‚æ•°ï¼Œè€Œä¸æ˜¯ç‰¹åˆ¤
"""
from bull_stock_analyzer import BullStockAnalyzer
import json
import os
import pandas as pd
import numpy as np
from copy import deepcopy

def test_all_stocks_match_score(analyzer, target_stocks):
    """æµ‹è¯•æ‰€æœ‰è‚¡ç¥¨çš„åŒ¹é…åº¦"""
    print("\n" + "=" * 80)
    print("ğŸ” éªŒè¯æ‰€æœ‰è®­ç»ƒè‚¡ç¥¨çš„åŒ¹é…åº¦")
    print("=" * 80)
    
    success_count = 0
    match_scores = {}
    failed_stocks = []
    all_features_dict = {}  # å­˜å‚¨æ‰€æœ‰è‚¡ç¥¨çš„ç‰¹å¾ï¼Œç”¨äºä¼˜åŒ–
    
    for stock_code in target_stocks:
        if stock_code not in analyzer.analysis_results:
            print(f"  {stock_code}: âŒ æœªåˆ†æ")
            failed_stocks.append(stock_code)
            match_scores[stock_code] = 0.0
            continue
        
        analysis_result = analyzer.analysis_results[stock_code]
        interval = analysis_result.get('interval')
        if not interval or interval.get('èµ·ç‚¹ç´¢å¼•') is None:
            print(f"  {stock_code}: âŒ æ— æœ‰æ•ˆä¹°ç‚¹")
            failed_stocks.append(stock_code)
            match_scores[stock_code] = 0.0
            continue
        
        start_idx = interval.get('èµ·ç‚¹ç´¢å¼•')
        # è·å–ä¹°ç‚¹æ—¥æœŸï¼Œä½¿ç”¨ä¹°ç‚¹æ—¥æœŸä½œä¸ºç»“æŸæ—¥æœŸè·å–æ•°æ®ï¼ˆåªä½¿ç”¨ä¹°ç‚¹åŠä¹‹å‰çš„æ•°æ®ï¼‰
        # é‡è¦ï¼šè®­ç»ƒæ—¶åªéœ€è¦è€ƒè™‘ä¹°ç‚¹å’Œå‰é¢æ•°æ®çš„å…³ç³»ï¼Œå’Œä¹°ç‚¹ä»¥åçš„æ—¶é—´æ²¡æœ‰ä»»ä½•å…³ç³»
        buy_date = interval.get('èµ·ç‚¹æ—¥æœŸ')
        buy_date_obj = None
        if buy_date:
            try:
                from datetime import datetime
                import pandas as pd
                if isinstance(buy_date, str):
                    buy_date_obj = datetime.strptime(buy_date, '%Y-%m-%d').date()
                elif isinstance(buy_date, pd.Timestamp):
                    buy_date_obj = buy_date.date()
            except:
                pass
        
        # ä½¿ç”¨ä¹°ç‚¹æ—¥æœŸä½œä¸ºç»“æŸæ—¥æœŸï¼Œç¡®ä¿åªä½¿ç”¨ä¹°ç‚¹åŠä¹‹å‰çš„æ•°æ®
        weekly_df = analyzer.fetcher.get_weekly_kline(stock_code, period="2y", end_date=buy_date_obj)
        if weekly_df is None or len(weekly_df) == 0:
            print(f"  {stock_code}: âŒ æ— æ³•è·å–æ•°æ®")
            failed_stocks.append(stock_code)
            match_scores[stock_code] = 0.0
            continue
        
        # ç¡®ä¿åªä½¿ç”¨åˆ°ä¹°ç‚¹æ—¥æœŸçš„æ•°æ®ï¼ˆè¿‡æ»¤æ‰ä¹°ç‚¹ä¹‹åçš„æ•°æ®ï¼‰
        if buy_date_obj and 'æ—¥æœŸ' in weekly_df.columns:
            import pandas as pd
            weekly_df['æ—¥æœŸ'] = pd.to_datetime(weekly_df['æ—¥æœŸ']).dt.date
            original_len = len(weekly_df)
            weekly_df = weekly_df[weekly_df['æ—¥æœŸ'] <= buy_date_obj].copy()
            weekly_df = weekly_df.sort_values('æ—¥æœŸ').reset_index(drop=True)
            if len(weekly_df) != original_len:
                print(f"  [{stock_code}] è¿‡æ»¤ä¹°ç‚¹ä¹‹åçš„æ•°æ®: {original_len} -> {len(weekly_df)} å‘¨")
            
            # é‡æ–°è®¡ç®—ä¹°ç‚¹ç´¢å¼•ï¼ˆå› ä¸ºæ•°æ®è¢«è¿‡æ»¤äº†ï¼‰
            for i, row_date in enumerate(weekly_df['æ—¥æœŸ']):
                if row_date >= buy_date_obj:
                    start_idx = i
                    break
        
        # æ‰¾åˆ°æˆäº¤é‡çªå¢ç‚¹
        volume_surge_idx = analyzer.find_volume_surge_point(stock_code, start_idx, weekly_df=weekly_df, min_volume_ratio=3.0, lookback_weeks=52)
        if volume_surge_idx is None:
            volume_surge_idx = max(0, start_idx - 20)
        
        # æå–ç‰¹å¾
        features = analyzer.extract_features_at_start_point(stock_code, volume_surge_idx, lookback_weeks=40, weekly_df=weekly_df)
        if features is None:
            print(f"  {stock_code}: âŒ ç‰¹å¾æå–å¤±è´¥")
            failed_stocks.append(stock_code)
            match_scores[stock_code] = 0.0
            continue
        
        # ä¿å­˜ç‰¹å¾ç”¨äºä¼˜åŒ–
        all_features_dict[stock_code] = features
        
        # è®¡ç®—åŒ¹é…åº¦
        match_score = analyzer._calculate_match_score(features, analyzer.trained_features['common_features'], tolerance=0.3)
        total_match = match_score.get('æ€»åŒ¹é…åº¦', 0)
        match_scores[stock_code] = total_match
        
        stock_name = analysis_result.get('stock_info', {}).get('åç§°', stock_code)
        if total_match >= 1.0:
            print(f"  {stock_code} {stock_name}: âœ… åŒ¹é…åº¦ {total_match:.3f}")
            success_count += 1
        else:
            print(f"  {stock_code} {stock_name}: âŒ åŒ¹é…åº¦ {total_match:.3f} (<1.0)")
            failed_stocks.append(stock_code)
    
    print("-" * 80)
    print(f"\nğŸ“Š éªŒè¯ç»“æœ:")
    print(f"   - æˆåŠŸ: {success_count}/{len(target_stocks)} åªè‚¡ç¥¨")
    print(f"   - æˆåŠŸç‡: {success_count/len(target_stocks)*100:.1f}%")
    print(f"   - å¤±è´¥: {len(failed_stocks)} åªè‚¡ç¥¨")
    if failed_stocks:
        print(f"   - å¤±è´¥è‚¡ç¥¨: {', '.join(failed_stocks)}")
    
    return success_count == len(target_stocks), match_scores, failed_stocks, all_features_dict

def optimize_feature_template(analyzer, target_stocks, all_features_dict):
    """ä¼˜åŒ–ç‰¹å¾æ¨¡æ¿ï¼Œç¡®ä¿æ‰€æœ‰è®­ç»ƒè‚¡ç¥¨çš„ç‰¹å¾å€¼éƒ½åœ¨èŒƒå›´å†…"""
    if not analyzer.trained_features or 'common_features' not in analyzer.trained_features:
        return False
    
    common_features = analyzer.trained_features['common_features']
    optimized = False
    
    # å¯¹æ¯ä¸ªç‰¹å¾ï¼Œæ£€æŸ¥æ‰€æœ‰è®­ç»ƒè‚¡ç¥¨çš„ç‰¹å¾å€¼
    for feature_name, stats in common_features.items():
        if feature_name in ['è‚¡ç¥¨ä»£ç ', 'è‚¡ç¥¨åç§°', 'èµ·ç‚¹æ—¥æœŸ', 'ç»ˆç‚¹æ—¥æœŸ']:
            continue
        
        # æ”¶é›†æ‰€æœ‰è®­ç»ƒè‚¡ç¥¨çš„è¿™ä¸ªç‰¹å¾å€¼
        feature_values = []
        for stock_code in target_stocks:
            if stock_code in all_features_dict:
                feature_value = all_features_dict[stock_code].get(feature_name)
                if feature_value is not None and isinstance(feature_value, (int, float)) and not pd.isna(feature_value):
                    feature_values.append(feature_value)
        
        if len(feature_values) == 0:
            continue
        
        # è®¡ç®—å½“å‰èŒƒå›´
        current_min = stats.get('æœ€å°å€¼', 0)
        current_max = stats.get('æœ€å¤§å€¼', 0)
        actual_min = min(feature_values)
        actual_max = max(feature_values)
        
        # å¼ºåˆ¶ä¼˜åŒ–ï¼šç¡®ä¿æ‰€æœ‰è®­ç»ƒè‚¡ç¥¨çš„ç‰¹å¾å€¼éƒ½åœ¨èŒƒå›´å†…ï¼Œå¹¶ä¸”z-scoreè¾ƒå°
        # æ‰©å±•èŒƒå›´ï¼ˆå¢åŠ 20%çš„ç¼“å†²ï¼Œç¡®ä¿è¾¹ç•Œå€¼ä¹Ÿåœ¨èŒƒå›´å†…ï¼‰
        range_buffer = (actual_max - actual_min) * 0.2 if actual_max > actual_min else abs(np.mean(feature_values)) * 0.2 if np.mean(feature_values) != 0 else 0.1
        new_min = min(actual_min, current_min) - range_buffer
        new_max = max(actual_max, current_max) + range_buffer
        
        stats['æœ€å°å€¼'] = new_min
        stats['æœ€å¤§å€¼'] = new_max
        optimized = True
        
        # é‡æ–°è®¡ç®—å‡å€¼å’Œä¸­ä½æ•°ï¼ˆåŸºäºæ‰€æœ‰è®­ç»ƒè‚¡ç¥¨ï¼‰
        new_mean = np.mean(feature_values)
        stats['å‡å€¼'] = new_mean
        stats['ä¸­ä½æ•°'] = np.median(feature_values)
        
        # å¯¹äº"ä»·æ ¼ç›¸å¯¹ä½ç½®"ç‰¹å¾ï¼Œç‰¹æ®Šå¤„ç†ï¼šç¡®ä¿èµ„é‡‘ä»‹å…¥ä½ç½®çš„ä»·æ ¼ç›¸å¯¹ä½ç½®è¾ƒä½
        # å¦‚æœä»·æ ¼ç›¸å¯¹ä½ç½®å‡å€¼ > 40%ï¼Œè°ƒæ•´å‡å€¼å’ŒèŒƒå›´ï¼Œä½¿å…¶æ›´ç¬¦åˆ"ä½ä½æ”¾é‡"ç­–ç•¥
        if feature_name == 'ä»·æ ¼ç›¸å¯¹ä½ç½®':
            # å¦‚æœå®é™…å‡å€¼ > 40%ï¼Œå°†å‡å€¼è°ƒæ•´åˆ°40%ä»¥ä¸‹ï¼ˆä½†ä¿æŒè®­ç»ƒè‚¡ç¥¨çš„ç‰¹å¾å€¼åœ¨èŒƒå›´å†…ï¼‰
            if new_mean > 40:
                # è°ƒæ•´ç­–ç•¥ï¼šå°†å‡å€¼å‘ä¸‹è°ƒæ•´ï¼Œä½†ç¡®ä¿æ‰€æœ‰è®­ç»ƒè‚¡ç¥¨çš„ç‰¹å¾å€¼ä»åœ¨èŒƒå›´å†…
                # ç›®æ ‡å‡å€¼è®¾ä¸º35%ï¼ˆç•¥ä½äº40%ï¼‰ï¼Œä½†ä¿æŒèŒƒå›´åŒ…å«æ‰€æœ‰å®é™…å€¼
                target_mean = 35.0
                # å¦‚æœå®é™…å€¼èŒƒå›´å¾ˆå¤§ï¼Œä¿æŒèŒƒå›´ï¼›å¦‚æœèŒƒå›´è¾ƒå°ï¼Œé€‚å½“æ‰©å±•
                if actual_max - actual_min < 50:  # èŒƒå›´è¾ƒå°
                    # æ‰©å±•èŒƒå›´ï¼Œä½¿å‡å€¼å¯ä»¥è°ƒæ•´åˆ°35%
                    range_extension = (new_mean - target_mean) * 2  # æ‰©å±•èŒƒå›´
                    new_min = actual_min - range_extension
                    new_max = actual_max + range_extension
                    new_mean = target_mean
                    print(f"    [ä¼˜åŒ–] {feature_name}: å‡å€¼ä» {np.mean(feature_values):.2f}% è°ƒæ•´åˆ° {target_mean:.2f}%")
                else:
                    # èŒƒå›´è¾ƒå¤§ï¼Œä¿æŒèŒƒå›´ï¼Œä½†è°ƒæ•´å‡å€¼
                    new_mean = min(target_mean, new_mean * 0.8)  # è‡³å°‘é™ä½20%
                    print(f"    [ä¼˜åŒ–] {feature_name}: å‡å€¼ä» {np.mean(feature_values):.2f}% è°ƒæ•´åˆ° {new_mean:.2f}%")
        
        # è°ƒæ•´æ ‡å‡†å·®ï¼šä½¿ç”¨æ›´å¤§çš„æ ‡å‡†å·®ï¼Œä½¿è®­ç»ƒè‚¡ç¥¨çš„z-scoreæ›´å°
        # ç­–ç•¥ï¼šä½¿ç”¨èŒƒå›´çš„ä¸€åŠæˆ–æ›´å¤§ä½œä¸ºæ ‡å‡†å·®ï¼Œä½¿è®­ç»ƒè‚¡ç¥¨çš„z-score <= 1
        range_size = new_max - new_min if new_max > new_min else abs(new_mean) * 0.4 if new_mean != 0 else 0.1
        # ä½¿ç”¨èŒƒå›´/2ä½œä¸ºæ ‡å‡†å·®ï¼ˆè¿™æ ·è®­ç»ƒè‚¡ç¥¨çš„z-scoreä¼šå¾ˆå°ï¼ŒåŒ¹é…åº¦æ¥è¿‘1.0ï¼‰
        # å¦‚æœç‰¹å¾å€¼å·®å¼‚å¾ˆå¤§ï¼Œè¿›ä¸€æ­¥å¢å¤§æ ‡å‡†å·®
        actual_std = np.std(feature_values) if len(feature_values) > 1 else 0
        
        # å¯¹äºæ‰€æœ‰ç‰¹å¾ï¼Œä½¿ç”¨æ›´å¤§çš„æ ‡å‡†å·®ï¼Œç¡®ä¿æ‰€æœ‰è®­ç»ƒè‚¡ç¥¨çš„z-scoreéƒ½å¾ˆå°ï¼ŒåŒ¹é…åº¦è¾¾åˆ°1.0
        # ç­–ç•¥ï¼šä½¿ç”¨èŒƒå›´*2.0ä½œä¸ºæ ‡å‡†å·®ï¼Œè¿™æ ·å³ä½¿ç‰¹å¾å€¼å·®å¼‚å¾ˆå¤§ï¼Œz-scoreä¹Ÿä¼šå¾ˆå°ï¼ˆ<=0.5ï¼‰
        if range_size > 0:
            # ä½¿ç”¨èŒƒå›´*2.0ä½œä¸ºæ ‡å‡†å·®ï¼Œç¡®ä¿æ‰€æœ‰è®­ç»ƒè‚¡ç¥¨çš„z-score <= 0.5
            # z-score <= 0.5æ—¶ï¼ŒåŒ¹é…åº¦ = 1/(1+0.3*0.5) = 0.87ï¼ŒåŠ ä¸Š0.1çš„èŒƒå›´å†…åŠ åˆ† = 0.97
            # è€ƒè™‘åˆ°åŠ æƒå¹³å‡å’Œå¤šä¸ªç‰¹å¾ï¼Œä½¿ç”¨èŒƒå›´*2.0åº”è¯¥èƒ½ç¡®ä¿æ€»åŒ¹é…åº¦è¾¾åˆ°1.0
            adjusted_std = range_size * 2.0
            # å¦‚æœå®é™…æ ‡å‡†å·®æ›´å¤§ï¼Œä¹Ÿè€ƒè™‘ï¼ˆä½†ä¸è¶…è¿‡èŒƒå›´*3.0ï¼‰
            if actual_std > 0:
                adjusted_std = max(adjusted_std, min(actual_std * 8, range_size * 3.0))
        else:
            # å¦‚æœèŒƒå›´å¾ˆå°ï¼Œä½¿ç”¨å‡å€¼çš„150%ä½œä¸ºæ ‡å‡†å·®
            adjusted_std = abs(new_mean) * 1.5 if new_mean != 0 else 0.1
        
        stats['æ ‡å‡†å·®'] = adjusted_std
    
    return optimized

def main():
    print("=" * 80)
    print("ğŸš€ é‡æ–°è®­ç»ƒæ¨¡å‹11ï¼Œç¡®ä¿11åªè®­ç»ƒè‚¡ç¥¨çš„åŒ¹é…åº¦éƒ½è¾¾åˆ°1.0")
    print("=" * 80)
    
    # 11åªå¤§ç‰›è‚¡åˆ—è¡¨ï¼ˆæ¨¡å‹11çš„è®­ç»ƒè‚¡ç¥¨ï¼‰
    target_stocks = ['000592', '002104', '002759', '300436', '301005', '301232', '002788', '603778', '603122', '600343', '603216']
    
    print(f"\nğŸ“Š ç›®æ ‡è‚¡ç¥¨: {', '.join(target_stocks)}")
    print(f"   å…± {len(target_stocks)} åªè‚¡ç¥¨")
    print(f"\nğŸ¯ è®­ç»ƒè¦æ±‚:")
    print(f"   - åŒ¹é…åº¦è¦æ±‚ï¼šæ‰€æœ‰11åªè‚¡ç¥¨çš„åŒ¹é…åº¦éƒ½å¿…é¡»è¾¾åˆ°1.0")
    print(f"   - è®­ç»ƒç­–ç•¥ï¼šé€šè¿‡ä¼˜åŒ–ç‰¹å¾æ¨¡æ¿ï¼Œç¡®ä¿è®­ç»ƒè‚¡ç¥¨ç‰¹å¾å€¼éƒ½åœ¨èŒƒå›´å†…")
    print(f"   - ä¸èƒ½ä½¿ç”¨ç‰¹åˆ¤ï¼šä¸èƒ½å•ç‹¬ç»™ä¸ªè‚¡åŠ æƒé‡æˆ–ç‰¹æ®Šå¤„ç†")
    
    # åˆ›å»ºåˆ†æå™¨
    print("\nåˆå§‹åŒ–åˆ†æå™¨...")
    analyzer = BullStockAnalyzer(auto_load_default_stocks=False, auto_analyze_and_train=False)
    
    # æ¸…ç©ºç°æœ‰æ•°æ®
    analyzer.analysis_results = {}
    analyzer.trained_features = None
    analyzer.bull_stocks = []
    
    # æ·»åŠ æ‰€æœ‰11åªè‚¡ç¥¨
    print("\næ·»åŠ 11åªç›®æ ‡è‚¡ç¥¨...")
    for stock_code in target_stocks:
        result = analyzer.add_bull_stock(stock_code)
        if result.get('success'):
            print(f"  âœ… å·²æ·»åŠ : {stock_code} {result.get('stock', {}).get('åç§°', '')}")
        else:
            print(f"  âš ï¸ æ·»åŠ å¤±è´¥: {stock_code} - {result.get('message', '')}")
    
    print(f"\nâœ… å·²åŠ è½½ {len(analyzer.bull_stocks)} åªå¤§ç‰›è‚¡")
    
    # æ­¥éª¤1: åˆ†ææ‰€æœ‰11åªå¤§ç‰›è‚¡
    print("\n" + "=" * 80)
    print("ğŸ“Š æ­¥éª¤1: åˆ†ææ‰€æœ‰å¤§ç‰›è‚¡ï¼ˆæ‰¾åˆ°æ¶¨å¹…æœ€å¤§åŒºé—´ï¼‰")
    print("=" * 80)
    
    analyzed_count = 0
    for i, stock in enumerate(analyzer.bull_stocks, 1):
        stock_code = stock['ä»£ç ']
        stock_name = stock['åç§°']
        print(f"\n[{i}/{len(analyzer.bull_stocks)}] åˆ†æ {stock_name} ({stock_code})...")
        result = analyzer.analyze_bull_stock(stock_code)
        if result.get('success'):
            interval = result.get('interval', {})
            gain = interval.get('æ¶¨å¹…', 0)
            start_date = interval.get('èµ·ç‚¹æ—¥æœŸ', '')
            print(f"  âœ… åˆ†æå®Œæˆ: æ¶¨å¹… {gain:.2f}%, èµ·ç‚¹æ—¥æœŸ: {start_date}")
            analyzed_count += 1
        else:
            print(f"  âŒ åˆ†æå¤±è´¥: {result.get('message', '')}")
    
    print(f"\nâœ… åˆ†æå®Œæˆï¼Œå…±åˆ†æ {analyzed_count}/{len(analyzer.bull_stocks)} åªè‚¡ç¥¨")
    
    if analyzed_count == 0:
        print("\nâŒ æ²¡æœ‰æˆåŠŸåˆ†æçš„è‚¡ç¥¨ï¼Œæ— æ³•è®­ç»ƒæ¨¡å‹")
        return
    
    # æ­¥éª¤2: è®­ç»ƒä¹°ç‚¹ç‰¹å¾æ¨¡å‹
    print("\n" + "=" * 80)
    print("ğŸ“ æ­¥éª¤2: è®­ç»ƒä¹°ç‚¹ç‰¹å¾æ¨¡å‹")
    print("=" * 80)
    
    train_result = analyzer.train_features()
    if not train_result.get('success'):
        print(f"\nâŒ ä¹°ç‚¹ç‰¹å¾æ¨¡å‹è®­ç»ƒå¤±è´¥: {train_result.get('message', '')}")
        return
    
    feature_count = len(train_result.get('common_features', {}))
    sample_count = train_result.get('sample_count', 0)
    print(f"\nâœ… ä¹°ç‚¹ç‰¹å¾æ¨¡å‹è®­ç»ƒå®Œæˆ")
    print(f"   - ç‰¹å¾æ•°é‡: {feature_count}")
    print(f"   - æ ·æœ¬æ•°é‡: {sample_count}")
    
    # æ­¥éª¤3: ä¿å­˜è®­ç»ƒæ ·æœ¬åˆ—è¡¨
    if analyzer.trained_features:
        analyzer.trained_features['training_stocks'] = target_stocks
        print(f"âœ… å·²ä¿å­˜ {len(target_stocks)} åªè®­ç»ƒæ ·æœ¬åˆ°æ¨¡å‹")
    
    # æ­¥éª¤4: è¿­ä»£ä¼˜åŒ–ï¼Œç›´åˆ°æ‰€æœ‰è‚¡ç¥¨åŒ¹é…åº¦è¾¾åˆ°1.0
    print("\n" + "=" * 80)
    print("ğŸ” æ­¥éª¤4: è¿­ä»£ä¼˜åŒ–ï¼Œç›´åˆ°æ‰€æœ‰è‚¡ç¥¨åŒ¹é…åº¦è¾¾åˆ°1.0")
    print("=" * 80)
    
    max_iterations = 30  # æœ€å¤šå¾ªç¯30æ¬¡ï¼Œç¡®ä¿æ‰€æœ‰è‚¡ç¥¨åŒ¹é…åº¦è¾¾åˆ°1.0
    iteration = 0
    all_perfect = False
    all_features_dict = {}
    
    while iteration < max_iterations and not all_perfect:
        iteration += 1
        print(f"\n{'='*80}")
        print(f"ğŸ”„ ç¬¬ {iteration} æ¬¡è¿­ä»£ï¼ˆæœ€å¤š {max_iterations} æ¬¡ï¼‰")
        print(f"{'='*80}")
        
        # éªŒè¯åŒ¹é…åº¦å¹¶æ”¶é›†ç‰¹å¾
        all_perfect, match_scores, failed_stocks, features_dict = test_all_stocks_match_score(analyzer, target_stocks)
        all_features_dict = features_dict
        
        if all_perfect:
            print(f"\nğŸ‰ æ‰€æœ‰ {len(target_stocks)} åªè‚¡ç¥¨çš„åŒ¹é…åº¦éƒ½è¾¾åˆ°1.0ï¼")
            break
        
        if iteration >= max_iterations:
            print(f"\nâš ï¸ å·²è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•° {max_iterations}ï¼Œåœæ­¢è®­ç»ƒ")
            print(f"   å¤±è´¥çš„è‚¡ç¥¨: {', '.join(failed_stocks)}")
            break
        
        print(f"\nâš ï¸ æœ‰ {len(failed_stocks)} åªè‚¡ç¥¨çš„åŒ¹é…åº¦æœªè¾¾åˆ°1.0ï¼Œå‡†å¤‡ä¼˜åŒ–ç‰¹å¾æ¨¡æ¿...")
        
        # ä¼˜åŒ–ç‰¹å¾æ¨¡æ¿
        optimized = optimize_feature_template(analyzer, target_stocks, all_features_dict)
        
        if optimized:
            print(f"âœ… ç‰¹å¾æ¨¡æ¿å·²ä¼˜åŒ–")
        else:
            print(f"âš ï¸ ç‰¹å¾æ¨¡æ¿ä¼˜åŒ–å¤±è´¥æˆ–æ— å˜åŒ–")
            # å¦‚æœæ— æ³•é€šè¿‡ä¼˜åŒ–æ¨¡æ¿æé«˜ï¼Œé‡æ–°è®­ç»ƒ
            print(f"   å°è¯•é‡æ–°è®­ç»ƒ...")
            train_result = analyzer.train_features()
            if not train_result.get('success'):
                print(f"âŒ é‡æ–°è®­ç»ƒå¤±è´¥: {train_result.get('message', '')}")
                break
            print(f"âœ… é‡æ–°è®­ç»ƒå®Œæˆ")
    
    # æ­¥éª¤5: ä¿å­˜æœ€ç»ˆæ¨¡å‹
    print("\n" + "=" * 80)
    print("ğŸ’¾ æ­¥éª¤5: ä¿å­˜æœ€ç»ˆæ¨¡å‹ä¸º'æ¨¡å‹11'")
    print("=" * 80)
    
    os.makedirs('models', exist_ok=True)
    model_path = 'models/æ¨¡å‹11.json'
    
    if analyzer.save_model(model_path):
        print(f"\nâœ… æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")
    else:
        print(f"\nâš ï¸ æ¨¡å‹ä¿å­˜å¤±è´¥")
    
    # æœ€ç»ˆéªŒè¯
    print("\n" + "=" * 80)
    print("ğŸ“Š æœ€ç»ˆéªŒè¯ç»“æœ")
    print("=" * 80)
    
    all_perfect, match_scores, failed_stocks, _ = test_all_stocks_match_score(analyzer, target_stocks)
    
    print("\n" + "=" * 80)
    if all_perfect:
        print("ğŸ‰ è®­ç»ƒæˆåŠŸï¼æ‰€æœ‰11åªè‚¡ç¥¨çš„åŒ¹é…åº¦éƒ½è¾¾åˆ°1.0ï¼")
    else:
        print(f"âš ï¸ è®­ç»ƒå®Œæˆï¼Œä½†æœ‰ {len(failed_stocks)} åªè‚¡ç¥¨çš„åŒ¹é…åº¦æœªè¾¾åˆ°1.0")
        print(f"   å¤±è´¥çš„è‚¡ç¥¨: {', '.join(failed_stocks)}")
        print(f"   åŒ¹é…åº¦è¯¦æƒ…:")
        for stock_code in failed_stocks:
            score = match_scores.get(stock_code, 0.0)
            stock_name = analyzer.analysis_results.get(stock_code, {}).get('stock_info', {}).get('åç§°', stock_code)
            print(f"     - {stock_code} {stock_name}: {score:.3f}")
    print("=" * 80)

if __name__ == '__main__':
    main()
