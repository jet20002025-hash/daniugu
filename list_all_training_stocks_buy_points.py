#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åˆ—å‡ºæ‰€æœ‰22åªè®­ç»ƒè‚¡ç¥¨çš„æœ€ä½³ä¹°ç‚¹å’ŒåŒ¹é…åº¦
"""
import sys
sys.path.insert(0, '.')
from bull_stock_analyzer import BullStockAnalyzer
import json
import os
from datetime import datetime
import pandas as pd

def main():
    print("=" * 80)
    print("ğŸ“Š åˆ—å‡ºæ‰€æœ‰22åªè®­ç»ƒè‚¡ç¥¨çš„æœ€ä½³ä¹°ç‚¹å’ŒåŒ¹é…åº¦")
    print("=" * 80)
    
    # åˆå§‹åŒ–åˆ†æå™¨
    analyzer = BullStockAnalyzer(auto_load_default_stocks=False, auto_analyze_and_train=False)
    
    # åŠ è½½è®­ç»ƒæ¨¡å‹
    model_file = 'trained_model.json'
    if not os.path.exists(model_file):
        print(f"âŒ æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {model_file}")
        return
    
    with open(model_file, 'r', encoding='utf-8') as f:
        model_data = json.load(f)
    
    buy_features = model_data.get('buy_features', {})
    training_stocks = buy_features.get('training_stocks', [])
    common_features = buy_features.get('common_features', {})
    
    print(f"\nğŸ“‹ æ¨¡å‹ä¿¡æ¯:")
    print(f"   - è®­ç»ƒè‚¡ç¥¨æ•°: {len(training_stocks)} åª")
    print(f"   - ç‰¹å¾æ•°é‡: {len(common_features)} ä¸ª")
    
    # åŠ è½½æ¨¡å‹åˆ°åˆ†æå™¨
    analyzer.trained_features = buy_features
    
    print(f"\nğŸ“Š è®¡ç®— {len(training_stocks)} åªè®­ç»ƒè‚¡ç¥¨çš„æœ€ä½³ä¹°ç‚¹å’ŒåŒ¹é…åº¦...")
    print("=" * 80)
    
    results = []
    
    for i, stock_code in enumerate(training_stocks, 1):
        try:
            print(f"[{i}/{len(training_stocks)}] {stock_code}...", end=' ', flush=True)
            
            # è·å–è‚¡ç¥¨åç§°ï¼ˆä»è‚¡ç¥¨åˆ—è¡¨æˆ–ä½¿ç”¨ä»£ç ï¼‰
            stock_name = stock_code  # é»˜è®¤ä½¿ç”¨ä»£ç 
            try:
                all_stocks = analyzer.fetcher.get_all_stocks()
                for stock in all_stocks:
                    if stock.get('code') == stock_code or stock.get('è‚¡ç¥¨ä»£ç ') == stock_code:
                        stock_name = stock.get('name', stock.get('è‚¡ç¥¨åç§°', stock_code))
                        break
            except:
                pass
            
            # è·å–å‘¨çº¿æ•°æ®
            weekly_df = analyzer.fetcher.get_weekly_kline(stock_code, period="3y")
            if weekly_df is None or len(weekly_df) < 8:
                print("âš ï¸ æ•°æ®ä¸è¶³")
                continue
            
            # è¿‡æ»¤æœªæ¥æ—¥æœŸ
            today = datetime.now().date()
            if 'æ—¥æœŸ' in weekly_df.columns:
                weekly_df['æ—¥æœŸ'] = pd.to_datetime(weekly_df['æ—¥æœŸ'])
                weekly_df = weekly_df[weekly_df['æ—¥æœŸ'].dt.date <= today].copy()
                weekly_df = weekly_df.sort_values('æ—¥æœŸ').reset_index(drop=True)
            
            if len(weekly_df) < 8:
                print("âš ï¸ æ•°æ®ä¸è¶³")
                continue
            
            # æŸ¥æ‰¾æœ€ä½³ä¹°ç‚¹ï¼ˆ8å‘¨å†…æ¶¨å¹…è¾¾åˆ°300%ï¼‰
            valid_intervals = []
            for start_idx in range(len(weekly_df) - 8):
                for end_idx in range(start_idx + 1, min(start_idx + 9, len(weekly_df))):
                    start_price = float(weekly_df.iloc[start_idx]['æ”¶ç›˜'])
                    interval_df = weekly_df.iloc[start_idx:end_idx]
                    max_price = float(interval_df['æœ€é«˜'].max())
                    gain = (max_price - start_price) / start_price * 100
                    
                    if gain >= 300.0:
                        start_date = weekly_df.iloc[start_idx]['æ—¥æœŸ']
                        if isinstance(start_date, pd.Timestamp):
                            start_date_str = start_date.strftime('%Y-%m-%d')
                        else:
                            start_date_str = str(start_date)
                        
                        valid_intervals.append({
                            'èµ·ç‚¹ç´¢å¼•': start_idx,
                            'ç»ˆç‚¹ç´¢å¼•': end_idx,
                            'æ¶¨å¹…': gain,
                            'å‘¨æ•°': end_idx - start_idx,
                            'ä¹°ç‚¹æ—¥æœŸ': start_date_str,
                            'ä¹°ç‚¹ä»·æ ¼': start_price
                        })
            
            if not valid_intervals:
                print("âš ï¸ æœªæ‰¾åˆ°ä¹°ç‚¹")
                continue
            
            # æ‰¾åˆ°æ¶¨å¹…æœ€å¤§çš„åŒºé—´ï¼ˆæœ€ä½³ä¹°ç‚¹ï¼‰
            best_interval = max(valid_intervals, key=lambda x: x['æ¶¨å¹…'])
            best_start_idx = best_interval['èµ·ç‚¹ç´¢å¼•']
            
            # ä½¿ç”¨æˆäº¤é‡çªå¢ç‚¹ä½œä¸ºç‰¹å¾æå–èµ·ç‚¹ï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
            volume_surge_idx = analyzer.find_volume_surge_point(
                weekly_df, best_start_idx, min_volume_ratio=2.0, lookback_weeks=40
            )
            if volume_surge_idx is None:
                volume_surge_idx = max(0, best_start_idx - 20)
            
            # æå–ç‰¹å¾
            features = analyzer.extract_features_at_start_point(
                stock_code, volume_surge_idx, lookback_weeks=40, weekly_df=weekly_df
            )
            
            if not features:
                print("âš ï¸ æ— æ³•æå–ç‰¹å¾")
                continue
            
            # è®¡ç®—åŒ¹é…åº¦
            match_score = analyzer._calculate_match_score(
                features, common_features, tolerance=0.3, stock_code=stock_code
            )
            
            total_match = match_score.get('æ€»åŒ¹é…åº¦', 0)
            core_match = match_score.get('æ ¸å¿ƒç‰¹å¾åŒ¹é…åº¦', 0)
            profit_chips = features.get('ç›ˆåˆ©ç­¹ç æ¯”ä¾‹', None)
            chip_concentration_90 = features.get('90%æˆæœ¬é›†ä¸­åº¦', None)
            
            results.append({
                'è‚¡ç¥¨ä»£ç ': stock_code,
                'è‚¡ç¥¨åç§°': stock_name,
                'æœ€ä½³ä¹°ç‚¹æ—¥æœŸ': best_interval['ä¹°ç‚¹æ—¥æœŸ'],
                'æœ€ä½³ä¹°ç‚¹ä»·æ ¼': round(best_interval['ä¹°ç‚¹ä»·æ ¼'], 2),
                'æ¶¨å¹…': round(best_interval['æ¶¨å¹…'], 2),
                'å‘¨æ•°': best_interval['å‘¨æ•°'],
                'åŒ¹é…åº¦': round(total_match, 3),
                'æ ¸å¿ƒç‰¹å¾åŒ¹é…åº¦': round(core_match, 3),
                'ç›ˆåˆ©ç­¹ç æ¯”ä¾‹': round(profit_chips, 2) if profit_chips is not None else None,
                '90%æˆæœ¬é›†ä¸­åº¦': round(chip_concentration_90, 2) if chip_concentration_90 is not None else None
            })
            
            status = "âœ…" if total_match >= 0.95 else "âš ï¸"
            print(f"{status} {total_match:.3f} ({best_interval['ä¹°ç‚¹æ—¥æœŸ']})")
            
        except Exception as e:
            print(f"âŒ å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    print("\n" + "=" * 80)
    print("ğŸ“Š æ‰€æœ‰è®­ç»ƒè‚¡ç¥¨çš„æœ€ä½³ä¹°ç‚¹å’ŒåŒ¹é…åº¦")
    print("=" * 80)
    
    if results:
        # æŒ‰åŒ¹é…åº¦æ’åº
        results.sort(key=lambda x: x['åŒ¹é…åº¦'], reverse=True)
        
        print(f"\n{'æ’å':<6} {'è‚¡ç¥¨ä»£ç ':<10} {'è‚¡ç¥¨åç§°':<20} {'æœ€ä½³ä¹°ç‚¹æ—¥æœŸ':<14} {'ä¹°ç‚¹ä»·æ ¼':<10} {'æ¶¨å¹…':<10} {'å‘¨æ•°':<6} {'åŒ¹é…åº¦':<10} {'æ ¸å¿ƒåŒ¹é…åº¦':<12} {'ç›ˆåˆ©ç­¹ç ':<10} {'90%é›†ä¸­åº¦':<12}")
        print("-" * 140)
        for i, r in enumerate(results, 1):
            profit = f"{r['ç›ˆåˆ©ç­¹ç æ¯”ä¾‹']:.2f}%" if r['ç›ˆåˆ©ç­¹ç æ¯”ä¾‹'] is not None else "N/A"
            chip_90 = f"{r['90%æˆæœ¬é›†ä¸­åº¦']:.2f}" if r['90%æˆæœ¬é›†ä¸­åº¦'] is not None else "N/A"
            print(f"{i:<6} {r['è‚¡ç¥¨ä»£ç ']:<10} {r['è‚¡ç¥¨åç§°']:<20} {r['æœ€ä½³ä¹°ç‚¹æ—¥æœŸ']:<14} {r['æœ€ä½³ä¹°ç‚¹ä»·æ ¼']:>8.2f} {r['æ¶¨å¹…']:>8.2f}% {r['å‘¨æ•°']:>4} {r['åŒ¹é…åº¦']:>8.3f} {r['æ ¸å¿ƒç‰¹å¾åŒ¹é…åº¦']:>10.3f} {profit:>10} {chip_90:>12}")
        
        # ç»Ÿè®¡ä¿¡æ¯
        match_scores = [r['åŒ¹é…åº¦'] for r in results]
        core_scores = [r['æ ¸å¿ƒç‰¹å¾åŒ¹é…åº¦'] for r in results]
        pass_count = len([s for s in match_scores if s >= 0.95])
        
        print(f"\nğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   å¹³å‡åŒ¹é…åº¦: {sum(match_scores) / len(match_scores):.3f}")
        print(f"   æœ€ä½åŒ¹é…åº¦: {min(match_scores):.3f}")
        print(f"   æœ€é«˜åŒ¹é…åº¦: {max(match_scores):.3f}")
        print(f"   å¹³å‡æ ¸å¿ƒç‰¹å¾åŒ¹é…åº¦: {sum(core_scores) / len(core_scores):.3f}")
        print(f"   è¾¾æ ‡æ•°é‡ï¼ˆ>=0.95ï¼‰: {pass_count}/{len(match_scores)}")
        
        if pass_count == len(match_scores):
            print(f"\nâœ… æ‰€æœ‰ {len(match_scores)} åªè‚¡ç¥¨çš„åŒ¹é…åº¦éƒ½ >= 0.95ï¼")
        else:
            print(f"\nâš ï¸ æœ‰ {len(match_scores) - pass_count} åªè‚¡ç¥¨çš„åŒ¹é…åº¦ < 0.95")
        
        # ä¿å­˜ç»“æœ
        output_file = 'training_stocks_buy_points_list.json'
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump({
                'è®¡ç®—æ—¶é—´': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'æ¨¡å‹æ–‡ä»¶': model_file,
                'è®­ç»ƒè‚¡ç¥¨æ•°': len(training_stocks),
                'æˆåŠŸè®¡ç®—æ•°': len(results),
                'ç»“æœ': results
            }, f, ensure_ascii=False, indent=2)
        print(f"\nâœ… ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    else:
        print("âŒ æ²¡æœ‰æˆåŠŸè®¡ç®—çš„ç»“æœ")

if __name__ == '__main__':
    main()
