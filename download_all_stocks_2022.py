#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸‹è½½æ‰€æœ‰Aè‚¡ä»2022å¹´å¼€å§‹çš„å®Œæ•´æ•°æ®ï¼ˆæ—¥K + å‘¨Kï¼‰
ä½¿ç”¨ akshareï¼Œæ”¯æŒæŒ‡å®šæ—¥æœŸèŒƒå›´ã€‚

ç”¨æ³•:
  python download_all_stocks_2022.py --list-cache
     ä» cache/stock_list_all.json è¯»åˆ—è¡¨ï¼Œä»…ä¸‹è½½ç¼ºå¤± 2022+ æ•°æ®çš„è‚¡ç¥¨ã€‚
  python download_all_stocks_2022.py --list-cache --force
     å¼ºåˆ¶é‡æ–°ä¸‹è½½å…¨éƒ¨ã€‚
  python download_all_stocks_2022.py --list-cache --limit 100 --workers 1
     ä»…å¤„ç†å‰ 100 åªï¼Œå•çº¿ç¨‹ï¼ˆç½‘ç»œä¸ç¨³æ—¶å»ºè®® --workers 1ï¼‰ã€‚

åå°è¿è¡Œ: nohup python download_all_stocks_2022.py --list-cache > download_2022.log 2>&1 &
"""
import os
import sys
import json
import time
from datetime import datetime, timezone
from concurrent.futures import ThreadPoolExecutor, as_completed

# ç¦ç”¨ä»£ç†
for k in ["http_proxy", "https_proxy", "HTTP_PROXY", "HTTPS_PROXY", "all_proxy", "ALL_PROXY", "no_proxy", "NO_PROXY"]:
    os.environ.pop(k, None)
os.environ["NO_PROXY"] = "*"
os.environ["no_proxy"] = "*"

import pandas as pd
import akshare as ak

PROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, PROJECT_ROOT)

from data_fetcher import DataFetcher


def _save_csv_with_meta(df: pd.DataFrame, csv_path: str, meta_path: str, meta: dict) -> None:
    """ä¿å­˜CSVå’Œmetaæ–‡ä»¶"""
    if df is None or len(df) == 0:
        return
    df.to_csv(csv_path, index=False, encoding="utf-8-sig")
    with open(meta_path, "w", encoding="utf-8") as f:
        json.dump(meta, f, ensure_ascii=False, indent=2)


def download_stock_2022_onwards(code: str, name: str, daily_dir: str, weekly_dir: str, end_ymd: str) -> tuple[str, str, bool, bool, str]:
    """ä¸‹è½½å•åªè‚¡ç¥¨ä»2022-01-01å¼€å§‹çš„æ•°æ®"""
    start_ymd = "20220101"
    
    daily_csv = os.path.join(daily_dir, f"{code}.csv")
    daily_meta = os.path.join(daily_dir, f"{code}.meta.json")
    weekly_csv = os.path.join(weekly_dir, f"{code}.csv")
    weekly_meta = os.path.join(weekly_dir, f"{code}.meta.json")
    
    saved_daily = False
    saved_weekly = False
    error_msg = None
    
    # ä¸‹è½½æ—¥Kçº¿
    try:
        daily_df = None
        for attempt in range(5):
            try:
                daily_df = ak.stock_zh_a_hist(
                    symbol=str(code),
                    period="daily",
                    start_date=start_ymd,
                    end_date=end_ymd,
                    adjust="qfq",
                )
                break
            except Exception as e:
                if attempt < 4:
                    time.sleep(3 * (attempt + 1))
                else:
                    error_msg = f"æ—¥Kä¸‹è½½å¤±è´¥: {str(e)[:100]}"
        
        if daily_df is not None and len(daily_df) > 0:
            # æ ‡å‡†åŒ–åˆ—å
            if len(daily_df.columns) > 0:
                daily_df = daily_df.rename(columns={daily_df.columns[0]: "æ—¥æœŸ"})
            if "æ—¥æœŸ" in daily_df.columns:
                daily_df["æ—¥æœŸ"] = pd.to_datetime(daily_df["æ—¥æœŸ"], errors="coerce")
                daily_df = daily_df.dropna(subset=["æ—¥æœŸ"]).sort_values("æ—¥æœŸ").reset_index(drop=True)
            
            # ä¿å­˜
            now_ts = datetime.now(timezone.utc).timestamp()
            meta = {"saved_at": now_ts, "start": start_ymd, "end": end_ymd, "code": code, "name": name}
            _save_csv_with_meta(daily_df, daily_csv, daily_meta, meta)
            saved_daily = True
    except Exception as e:
        if not error_msg:
            error_msg = f"æ—¥Kå¼‚å¸¸: {str(e)[:100]}"
    
    time.sleep(1)
    
    # ä¸‹è½½å‘¨Kçº¿
    try:
        weekly_df = None
        for attempt in range(5):
            try:
                weekly_df = ak.stock_zh_a_hist(
                    symbol=str(code),
                    period="weekly",
                    start_date=start_ymd,
                    end_date=end_ymd,
                    adjust="qfq",
                )
                break
            except Exception as e:
                if attempt < 4:
                    time.sleep(3 * (attempt + 1))
                else:
                    if error_msg:
                        error_msg += f"; å‘¨Kä¸‹è½½å¤±è´¥: {str(e)[:100]}"
                    else:
                        error_msg = f"å‘¨Kä¸‹è½½å¤±è´¥: {str(e)[:100]}"
        
        if weekly_df is not None and len(weekly_df) > 0:
            # æ ‡å‡†åŒ–åˆ—å
            if len(weekly_df.columns) > 0:
                weekly_df = weekly_df.rename(columns={weekly_df.columns[0]: "æ—¥æœŸ"})
            if "æ—¥æœŸ" in weekly_df.columns:
                weekly_df["æ—¥æœŸ"] = pd.to_datetime(weekly_df["æ—¥æœŸ"], errors="coerce")
                weekly_df = weekly_df.dropna(subset=["æ—¥æœŸ"]).sort_values("æ—¥æœŸ").reset_index(drop=True)
            if "æˆäº¤é‡" in weekly_df.columns and "å‘¨æˆäº¤é‡" not in weekly_df.columns:
                weekly_df = weekly_df.rename(columns={"æˆäº¤é‡": "å‘¨æˆäº¤é‡"})
            
            # ä¿å­˜
            now_ts = datetime.now(timezone.utc).timestamp()
            meta = {"saved_at": now_ts, "start": start_ymd, "end": end_ymd, "code": code, "name": name}
            _save_csv_with_meta(weekly_df, weekly_csv, weekly_meta, meta)
            saved_weekly = True
    except Exception as e:
        if error_msg:
            error_msg += f"; å‘¨Kå¼‚å¸¸: {str(e)[:100]}"
        else:
            error_msg = f"å‘¨Kå¼‚å¸¸: {str(e)[:100]}"
    
    status = "ok" if (saved_daily or saved_weekly) else "fail"
    return code, status, saved_daily, saved_weekly, error_msg or ""


def main():
    import argparse
    parser = argparse.ArgumentParser(description='ä¸‹è½½æ‰€æœ‰Aè‚¡ä»2022å¹´å¼€å§‹çš„æ•°æ®')
    parser.add_argument('--force', action='store_true', help='å¼ºåˆ¶é‡æ–°ä¸‹è½½æ‰€æœ‰æ•°æ®')
    parser.add_argument('--list-cache', action='store_true', help='ä» cache/stock_list_all.json è¯»å–è‚¡ç¥¨åˆ—è¡¨ï¼ˆä¸è°ƒç”¨ akshareï¼‰')
    parser.add_argument('--limit', type=int, default=0, help='ä»…å¤„ç†å‰ N åªï¼ˆ0=å…¨éƒ¨ï¼‰')
    parser.add_argument('--workers', type=int, default=3, help='å¹¶å‘æ•°ï¼Œç½‘ç»œä¸ç¨³æ—¶å¯è®¾ä¸º 1')
    args = parser.parse_args()
    
    print("=" * 80)
    print("ğŸ“¥ ä¸‹è½½æ‰€æœ‰Aè‚¡ä»2022å¹´å¼€å§‹çš„å®Œæ•´æ•°æ®")
    if args.force:
        print("âš ï¸  å¼ºåˆ¶æ¨¡å¼ï¼šå°†é‡æ–°ä¸‹è½½æ‰€æœ‰æ•°æ®")
    if args.list_cache:
        print("âš ï¸  ä½¿ç”¨æœ¬åœ°è‚¡ç¥¨åˆ—è¡¨: cache/stock_list_all.json")
    print("=" * 80)
    print()
    
    codes = []
    names = []
    fetcher = DataFetcher()
    
    if args.list_cache:
        list_path = os.path.join(PROJECT_ROOT, "cache", "stock_list_all.json")
        if not os.path.exists(list_path):
            print(f"âŒ è‚¡ç¥¨åˆ—è¡¨ä¸å­˜åœ¨: {list_path}")
            return
        with open(list_path, "r", encoding="utf-8") as f:
            raw = json.load(f)
        for item in raw:
            code = (item.get("code") or item.get("ä»£ç ", "")).strip()
            name = item.get("name") or item.get("åç§°", "") or ""
            if not code or len(code) != 6 or not code.isdigit():
                continue
            if name and ("ST" in name or "é€€" in name):
                continue
            if code.startswith("9") or code.startswith("2"):
                continue
            codes.append(code)
            names.append(name)
        print(f"ğŸ“Š ä»ç¼“å­˜è¯»å–è‚¡ç¥¨åˆ—è¡¨: {len(codes)} åª")
    else:
        print("ğŸ“Š æ­£åœ¨è·å–æ‰€æœ‰Aè‚¡åˆ—è¡¨...")
        stock_df = fetcher.get_all_stocks(timeout=30, max_retries=3)
        if stock_df is None or len(stock_df) == 0:
            print("âŒ æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨")
            return
        code_col = None
        name_col = None
        for col in stock_df.columns:
            col_lower = str(col).lower()
            if "code" in col_lower or "ä»£ç " in col or col == stock_df.columns[0]:
                code_col = col
            if "name" in col_lower or "åç§°" in col or (len(stock_df.columns) >= 2 and col == stock_df.columns[1]):
                name_col = col
        if code_col is None:
            code_col = stock_df.columns[0]
        if name_col is None and len(stock_df.columns) >= 2:
            name_col = stock_df.columns[1]
        for _, row in stock_df.iterrows():
            code = str(row[code_col]).strip()
            name = str(row[name_col]).strip() if name_col else ""
            if not code or len(code) != 6 or not code.isdigit():
                continue
            if name and ("ST" in name or "é€€" in name):
                continue
            if code.startswith("9") or code.startswith("2"):
                continue
            codes.append(code)
            names.append(name)
        print(f"âœ… è·å–åˆ° {len(codes)} åªAè‚¡")
    
    if args.limit > 0:
        codes = codes[: args.limit]
        names = names[: args.limit]
        print(f"âš ï¸ --limit={args.limit}ï¼Œä»…å¤„ç†å‰ {len(codes)} åª")
    
    if not codes:
        print("âŒ æ— æœ‰æ•ˆè‚¡ç¥¨")
        return
    print()
    
    # è®¾ç½®ç›®å½•
    paths = fetcher._local_cache_paths()
    daily_dir = paths["daily_dir"]
    weekly_dir = paths["weekly_dir"]
    os.makedirs(daily_dir, exist_ok=True)
    os.makedirs(weekly_dir, exist_ok=True)
    
    end_ymd = datetime.now().strftime("%Y%m%d")
    start_ymd = "20220101"
    
    workers = args.workers
    print(f"æ—¥æœŸèŒƒå›´: {start_ymd} è‡³ {end_ymd}")
    print(f"å¹¶å‘æ•°: {workers}")
    print(f"é¢„è®¡è€—æ—¶: çº¦ {len(codes) * 2 / max(1, workers) / 60:.1f} åˆ†é’Ÿ")
    print()
    
    stats = {"total": len(codes), "done": 0, "daily_ok": 0, "weekly_ok": 0, "fail": 0, "skip": 0}
    start_ts = time.time()
    last_report_ts = start_ts
    
    # æ£€æŸ¥å·²å­˜åœ¨çš„æ–‡ä»¶ï¼Œè·³è¿‡å·²æœ‰å®Œæ•´æ•°æ®çš„è‚¡ç¥¨
    print("ğŸ” æ£€æŸ¥å·²æœ‰æ•°æ®...")
    to_download = []
    for i, (code, name) in enumerate(zip(codes, names)):
        daily_csv = os.path.join(daily_dir, f"{code}.csv")
        weekly_csv = os.path.join(weekly_dir, f"{code}.csv")
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰2022å¹´æ•°æ®
        has_daily_2022 = False
        has_weekly_2022 = False
        
        if os.path.exists(daily_csv):
            try:
                df = pd.read_csv(daily_csv, encoding='utf-8-sig', nrows=1)
                if 'æ—¥æœŸ' in df.columns:
                    df_full = pd.read_csv(daily_csv, encoding='utf-8-sig')
                    df_full['æ—¥æœŸ'] = pd.to_datetime(df_full['æ—¥æœŸ'], errors='coerce')
                    df_2022 = df_full[df_full['æ—¥æœŸ'] >= datetime(2022, 1, 1)]
                    if len(df_2022) > 0:
                        has_daily_2022 = True
            except:
                pass
        
        if os.path.exists(weekly_csv):
            try:
                df = pd.read_csv(weekly_csv, encoding='utf-8-sig', nrows=1)
                if 'æ—¥æœŸ' in df.columns:
                    df_full = pd.read_csv(weekly_csv, encoding='utf-8-sig')
                    df_full['æ—¥æœŸ'] = pd.to_datetime(df_full['æ—¥æœŸ'], errors='coerce')
                    df_2022 = df_full[df_full['æ—¥æœŸ'] >= datetime(2022, 1, 1)]
                    if len(df_2022) > 0:
                        has_weekly_2022 = True
            except:
                pass
        
        if args.force:
            to_download.append((code, name))
        elif has_daily_2022 and has_weekly_2022:
            stats["skip"] += 1
        else:
            to_download.append((code, name))
    
    print(f"âœ… å·²æœ‰å®Œæ•´æ•°æ®ï¼ˆè·³è¿‡ï¼‰: {stats['skip']} åª")
    print(f"ğŸ“¥ éœ€è¦ä¸‹è½½: {len(to_download)} åª")
    print()
    
    if len(to_download) == 0:
        print("âœ… æ‰€æœ‰è‚¡ç¥¨æ•°æ®å·²å®Œæ•´ï¼Œæ— éœ€ä¸‹è½½")
        return
    
    # å¼€å§‹ä¸‹è½½
    print("=" * 80)
    print("å¼€å§‹ä¸‹è½½...")
    print("=" * 80)
    print()
    
    with ThreadPoolExecutor(max_workers=workers) as ex:
        futs = {
            ex.submit(download_stock_2022_onwards, c, n, daily_dir, weekly_dir, end_ymd): (c, n)
            for c, n in to_download
        }
        
        for fut in as_completed(futs):
            c, n = futs[fut]
            try:
                code, status, d_ok, w_ok, err = fut.result()
                if status == "ok":
                    if d_ok:
                        stats["daily_ok"] += 1
                    if w_ok:
                        stats["weekly_ok"] += 1
                else:
                    stats["fail"] += 1
            except Exception as e:
                print(f"  [{c}] âŒ å¼‚å¸¸: {e}")
                stats["fail"] += 1
            
            stats["done"] += 1
            
            # æ¯10ç§’æˆ–æ¯50åªè‚¡ç¥¨æŠ¥å‘Šä¸€æ¬¡è¿›åº¦
            now_ts = time.time()
            if now_ts - last_report_ts >= 10 or stats["done"] % 50 == 0 or stats["done"] == len(to_download):
                el = now_ts - start_ts
                speed = stats["done"] / el if el > 0 else 0
                remaining = (len(to_download) - stats["done"]) / speed if speed > 0 else 0
                print(f"[è¿›åº¦] {stats['done']}/{len(to_download)} "
                      f"daily_ok={stats['daily_ok']} weekly_ok={stats['weekly_ok']} "
                      f"fail={stats['fail']} speed={speed:.2f}/s "
                      f"å‰©ä½™çº¦{remaining/60:.1f}åˆ†é’Ÿ")
                last_report_ts = now_ts
    
    print()
    print("=" * 80)
    print("âœ… ä¸‹è½½å®Œæˆ")
    print("=" * 80)
    print(f"æ€»è®¡: {stats['total']} åª")
    print(f"è·³è¿‡ï¼ˆå·²æœ‰æ•°æ®ï¼‰: {stats['skip']} åª")
    print(f"æ—¥KæˆåŠŸ: {stats['daily_ok']} åª")
    print(f"å‘¨KæˆåŠŸ: {stats['weekly_ok']} åª")
    print(f"å¤±è´¥: {stats['fail']} åª")
    print(f"æ€»è€—æ—¶: {(time.time() - start_ts) / 60:.1f} åˆ†é’Ÿ")
    print()


if __name__ == "__main__":
    main()
