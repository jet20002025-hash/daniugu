#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤§ç‰›è‚¡åˆ†æå™¨Webç•Œé¢
æä¾›æ·»åŠ å¤§ç‰›è‚¡çš„åŠŸèƒ½
"""
from flask import Flask, render_template, jsonify, request, session, redirect, url_for, send_file
from bull_stock_analyzer import BullStockAnalyzer
from technical_analysis import TechnicalAnalysis
from bull_stock_v2_model import BullStockV2Model
from datetime import datetime
# æ ¹æ®ç¯å¢ƒé€‰æ‹©ä½¿ç”¨å“ªä¸ªè®¤è¯æ¨¡å—
import os

# æ£€æµ‹ Vercel ç¯å¢ƒï¼ˆæ›´å¯é çš„æ–¹å¼ï¼‰
is_vercel = (
    os.environ.get('VERCEL') == '1' or 
    os.environ.get('VERCEL_ENV') is not None or
    os.environ.get('VERCEL_URL') is not None
)

# æ£€æµ‹ Render ç¯å¢ƒï¼ˆRenderçš„æ–‡ä»¶ç³»ç»Ÿä¹Ÿæ˜¯åªè¯»çš„ï¼Œéœ€è¦ä½¿ç”¨Redisï¼‰
is_render = (
    os.environ.get('RENDER') == 'true' or
    os.environ.get('RENDER_SERVICE_NAME') is not None or
    os.environ.get('RENDER_EXTERNAL_URL') is not None
)

# æ£€æµ‹æœ¬åœ°ç¯å¢ƒï¼ˆæ—¢ä¸æ˜¯Vercelä¹Ÿä¸æ˜¯Renderï¼‰
is_local = not is_vercel and not is_render

# æ£€æµ‹æ˜¯å¦æœ‰Redisé…ç½®ï¼ˆå¦‚æœæœ‰ï¼Œä¼˜å…ˆä½¿ç”¨Rediså­˜å‚¨ï¼‰
has_redis = (
    os.environ.get('UPSTASH_REDIS_REST_URL') is not None and
    os.environ.get('UPSTASH_REDIS_REST_TOKEN') is not None
)

try:
    # å¦‚æœæ˜¯Vercelã€Renderç¯å¢ƒï¼Œæˆ–è€…é…ç½®äº†Redisï¼Œä½¿ç”¨Rediså­˜å‚¨ç‰ˆæœ¬
    if is_vercel or is_render or has_redis:
        # Vercel/Renderç¯å¢ƒæˆ–é…ç½®äº†Redisï¼šä½¿ç”¨Rediså­˜å‚¨ç‰ˆæœ¬
        from user_auth_vercel import (
            register_user, login_user, is_logged_in, get_current_user,
            require_login, create_invite_code, list_invite_codes, get_user_stats
        )
        if is_render:
            print("[ç¯å¢ƒæ£€æµ‹] Renderç¯å¢ƒæ£€æµ‹åˆ°ï¼Œä½¿ç”¨Rediså­˜å‚¨ï¼ˆuser_auth_vercelï¼‰")
    else:
        # æœ¬åœ°ç¯å¢ƒï¼šä½¿ç”¨æ–‡ä»¶å­˜å‚¨ç‰ˆæœ¬
        from user_auth import (
            register_user, login_user, is_logged_in, get_current_user,
            require_login, create_invite_code, list_invite_codes, get_user_stats
        )
except ImportError as e:
    # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ Vercel ç‰ˆæœ¬
    print(f"è­¦å‘Šï¼šå¯¼å…¥è®¤è¯æ¨¡å—å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ Vercel ç‰ˆæœ¬: {e}")
    try:
        from user_auth_vercel import (
            register_user, login_user, is_logged_in, get_current_user,
            require_login, create_invite_code, list_invite_codes, get_user_stats
        )
    except ImportError:
        # å¦‚æœéƒ½å¤±è´¥ï¼Œåˆ›å»ºç®€å•çš„å ä½å‡½æ•°
        print("é”™è¯¯ï¼šæ— æ³•å¯¼å…¥è®¤è¯æ¨¡å—ï¼Œä½¿ç”¨å ä½å‡½æ•°")
        def register_user(*args, **kwargs):
            return {'success': False, 'message': 'è®¤è¯æ¨¡å—æœªåŠ è½½'}
        def login_user(*args, **kwargs):
            return {'success': False, 'message': 'è®¤è¯æ¨¡å—æœªåŠ è½½'}
        def is_logged_in():
            return False
        def get_current_user():
            return None
        def require_login(f):
            return f
        def create_invite_code(*args, **kwargs):
            return {'success': False, 'message': 'è®¤è¯æ¨¡å—æœªåŠ è½½'}
        def list_invite_codes():
            return {}
        def get_user_stats():
            return {}
import json
import pandas as pd
import numpy as np
import time
import os

app = Flask(__name__)

# ç™»å½•æ—¥å¿—æ–‡ä»¶
LOGIN_LOG_FILE = 'login_monitor.log'

def _log_login_attempt(username, success, duration_ms, timestamp, message):
    """è®°å½•ç™»å½•å°è¯•åˆ°æ—¥å¿—æ–‡ä»¶"""
    try:
        log_entry = {
            'timestamp': timestamp.isoformat(),
            'username': username,
            'success': success,
            'duration_ms': round(duration_ms, 3),
            'message': message
        }
        
        # è¿½åŠ åˆ°æ—¥å¿—æ–‡ä»¶
        with open(LOGIN_LOG_FILE, 'a', encoding='utf-8') as f:
            f.write(json.dumps(log_entry, ensure_ascii=False) + '\n')
    except Exception as e:
        # è®°å½•å¤±è´¥ä¸åº”è¯¥å½±å“ç™»å½•æµç¨‹
        print(f"è®°å½•ç™»å½•æ—¥å¿—å¤±è´¥: {e}")
# æ¯æ¬¡é‡å¯æœåŠ¡å™¨ç”Ÿæˆæ–°çš„ SECRET_KEYï¼Œä½¿æ‰€æœ‰æ—§ session å¤±æ•ˆï¼Œç”¨æˆ·éœ€è¦é‡æ–°ç™»å½•
import uuid
app.config['SECRET_KEY'] = f'bull-stock-{uuid.uuid4().hex}'

# æ·»åŠ å…¨å±€é”™è¯¯å¤„ç†å™¨ï¼Œç¡®ä¿æ‰€æœ‰é”™è¯¯éƒ½è¿”å› JSON æ ¼å¼ï¼ˆè€Œä¸æ˜¯ HTMLï¼‰
# æ³¨æ„ï¼šå¿…é¡»ä½¿ç”¨ app.errorhandler æ³¨å†Œï¼Œä¸èƒ½ä½¿ç”¨ register_error_handler
# å¹¶ä¸”éœ€è¦å…ˆæ³¨å†Œå…·ä½“çš„é”™è¯¯ç±»å‹ï¼Œå†æ³¨å†Œé€šç”¨çš„ Exception

@app.errorhandler(500)
def handle_500_error(error):
    """å¤„ç† 500 é”™è¯¯ï¼Œè¿”å› JSON æ ¼å¼"""
    import traceback
    from flask import request, has_request_context
    
    # è·å–é”™è¯¯è¯¦æƒ…
    error_detail = traceback.format_exc()
    error_type = type(error).__name__ if error else 'UnknownError'
    error_message = str(error) if error else "æœªçŸ¥é”™è¯¯"
    
    print(f"[Flask Error Handler] âŒ 500 é”™è¯¯ ({error_type}): {error_detail}")
    
    # æ£€æŸ¥è¯·æ±‚ä¸Šä¸‹æ–‡ï¼Œå¦‚æœæ˜¯ API è·¯å¾„ï¼Œè¿”å› JSON æ ¼å¼
    try:
        if has_request_context() and request.path.startswith('/api/'):
            return jsonify({
                'success': False,
                'message': f'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {error_message}',
                'error_type': error_type,
                'path': request.path,
                'method': request.method
            }), 500
    except Exception as handler_error:
        print(f"[Flask Error Handler] âš ï¸ é”™è¯¯å¤„ç†å™¨å†…éƒ¨å‡ºé”™: {handler_error}")
        import traceback
        print(f"[Flask Error Handler] é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
    
    # é API è·¯å¾„æˆ–æ²¡æœ‰è¯·æ±‚ä¸Šä¸‹æ–‡ï¼Œä½¿ç”¨ Flask é»˜è®¤é”™è¯¯å¤„ç†
    # æ³¨æ„ï¼šä¸èƒ½è¿”å› Noneï¼Œéœ€è¦è¿”å›ä¸€ä¸ªå“åº”æˆ–é‡æ–°æŠ›å‡ºå¼‚å¸¸
    # ä½†å¯¹äºé API è·¯å¾„ï¼Œæˆ‘ä»¬å¸Œæœ›è¿”å› HTML é”™è¯¯é¡µé¢
    from flask import render_template_string
    return render_template_string(
        '<!DOCTYPE html><html><head><title>500 Internal Server Error</title></head>'
        '<body><h1>Internal Server Error</h1><p>The server encountered an internal error.</p></body></html>'
    ), 500

@app.errorhandler(Exception)
def handle_all_exceptions(error):
    """å¤„ç†æ‰€æœ‰æœªæ•è·çš„å¼‚å¸¸ï¼Œè¿”å› JSON æ ¼å¼"""
    import traceback
    from flask import request, has_request_context
    
    # è·å–é”™è¯¯è¯¦æƒ…
    error_detail = traceback.format_exc()
    error_type = type(error).__name__
    error_message = str(error) if error else "æœªçŸ¥é”™è¯¯"
    
    print(f"[Flask Error Handler] âŒ æœªæ•è·çš„å¼‚å¸¸ ({error_type}): {error_detail}")
    
    # æ£€æŸ¥è¯·æ±‚ä¸Šä¸‹æ–‡ï¼Œå¦‚æœæ˜¯ API è·¯å¾„ï¼Œè¿”å› JSON æ ¼å¼
    try:
        if has_request_context() and request.path.startswith('/api/'):
            return jsonify({
                'success': False,
                'message': f'æœåŠ¡å™¨é”™è¯¯: {error_message}',
                'error_type': error_type,
                'path': request.path,
                'method': request.method
            }), 500
    except Exception as handler_error:
        print(f"[Flask Error Handler] âš ï¸ é”™è¯¯å¤„ç†å™¨å†…éƒ¨å‡ºé”™: {handler_error}")
        import traceback
        print(f"[Flask Error Handler] é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
    
    # é API è·¯å¾„æˆ–æ²¡æœ‰è¯·æ±‚ä¸Šä¸‹æ–‡ï¼Œé‡æ–°æŠ›å‡ºå¼‚å¸¸è®© Flask ä½¿ç”¨é»˜è®¤é”™è¯¯å¤„ç†
    # æ³¨æ„ï¼šå¯¹äº HTTPExceptionï¼ˆå¦‚ 404, 401ï¼‰ï¼Œä¸åº”è¯¥é‡æ–°æŠ›å‡ºï¼Œåº”è¯¥è¿”å›é»˜è®¤å“åº”
    from werkzeug.exceptions import HTTPException
    if isinstance(error, HTTPException):
        # HTTPException å·²ç»æœ‰è‡ªå·±çš„å“åº”ï¼Œç›´æ¥è¿”å›
        return error
    
    # å…¶ä»–å¼‚å¸¸ï¼Œé‡æ–°æŠ›å‡ºè®© Flask ä½¿ç”¨é»˜è®¤é”™è¯¯å¤„ç†
    raise

# åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–é»˜è®¤æµ‹è¯•ç”¨æˆ·ï¼ˆæ°¸ä¹…ä¿ç•™ï¼Œç›´åˆ°ç”¨æˆ·æ˜ç¡®åˆ é™¤ï¼‰
try:
    if is_vercel:
        from user_auth_vercel import init_default_test_users
    else:
        from user_auth import init_default_test_users
    # åœ¨åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–æµ‹è¯•ç”¨æˆ·
    try:
        init_default_test_users()
    except Exception as e:
        print(f"âš ï¸ åˆå§‹åŒ–é»˜è®¤æµ‹è¯•ç”¨æˆ·å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
except Exception as e:
    print(f"âš ï¸ æ— æ³•å¯¼å…¥æµ‹è¯•ç”¨æˆ·åˆå§‹åŒ–å‡½æ•°: {e}")

# åˆ›å»ºå…¨å±€åˆ†æå™¨å®ä¾‹ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼Œå…ˆå¯åŠ¨FlaskæœåŠ¡ï¼‰
# ä½¿ç”¨å»¶è¿Ÿåˆå§‹åŒ–ï¼Œé¿å…é˜»å¡Flaskå¯åŠ¨
analyzer = None
# æ¨¡å‹æ–‡ä»¶ä¸Šæ¬¡åŠ è½½çš„ mtimeï¼Œç”¨äºæ£€æµ‹ trained_model.json ä¿®æ”¹åè‡ªåŠ¨é‡æ–°åŠ è½½
_model_last_loaded_mtime = 0

# å½“å‰é€‰æ‹©çš„æ¨¡å‹æ–‡ä»¶åï¼ˆé»˜è®¤ä½¿ç”¨ trained_model.jsonï¼‰
_current_model_file = 'trained_model.json'

# V2æ¨¡å‹å®ä¾‹
v2_model = None

def init_v2_model():
    """åˆå§‹åŒ–V2æ¨¡å‹"""
    global v2_model
    if v2_model is None:
        try:
            v2_model = BullStockV2Model()
            model_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'bull_stock_v2.json')
            if os.path.exists(model_path):
                v2_model.load_model(model_path)
                print(f"âœ… V2æ¨¡å‹åŠ è½½æˆåŠŸï¼Œç‰¹å¾æ•°: {len(v2_model.feature_template)}")
            else:
                print(f"âš ï¸ V2æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        except Exception as e:
            print(f"âš ï¸ V2æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            v2_model = None
    return v2_model

def is_premium_user():
    """æ£€æŸ¥ç”¨æˆ·æ˜¯å¦ä¸ºä»˜è´¹ç”¨æˆ·ï¼ˆVIPï¼‰"""
    try:
        user = get_current_user()
        if not user:
            return False
        return user.get('is_vip', False) or user.get('is_premium', False)
    except:
        return False

def is_super_user():
    """æ£€æŸ¥ç”¨æˆ·æ˜¯å¦ä¸ºè¶…çº§ç”¨æˆ·ï¼ˆç®¡ç†å‘˜ï¼‰"""
    try:
        user = get_current_user()
        if not user:
            return False
        # è¶…çº§ç”¨æˆ·ï¼šis_super ä¸º Trueï¼Œæˆ–è€…ç”¨æˆ·åä¸ºç‰¹å®šç®¡ç†å‘˜ç”¨æˆ·å
        is_super = user.get('is_super', False) or user.get('is_admin', False)
        username = user.get('username', '').lower()
        # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ ç‰¹å®šçš„ç®¡ç†å‘˜ç”¨æˆ·ååˆ—è¡¨
        admin_users = ['admin', 'super', 'root']  # å¯ä»¥æ ¹æ®éœ€è¦ä¿®æ”¹
        return is_super or username in admin_users
    except:
        return False

def get_user_tier():
    """è·å–ç”¨æˆ·ç­‰çº§ï¼š'free'ã€'premium' æˆ– 'super'"""
    if is_super_user():
        return 'super'
    if is_premium_user():
        return 'premium'
    return 'free'

def get_scan_config():
    """æ ¹æ®ç”¨æˆ·ç­‰çº§è¿”å›æ‰«æé…ç½®ï¼ˆä¼˜åŒ–å†…å­˜ä½¿ç”¨ï¼‰"""
    tier = get_user_tier()
    
    if tier == 'super':
        # è¶…çº§ç”¨æˆ·ï¼šæœ€å¿«æ‰«æï¼Œæ— é™åˆ¶ï¼ˆä½†è€ƒè™‘å†…å­˜é™åˆ¶ï¼‰
        return {
            'batch_size': 30,      # ä»50é™åˆ°30ï¼Œå‡å°‘å†…å­˜ä½¿ç”¨
            'batch_delay': 1,      # å»¶è¿Ÿ1ç§’
            'stock_timeout': 10,   # å•è‚¡ç¥¨10ç§’
            'retry_delay': 2,      # é‡è¯•å»¶è¿Ÿ2ç§’
            'daily_limit': None,   # æ— é™åˆ¶
            'scan_interval': 0,    # æ— é—´éš”
            'scan_start_hour': 0,  # 0ç‚¹åå³å¯æ‰«æ
            'result_view_hour': 0  # 0ç‚¹åå³å¯æŸ¥çœ‹ç»“æœ
        }
    elif tier == 'premium':
        # æ”¶è´¹ç‰ˆï¼ˆVIPï¼‰ï¼šç³»ç»Ÿ11:30è‡ªåŠ¨æ‰«æï¼Œä¹Ÿå¯ä»¥æ‰‹åŠ¨æ‰«æ
        return {
            'batch_size': 30,      # ä»50é™åˆ°30ï¼Œå‡å°‘å†…å­˜ä½¿ç”¨
            'batch_delay': 1,      # å»¶è¿Ÿ1ç§’
            'stock_timeout': 10,   # å•è‚¡ç¥¨10ç§’
            'retry_delay': 2,      # é‡è¯•å»¶è¿Ÿ2ç§’
            'daily_limit': None,   # æ— é™åˆ¶
            'scan_interval': 0,    # æ— é—´éš”
            'scan_start_hour': 0,  # 0ç‚¹åå³å¯æ‰‹åŠ¨æ‰«æ
            'auto_scan_hour': 11,  # ç³»ç»Ÿè‡ªåŠ¨æ‰«ææ—¶é—´ï¼š11:30
            'auto_scan_minute': 30,
            'result_view_hour': 12  # ä¸­åˆ12ç‚¹åå¯æŸ¥çœ‹ç»“æœ
        }
    else:
        # å…è´¹ç‰ˆï¼šç³»ç»Ÿæ¯å¤©3:00è‡ªåŠ¨æ‰«æï¼Œç”¨æˆ·ç›´æ¥çœ‹ç»“æœ
        return {
            'batch_size': 15,      # ä»20é™åˆ°15ï¼Œå‡å°‘å†…å­˜ä½¿ç”¨
            'batch_delay': 3,      # å»¶è¿Ÿ3ç§’ï¼ˆæ›´æ…¢ï¼‰
            'stock_timeout': 8,    # å•è‚¡ç¥¨8ç§’
            'retry_delay': 5,      # é‡è¯•å»¶è¿Ÿ5ç§’
            'daily_limit': 2000,   # æ¯æ—¥2000åª
            'scan_interval': 180,  # é—´éš”3åˆ†é’Ÿ
            'auto_scan_hour': 15,  # æ¯å¤©15:00ï¼ˆä¸‹åˆ3ç‚¹ï¼‰è‡ªåŠ¨æ‰«æ
            'auto_scan_minute': 0,  # 15:00æ•´ç‚¹
            'result_view_hour': 15,  # ä¸‹åˆ3ç‚¹åå¯æŸ¥çœ‹ç»“æœ
            'result_view_minute': 0,  # 15:00åå³å¯æŸ¥çœ‹
            'manual_scan_allowed': False  # ä¸å…è®¸æ‰‹åŠ¨æ‰«æ
        }

def init_analyzer():
    """å»¶è¿Ÿåˆå§‹åŒ–åˆ†æå™¨ï¼›è‹¥å½“å‰æ¨¡å‹æ–‡ä»¶å·²æ›´æ–°åˆ™è‡ªåŠ¨é‡æ–°åŠ è½½"""
    global analyzer, _model_last_loaded_mtime, _current_model_file
    project_root = os.path.dirname(os.path.abspath(__file__))
    model_path_to_check = os.path.join(project_root, _current_model_file)
    if os.path.exists(model_path_to_check):
        try:
            current_mtime = os.path.getmtime(model_path_to_check)
        except OSError:
            current_mtime = 0
    else:
        current_mtime = 0
    if analyzer is not None and current_mtime > _model_last_loaded_mtime:
        analyzer = None
        print(f"[init_analyzer] æ£€æµ‹åˆ° {_current_model_file} å·²æ›´æ–°ï¼Œè‡ªåŠ¨é‡æ–°åŠ è½½æ¨¡å‹")
    if analyzer is None:
        try:
            # åœ¨ Vercel ç¯å¢ƒä¸­ï¼Œå®Œå…¨ç¦ç”¨è‡ªåŠ¨åŠ è½½å’Œè®­ç»ƒ
            if is_vercel:
                print("Vercel ç¯å¢ƒï¼šç¦ç”¨è‡ªåŠ¨åŠ è½½å’Œè®­ç»ƒä»¥é¿å…è¶…æ—¶")
                # Vercel ç¯å¢ƒï¼šä¸è‡ªåŠ¨åŠ è½½ï¼Œä¸è‡ªåŠ¨è®­ç»ƒ
                analyzer = BullStockAnalyzer(
                    auto_load_default_stocks=False, 
                    auto_analyze_and_train=False
                )
                
                # åœ¨ Vercel ç¯å¢ƒä¸­ä¹Ÿè¦å°è¯•åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹
                # å°è¯•å¤šä¸ªå¯èƒ½çš„è·¯å¾„ï¼ˆVercel serverless å‡½æ•°çš„å·¥ä½œç›®å½•å¯èƒ½ä¸åŒï¼‰
                # è·å–å½“å‰è„šæœ¬çš„ç›®å½•å’Œé¡¹ç›®æ ¹ç›®å½•
                current_file_dir = os.path.dirname(os.path.abspath(__file__))
                project_root = current_file_dir  # bull_stock_web.py åœ¨é¡¹ç›®æ ¹ç›®å½•
                
                model_paths = [
                    os.path.join(project_root, _current_model_file),  # é¡¹ç›®æ ¹ç›®å½•ï¼ˆæœ€å¯èƒ½ï¼‰
                    _current_model_file,  # å½“å‰å·¥ä½œç›®å½•
                    os.path.join(current_file_dir, _current_model_file),  # å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•
                ]
                
                model_loaded = False
                for model_path in model_paths:
                    abs_path = os.path.abspath(model_path)
                    print(f"å°è¯•åŠ è½½æ¨¡å‹æ–‡ä»¶: {model_path} (ç»å¯¹è·¯å¾„: {abs_path})")
                    if os.path.exists(model_path):
                        print(f"  âœ“ æ–‡ä»¶å­˜åœ¨ï¼Œå°è¯•åŠ è½½...")
                        # åœ¨ Vercel ç¯å¢ƒä¸­ï¼ŒåŠ è½½æ¨¡å‹æ—¶è·³è¿‡ç½‘ç»œè¯·æ±‚ï¼ˆskip_network=Trueï¼‰
                        if analyzer.load_model(model_path, skip_network=True):
                            print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {model_path}")
                            # æ£€æŸ¥æ¨¡å‹å®Œæ•´æ€§
                            if analyzer.trained_features:
                                feature_count = len(analyzer.trained_features.get('common_features', {}))
                                print(f"   - ä¹°ç‚¹ç‰¹å¾æ•°: {feature_count}")
                            if analyzer.trained_sell_features:
                                sell_feature_count = len(analyzer.trained_sell_features.get('common_features', {}))
                                print(f"   - å–ç‚¹ç‰¹å¾æ•°: {sell_feature_count}")
                            model_loaded = True
                            try:
                                _model_last_loaded_mtime = os.path.getmtime(os.path.abspath(model_path))
                            except OSError:
                                pass
                            break
                        else:
                            print(f"  âš ï¸ æ–‡ä»¶å­˜åœ¨ä½†åŠ è½½å¤±è´¥: {model_path}")
                    else:
                        print(f"  âœ— æ–‡ä»¶ä¸å­˜åœ¨: {abs_path}")
                
                if not model_loaded:
                    print("âš ï¸ æœªæ‰¾åˆ°å·²ä¿å­˜çš„æ¨¡å‹æ–‡ä»¶ï¼Œå°è¯•çš„è·¯å¾„ï¼š")
                    for path in model_paths:
                        abs_path = os.path.abspath(path)
                        exists = os.path.exists(path)
                        print(f"   - {path}")
                        print(f"     ç»å¯¹è·¯å¾„: {abs_path}")
                        print(f"     å­˜åœ¨: {exists}")
                    print("âš ï¸ éœ€è¦é‡æ–°è®­ç»ƒæ¨¡å‹")
                    print(f"å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
                    print(f"å½“å‰æ–‡ä»¶ç›®å½•: {current_file_dir}")
                    print(f"é¡¹ç›®æ ¹ç›®å½•: {project_root}")
            else:
                # æœ¬åœ°ç¯å¢ƒï¼šå¿«é€Ÿåˆå§‹åŒ–ï¼ˆç¦ç”¨è‡ªåŠ¨åŠ è½½è‚¡ç¥¨ï¼Œé¿å…ç½‘ç»œè¯·æ±‚ï¼‰
                print("æ­£åœ¨åˆå§‹åŒ–åˆ†æå™¨ï¼ˆå¿«é€Ÿæ¨¡å¼ï¼‰...")
                analyzer = BullStockAnalyzer(
                    auto_load_default_stocks=False,  # ç¦ç”¨è‡ªåŠ¨åŠ è½½ï¼Œé¿å…ç½‘ç»œè¯·æ±‚å¯¼è‡´ç¼“æ…¢
                    auto_analyze_and_train=False  # ç¦ç”¨è‡ªåŠ¨è®­ç»ƒ
                )
                
                # å°è¯•åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹ï¼ˆæœ¬åœ°ç¯å¢ƒä¹Ÿè·³è¿‡ç½‘ç»œè¯·æ±‚ï¼Œä»…åŠ è½½æ¨¡å‹æ–‡ä»¶ï¼‰
                print(f"å°è¯•åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹: {_current_model_file}...")
                if analyzer.load_model(_current_model_file, skip_network=True):
                    print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
                    # æ£€æŸ¥æ¨¡å‹å®Œæ•´æ€§
                    if analyzer.trained_features:
                        feature_count = len(analyzer.trained_features.get('common_features', {}))
                        print(f"   - ä¹°ç‚¹ç‰¹å¾æ•°: {feature_count}")
                    if analyzer.trained_sell_features:
                        sell_feature_count = len(analyzer.trained_sell_features.get('common_features', {}))
                        print(f"   - å–ç‚¹ç‰¹å¾æ•°: {sell_feature_count}")
                    try:
                        _model_last_loaded_mtime = os.path.getmtime(os.path.join(project_root, _current_model_file))
                    except OSError:
                        pass
                else:
                    print("âš ï¸ æœªæ‰¾åˆ°å·²ä¿å­˜çš„æ¨¡å‹ï¼Œéœ€è¦é‡æ–°è®­ç»ƒ")
            
            print("âœ… åˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            print(f"âš ï¸ åˆ†æå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            # åˆ›å»ºä¸€ä¸ªç©ºçš„åˆ†æå™¨å¯¹è±¡ï¼Œé¿å…åç»­è°ƒç”¨å¤±è´¥
            analyzer = None
    return analyzer


@app.route('/')
def index():
    """ä¸»é¡µé¢"""
    try:
        # æ£€æŸ¥æ˜¯å¦å·²ç™»å½•
        if not is_logged_in():
            return redirect(url_for('login_page'))
        # âœ… ä¸åœ¨ä¸»é¡µæ¸²æŸ“æ—¶åˆå§‹åŒ–åˆ†æå™¨ï¼Œå»¶è¿Ÿåˆ°APIè°ƒç”¨æ—¶åˆå§‹åŒ–ï¼ˆæå‡é¡µé¢åŠ è½½é€Ÿåº¦ï¼‰
        # init_analyzer() ä¼šåœ¨ç¬¬ä¸€æ¬¡APIè°ƒç”¨æ—¶è‡ªåŠ¨åˆå§‹åŒ–
        return render_template('bull_stock_web.html')
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"ä¸»é¡µé”™è¯¯: {error_detail}")
        return f"<h1>æœåŠ¡å™¨é”™è¯¯</h1><pre>{error_detail}</pre>", 500

@app.route('/favicon.ico')
def favicon():
    """å¤„ç†faviconè¯·æ±‚ï¼Œè¿”å›204 No Content"""
    return '', 204

@app.route('/login')
def login_page():
    """ç™»å½•é¡µé¢"""
    if is_logged_in():
        return redirect(url_for('index'))
    return render_template('login.html')

@app.route('/register')
def register_page():
    """æ³¨å†Œé¡µé¢"""
    try:
        if is_logged_in():
            return redirect(url_for('index'))
        return render_template('register.html')
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"æ³¨å†Œé¡µé¢é”™è¯¯: {error_detail}")
        return f"<h1>æœåŠ¡å™¨é”™è¯¯</h1><pre>{error_detail}</pre>", 500

# ==================== è®¤è¯ç›¸å…³ API ====================

@app.route('/api/register', methods=['POST'])
def api_register():
    """ç”¨æˆ·æ³¨å†ŒAPIï¼ˆé‚®ç®±æ³¨å†Œï¼Œæ— éœ€é‚€è¯·ç ï¼‰"""
    try:
        data = request.get_json() or {}
        username = data.get('username', '').strip()
        email = data.get('email', '').strip()
        password = data.get('password', '')
        invite_code = data.get('invite_code', '').strip().upper() or None  # é‚€è¯·ç æ”¹ä¸ºå¯é€‰
        
        if not username or not email or not password:
            return jsonify({
                'success': False,
                'message': 'è¯·å¡«å†™ç”¨æˆ·åã€é‚®ç®±å’Œå¯†ç '
            }), 400
        
        result = register_user(username, email, password, invite_code)
        
        if result['success']:
            # æ³¨å†ŒæˆåŠŸåè‡ªåŠ¨ç™»å½•
            session['username'] = username
            return jsonify({
                'success': True,
                'message': 'æ³¨å†ŒæˆåŠŸ',
                'user': {
                    'username': username,
                    'email': email
                }
            })
        else:
            return jsonify(result), 400
            
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"æ³¨å†Œé”™è¯¯: {error_detail}")
        return jsonify({
            'success': False,
            'message': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}'
        }), 500

@app.route('/api/login', methods=['POST'])
def api_login():
    """ç”¨æˆ·ç™»å½•API"""
    # è®°å½•ç™»å½•å¼€å§‹æ—¶é—´
    login_start_time = time.time()
    login_start_datetime = datetime.now()
    
    try:
        data = request.get_json() or {}
        username = data.get('username', '').strip()
        password = data.get('password', '')
        
        if not username or not password:
            login_end_time = time.time()
            login_duration = (login_end_time - login_start_time) * 1000
            _log_login_attempt(username, False, login_duration, login_start_datetime, "è¯·è¾“å…¥ç”¨æˆ·åå’Œå¯†ç ")
            return jsonify({
                'success': False,
                'message': 'è¯·è¾“å…¥ç”¨æˆ·åå’Œå¯†ç '
            }), 400
        
        # æœ¬åœ°ç¯å¢ƒå¿«é€Ÿç™»å½•ï¼šå¦‚æœç”¨æˆ·åæ˜¯ 'test' ä¸”å¯†ç æ˜¯ 'test123'ï¼Œç›´æ¥ç™»å½•
        if not is_vercel and username == 'test' and password == 'test123':
            # ç¡®ä¿æµ‹è¯•ç”¨æˆ·å­˜åœ¨
            if is_vercel:
                from user_auth_vercel import load_users, save_users, hash_password
            else:
                from user_auth import load_users, save_users, hash_password
            
            users = load_users()
            if 'test' not in users:
                # è‡ªåŠ¨åˆ›å»ºæµ‹è¯•ç”¨æˆ·
                users['test'] = {
                    'username': 'test',
                    'email': 'test@local.com',
                    'password': hash_password('test123'),
                    'created_at': datetime.now().isoformat(),
                    'last_login': datetime.now().isoformat(),
                    'invite_code': 'LOCAL_TEST',
                    'is_active': True,
                    'is_vip': True,
                    'is_super': False
                }
                save_users(users)
            
            session['username'] = 'test'
            login_end_time = time.time()
            login_duration = (login_end_time - login_start_time) * 1000
            _log_login_attempt('test', True, login_duration, login_start_datetime, "å¿«é€Ÿç™»å½•æˆåŠŸï¼ˆæœ¬åœ°æµ‹è¯•æ¨¡å¼ï¼‰")
            return jsonify({
                'success': True,
                'message': 'å¿«é€Ÿç™»å½•æˆåŠŸï¼ˆæœ¬åœ°æµ‹è¯•æ¨¡å¼ï¼‰',
                'user': {
                    'username': 'test',
                    'email': 'test@local.com',
                    'is_vip': True
                }
            })
        
        result = login_user(username, password)
        
        login_end_time = time.time()
        login_duration = (login_end_time - login_start_time) * 1000
        
        if result['success']:
            session['username'] = username
            _log_login_attempt(username, True, login_duration, login_start_datetime, result.get('message', 'ç™»å½•æˆåŠŸ'))
            return jsonify(result)
        else:
            _log_login_attempt(username, False, login_duration, login_start_datetime, result.get('message', 'ç™»å½•å¤±è´¥'))
            return jsonify(result), 401
            
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"ç™»å½•é”™è¯¯: {error_detail}")
        login_end_time = time.time()
        login_duration = (login_end_time - login_start_time) * 1000
        _log_login_attempt(username if 'username' in locals() else 'unknown', False, login_duration, login_start_datetime, f'æœåŠ¡å™¨é”™è¯¯: {str(e)}')
        return jsonify({
            'success': False,
            'message': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}'
        }), 500

@app.route('/api/logout', methods=['POST'])
@require_login
def api_logout():
    """ç”¨æˆ·ç™»å‡ºAPI"""
    session.clear()
    return jsonify({
        'success': True,
        'message': 'å·²é€€å‡ºç™»å½•'
    })

# ========== æ•°æ®è‡ªåŠ¨æ›´æ–°åŠŸèƒ½ ==========
data_update_progress = {
    'status': 'idle',  # idle, running, completed, error
    'processed': 0,
    'total': 0,
    'percentage': 0,
    'current_stock': '',
    'message': '',
    'updated_count': 0,
    'failed_count': 0,
    'start_time': None
}
data_update_stop_flag = False

# æ•°æ®æ›´æ–°æ—¶é—´æˆ³æ–‡ä»¶è·¯å¾„
DATA_UPDATE_TIMESTAMP_FILE = 'cache/data_update_timestamp.json'

def _load_data_update_timestamp():
    """åŠ è½½æ•°æ®æ›´æ–°æ—¶é—´æˆ³"""
    import json as json_module
    import os
    if os.path.exists(DATA_UPDATE_TIMESTAMP_FILE):
        try:
            with open(DATA_UPDATE_TIMESTAMP_FILE, 'r', encoding='utf-8') as f:
                return json_module.load(f)
        except Exception:
            return {}
    return {}

def _save_data_update_timestamp(timestamp_str):
    """ä¿å­˜æ•°æ®æ›´æ–°æ—¶é—´æˆ³"""
    import json as json_module
    import os
    try:
        os.makedirs('cache', exist_ok=True)
        with open(DATA_UPDATE_TIMESTAMP_FILE, 'w', encoding='utf-8') as f:
            json_module.dump({
                'last_update_time': timestamp_str,
                'last_update_date': timestamp_str.split()[0] if ' ' in timestamp_str else timestamp_str[:10]
            }, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"[_save_data_update_timestamp] ä¿å­˜æ—¶é—´æˆ³å¤±è´¥: {e}")

def _should_skip_update_after_trading_hours():
    """æ£€æŸ¥æ˜¯å¦åº”è¯¥è·³è¿‡æ›´æ–°ï¼ˆäº¤æ˜“æ—¥15:00åå·²æ›´æ–°è¿‡ï¼‰"""
    from datetime import datetime, timezone, timedelta
    
    # è·å–åŒ—äº¬æ—¶é—´ï¼ˆUTC+8ï¼‰
    utc_now = datetime.now(timezone.utc)
    beijing_tz = timezone(timedelta(hours=8))
    beijing_now = utc_now.astimezone(beijing_tz)
    
    current_hour = beijing_now.hour
    current_minute = beijing_now.minute
    today_str = beijing_now.strftime('%Y-%m-%d')
    
    # âœ… æ£€æŸ¥æ˜¯å¦æ˜¯äº¤æ˜“æ—¥15:00ä¹‹å
    if current_hour < 15:
        return False, None  # è¿˜æ²¡åˆ°15:00ï¼Œå¯ä»¥æ›´æ–°
    
    # âœ… 15:00ä¹‹åï¼Œæ£€æŸ¥ä»Šå¤©æ˜¯å¦å·²ç»æ›´æ–°è¿‡
    timestamp_data = _load_data_update_timestamp()
    if timestamp_data:
        last_update_date = timestamp_data.get('last_update_date')
        last_update_time_str = timestamp_data.get('last_update_time', '')
        
        # å¦‚æœä»Šå¤©å·²ç»æ›´æ–°è¿‡
        if last_update_date == today_str:
            # æ£€æŸ¥æ›´æ–°æ—¶é—´æ˜¯å¦åœ¨15:00ä¹‹å
            if last_update_time_str:
                try:
                    # è§£ææ—¶é—´æˆ³ï¼ˆå‡è®¾æ˜¯åŒ—äº¬æ—¶é—´ï¼‰
                    update_time = datetime.strptime(last_update_time_str, '%Y-%m-%d %H:%M:%S')
                    update_hour = update_time.hour
                    if update_hour >= 15:
                        return True, f'ä»Šæ—¥ {last_update_time_str} å·²æ›´æ–°ï¼Œäº¤æ˜“å·²ç»“æŸï¼Œæ— éœ€å†æ¬¡æ›´æ–°'
                except:
                    pass
        
        # å¦‚æœæ˜¨å¤©15:00åæ›´æ–°è¿‡ï¼Œä»Šå¤©15:00åä¹Ÿè®¤ä¸ºä¸éœ€è¦æ›´æ–°
        if last_update_date:
            try:
                last_date = datetime.strptime(last_update_date, '%Y-%m-%d')
                days_diff = (beijing_now.date() - last_date.date()).days
                if days_diff == 1:  # æ˜¨å¤©
                    if last_update_time_str:
                        try:
                            update_time = datetime.strptime(last_update_time_str, '%Y-%m-%d %H:%M:%S')
                            if update_time.hour >= 15:
                                return True, f'{last_update_date} {last_update_time_str.split()[1] if " " in last_update_time_str else ""} å·²æ›´æ–°ï¼Œä»Šæ—¥äº¤æ˜“å·²ç»“æŸ'
                        except:
                            pass
            except:
                pass
    
    # âœ… å…³é”®ä¿®å¤ï¼šå¦‚æœæ—¶é—´æˆ³æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½†å½“å‰æ—¶é—´å·²ç»æ˜¯15:00åï¼Œä¹Ÿé˜»æ­¢æ›´æ–°
    # å› ä¸ºäº¤æ˜“å·²ç»“æŸï¼Œå³ä½¿æ²¡æœ‰æ—¶é—´æˆ³è®°å½•ï¼Œä¹Ÿä¸åº”è¯¥è‡ªåŠ¨æ›´æ–°ï¼ˆé¿å…åœ¨éäº¤æ˜“æ—¶é—´æµªè´¹èµ„æºï¼‰
    # æ³¨æ„ï¼šè¿™ä¸ªé€»è¾‘åªé€‚ç”¨äºè‡ªåŠ¨æ›´æ–°ï¼Œæ‰‹åŠ¨ç‚¹å‡»"æ›´æ–°æ•°æ®"æŒ‰é’®ä»ç„¶å…è®¸æ›´æ–°
    # ä½†è¿™é‡Œæˆ‘ä»¬ç»Ÿä¸€å¤„ç†ï¼š15:00åå¦‚æœæ²¡æœ‰ä»Šå¤©çš„æ—¶é—´æˆ³ï¼Œä¹Ÿé˜»æ­¢æ›´æ–°
    # ç”¨æˆ·å¦‚æœç¡®å®éœ€è¦æ›´æ–°ï¼Œå¯ä»¥æ‰‹åŠ¨ç‚¹å‡»æŒ‰é’®ï¼ˆæ‰‹åŠ¨æ›´æ–°ä¼šç»•è¿‡è¿™ä¸ªæ£€æŸ¥ï¼Œæˆ–è€…æˆ‘ä»¬å¯ä»¥åœ¨æ‰‹åŠ¨æ›´æ–°æ—¶ä¹Ÿæ£€æŸ¥ï¼‰
    
    # å®é™…ä¸Šï¼Œå¦‚æœæ—¶é—´æˆ³æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯´æ˜å¯èƒ½æ˜¯ç¬¬ä¸€æ¬¡è¿è¡Œæˆ–åˆšéƒ¨ç½²
    # åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œ15:00åä¸åº”è¯¥è‡ªåŠ¨æ›´æ–°ï¼ˆå› ä¸ºäº¤æ˜“å·²ç»“æŸï¼‰
    # ä½†å¦‚æœæ˜¯æ‰‹åŠ¨ç‚¹å‡»"æ›´æ–°æ•°æ®"ï¼Œåº”è¯¥å…è®¸ï¼ˆå› ä¸ºç”¨æˆ·æ˜ç¡®è¦æ±‚ï¼‰
    # æ‰€ä»¥æˆ‘ä»¬è¿”å› Falseï¼Œè®©è°ƒç”¨æ–¹å†³å®šï¼ˆå¦‚æœæ˜¯è‡ªåŠ¨æ›´æ–°ï¼Œåº”è¯¥é˜»æ­¢ï¼›å¦‚æœæ˜¯æ‰‹åŠ¨ï¼Œå¯ä»¥å…è®¸ï¼‰
    
    # ä½†é—®é¢˜æ˜¯ï¼šå‰ç«¯æ— æ³•åŒºåˆ†æ˜¯è‡ªåŠ¨è¿˜æ˜¯æ‰‹åŠ¨
    # è§£å†³æ–¹æ¡ˆï¼šåœ¨ check_data_freshness ä¸­ï¼Œå¦‚æœæ˜¯15:00åä¸”æ²¡æœ‰æ—¶é—´æˆ³ï¼Œè¿”å› fresh=True
    # åœ¨ start_data_update ä¸­ï¼Œå¦‚æœæ˜¯15:00åä¸”æ²¡æœ‰æ—¶é—´æˆ³ï¼Œä¹Ÿé˜»æ­¢æ›´æ–°
    
    return False, None  # æš‚æ—¶å…è®¸ï¼Œä½†ä¼šåœ¨ check_data_freshness å’Œ start_data_update ä¸­å†æ¬¡æ£€æŸ¥

def check_data_freshness(target_date: str = None) -> dict:
    """
    æ£€æŸ¥æœ¬åœ°æ•°æ®æ˜¯å¦æ»¡è¶³æ‰«æéœ€æ±‚
    :param target_date: ç›®æ ‡æ‰«ææ—¥æœŸï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨ä»Šå¤©
    :return: {'fresh': bool, 'outdated_count': int, 'total': int, 'latest_data_date': str}
    """
    import os
    import pandas as pd
    from datetime import datetime
    
    if target_date is None:
        target_date = datetime.now().strftime('%Y-%m-%d')
    
    weekly_dir = 'cache/weekly_kline'
    if not os.path.exists(weekly_dir):
        return {'fresh': False, 'outdated_count': 0, 'total': 0, 'latest_data_date': None, 'message': 'ç¼“å­˜ç›®å½•ä¸å­˜åœ¨'}
    
    target_ts = pd.to_datetime(target_date)
    # å…è®¸7å¤©çš„è¯¯å·®ï¼ˆå‘¨Kçº¿æ•°æ®å¯èƒ½æ»åï¼‰
    min_acceptable_date = target_ts - pd.Timedelta(days=7)
    
    total = 0
    outdated = 0
    dates = []
    
    for f in os.listdir(weekly_dir):
        if f.endswith('.csv'):
            total += 1
            try:
                df = pd.read_csv(os.path.join(weekly_dir, f))
                if 'æ—¥æœŸ' in df.columns and len(df) > 0:
                    max_date = pd.to_datetime(str(df['æ—¥æœŸ'].max())[:10])
                    dates.append(max_date)
                    if max_date < min_acceptable_date:
                        outdated += 1
            except:
                outdated += 1
    
    latest_data_date = max(dates).strftime('%Y-%m-%d') if dates else None
    # å¦‚æœè¶…è¿‡10%çš„è‚¡ç¥¨æ•°æ®è¿‡æœŸï¼Œè®¤ä¸ºéœ€è¦æ›´æ–°
    need_update = outdated > total * 0.1 if total > 0 else True
    
    return {
        'fresh': not need_update,
        'outdated_count': outdated,
        'total': total,
        'latest_data_date': latest_data_date,
        'target_date': target_date,
        'message': f'å…±{total}åªè‚¡ç¥¨ï¼Œ{outdated}åªæ•°æ®è¿‡æœŸ' if need_update else 'æ•°æ®å·²æ˜¯æœ€æ–°'
    }

def _load_data_markers():
    """åŠ è½½æ•°æ®æ ‡è®°æ–‡ä»¶ï¼Œè®°å½•æ¯åªè‚¡ç¥¨çš„æœ€æ–°æ•°æ®æ—¥æœŸå’Œæ›´æ–°æ—¶é—´æˆ³"""
    import json as json_module
    marker_file = 'cache/data_markers.json'
    if os.path.exists(marker_file):
        try:
            with open(marker_file, 'r', encoding='utf-8') as f:
                return json_module.load(f)
        except Exception:
            return {}
    return {}

def _save_data_markers(markers):
    """ä¿å­˜æ•°æ®æ ‡è®°æ–‡ä»¶"""
    import json as json_module
    os.makedirs('cache', exist_ok=True)
    marker_file = 'cache/data_markers.json'
    with open(marker_file, 'w', encoding='utf-8') as f:
        json_module.dump(markers, f, ensure_ascii=False, indent=2)

def _get_stock_latest_dates(code):
    """è·å–è‚¡ç¥¨çš„æœ€æ–°æ•°æ®æ—¥æœŸï¼ˆä»æ ‡è®°æ–‡ä»¶æˆ–CSVæ–‡ä»¶ï¼‰"""
    markers = _load_data_markers()
    
    # ä¼˜å…ˆä»æ ‡è®°æ–‡ä»¶è¯»å–
    if code in markers:
        return {
            'daily': markers[code].get('daily_latest_date'),
            'weekly': markers[code].get('weekly_latest_date'),
            'last_update_timestamp': markers[code].get('last_update_timestamp')
        }
    
    # å¦‚æœæ ‡è®°æ–‡ä»¶æ²¡æœ‰ï¼Œä»CSVæ–‡ä»¶è¯»å–å¹¶æ›´æ–°æ ‡è®°
    result = {'daily': None, 'weekly': None, 'last_update_timestamp': None}
    
    # è¯»å–æ—¥Kçº¿æœ€æ–°æ—¥æœŸ
    daily_path = f'cache/daily_kline/{code}.csv'
    if os.path.exists(daily_path):
        try:
            df = pd.read_csv(daily_path)
            if len(df) > 0 and 'æ—¥æœŸ' in df.columns:
                result['daily'] = str(df['æ—¥æœŸ'].max())[:10]
        except Exception:
            pass
    
    # è¯»å–å‘¨Kçº¿æœ€æ–°æ—¥æœŸ
    weekly_path = f'cache/weekly_kline/{code}.csv'
    if os.path.exists(weekly_path):
        try:
            df = pd.read_csv(weekly_path)
            if len(df) > 0 and 'æ—¥æœŸ' in df.columns:
                result['weekly'] = str(df['æ—¥æœŸ'].max())[:10]
        except Exception:
            pass
    
    # æ›´æ–°æ ‡è®°æ–‡ä»¶
    if code not in markers:
        markers[code] = {}
    markers[code]['daily_latest_date'] = result['daily']
    markers[code]['weekly_latest_date'] = result['weekly']
    _save_data_markers(markers)
    
    return result

def _update_stock_marker(code, daily_latest_date=None, weekly_latest_date=None):
    """æ›´æ–°è‚¡ç¥¨çš„æ•°æ®æ ‡è®°ï¼ˆåŒ…å«æ—¶é—´æˆ³ï¼‰"""
    from datetime import datetime
    markers = _load_data_markers()
    if code not in markers:
        markers[code] = {}
    if daily_latest_date:
        markers[code]['daily_latest_date'] = daily_latest_date
    if weekly_latest_date:
        markers[code]['weekly_latest_date'] = weekly_latest_date
    # âœ… æ›´æ–°æ—¶è®°å½•æ—¶é—´æˆ³
    markers[code]['last_update_timestamp'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    _save_data_markers(markers)

def _is_data_up_to_date(code, latest_date=None, last_update_timestamp=None):
    """
    åˆ¤æ–­æ•°æ®æ˜¯å¦å·²æ˜¯æœ€æ–°ï¼ˆæ™ºèƒ½åˆ¤æ–­ï¼‰
    è§„åˆ™ï¼š
    - å¦‚æœæœ€æ–°æ—¥æœŸæ˜¯ä»Šå¤© â†’ è®¤ä¸ºæ˜¯æœ€æ–°
    - å¦‚æœæœ€æ–°æ—¥æœŸæ˜¯æ˜¨å¤©ï¼Œä¸”æ›´æ–°æ—¶é—´åœ¨å½“å¤©15:00åï¼Œåœ¨ç¬¬äºŒå¤©9:30å‰éƒ½è®¤ä¸ºæ˜¯æœ€æ–°
    - å¦‚æœæœ€æ–°æ—¥æœŸæ˜¯2å¤©å‰æˆ–æ›´æ—© â†’ éœ€è¦æ›´æ–°
    """
    from datetime import datetime, timedelta
    
    if not latest_date:
        return False
    
    today = datetime.now()
    today_str = today.strftime('%Y-%m-%d')
    
    # å¦‚æœæœ€æ–°æ—¥æœŸæ˜¯ä»Šå¤©ï¼Œè®¤ä¸ºæ˜¯æœ€æ–°
    if latest_date >= today_str:
        return True
    
    # å¦‚æœæœ€æ–°æ—¥æœŸæ˜¯æ˜¨å¤©ï¼Œæ£€æŸ¥æ›´æ–°æ—¶é—´
    yesterday = (today - timedelta(days=1)).strftime('%Y-%m-%d')
    if latest_date == yesterday:
        if last_update_timestamp:
            try:
                update_time = datetime.strptime(last_update_timestamp, '%Y-%m-%d %H:%M:%S')
                update_date = update_time.strftime('%Y-%m-%d')
                
                # å¦‚æœæ›´æ–°æ—¥æœŸæ˜¯ä»Šå¤©æˆ–æ˜¨å¤©ï¼Œä¸”æ›´æ–°æ—¶é—´åœ¨å½“å¤©15:00å
                if update_date in [today_str, yesterday]:
                    update_hour = update_time.hour
                    if update_hour >= 15:  # 15:00åï¼ˆ3ç‚¹åï¼‰
                        # æ£€æŸ¥å½“å‰æ—¶é—´ï¼šå¦‚æœæ˜¯ç¬¬äºŒå¤©9:30ä»¥åï¼Œéœ€è¦æ›´æ–°
                        current_hour = today.hour
                        current_minute = today.minute
                        if current_hour < 9 or (current_hour == 9 and current_minute < 30):
                            # ç¬¬äºŒå¤©9:30å‰ï¼Œè®¤ä¸ºæ˜¯æœ€æ–°
                            return True
                        # ç¬¬äºŒå¤©9:30åï¼Œéœ€è¦æ›´æ–°
                        return False
            except Exception:
                pass
        # å¦‚æœæ²¡æœ‰æ—¶é—´æˆ³ï¼Œä½†æ—¥æœŸæ˜¯æ˜¨å¤©ï¼Œä¹Ÿè®¤ä¸ºæ˜¯æœ€æ–°ï¼ˆå…¼å®¹æ—§æ•°æ®ï¼‰
        return True
    
    # å¦‚æœæœ€æ–°æ—¥æœŸæ˜¯2å¤©å‰æˆ–æ›´æ—©ï¼Œéœ€è¦æ›´æ–°
    latest_dt = datetime.strptime(latest_date, '%Y-%m-%d')
    days_diff = (today - latest_dt).days
    return days_diff <= 1  # 1å¤©å†…è®¤ä¸ºæ˜¯æœ€æ–°ï¼Œè¶…è¿‡1å¤©éœ€è¦æ›´æ–°

def _get_sina_daily_kline(code, datalen=500):
    """ä»æ–°æµªè·å–æ—¥Kçº¿æ•°æ®ï¼ˆæ”¯æŒæŒ‡å®šæ•°æ®æ¡æ•°ï¼‰"""
    try:
        import requests
        import json as json_module
        import pandas as pd
        
        # è½¬æ¢ä»£ç æ ¼å¼
        if code.startswith('6'):
            symbol = f'sh{code}'
        else:
            symbol = f'sz{code}'
        
        url = f'https://quotes.sina.cn/cn/api/jsonp_v2.php/data/CN_MarketDataService.getKLineData?symbol={symbol}&scale=240&datalen={datalen}'
        
        session = requests.Session()
        session.trust_env = False
        session.headers.update({'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)'})
        
        resp = session.get(url, timeout=5)
        if resp.status_code == 200:
            text = resp.text
            if 'data(' in text:
                json_str = text.split('data(')[1].rsplit(')', 1)[0]
                data = json_module.loads(json_str)
                if data:
                    df = pd.DataFrame(data)
                    df = df.rename(columns={
                        'day': 'æ—¥æœŸ',
                        'open': 'å¼€ç›˜',
                        'close': 'æ”¶ç›˜',
                        'high': 'æœ€é«˜',
                        'low': 'æœ€ä½',
                        'volume': 'æˆäº¤é‡'
                    })
                    df = df[['æ—¥æœŸ', 'å¼€ç›˜', 'æ”¶ç›˜', 'æœ€é«˜', 'æœ€ä½', 'æˆäº¤é‡']]
                    df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
                    df = df.dropna(subset=['æ—¥æœŸ'])
                    df = df.sort_values('æ—¥æœŸ').reset_index(drop=True)
                    df['æ—¥æœŸ'] = df['æ—¥æœŸ'].dt.strftime('%Y-%m-%d')
                    return df
        return None
    except Exception:
        return None

def _get_sina_weekly_kline(code, datalen=200):
    """ä»æ–°æµªè·å–å‘¨Kçº¿æ•°æ®ï¼ˆæ”¯æŒæŒ‡å®šæ•°æ®æ¡æ•°ï¼‰"""
    try:
        import requests
        import json as json_module
        import pandas as pd
        
        # è½¬æ¢ä»£ç æ ¼å¼
        if code.startswith('6'):
            symbol = f'sh{code}'
        else:
            symbol = f'sz{code}'
        
        url = f'https://quotes.sina.cn/cn/api/jsonp_v2.php/data/CN_MarketDataService.getKLineData?symbol={symbol}&scale=1200&datalen={datalen}'
        
        session = requests.Session()
        session.trust_env = False
        session.headers.update({'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)'})
        
        resp = session.get(url, timeout=5)
        if resp.status_code == 200:
            text = resp.text
            if 'data(' in text:
                json_str = text.split('data(')[1].rsplit(')', 1)[0]
                data = json_module.loads(json_str)
                if data:
                    df = pd.DataFrame(data)
                    df = df.rename(columns={
                        'day': 'æ—¥æœŸ',
                        'open': 'å¼€ç›˜',
                        'close': 'æ”¶ç›˜',
                        'high': 'æœ€é«˜',
                        'low': 'æœ€ä½',
                        'volume': 'å‘¨æˆäº¤é‡'
                    })
                    df = df[['æ—¥æœŸ', 'å¼€ç›˜', 'æ”¶ç›˜', 'æœ€é«˜', 'æœ€ä½', 'å‘¨æˆäº¤é‡']]
                    df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
                    df = df.dropna(subset=['æ—¥æœŸ'])
                    df = df.sort_values('æ—¥æœŸ').reset_index(drop=True)
                    df['æ—¥æœŸ'] = df['æ—¥æœŸ'].dt.strftime('%Y-%m-%d')
                    return df
        return None
    except Exception:
        return None

def _data_update_worker():
    """åå°æ•°æ®æ›´æ–°å·¥ä½œçº¿ç¨‹ï¼šè°ƒç”¨ update_data_sina.py æ‰¹é‡ä¸‹è½½ï¼Œå®Œæˆåè‡ªåŠ¨èåˆ"""
    global data_update_progress, data_update_stop_flag
    import subprocess
    import sys
    import time
    import os
    
    try:
        data_update_progress['status'] = 'running'
        data_update_progress['message'] = 'æ­£åœ¨å¯åŠ¨æ‰¹é‡æ•°æ®ä¸‹è½½...'
        data_update_progress['start_time'] = time.time()
        
        # è°ƒç”¨ update_data_sina.py è„šæœ¬è¿›è¡Œæ‰¹é‡ä¸‹è½½
        script_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'update_data_sina.py')
        
        if not os.path.exists(script_path):
            data_update_progress['status'] = 'error'
            data_update_progress['message'] = f'æ›´æ–°è„šæœ¬ä¸å­˜åœ¨: {script_path}'
            return
        
        data_update_progress['message'] = 'æ­£åœ¨æ‰¹é‡ä¸‹è½½æœ€æ–°æ•°æ®ï¼ˆä½¿ç”¨æ–°æµªè´¢ç»APIï¼‰...'
        data_update_progress['data_source'] = 'sina'
        
        # è¿è¡Œè„šæœ¬ï¼ˆå®æ—¶è¾“å‡ºè¿›åº¦ï¼‰
        process = subprocess.Popen(
            [sys.executable, script_path],
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True,
            bufsize=1,
            universal_newlines=True,
            cwd=os.path.dirname(os.path.abspath(__file__))
        )
        
        # å®æ—¶è¯»å–è¾“å‡ºå¹¶æ›´æ–°è¿›åº¦
        output_lines = []
        for line in process.stdout:
            if data_update_stop_flag:
                process.terminate()
                data_update_progress['status'] = 'stopped'
                data_update_progress['message'] = 'æ›´æ–°å·²åœæ­¢'
                return
            
            line = line.strip()
            if line:
                output_lines.append(line)
                # è§£ææ€»è‚¡ç¥¨æ•°ï¼ˆä¾‹å¦‚ï¼šğŸ“Š å‚ä¸æ›´æ–°è‚¡ç¥¨æ•°: 5007ï¼ˆå…¨éƒ¨ï¼‰ï¼‰
                if 'å‚ä¸æ›´æ–°è‚¡ç¥¨æ•°:' in line and 'ï¼ˆå…¨éƒ¨ï¼‰' in line:
                    try:
                        parts = line.split('å‚ä¸æ›´æ–°è‚¡ç¥¨æ•°:')[1].split('ï¼ˆ')[0].strip()
                        total = int(parts)
                        data_update_progress['total'] = total
                    except:
                        pass
                # è§£æè¿›åº¦ä¿¡æ¯ï¼ˆä¾‹å¦‚ï¼šè¿›åº¦: 200/5007 (4.0%)ï¼‰
                if 'è¿›åº¦:' in line and '/' in line:
                    try:
                        parts = line.split('è¿›åº¦:')[1].split('|')[0].strip()
                        if '/' in parts:
                            current, total = parts.split('/')
                            current = int(current.split()[0])
                            total = int(total.split()[0])
                            data_update_progress['processed'] = current
                            if not data_update_progress.get('total'):
                                data_update_progress['total'] = total
                            data_update_progress['percentage'] = round(current / total * 100, 1) if total > 0 else 0
                            # è§£æé€Ÿåº¦ä¿¡æ¯
                            speed_info = ''
                            if 'é€Ÿåº¦:' in line:
                                try:
                                    speed_part = line.split('é€Ÿåº¦:')[1].split('|')[0].strip()
                                    speed = float(speed_part.split()[0])
                                    speed_info = f' | é€Ÿåº¦: {speed:.1f}åª/ç§’'
                                except:
                                    pass
                            data_update_progress['message'] = f'æ­£åœ¨æ‰¹é‡ä¸‹è½½: {current}/{total} ({data_update_progress["percentage"]:.1f}%){speed_info}'
                    except:
                        pass
                # è§£ææ–°å¢è®°å½•æ•°
                if 'æ—¥Kæ–°å¢:' in line:
                    try:
                        parts = line.split('æ—¥Kæ–°å¢:')[1].split('|')[0].strip()
                        daily_new = int(parts.split()[0])
                        data_update_progress['updated_count'] = daily_new
                    except:
                        pass
                if 'å‘¨Kæ–°å¢:' in line:
                    try:
                        parts = line.split('å‘¨Kæ–°å¢:')[1].split('|')[0].strip()
                        weekly_new = int(parts.split()[0])
                        # å¯ä»¥è®°å½•å‘¨Kæ–°å¢æ•°ï¼Œä½†ä¸»è¦ç”¨æ—¥Kæ–°å¢ä½œä¸º updated_count
                    except:
                        pass
        
        # ç­‰å¾…è¿›ç¨‹å®Œæˆ
        return_code = process.wait()
        
        if return_code != 0:
            error_msg = '\n'.join(output_lines[-10:])  # æœ€å10è¡Œ
            data_update_progress['status'] = 'error'
            data_update_progress['message'] = f'ä¸‹è½½å¤±è´¥ï¼ˆè¿”å›ç : {return_code}ï¼‰: {error_msg[:200]}'
            return
        
        elapsed = time.time() - data_update_progress['start_time']
        
        # âœ… ä¸‹è½½å®Œæˆåï¼Œè‡ªåŠ¨èåˆæ•°æ®ï¼ˆé‡å»º data_markers.jsonï¼‰
        data_update_progress['message'] = f'ä¸‹è½½å®Œæˆï¼è€—æ—¶ {elapsed:.1f}ç§’ã€‚æ­£åœ¨èåˆæ•°æ®åˆ°ä¸ªè‚¡æ•°æ®...'
        data_update_progress['status'] = 'merging'  # èåˆä¸­çŠ¶æ€
        
        try:
            # è°ƒç”¨ merge_data_markers.py è¿›è¡Œæ•°æ®èåˆ
            merge_script = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'merge_data_markers.py')
            if os.path.exists(merge_script):
                merge_result = subprocess.run(
                    [sys.executable, merge_script],
                    capture_output=True,
                    text=True,
                    timeout=300,  # 5åˆ†é’Ÿè¶…æ—¶
                    cwd=os.path.dirname(os.path.abspath(__file__))
                )
                if merge_result.returncode == 0:
                    # è§£æèåˆç»“æœ
                    merge_output = merge_result.stdout
                    daily_info = ''
                    weekly_info = ''
                    total_markers = ''
                    if 'æ—¥ K:' in merge_output:
                        daily_info = merge_output.split('æ—¥ K:')[1].split('\n')[0].strip()
                    if 'å‘¨ K:' in merge_output:
                        weekly_info = merge_output.split('å‘¨ K:')[1].split('\n')[0].strip()
                    if 'data_markers æ€»æ¡æ•°:' in merge_output:
                        total_markers = merge_output.split('data_markers æ€»æ¡æ•°:')[1].split('\n')[0].strip()
                    
                    data_update_progress['status'] = 'completed'
                    summary = f'âœ… æ›´æ–°å®Œæˆï¼è€—æ—¶ {elapsed:.1f}ç§’ã€‚æ•°æ®å·²èåˆåˆ°ä¸ªè‚¡æ•°æ®ã€‚'
                    if daily_info:
                        summary += f' {daily_info}'
                    if weekly_info:
                        summary += f' {weekly_info}'
                    if total_markers:
                        summary += f' æ€»æ¡æ•°: {total_markers}'
                    data_update_progress['message'] = summary
                    
                    # âœ… è®°å½•æ›´æ–°æ—¶é—´æˆ³
                    from datetime import datetime
                    timestamp_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    _save_data_update_timestamp(timestamp_str)
                    print(f"[æ•°æ®æ›´æ–°] âœ… æ›´æ–°æ—¶é—´æˆ³å·²è®°å½•: {timestamp_str}")
                else:
                    data_update_progress['status'] = 'completed'
                    data_update_progress['message'] = f'âœ… ä¸‹è½½å®Œæˆï¼è€—æ—¶ {elapsed:.1f}ç§’ã€‚âš ï¸ èåˆè¿‡ç¨‹æœ‰è­¦å‘Š: {merge_result.stderr[:200] if merge_result.stderr else "æ— é”™è¯¯ä¿¡æ¯"}'
                    # âœ… è®°å½•æ›´æ–°æ—¶é—´æˆ³ï¼ˆå³ä½¿èåˆæœ‰è­¦å‘Šï¼Œæ•°æ®å·²ä¸‹è½½å®Œæˆï¼‰
                    from datetime import datetime
                    timestamp_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    _save_data_update_timestamp(timestamp_str)
                    print(f"[æ•°æ®æ›´æ–°] âœ… æ›´æ–°æ—¶é—´æˆ³å·²è®°å½•: {timestamp_str}")
            else:
                data_update_progress['status'] = 'completed'
                data_update_progress['message'] = f'âœ… ä¸‹è½½å®Œæˆï¼è€—æ—¶ {elapsed:.1f}ç§’ã€‚âš ï¸ èåˆè„šæœ¬ä¸å­˜åœ¨ï¼Œè·³è¿‡èåˆã€‚'
                # âœ… è®°å½•æ›´æ–°æ—¶é—´æˆ³ï¼ˆå³ä½¿èåˆè„šæœ¬ä¸å­˜åœ¨ï¼Œæ•°æ®å·²ä¸‹è½½å®Œæˆï¼‰
                from datetime import datetime
                timestamp_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                _save_data_update_timestamp(timestamp_str)
                print(f"[æ•°æ®æ›´æ–°] âœ… æ›´æ–°æ—¶é—´æˆ³å·²è®°å½•: {timestamp_str}")
        except subprocess.TimeoutExpired:
            data_update_progress['status'] = 'completed'
            data_update_progress['message'] = f'âœ… ä¸‹è½½å®Œæˆï¼è€—æ—¶ {elapsed:.1f}ç§’ã€‚âš ï¸ èåˆè¶…æ—¶ï¼ˆ5åˆ†é’Ÿï¼‰ï¼Œä½†æ•°æ®å·²ä¸‹è½½å®Œæˆã€‚'
            # âœ… è®°å½•æ›´æ–°æ—¶é—´æˆ³ï¼ˆå³ä½¿èåˆè¶…æ—¶ï¼Œæ•°æ®å·²ä¸‹è½½å®Œæˆï¼‰
            from datetime import datetime
            timestamp_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            _save_data_update_timestamp(timestamp_str)
            print(f"[æ•°æ®æ›´æ–°] âœ… æ›´æ–°æ—¶é—´æˆ³å·²è®°å½•: {timestamp_str}")
        except Exception as merge_error:
            data_update_progress['status'] = 'completed'
            data_update_progress['message'] = f'âœ… ä¸‹è½½å®Œæˆï¼è€—æ—¶ {elapsed:.1f}ç§’ã€‚âš ï¸ èåˆå¤±è´¥: {str(merge_error)[:100]}'
            # âœ… è®°å½•æ›´æ–°æ—¶é—´æˆ³ï¼ˆå³ä½¿èåˆå¤±è´¥ï¼Œæ•°æ®å·²ä¸‹è½½å®Œæˆï¼‰
            from datetime import datetime
            timestamp_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            _save_data_update_timestamp(timestamp_str)
            print(f"[æ•°æ®æ›´æ–°] âœ… æ›´æ–°æ—¶é—´æˆ³å·²è®°å½•: {timestamp_str}")
        
    except Exception as e:
        data_update_progress['status'] = 'error'
        data_update_progress['message'] = f'æ›´æ–°å‡ºé”™: {str(e)}'

@app.route('/api/start_data_update', methods=['POST'])
@require_login
def start_data_update():
    """å¯åŠ¨æ•°æ®æ›´æ–°"""
    global data_update_progress, data_update_stop_flag
    import threading  # âœ… æ·»åŠ  threading å¯¼å…¥
    
    if data_update_progress['status'] == 'running':
        return jsonify({'success': False, 'message': 'æ•°æ®æ›´æ–°æ­£åœ¨è¿›è¡Œä¸­'})
    
    # âœ… æ£€æŸ¥æ˜¯å¦åº”è¯¥è·³è¿‡æ›´æ–°ï¼ˆäº¤æ˜“æ—¥15:00åå·²æ›´æ–°è¿‡ï¼‰
    should_skip, skip_reason = _should_skip_update_after_trading_hours()
    if should_skip:
        return jsonify({
            'success': False,
            'message': skip_reason or 'äº¤æ˜“å·²ç»“æŸï¼Œä»Šæ—¥å·²æ›´æ–°ï¼Œæ— éœ€å†æ¬¡æ›´æ–°',
            'skip_reason': 'trading_hours_ended'
        })
    
    # âœ… é¢å¤–æ£€æŸ¥ï¼šå¦‚æœå½“å‰æ—¶é—´å·²ç»æ˜¯15:00åï¼Œä¸”æ²¡æœ‰æ—¶é—´æˆ³æ–‡ä»¶ï¼Œä¹Ÿé˜»æ­¢æ›´æ–°
    from datetime import datetime, timezone, timedelta
    utc_now = datetime.now(timezone.utc)
    beijing_tz = timezone(timedelta(hours=8))
    beijing_now = utc_now.astimezone(beijing_tz)
    if beijing_now.hour >= 15:
        timestamp_data = _load_data_update_timestamp()
        if not timestamp_data or not timestamp_data.get('last_update_date'):
            # 15:00åä¸”æ²¡æœ‰æ—¶é—´æˆ³è®°å½•ï¼Œé˜»æ­¢æ›´æ–°ï¼ˆäº¤æ˜“å·²ç»“æŸï¼‰
            return jsonify({
                'success': False,
                'message': f'å½“å‰æ—¶é—´ {beijing_now.strftime("%H:%M")}ï¼Œäº¤æ˜“å·²ç»“æŸã€‚å¦‚éœ€æ›´æ–°æ•°æ®ï¼Œè¯·ç¨åå†è¯•æˆ–æ‰‹åŠ¨ç‚¹å‡»"æ›´æ–°æ•°æ®"æŒ‰é’®',
                'skip_reason': 'trading_hours_ended_no_timestamp'
            })
    
    # âœ… å…ˆæ£€æŸ¥æ•°æ®æ˜¯å¦å·²æ˜¯æœ€æ–°ï¼ˆä½¿ç”¨æ ‡è®°æ–‡ä»¶å¿«é€Ÿæ£€æŸ¥ï¼‰
    from datetime import datetime
    today = datetime.now()
    today_str = today.strftime('%Y-%m-%d')
    markers = _load_data_markers()
    
    if markers:
        # ç»Ÿè®¡å·²æ˜¯æœ€æ–°çš„è‚¡ç¥¨æ•°é‡
        up_to_date_count = 0
        total_marked = len(markers)
        
        for code, marker_data in markers.items():
            daily_date = marker_data.get('daily_latest_date')
            weekly_date = marker_data.get('weekly_latest_date')
            last_update_timestamp = marker_data.get('last_update_timestamp')
            
            # ä½¿ç”¨æ™ºèƒ½åˆ¤æ–­å‡½æ•°
            daily_is_up_to_date = _is_data_up_to_date(code, daily_date, last_update_timestamp)
            weekly_is_up_to_date = _is_data_up_to_date(code, weekly_date, last_update_timestamp)
            
            # å¦‚æœæ—¥Kçº¿å’Œå‘¨Kçº¿éƒ½å·²æ˜¯æœ€æ–°ï¼Œè®¤ä¸ºè¯¥è‚¡ç¥¨å·²æ˜¯æœ€æ–°
            if daily_is_up_to_date and weekly_is_up_to_date:
                up_to_date_count += 1
        
        # å¦‚æœè¶…è¿‡90%çš„è‚¡ç¥¨å·²æ˜¯æœ€æ–°ï¼Œæç¤ºç”¨æˆ·ä¸éœ€è¦æ›´æ–°
        if total_marked > 0:
            up_to_date_pct = (up_to_date_count / total_marked) * 100
            # âœ… é™ä½é˜ˆå€¼åˆ°85%ï¼Œå› ä¸ºé€šè¾¾ä¿¡å¯¼å…¥çš„æ•°æ®æ²¡æœ‰æ—¶é—´æˆ³ï¼Œä½†æ—¥æœŸæ˜¯æœ€æ–°çš„
            if up_to_date_pct >= 85:
                return jsonify({
                    'success': False,
                    'message': f'æ•°æ®å·²æ˜¯æœ€æ–°ï¼{up_to_date_count}/{total_marked} ({up_to_date_pct:.1f}%) åªè‚¡ç¥¨æ•°æ®å·²æ˜¯æœ€æ–°ï¼Œæ— éœ€æ›´æ–°',
                    'up_to_date_count': up_to_date_count,
                    'total_marked': total_marked,
                    'up_to_date_pct': round(up_to_date_pct, 1)
                })
    
    # é‡ç½®çŠ¶æ€
    data_update_stop_flag = False
    data_update_progress = {
        'status': 'running',
        'processed': 0,
        'total': 0,
        'percentage': 0,
        'current_stock': '',
        'message': 'æ­£åœ¨å¯åŠ¨...',
        'updated_count': 0,
        'failed_count': 0,
        'start_time': None
    }
    
    # å¯åŠ¨åå°çº¿ç¨‹
    update_thread = threading.Thread(target=_data_update_worker)
    update_thread.daemon = True
    update_thread.start()
    
    return jsonify({'success': True, 'message': 'æ•°æ®æ›´æ–°å·²å¯åŠ¨'})

@app.route('/api/get_data_update_timestamp', methods=['GET'])
@require_login
def get_data_update_timestamp():
    """è·å–æ•°æ®æ›´æ–°æ—¶é—´æˆ³"""
    try:
        timestamp_data = _load_data_update_timestamp()
        should_skip, skip_reason = _should_skip_update_after_trading_hours()
        
        return jsonify({
            'success': True,
            'last_update_time': timestamp_data.get('last_update_time', ''),
            'last_update_date': timestamp_data.get('last_update_date', ''),
            'should_skip': should_skip,
            'message': skip_reason
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'è·å–æ—¶é—´æˆ³å¤±è´¥: {str(e)}',
            'should_skip': False
        }), 500

@app.route('/api/get_data_update_progress', methods=['GET'])
@require_login
def get_data_update_progress():
    """è·å–æ•°æ®æ›´æ–°è¿›åº¦"""
    global data_update_progress
    return jsonify(data_update_progress)

@app.route('/api/stop_data_update', methods=['POST'])
@require_login
def stop_data_update():
    """åœæ­¢æ•°æ®æ›´æ–°"""
    global data_update_stop_flag
    data_update_stop_flag = True
    return jsonify({'success': True, 'message': 'å·²å‘é€åœæ­¢è¯·æ±‚'})

@app.route('/api/check_data_freshness', methods=['POST'])
@require_login
def api_check_data_freshness():
    """æ£€æŸ¥æ•°æ®æ–°é²œåº¦"""
    data = request.get_json() or {}
    target_date = data.get('scan_date', None)
    
    # âœ… å…ˆæ£€æŸ¥æ˜¯å¦åº”è¯¥è·³è¿‡æ›´æ–°ï¼ˆäº¤æ˜“æ—¥15:00åå·²æ›´æ–°è¿‡ï¼‰
    should_skip, skip_reason = _should_skip_update_after_trading_hours()
    print(f"[api_check_data_freshness] _should_skip_update_after_trading_hours() è¿”å›: should_skip={should_skip}, skip_reason={skip_reason}")
    if should_skip:
        print(f"[api_check_data_freshness] âœ… è¿”å› should_skip=Trueï¼ˆé€šè¿‡ _should_skip_update_after_trading_hoursï¼‰")
        return jsonify({
            'success': True,
            'fresh': True,  # æ ‡è®°ä¸ºå·²æ˜¯æœ€æ–°ï¼Œé¿å…è§¦å‘æ›´æ–°
            'message': skip_reason or 'äº¤æ˜“å·²ç»“æŸï¼Œä»Šæ—¥å·²æ›´æ–°ï¼Œæ— éœ€æ›´æ–°',
            'skip_reason': 'trading_hours_ended',
            'should_skip': True
        })
    
    # âœ… é¢å¤–æ£€æŸ¥ï¼šå¦‚æœå½“å‰æ—¶é—´å·²ç»æ˜¯15:00åï¼Œä¸”æ²¡æœ‰æ—¶é—´æˆ³æ–‡ä»¶ï¼Œä¹Ÿé˜»æ­¢è‡ªåŠ¨æ›´æ–°
    # ï¼ˆå› ä¸ºäº¤æ˜“å·²ç»“æŸï¼Œä¸åº”è¯¥è‡ªåŠ¨æ›´æ–°ï¼‰
    from datetime import datetime, timezone, timedelta
    utc_now = datetime.now(timezone.utc)
    beijing_tz = timezone(timedelta(hours=8))
    beijing_now = utc_now.astimezone(beijing_tz)
    print(f"[api_check_data_freshness] å½“å‰åŒ—äº¬æ—¶é—´: {beijing_now.strftime('%Y-%m-%d %H:%M:%S')}, å°æ—¶: {beijing_now.hour}")
    if beijing_now.hour >= 15:
        timestamp_data = _load_data_update_timestamp()
        print(f"[api_check_data_freshness] æ—¶é—´æˆ³æ•°æ®: {timestamp_data}")
        if not timestamp_data or not timestamp_data.get('last_update_date'):
            # 15:00åä¸”æ²¡æœ‰æ—¶é—´æˆ³è®°å½•ï¼Œé˜»æ­¢è‡ªåŠ¨æ›´æ–°
            print(f"[api_check_data_freshness] âœ… 15:00åä¸”æ²¡æœ‰æ—¶é—´æˆ³ï¼Œè¿”å› should_skip=True")
            return jsonify({
                'success': True,
                'fresh': True,
                'message': f'å½“å‰æ—¶é—´ {beijing_now.strftime("%H:%M")}ï¼Œäº¤æ˜“å·²ç»“æŸã€‚å¦‚éœ€æ›´æ–°æ•°æ®ï¼Œè¯·æ‰‹åŠ¨ç‚¹å‡»"æ›´æ–°æ•°æ®"æŒ‰é’®',
                'skip_reason': 'trading_hours_ended_no_timestamp',
                'should_skip': True
            })
        else:
            print(f"[api_check_data_freshness] æœ‰æ—¶é—´æˆ³: {timestamp_data.get('last_update_date')}")
    
    # âœ… ä¼˜å…ˆä½¿ç”¨æ ‡è®°æ–‡ä»¶å¿«é€Ÿæ£€æŸ¥
    from datetime import datetime
    today = datetime.now()
    today_str = today.strftime('%Y-%m-%d')
    
    if markers:
        # ç»Ÿè®¡å·²æ˜¯æœ€æ–°çš„è‚¡ç¥¨æ•°é‡
        up_to_date_count = 0
        total_marked = len(markers)
        outdated_count = 0
        
        for code, marker_data in markers.items():
            daily_date = marker_data.get('daily_latest_date')
            weekly_date = marker_data.get('weekly_latest_date')
            last_update_timestamp = marker_data.get('last_update_timestamp')
            
            # ä½¿ç”¨æ™ºèƒ½åˆ¤æ–­å‡½æ•°
            daily_is_up_to_date = _is_data_up_to_date(code, daily_date, last_update_timestamp)
            weekly_is_up_to_date = _is_data_up_to_date(code, weekly_date, last_update_timestamp)
            
            # å¦‚æœæ—¥Kçº¿å’Œå‘¨Kçº¿éƒ½å·²æ˜¯æœ€æ–°ï¼Œè®¤ä¸ºè¯¥è‚¡ç¥¨å·²æ˜¯æœ€æ–°
            if daily_is_up_to_date and weekly_is_up_to_date:
                up_to_date_count += 1
            else:
                outdated_count += 1
        
        # å¦‚æœè¶…è¿‡85%çš„è‚¡ç¥¨å·²æ˜¯æœ€æ–°ï¼Œè®¤ä¸ºæ•°æ®å·²æ˜¯æœ€æ–°
        if total_marked > 0:
            up_to_date_pct = (up_to_date_count / total_marked) * 100
            latest_date = today_str  # ä½¿ç”¨ä»Šå¤©ä½œä¸ºæœ€æ–°æ—¥æœŸ
            
            # âœ… é™ä½é˜ˆå€¼åˆ°85%ï¼Œå› ä¸ºé€šè¾¾ä¿¡å¯¼å…¥çš„æ•°æ®æ²¡æœ‰æ—¶é—´æˆ³ï¼Œä½†æ—¥æœŸæ˜¯æœ€æ–°çš„
            if up_to_date_pct >= 85:
                # âœ… å³ä½¿æ•°æ®æ˜¯æœ€æ–°çš„ï¼Œå¦‚æœæ˜¯15:00åï¼Œä¹Ÿè¦æ ‡è®° should_skip
                should_skip_after_check = False
                skip_reason_after_check = None
                if beijing_now.hour >= 15:
                    timestamp_data_after = _load_data_update_timestamp()
                    if not timestamp_data_after or not timestamp_data_after.get('last_update_date'):
                        should_skip_after_check = True
                        skip_reason_after_check = f'å½“å‰æ—¶é—´ {beijing_now.strftime("%H:%M")}ï¼Œäº¤æ˜“å·²ç»“æŸ'
                
                return jsonify({
                    'fresh': True,
                    'outdated_count': outdated_count,
                    'total': total_marked,
                    'latest_data_date': latest_date,
                    'target_date': target_date or today_str,
                    'message': f'æ•°æ®å·²æ˜¯æœ€æ–°ï¼ˆ{up_to_date_count}/{total_marked}ï¼Œ{up_to_date_pct:.1f}%å·²æ˜¯æœ€æ–°ï¼‰',
                    'up_to_date_count': up_to_date_count,
                    'up_to_date_pct': round(up_to_date_pct, 1),
                    'should_skip': should_skip_after_check,  # âœ… æ·»åŠ  should_skip å­—æ®µ
                    'skip_reason': skip_reason_after_check  # âœ… æ·»åŠ  skip_reason å­—æ®µ
                })
    
    # å¦‚æœæ ‡è®°æ–‡ä»¶æ£€æŸ¥ä¸é€šè¿‡ï¼Œä½¿ç”¨åŸæ¥çš„CSVæ–‡ä»¶æ£€æŸ¥æ–¹æ³•
    # âœ… ä½†åœ¨è°ƒç”¨å‰ï¼Œå†æ¬¡æ£€æŸ¥æ—¶é—´ï¼ˆç¡®ä¿15:00åä¸ä¼šè§¦å‘æ›´æ–°ï¼‰
    # æ³¨æ„ï¼šè¿™é‡Œçš„æ—¶é—´æ£€æŸ¥å·²ç»åœ¨å‰é¢æ‰§è¡Œè¿‡äº†ï¼Œä½†ä¸ºäº†ä¿é™©ï¼Œå†æ¬¡æ£€æŸ¥
    print(f"[api_check_data_freshness] æ ‡è®°æ–‡ä»¶æ£€æŸ¥ä¸é€šè¿‡ï¼Œå‡†å¤‡è°ƒç”¨ check_data_freshness()ï¼Œå½“å‰æ—¶é—´: {beijing_now.strftime('%Y-%m-%d %H:%M:%S')}, å°æ—¶: {beijing_now.hour}")
    if beijing_now.hour >= 15:
        timestamp_data_final = _load_data_update_timestamp()
        print(f"[api_check_data_freshness] æ—¶é—´æˆ³æ•°æ®: {timestamp_data_final}")
        if not timestamp_data_final or not timestamp_data_final.get('last_update_date'):
            # 15:00åä¸”æ²¡æœ‰æ—¶é—´æˆ³è®°å½•ï¼Œé˜»æ­¢æ›´æ–°
            print(f"[api_check_data_freshness] âœ… æ ‡è®°æ–‡ä»¶æ£€æŸ¥ä¸é€šè¿‡ï¼Œä½†15:00åä¸”æ²¡æœ‰æ—¶é—´æˆ³ï¼Œè¿”å› should_skip=True")
            return jsonify({
                'success': True,
                'fresh': True,  # æ ‡è®°ä¸ºå·²æ˜¯æœ€æ–°ï¼Œé¿å…è§¦å‘æ›´æ–°
                'message': f'å½“å‰æ—¶é—´ {beijing_now.strftime("%H:%M")}ï¼Œäº¤æ˜“å·²ç»“æŸã€‚å¦‚éœ€æ›´æ–°æ•°æ®ï¼Œè¯·æ‰‹åŠ¨ç‚¹å‡»"æ›´æ–°æ•°æ®"æŒ‰é’®',
                'skip_reason': 'trading_hours_ended_no_timestamp',
                'should_skip': True
            })
    
    print(f"[api_check_data_freshness] è°ƒç”¨ check_data_freshness() å‡½æ•°")
    result = check_data_freshness(target_date)
    print(f"[api_check_data_freshness] check_data_freshness() è¿”å›ç»“æœ: fresh={result.get('fresh')}, message={result.get('message')}")
    # âœ… ç¡®ä¿è¿”å›ç»“æœåŒ…å« should_skip å­—æ®µ
    if isinstance(result, dict):
        # å¦‚æœ15:00åä¸”æ²¡æœ‰æ—¶é—´æˆ³ï¼Œå¼ºåˆ¶è®¾ç½® should_skip
        if beijing_now.hour >= 15:
            timestamp_data_result = _load_data_update_timestamp()
            if not timestamp_data_result or not timestamp_data_result.get('last_update_date'):
                print(f"[api_check_data_freshness] âœ… å¼ºåˆ¶è®¾ç½® should_skip=Trueï¼ˆ15:00åä¸”æ²¡æœ‰æ—¶é—´æˆ³ï¼‰")
                result['should_skip'] = True
                result['skip_reason'] = 'trading_hours_ended_no_timestamp'
                result['fresh'] = True  # å¼ºåˆ¶æ ‡è®°ä¸ºå·²æ˜¯æœ€æ–°
                result['message'] = f'å½“å‰æ—¶é—´ {beijing_now.strftime("%H:%M")}ï¼Œäº¤æ˜“å·²ç»“æŸã€‚å¦‚éœ€æ›´æ–°æ•°æ®ï¼Œè¯·æ‰‹åŠ¨ç‚¹å‡»"æ›´æ–°æ•°æ®"æŒ‰é’®'
        else:
            result['should_skip'] = result.get('should_skip', False)
    print(f"[api_check_data_freshness] æœ€ç»ˆè¿”å›ç»“æœ: should_skip={result.get('should_skip') if isinstance(result, dict) else 'N/A'}")
    return jsonify(result)

@app.route('/api/update_and_scan', methods=['POST'])
@require_login
def api_update_and_scan():
    """å…ˆæ›´æ–°æ•°æ®å†æ‰«æï¼ˆå¦‚æœéœ€è¦ï¼‰"""
    global data_update_progress, data_update_stop_flag
    
    data = request.get_json() or {}
    scan_date = data.get('scan_date', None)
    
    # æ£€æŸ¥æ•°æ®æ–°é²œåº¦
    freshness = check_data_freshness(scan_date)
    
    if freshness['fresh']:
        # æ•°æ®è¶³å¤Ÿæ–°ï¼Œç›´æ¥è¿”å›å¯ä»¥æ‰«æ
        return jsonify({
            'success': True,
            'need_update': False,
            'message': 'æ•°æ®å·²æ˜¯æœ€æ–°ï¼Œå¯ä»¥å¼€å§‹æ‰«æ',
            'freshness': freshness
        })
    
    # æ•°æ®éœ€è¦æ›´æ–°
    if data_update_progress['status'] == 'running':
        return jsonify({
            'success': True,
            'need_update': True,
            'already_running': True,
            'message': 'æ•°æ®æ›´æ–°æ­£åœ¨è¿›è¡Œä¸­ï¼Œè¯·ç­‰å¾…å®Œæˆåæ‰«æ',
            'freshness': freshness
        })
    
    # å¯åŠ¨æ•°æ®æ›´æ–°
    data_update_stop_flag = False
    data_update_progress = {
        'status': 'running',
        'processed': 0,
        'total': 0,
        'percentage': 0,
        'current_stock': '',
        'message': 'å‡†å¤‡æ›´æ–°æ•°æ®...',
        'updated_count': 0,
        'failed_count': 0,
        'start_time': None
    }
    
    import threading
    update_thread = threading.Thread(target=_data_update_worker)
    update_thread.daemon = True
    update_thread.start()
    
    return jsonify({
        'success': True,
        'need_update': True,
        'already_running': False,
        'message': f'æ•°æ®éœ€è¦æ›´æ–°ï¼ˆ{freshness["outdated_count"]}/{freshness["total"]}åªè¿‡æœŸï¼‰ï¼Œå·²å¯åŠ¨æ›´æ–°ä»»åŠ¡',
        'freshness': freshness
    })

@app.route('/api/check_login', methods=['GET'])
def api_check_login():
    """æ£€æŸ¥ç™»å½•çŠ¶æ€API"""
    try:
        if is_logged_in():
            user = get_current_user()
            return jsonify({
                'success': True,
                'logged_in': True,
                'user': user
            })
        else:
            return jsonify({
                'success': True,
                'logged_in': False
            })
    except Exception as e:
        return jsonify({
            'success': False,
            'logged_in': False,
            'error': str(e)
        }), 500

@app.route('/api/version', methods=['GET'])
def api_version():
    """è·å–ç‰ˆæœ¬ä¿¡æ¯API"""
    try:
        import subprocess
        import os
        
        # å°è¯•è·å– Git commit SHA
        version_info = {
            'success': True,
            'environment': 'vercel' if is_vercel else 'local',
            'commit_sha': 'unknown',
            'commit_short': 'unknown',
            'commit_message': 'unknown',
            'commit_date': 'unknown'
        }
        
        try:
            # æ–¹æ³•1: ä» Vercel ç¯å¢ƒå˜é‡è·å–ï¼ˆä¼˜å…ˆï¼ŒVercel è‡ªåŠ¨æä¾›ï¼‰
            vercel_commit_sha = os.environ.get('VERCEL_GIT_COMMIT_SHA')
            if vercel_commit_sha:
                version_info['commit_sha'] = vercel_commit_sha
                version_info['commit_short'] = vercel_commit_sha[:7]
                
                # Vercel è¿˜å¯èƒ½æä¾›å…¶ä»– Git ä¿¡æ¯
                vercel_git_commit_message = os.environ.get('VERCEL_GIT_COMMIT_MESSAGE', '')
                if vercel_git_commit_message:
                    version_info['commit_message'] = vercel_git_commit_message
                
                vercel_git_commit_ref = os.environ.get('VERCEL_GIT_COMMIT_REF', '')
                if vercel_git_commit_ref:
                    version_info['branch'] = vercel_git_commit_ref
            
            # æ–¹æ³•2: ä» .git-version æ–‡ä»¶è¯»å–ï¼ˆå¦‚æœå­˜åœ¨ï¼Œä½œä¸ºå¤‡ç”¨ï¼‰
            if version_info['commit_sha'] == 'unknown':
                version_file = os.path.join(os.path.dirname(__file__), '.git-version')
                if os.path.exists(version_file):
                    with open(version_file, 'r') as f:
                        commit_sha = f.read().strip()
                        if commit_sha and commit_sha != 'unknown':
                            version_info['commit_sha'] = commit_sha
                            version_info['commit_short'] = commit_sha[:7]
            
            # æ–¹æ³•3: ç›´æ¥ä» Git è·å–ï¼ˆæœ¬åœ°ç¯å¢ƒï¼Œå¦‚æœå‰ä¸¤ç§æ–¹æ³•éƒ½å¤±è´¥ï¼‰
            if version_info['commit_sha'] == 'unknown' and not is_vercel:
                try:
                    result = subprocess.run(
                        ['git', 'rev-parse', 'HEAD'],
                        capture_output=True,
                        text=True,
                        cwd=os.path.dirname(__file__),
                        timeout=2
                    )
                    if result.returncode == 0:
                        commit_sha = result.stdout.strip()
                        version_info['commit_sha'] = commit_sha
                        version_info['commit_short'] = commit_sha[:7]
                    
                    # è·å– commit ä¿¡æ¯
                    result = subprocess.run(
                        ['git', 'log', '-1', '--pretty=format:%s|%ci'],
                        capture_output=True,
                        text=True,
                        cwd=os.path.dirname(__file__),
                        timeout=2
                    )
                    if result.returncode == 0:
                        parts = result.stdout.strip().split('|')
                        if len(parts) == 2:
                            version_info['commit_message'] = parts[0]
                            version_info['commit_date'] = parts[1]
                except Exception:
                    pass
        except Exception as e:
            print(f"è·å–ç‰ˆæœ¬ä¿¡æ¯å¤±è´¥: {e}")
        
        return jsonify(version_info)
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/health', methods=['GET'])
def api_health():
    """å¥åº·æ£€æŸ¥API"""
    try:
        return jsonify({
            'success': True,
            'status': 'ok',
            'environment': 'vercel' if is_vercel else 'local',
            'analyzer_initialized': analyzer is not None
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'status': 'error',
            'error': str(e)
        }), 500


@app.route('/api/check_cache_status', methods=['GET'])
@require_login
def check_cache_status():
    """æ£€æŸ¥è‚¡ç¥¨åˆ—è¡¨ç¼“å­˜çŠ¶æ€API"""
    try:
        # ç¡®ä¿åˆ†æå™¨å·²åˆå§‹åŒ–ï¼ˆåœ¨ try å—å†…ï¼Œä»¥ä¾¿æ•è·å¼‚å¸¸ï¼‰
        try:
            init_analyzer()
        except Exception as init_error:
            import traceback
            error_detail = traceback.format_exc()
            print(f"[check_cache_status] âŒ åˆå§‹åŒ–åˆ†æå™¨å¤±è´¥: {error_detail}")
            return jsonify({
                'success': False,
                'message': f'åˆå§‹åŒ–åˆ†æå™¨å¤±è´¥: {str(init_error)}',
                'cache_exists': False,
                'cached_stock_count': 0,
                'error_type': 'init_error',
                'error_detail': error_detail
            }), 500
        
        # æ£€æŸ¥åˆ†æå™¨æ˜¯å¦åˆå§‹åŒ–æˆåŠŸ
        if analyzer is None or analyzer.fetcher is None:
            return jsonify({
                'success': False,
                'message': 'åˆ†æå™¨æœªåˆå§‹åŒ–æˆ–åˆå§‹åŒ–å¤±è´¥',
                'cache_exists': False,
                'cached_stock_count': 0,
                'error_type': 'analyzer_not_initialized'
            }), 500
        
        # æ£€æµ‹ç¼“å­˜æ˜¯å¦å­˜åœ¨
        cache_exists = False
        cached_stock_count = 0
        try:
            # ä¸æ£€æŸ¥ç¼“å­˜å¹´é¾„ï¼Œåªæ£€æŸ¥æ˜¯å¦å­˜åœ¨
            cached_stocks = analyzer.fetcher._get_stock_list_from_cache(check_age=False)
            if cached_stocks is not None and len(cached_stocks) > 0:
                cache_exists = True
                cached_stock_count = len(cached_stocks)
                print(f"[check_cache_status] âœ… ç¼“å­˜å­˜åœ¨ï¼Œè‚¡ç¥¨æ•°: {cached_stock_count} åª")
            else:
                print(f"[check_cache_status] âš ï¸ ç¼“å­˜ä¸å­˜åœ¨æˆ–ä¸ºç©º")
        except Exception as e:
            import traceback
            error_detail = traceback.format_exc()
            print(f"[check_cache_status] âš ï¸ æ£€æµ‹ç¼“å­˜æ—¶å‡ºé”™: {e}")
            print(f"[check_cache_status] é”™è¯¯è¯¦æƒ…: {error_detail}")
        
        return jsonify({
            'success': True,
            'cache_exists': cache_exists,
            'cached_stock_count': cached_stock_count,
            'message': f'ç¼“å­˜{"å­˜åœ¨" if cache_exists else "ä¸å­˜åœ¨"}ï¼Œè‚¡ç¥¨æ•°: {cached_stock_count} åª'
        }), 200
        
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"[check_cache_status] âŒ é”™è¯¯: {error_detail}")
        return jsonify({
            'success': False,
            'message': f'æ£€æŸ¥ç¼“å­˜çŠ¶æ€å¤±è´¥: {str(e)}',
            'cache_exists': False,
            'cached_stock_count': 0
        }), 500


@app.route('/api/add_stock', methods=['POST'])
@require_login
def add_stock():
    """æ·»åŠ å¤§ç‰›è‚¡API"""
    try:
        init_analyzer()  # ç¡®ä¿åˆ†æå™¨å·²åˆå§‹åŒ–
        data = request.get_json()
        if not data:
            return jsonify({
                'success': False,
                'message': 'è¯·æ±‚æ•°æ®ä¸ºç©º'
            }), 400
        
        # å®‰å…¨åœ°è·å–å’Œæ¸…ç†æ•°æ®
        stock_code = (data.get('code') or '').strip()
        stock_name_raw = data.get('name')
        stock_name = stock_name_raw.strip() if stock_name_raw else None
        
        if not stock_code:
            return jsonify({
                'success': False,
                'message': 'è‚¡ç¥¨ä»£ç ä¸èƒ½ä¸ºç©º'
            }), 400
        
        # æ·»åŠ è‚¡ç¥¨
        result = analyzer.add_bull_stock(stock_code, stock_name)
        
        return jsonify(result)
        
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"æ·»åŠ è‚¡ç¥¨é”™è¯¯: {error_detail}")
        return jsonify({
            'success': False,
            'message': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}'
        }), 500


@app.route('/api/user_info')
@require_login
def get_user_info():
    """è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯ï¼ˆåŒ…æ‹¬ç­‰çº§ï¼‰- ä¼˜åŒ–ç‰ˆæœ¬ï¼ˆå¿«é€Ÿå“åº”ï¼‰"""
    try:
        user = get_current_user()
        if not user:
            return jsonify({
                'success': False,
                'message': 'æœªç™»å½•'
            }), 401
        
        # âœ… å¿«é€Ÿè¿”å›åŸºæœ¬ç”¨æˆ·ä¿¡æ¯ï¼ˆä¸ç­‰å¾…å¤æ‚çš„æ‰«æé™åˆ¶æ£€æŸ¥ï¼‰
        is_premium = user.get('is_vip', False) or user.get('is_premium', False)
        tier = get_user_tier()
        
        # âœ… ç®€åŒ–å“åº”ï¼Œç§»é™¤å¤æ‚çš„æ‰«æé™åˆ¶æ£€æŸ¥ï¼ˆè¿™äº›å¯ä»¥åœ¨éœ€è¦æ—¶å•ç‹¬è°ƒç”¨ï¼‰
        return jsonify({
            'success': True,
            'user': {
                'username': user.get('username', 'unknown'),
                'email': user.get('email', ''),
                'tier': tier,
                'is_premium': is_premium,
                'is_super': is_super_user(),
                'scan_config': get_scan_config(),
                'scan_restrictions': {
                    'can_scan_now': True,
                    'scan_time_error': None,
                    'can_view_now': True,
                    'view_time_error': None,
                    'can_scan_daily': True,
                    'daily_error': None,
                    'today_scan_count': 0,
                    'current_time': ''
                }
            }
        })
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"[get_user_info] âŒ è·å–ç”¨æˆ·ä¿¡æ¯é”™è¯¯: {error_detail}")
        # å³ä½¿å‡ºé”™ï¼Œä¹Ÿå°è¯•è¿”å›åŸºæœ¬ç”¨æˆ·ä¿¡æ¯
        try:
            user = get_current_user()
            if user:
                tier = get_user_tier()
                return jsonify({
                    'success': True,
                    'user': {
                        'username': user.get('username', 'unknown'),
                        'email': user.get('email', ''),
                        'tier': tier,
                        'is_premium': user.get('is_vip', False) or user.get('is_premium', False),
                        'is_super': is_super_user(),
                        'scan_config': {},
                        'scan_restrictions': {
                            'can_scan_now': True,
                            'scan_time_error': None,
                            'can_view_now': True,
                            'view_time_error': None,
                            'can_scan_daily': True,
                            'daily_error': None,
                            'today_scan_count': 0,
                            'current_time': ''
                        }
                    }
                })
        except Exception as fallback_error:
            print(f"[get_user_info] âŒ å¤‡ç”¨æ–¹æ¡ˆä¹Ÿå¤±è´¥: {fallback_error}")
        
        return jsonify({
            'success': False,
            'message': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}'
        }), 500

@app.route('/cs')
@require_login
def admin_page():
    """ç®¡ç†å‘˜é¡µé¢ï¼ˆå®¢æœé¡µé¢ï¼‰"""
    return render_template('admin.html')

@app.route('/api/admin/users')
@require_login
def admin_get_users():
    """è·å–æ‰€æœ‰ç”¨æˆ·åˆ—è¡¨ï¼ˆç®¡ç†å‘˜ï¼‰"""
    try:
        if is_vercel:
            from user_auth_vercel import load_users
        else:
            from user_auth import load_users
        
        users = load_users()
        
        # è°ƒè¯•ï¼šæ‰“å°ç”¨æˆ·æ•°æ®
        print(f"[admin_get_users] å½“å‰ç”¨æˆ·æ•°: {len(users)}")
        if users:
            print(f"[admin_get_users] ç”¨æˆ·åˆ—è¡¨: {list(users.keys())}")
            for username, user_data in users.items():
                print(f"  - {username}: VIP={user_data.get('is_vip', False)}, Email={user_data.get('email', 'N/A')}")
        
        # è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼ï¼Œéšè—æ•æ„Ÿä¿¡æ¯
        users_list = []
        for username, user_data in users.items():
            users_list.append({
                'username': username,
                'email': user_data.get('email', ''),
                'is_vip': user_data.get('is_vip', False),
                'created_at': user_data.get('created_at', ''),
                'last_login': user_data.get('last_login', ''),
                'invite_code': user_data.get('invite_code', ''),
                'is_active': user_data.get('is_active', True)
            })
        
        return jsonify({
            'success': True,
            'users': users_list,
            'total': len(users_list)
        })
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"è·å–ç”¨æˆ·åˆ—è¡¨é”™è¯¯: {error_detail}")
        return jsonify({
            'success': False,
            'message': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}'
        }), 500

@app.route('/api/admin/create_super_user', methods=['POST'])
def admin_create_super_user():
    """åˆ›å»ºæˆ–æ›´æ–°è¶…çº§ç”¨æˆ·ï¼ˆéœ€è¦å¯†é’¥éªŒè¯ï¼‰"""
    try:
        data = request.get_json() or {}
        
        # éªŒè¯å¯†é’¥ï¼ˆä»ç¯å¢ƒå˜é‡è·å–ï¼Œå¦‚æœæ²¡æœ‰è®¾ç½®åˆ™ä½¿ç”¨é»˜è®¤å¯†é’¥ï¼‰
        secret = os.environ.get('SUPER_USER_SECRET', 'create_super_user_2024')
        provided_secret = data.get('secret')
        
        if provided_secret != secret:
            return jsonify({
                'success': False,
                'message': 'å¯†é’¥éªŒè¯å¤±è´¥'
            }), 403
        
        # è·å–ç”¨æˆ·ä¿¡æ¯ï¼ˆé»˜è®¤å€¼ï¼‰
        username = data.get('username', 'super')
        password = data.get('password', 'superzwj')
        email = data.get('email', 'super@admin.com')
        
        # åŠ è½½ç”¨æˆ·æ•°æ®
        if is_vercel or is_render or has_redis:
            from user_auth_vercel import load_users, save_users, hash_password
        else:
            from user_auth import load_users, save_users, hash_password
        
        users = load_users()
        
        # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å·²å­˜åœ¨
        if username in users:
            # æ›´æ–°ç°æœ‰ç”¨æˆ·
            users[username]['password'] = hash_password(password)
            users[username]['is_vip'] = True
            users[username]['is_super'] = True
            users[username]['is_active'] = True
            users[username]['email'] = email
            users[username]['updated_at'] = datetime.now().isoformat()
            action = 'æ›´æ–°'
        else:
            # åˆ›å»ºæ–°ç”¨æˆ·
            users[username] = {
                'username': username,
                'email': email,
                'password': hash_password(password),
                'created_at': datetime.now().isoformat(),
                'last_login': None,
                'invite_code': 'ADMIN_CREATED',
                'is_active': True,
                'is_vip': True,
                'is_super': True,
                'is_test_user': False
            }
            action = 'åˆ›å»º'
        
        # ä¿å­˜ç”¨æˆ·æ•°æ®
        save_users(users)
        
        print(f"âœ… {action}è¶…çº§ç”¨æˆ·æˆåŠŸ: {username}")
        
        return jsonify({
            'success': True,
            'message': f'è¶…çº§ç”¨æˆ·å·²{action}æˆåŠŸ',
            'user': {
                'username': username,
                'email': email,
                'is_vip': True,
                'is_super': True
            }
        })
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"åˆ›å»ºè¶…çº§ç”¨æˆ·é”™è¯¯: {error_detail}")
        return jsonify({
            'success': False,
            'message': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}'
        }), 500

@app.route('/api/admin/set_vip', methods=['POST'])
@require_login
def admin_set_vip():
    """ç®¡ç†å‘˜è®¾ç½®ç”¨æˆ·VIPçŠ¶æ€ï¼ˆæ‰‹åŠ¨æ”¶è´¹ï¼‰"""
    try:
        # æ£€æŸ¥æ˜¯å¦ä¸ºç®¡ç†å‘˜ï¼ˆå¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ ç®¡ç†å‘˜åˆ¤æ–­ï¼‰
        user = get_current_user()
        if not user:
            return jsonify({
                'success': False,
                'message': 'æœªç™»å½•'
            }), 401
        
        data = request.get_json() or {}
        target_username = data.get('username')
        is_vip = data.get('is_vip', False)
        
        if not target_username:
            return jsonify({
                'success': False,
                'message': 'ç¼ºå°‘ç”¨æˆ·åå‚æ•°'
            }), 400
        
        # åŠ è½½ç”¨æˆ·æ•°æ®
        if is_vercel:
            from user_auth_vercel import load_users, save_users
        else:
            from user_auth import load_users, save_users
        
        users = load_users()
        
        if target_username not in users:
            return jsonify({
                'success': False,
                'message': 'ç”¨æˆ·ä¸å­˜åœ¨'
            }), 404
        
        # æ›´æ–°VIPçŠ¶æ€
        users[target_username]['is_vip'] = bool(is_vip)
        if is_vip:
            users[target_username]['vip_set_at'] = datetime.now().isoformat()
        
        if is_vercel:
            from user_auth_vercel import save_users
        else:
            from user_auth import save_users
        
        save_users(users)
        
        return jsonify({
            'success': True,
            'message': f'å·²{"è®¾ç½®" if is_vip else "å–æ¶ˆ"}ç”¨æˆ· {target_username} çš„VIPçŠ¶æ€',
            'user': {
                'username': target_username,
                'is_vip': is_vip
            }
        })
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"è®¾ç½®VIPçŠ¶æ€é”™è¯¯: {error_detail}")
        return jsonify({
            'success': False,
            'message': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}'
        }), 500

@app.route('/api/vip/apply', methods=['POST'])
@require_login
def vip_apply():
    """æäº¤VIPå‡çº§ç”³è¯·"""
    try:
        user = get_current_user()
        if not user:
            return jsonify({
                'success': False,
                'message': 'æœªç™»å½•'
            }), 401
        
        # æ£€æŸ¥æ˜¯å¦å·²ç»æ˜¯VIP
        if is_premium_user() or is_super_user():
            return jsonify({
                'success': False,
                'message': 'æ‚¨å·²ç»æ˜¯VIPä¼šå‘˜ï¼Œæ— éœ€å†æ¬¡ç”³è¯·'
            }), 400
        
        data = request.get_json() or {}
        plan = data.get('plan', 'monthly')  # 'monthly' æˆ– 'yearly'
        contact = data.get('contact', '').strip()
        note = data.get('note', '').strip()
        
        if plan not in ['monthly', 'yearly']:
            return jsonify({
                'success': False,
                'message': 'æ— æ•ˆçš„å¥—é¤ç±»å‹'
            }), 400
        
        if not contact:
            return jsonify({
                'success': False,
                'message': 'è¯·è¾“å…¥è”ç³»æ–¹å¼ï¼ˆå¾®ä¿¡/QQ/æ‰‹æœºå·ï¼‰'
            }), 400
        
        # å¯¼å…¥VIPç”³è¯·å­˜å‚¨æ¨¡å—
        try:
            from vip_upgrade_store import save_vip_application, get_user_application
        except ImportError:
            # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨æœ¬åœ°ç‰ˆæœ¬
            import vip_upgrade_store
            save_vip_application = vip_upgrade_store.save_vip_application
            get_user_application = vip_upgrade_store.get_user_application
        
        # è·å–ç”¨æˆ·é‚®ç®±
        if is_vercel:
            from user_auth_vercel import load_users
        else:
            from user_auth import load_users
        
        users = load_users()
        user_email = users.get(user['username'], {}).get('email', '')
        
        # ä¿å­˜ç”³è¯·
        success = save_vip_application(
            username=user['username'],
            email=user_email,
            plan=plan,
            contact=contact,
            note=note
        )
        
        if success:
            return jsonify({
                'success': True,
                'message': 'VIPå‡çº§ç”³è¯·å·²æäº¤ï¼Œæˆ‘ä»¬ä¼šåœ¨24å°æ—¶å†…å¤„ç†å¹¶è”ç³»æ‚¨'
            })
        else:
            return jsonify({
                'success': False,
                'message': 'æäº¤ç”³è¯·å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•'
            }), 500
            
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"æäº¤VIPç”³è¯·é”™è¯¯: {error_detail}")
        return jsonify({
            'success': False,
            'message': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}'
        }), 500

@app.route('/api/vip/check_application', methods=['GET'])
@require_login
def vip_check_application():
    """æ£€æŸ¥ç”¨æˆ·çš„VIPç”³è¯·çŠ¶æ€"""
    try:
        user = get_current_user()
        if not user:
            return jsonify({
                'success': False,
                'message': 'æœªç™»å½•'
            }), 401
        
        try:
            from vip_upgrade_store import get_user_application
        except ImportError:
            import vip_upgrade_store
            get_user_application = vip_upgrade_store.get_user_application
        
        application = get_user_application(user['username'])
        
        if application:
            return jsonify({
                'success': True,
                'has_application': True,
                'application': {
                    'status': application.get('status', 'pending'),
                    'plan': application.get('plan'),
                    'plan_name': application.get('plan_name'),
                    'amount': application.get('amount'),
                    'created_at': application.get('created_at')
                }
            })
        else:
            return jsonify({
                'success': True,
                'has_application': False
            })
            
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"æ£€æŸ¥VIPç”³è¯·çŠ¶æ€é”™è¯¯: {error_detail}")
        return jsonify({
            'success': False,
            'message': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}'
        }), 500

@app.route('/api/admin/vip_applications', methods=['GET'])
@require_login
def admin_get_vip_applications():
    """è·å–æ‰€æœ‰VIPå‡çº§ç”³è¯·åˆ—è¡¨ï¼ˆç®¡ç†å‘˜ï¼‰"""
    try:
        user = get_current_user()
        if not user:
            return jsonify({
                'success': False,
                'message': 'æœªç™»å½•'
            }), 401
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºç®¡ç†å‘˜ï¼ˆå¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ ç®¡ç†å‘˜åˆ¤æ–­ï¼‰
        # æš‚æ—¶å…è®¸æ‰€æœ‰ç™»å½•ç”¨æˆ·æŸ¥çœ‹ï¼ˆå®é™…åº”è¯¥åªå…è®¸ç®¡ç†å‘˜ï¼‰
        
        status = request.args.get('status')  # å¯é€‰ï¼š'pending', 'approved', 'rejected', 'completed'
        
        try:
            from vip_upgrade_store import get_vip_applications
        except ImportError:
            import vip_upgrade_store
            get_vip_applications = vip_upgrade_store.get_vip_applications
        
        applications = get_vip_applications(status=status)
        
        return jsonify({
            'success': True,
            'applications': applications,
            'total': len(applications)
        })
        
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"è·å–VIPç”³è¯·åˆ—è¡¨é”™è¯¯: {error_detail}")
        return jsonify({
            'success': False,
            'message': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}'
        }), 500

@app.route('/api/admin/vip_application/<application_id>/status', methods=['POST'])
@require_login
def admin_update_application_status(application_id):
    """æ›´æ–°VIPç”³è¯·çŠ¶æ€ï¼ˆç®¡ç†å‘˜ï¼‰"""
    try:
        user = get_current_user()
        if not user:
            return jsonify({
                'success': False,
                'message': 'æœªç™»å½•'
            }), 401
        
        data = request.get_json() or {}
        status = data.get('status')  # 'pending', 'approved', 'rejected', 'completed'
        
        if status not in ['pending', 'approved', 'rejected', 'completed']:
            return jsonify({
                'success': False,
                'message': 'æ— æ•ˆçš„çŠ¶æ€å€¼'
            }), 400
        
        try:
            from vip_upgrade_store import update_application_status
        except ImportError:
            import vip_upgrade_store
            update_application_status = vip_upgrade_store.update_application_status
        
        success = update_application_status(
            application_id=application_id,
            status=status,
            processed_by=user['username']
        )
        
        if success:
            # å¦‚æœçŠ¶æ€æ˜¯ 'approved' æˆ– 'completed'ï¼Œè‡ªåŠ¨è®¾ç½®ç”¨æˆ·ä¸ºVIP
            if status in ['approved', 'completed']:
                try:
                    from vip_upgrade_store import get_vip_applications
                    applications = get_vip_applications()
                    application = next((app for app in applications if app.get('application_id') == application_id), None)
                    
                    if application:
                        target_username = application.get('username')
                        
                        # è®¾ç½®ç”¨æˆ·ä¸ºVIP
                        if is_vercel:
                            from user_auth_vercel import load_users, save_users
                        else:
                            from user_auth import load_users, save_users
                        
                        users = load_users()
                        if target_username in users:
                            users[target_username]['is_vip'] = True
                            users[target_username]['vip_set_at'] = datetime.now().isoformat()
                            save_users(users)
                            
                except Exception as e2:
                    print(f"è‡ªåŠ¨è®¾ç½®VIPçŠ¶æ€å¤±è´¥: {e2}")
            
            return jsonify({
                'success': True,
                'message': f'ç”³è¯·çŠ¶æ€å·²æ›´æ–°ä¸º: {status}'
            })
        else:
            return jsonify({
                'success': False,
                'message': 'æ›´æ–°ç”³è¯·çŠ¶æ€å¤±è´¥'
            }), 500
            
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"æ›´æ–°VIPç”³è¯·çŠ¶æ€é”™è¯¯: {error_detail}")
        return jsonify({
            'success': False,
            'message': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}'
        }), 500

@app.route('/api/vip/payment_info', methods=['GET'])
def vip_payment_info():
    """è·å–VIPä»˜è´¹è´¦å·ä¿¡æ¯ï¼ˆæ”¯ä»˜å®/å¾®ä¿¡ï¼‰"""
    try:
        # ä»ç¯å¢ƒå˜é‡è¯»å–ä»˜æ¬¾è´¦å·ä¿¡æ¯ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
        alipay_account = os.environ.get('VIP_ALIPAY_ACCOUNT', '522168878@qq.com')  # æ”¯ä»˜å®è´¦å·ï¼ˆé»˜è®¤å€¼ï¼‰
        wechat_account = os.environ.get('VIP_WECHAT_ACCOUNT', '')  # å¾®ä¿¡è´¦å·
        
        # å¦‚æœç¯å¢ƒå˜é‡ä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤å€¼
        if not alipay_account:
            alipay_account = '522168878@qq.com'
        
        return jsonify({
            'success': True,
            'alipay_account': alipay_account,
            'wechat_account': wechat_account if wechat_account else 'è¯·ç­‰å¾…ç®¡ç†å‘˜é…ç½®'
        })
        
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"è·å–ä»˜æ¬¾ä¿¡æ¯é”™è¯¯: {error_detail}")
        return jsonify({
            'success': False,
            'message': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}'
        }), 500

@app.route('/api/get_stocks', methods=['GET'])
@require_login
def get_stocks():
    """è·å–æ‰€æœ‰å·²æ·»åŠ çš„å¤§ç‰›è‚¡API"""
    try:
        init_analyzer()  # ç¡®ä¿åˆ†æå™¨å·²åˆå§‹åŒ–
        
        # æ£€æŸ¥ analyzer æ˜¯å¦å·²åˆå§‹åŒ–
        if analyzer is None:
            return jsonify({
                'success': True,
                'stocks': [],
                'count': 0
            })
        
        stocks = analyzer.get_bull_stocks()
        
        # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„æ ¼å¼
        stocks_list = []
        for stock in stocks:
            try:
                # å¤„ç†æ·»åŠ æ—¶é—´å­—æ®µ
                add_time = stock.get('æ·»åŠ æ—¶é—´')
                if isinstance(add_time, datetime):
                    add_time_str = add_time.strftime('%Y-%m-%d %H:%M:%S')
                elif isinstance(add_time, str):
                    add_time_str = add_time
                else:
                    add_time_str = str(add_time) if add_time else ''
                
                stocks_list.append({
                    'ä»£ç ': stock.get('ä»£ç ', ''),
                    'åç§°': stock.get('åç§°', ''),
                    'æ·»åŠ æ—¶é—´': add_time_str,
                    'æ•°æ®æ¡æ•°': stock.get('æ•°æ®æ¡æ•°', 0)
                })
            except Exception as e:
                print(f"å¤„ç†è‚¡ç¥¨æ•°æ®æ—¶å‡ºé”™: {stock} - {e}")
                continue
        
        return jsonify({
            'success': True,
            'stocks': stocks_list,
            'count': len(stocks_list)
        })
        
    except AttributeError as e:
        # analyzer æœªåˆå§‹åŒ–æˆ–æ–¹æ³•ä¸å­˜åœ¨
        print(f"è·å–è‚¡ç¥¨åˆ—è¡¨é”™è¯¯ (AttributeError): {e}")
        return jsonify({
            'success': True,
            'stocks': [],
            'count': 0
        })
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"è·å–è‚¡ç¥¨åˆ—è¡¨é”™è¯¯: {error_detail}")
        return jsonify({
            'success': False,
            'message': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}',
            'error_detail': error_detail if is_vercel else None  # ä»…åœ¨ Vercel ç¯å¢ƒä¸­è¿”å›è¯¦ç»†é”™è¯¯
        }), 500


@app.route('/api/remove_stock', methods=['POST'])
@require_login
def remove_stock():
    init_analyzer()  # ç¡®ä¿åˆ†æå™¨å·²åˆå§‹åŒ–
    """ç§»é™¤å¤§ç‰›è‚¡API"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({
                'success': False,
                'message': 'è¯·æ±‚æ•°æ®ä¸ºç©º'
            }), 400
        
        # å®‰å…¨åœ°è·å–å’Œæ¸…ç†æ•°æ®
        stock_code = (data.get('code') or '').strip()
        
        if not stock_code:
            return jsonify({
                'success': False,
                'message': 'è‚¡ç¥¨ä»£ç ä¸èƒ½ä¸ºç©º'
            }), 400
        
        # ç§»é™¤è‚¡ç¥¨
        success = analyzer.remove_bull_stock(stock_code)
        
        return jsonify({
            'success': success,
            'message': f'å·²ç§»é™¤è‚¡ç¥¨ {stock_code}' if success else f'æœªæ‰¾åˆ°è‚¡ç¥¨ {stock_code}'
        })
        
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"ç§»é™¤è‚¡ç¥¨é”™è¯¯: {error_detail}")
        return jsonify({
            'success': False,
            'message': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}'
        }), 500


@app.route('/api/clear_stocks', methods=['POST'])
@require_login
def clear_stocks():
    """æ¸…ç©ºæ‰€æœ‰å¤§ç‰›è‚¡API"""
    try:
        analyzer.clear_bull_stocks()
        return jsonify({
            'success': True,
            'message': 'å·²æ¸…ç©ºæ‰€æœ‰å¤§ç‰›è‚¡'
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}'
        }), 500


@app.route('/api/analyze_stock', methods=['POST'])
@require_login
def analyze_stock():
    """åˆ†æå•åªå¤§ç‰›è‚¡API"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({
                'success': False,
                'message': 'è¯·æ±‚æ•°æ®ä¸ºç©º'
            }), 400
        
        stock_code = (data.get('code') or '').strip()
        
        if not stock_code:
            return jsonify({
                'success': False,
                'message': 'è‚¡ç¥¨ä»£ç ä¸èƒ½ä¸ºç©º'
            }), 400
        
        # åˆ†æè‚¡ç¥¨
        result = analyzer.analyze_bull_stock(stock_code)
        
        # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„æ ¼å¼
        if result['success'] and result.get('interval'):
            interval = result['interval']
            result['interval'] = {
                'è‚¡ç¥¨ä»£ç ': interval.get('è‚¡ç¥¨ä»£ç '),
                'èµ·ç‚¹æ—¥æœŸ': str(interval.get('èµ·ç‚¹æ—¥æœŸ', '')),
                'èµ·ç‚¹ä»·æ ¼': float(interval.get('èµ·ç‚¹ä»·æ ¼', 0)) if interval.get('èµ·ç‚¹ä»·æ ¼') is not None else 0,
                'èµ·ç‚¹ç´¢å¼•': int(interval.get('èµ·ç‚¹ç´¢å¼•')) if interval.get('èµ·ç‚¹ç´¢å¼•') is not None else None,
                'ç»ˆç‚¹æ—¥æœŸ': str(interval.get('ç»ˆç‚¹æ—¥æœŸ', '')),
                'ç»ˆç‚¹ä»·æ ¼': float(interval.get('ç»ˆç‚¹ä»·æ ¼', 0)) if interval.get('ç»ˆç‚¹ä»·æ ¼') is not None else 0,
                'ç»ˆç‚¹ç´¢å¼•': int(interval.get('ç»ˆç‚¹ç´¢å¼•')) if interval.get('ç»ˆç‚¹ç´¢å¼•') is not None else None,
                'æ¶¨å¹…': float(interval.get('æ¶¨å¹…', 0)) if interval.get('æ¶¨å¹…') is not None else 0,
                'ç¿»å€å€æ•°': float(interval.get('ç¿»å€å€æ•°', 0)) if interval.get('ç¿»å€å€æ•°') is not None else 0,
                'å®é™…å‘¨æ•°': int(interval.get('å®é™…å‘¨æ•°')) if interval.get('å®é™…å‘¨æ•°') is not None else None,
                'æŸ¥æ‰¾çª—å£å‘¨æ•°': int(interval.get('æŸ¥æ‰¾çª—å£å‘¨æ•°', 10)) if interval.get('æŸ¥æ‰¾çª—å£å‘¨æ•°') is not None else 10
            }
        
        return jsonify(result)
        
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"åˆ†æè‚¡ç¥¨é”™è¯¯: {error_detail}")
        return jsonify({
            'success': False,
            'message': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}'
        }), 500


@app.route('/api/analyze_all', methods=['POST'])
@require_login
def analyze_all():
    init_analyzer()  # ç¡®ä¿åˆ†æå™¨å·²åˆå§‹åŒ–
    """åˆ†ææ‰€æœ‰å¤§ç‰›è‚¡API"""
    try:
        # åˆ†ææ‰€æœ‰è‚¡ç¥¨
        result = analyzer.analyze_all_bull_stocks()
        
        # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„æ ¼å¼
        if result.get('results'):
            for item in result['results']:
                analysis_result = item.get('åˆ†æç»“æœ', {})
                if analysis_result.get('success') and analysis_result.get('interval'):
                    interval = analysis_result['interval']
                    analysis_result['interval'] = {
                        'è‚¡ç¥¨ä»£ç ': interval.get('è‚¡ç¥¨ä»£ç '),
                        'èµ·ç‚¹æ—¥æœŸ': str(interval.get('èµ·ç‚¹æ—¥æœŸ', '')),
                        'èµ·ç‚¹ä»·æ ¼': float(interval.get('èµ·ç‚¹ä»·æ ¼', 0)) if interval.get('èµ·ç‚¹ä»·æ ¼') is not None else 0,
                        'èµ·ç‚¹ç´¢å¼•': int(interval.get('èµ·ç‚¹ç´¢å¼•')) if interval.get('èµ·ç‚¹ç´¢å¼•') is not None else None,
                        'ç»ˆç‚¹æ—¥æœŸ': str(interval.get('ç»ˆç‚¹æ—¥æœŸ', '')),
                        'ç»ˆç‚¹ä»·æ ¼': float(interval.get('ç»ˆç‚¹ä»·æ ¼', 0)) if interval.get('ç»ˆç‚¹ä»·æ ¼') is not None else 0,
                        'ç»ˆç‚¹ç´¢å¼•': int(interval.get('ç»ˆç‚¹ç´¢å¼•')) if interval.get('ç»ˆç‚¹ç´¢å¼•') is not None else None,
                        'æ¶¨å¹…': float(interval.get('æ¶¨å¹…', 0)) if interval.get('æ¶¨å¹…') is not None else 0,
                        'ç¿»å€å€æ•°': float(interval.get('ç¿»å€å€æ•°', 0)) if interval.get('ç¿»å€å€æ•°') is not None else 0,
                        'å‘¨æ•°': int(interval.get('å‘¨æ•°')) if interval.get('å‘¨æ•°') is not None else None,
                        'åŒºé—´å‘¨æ•°': int(interval.get('åŒºé—´å‘¨æ•°', 4)) if interval.get('åŒºé—´å‘¨æ•°') is not None else 4
                    }
        
        return jsonify(result)
        
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"åˆ†ææ‰€æœ‰è‚¡ç¥¨é”™è¯¯: {error_detail}")
        return jsonify({
            'success': False,
            'message': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}'
        }), 500


@app.route('/api/analyze_stock_detail', methods=['POST'])
@require_login
def analyze_stock_detail():
    """ä¸ªè‚¡æ·±åº¦åˆ†æAPIï¼ˆVIPä¸“äº«åŠŸèƒ½ï¼‰"""
    try:
        # è·å–ç”¨æˆ·ä¿¡æ¯å’Œç­‰çº§
        user = get_current_user()
        if not user:
            return jsonify({
                'success': False,
                'message': 'è¯·å…ˆç™»å½•'
            }), 401
        
        user_tier = get_user_tier()
        
        # æ£€æŸ¥ç”¨æˆ·ç­‰çº§ï¼ˆä»…VIPå’Œè¶…çº§ç”¨æˆ·å¯ä»¥ä½¿ç”¨æ·±åº¦åˆ†æï¼‰
        if user_tier != 'premium' and user_tier != 'super':
            is_super = user.get('is_super', False)
            if not is_super:
                return jsonify({
                    'success': False,
                    'message': 'ä¸ªè‚¡æ·±åº¦åˆ†æåŠŸèƒ½ä»…é™VIPç”¨æˆ·ä½¿ç”¨ï¼Œè¯·å‡çº§ä¸ºVIPä¼šå‘˜'
                }), 403
        
        data = request.get_json() or {}
        stock_code = (data.get('stock_code') or '').strip()
        stock_name = data.get('stock_name', '').strip()
        buy_date = data.get('buy_date', '')
        buy_price = float(data.get('buy_price', 0))
        match_score = float(data.get('match_score', 0))
        
        if not stock_code:
            return jsonify({
                'success': False,
                'message': 'è‚¡ç¥¨ä»£ç ä¸èƒ½ä¸ºç©º'
            }), 400
        
        init_analyzer()
        
        if analyzer is None or not hasattr(analyzer, 'fetcher'):
            return jsonify({
                'success': False,
                'message': 'åˆ†æå™¨æœªåˆå§‹åŒ–'
            }), 500
        
        # è·å–è‚¡ç¥¨çš„è¯¦ç»†ä¿¡æ¯
        features = {}
        match_details = {}
        predictions = {}
        kline_data = None
        
        try:
            # å¦‚æœå·²è®­ç»ƒç‰¹å¾æ¨¡å‹ï¼Œè®¡ç®—ç‰¹å¾åŒ¹é…è¯¦æƒ…
            if analyzer.trained_features and analyzer.trained_features.get('common_features'):
                common_features = analyzer.trained_features.get('common_features', {})
                
                # è·å–è‚¡ç¥¨å‘¨çº¿æ•°æ®
                weekly_df = analyzer.fetcher.get_weekly_kline(stock_code, weeks=100)
                if weekly_df is not None and len(weekly_df) >= 40:
                    # æ‰¾åˆ°ä¹°ç‚¹æ—¥æœŸå¯¹åº”çš„ç´¢å¼•
                    buy_idx = None
                    if buy_date:
                        try:
                            buy_date_obj = pd.to_datetime(buy_date)
                            for i in range(len(weekly_df)):
                                date_col = weekly_df.iloc[i]['æ—¥æœŸ'] if 'æ—¥æœŸ' in weekly_df.columns else weekly_df.index[i]
                                if isinstance(date_col, pd.Timestamp):
                                    if date_col >= buy_date_obj:
                                        buy_idx = i
                                        break
                                elif isinstance(date_col, str):
                                    if pd.to_datetime(date_col) >= buy_date_obj:
                                        buy_idx = i
                                        break
                        except Exception as e:
                            print(f"[analyze_stock_detail] æŸ¥æ‰¾ä¹°ç‚¹æ—¥æœŸå¤±è´¥: {e}")
                            buy_idx = len(weekly_df) - 40
                    else:
                        buy_idx = len(weekly_df) - 40
                    
                    if buy_idx and buy_idx >= 40:
                        # æå–ä¹°ç‚¹å‰çš„ç‰¹å¾
                        features = analyzer.extract_features_at_start_point(
                            stock_code, buy_idx, lookback_weeks=40, weekly_df=weekly_df
                        )
                        
                        if features:
                            # è®¡ç®—ç‰¹å¾åŒ¹é…è¯¦æƒ…
                            match_details_dict = analyzer._calculate_match_score(
                                features, common_features, analyzer.tolerance
                            )
                            
                            match_details = {
                                'total_match_score': match_details_dict.get('æ€»åŒ¹é…åº¦', match_score),
                                'matched_features_count': match_details_dict.get('åŒ¹é…ç‰¹å¾æ•°', 0),
                                'core_features_match': match_details_dict.get('æ ¸å¿ƒç‰¹å¾åŒ¹é…', {}),
                                'all_features_match': match_details_dict.get('æ‰€æœ‰ç‰¹å¾åŒ¹é…', {})
                            }
                            
                            # è®¡ç®—æ¶¨è·Œå¹…é¢„æµ‹
                            if buy_idx < len(weekly_df):
                                buy_price_actual = float(weekly_df.iloc[buy_idx]['æ”¶ç›˜'])
                                
                                if buy_idx + 4 < len(weekly_df):
                                    price_4w = float(weekly_df.iloc[buy_idx + 4]['æ”¶ç›˜'])
                                    gain_4w = (price_4w - buy_price_actual) / buy_price_actual * 100
                                    predictions['gain_4w'] = round(gain_4w, 2)
                                
                                if buy_idx + 10 < len(weekly_df):
                                    price_10w = float(weekly_df.iloc[buy_idx + 10]['æ”¶ç›˜'])
                                    gain_10w = (price_10w - buy_price_actual) / buy_price_actual * 100
                                    predictions['gain_10w'] = round(gain_10w, 2)
                                    
                                    max_price_10w = float(weekly_df.iloc[buy_idx+1:buy_idx+11]['æœ€é«˜'].max())
                                    max_gain_10w = (max_price_10w - buy_price_actual) / buy_price_actual * 100
                                    predictions['max_gain_10w'] = round(max_gain_10w, 2)
                                
                                if buy_idx + 20 < len(weekly_df):
                                    price_20w = float(weekly_df.iloc[buy_idx + 20]['æ”¶ç›˜'])
                                    gain_20w = (price_20w - buy_price_actual) / buy_price_actual * 100
                                    predictions['gain_20w'] = round(gain_20w, 2)
                                
                                stop_loss_price = buy_price_actual * 0.90
                                if 'MA20' in weekly_df.columns:
                                    ma20 = float(weekly_df.iloc[buy_idx]['MA20'])
                                    if ma20 > 0:
                                        stop_loss_price = min(stop_loss_price, ma20 * 0.95)
                                predictions['stop_loss_price'] = round(stop_loss_price, 2)
                                
                                if buy_idx + 1 < len(weekly_df):
                                    future_window = weekly_df.iloc[buy_idx+1:]
                                    if len(future_window) > 0:
                                        max_price_pos = future_window['æœ€é«˜'].values.argmax()
                                        max_price = float(future_window.iloc[max_price_pos]['æœ€é«˜'])
                                        max_date = future_window.iloc[max_price_pos]['æ—¥æœŸ']
                                        if isinstance(max_date, pd.Timestamp):
                                            max_date_str = max_date.strftime('%Y-%m-%d')
                                        else:
                                            max_date_str = str(max_date)
                                        predictions['best_sell_price'] = round(max_price, 2)
                                        predictions['best_sell_date'] = max_date_str
                                
                                # è·å–Kçº¿æ•°æ®
                                try:
                                    start_idx = max(0, buy_idx - 20)
                                    end_idx = min(len(weekly_df), buy_idx + 40)
                                    kline_window = weekly_df.iloc[start_idx:end_idx]
                                    
                                    dates = []
                                    values = []
                                    for i, row in kline_window.iterrows():
                                        date_col = row['æ—¥æœŸ'] if 'æ—¥æœŸ' in row else row.index[0]
                                        if isinstance(date_col, pd.Timestamp):
                                            dates.append(date_col.strftime('%Y-%m-%d'))
                                        else:
                                            dates.append(str(date_col))
                                        
                                        open_price = float(row.get('å¼€ç›˜', 0))
                                        close_price = float(row.get('æ”¶ç›˜', 0))
                                        high_price = float(row.get('æœ€é«˜', 0))
                                        low_price = float(row.get('æœ€ä½', 0))
                                        values.append([open_price, close_price, low_price, high_price])
                                    
                                    kline_data = {
                                        'dates': dates,
                                        'values': values,
                                        'buy_point_idx': buy_idx - start_idx
                                    }
                                except Exception as e:
                                    print(f"[analyze_stock_detail] è·å–Kçº¿æ•°æ®å¤±è´¥: {e}")
        except Exception as e:
            import traceback
            error_detail = traceback.format_exc()
            print(f"[analyze_stock_detail] è·å–è‚¡ç¥¨è¯¦ç»†ä¿¡æ¯å¤±è´¥: {error_detail}")
        
        # è·å–è‚¡ç¥¨åç§°
        if not stock_name:
            stock_name = analyzer._get_stock_name(stock_code) or stock_code
        
        # æ„å»ºè¿”å›æ•°æ®
        result_data = {
            'stock_code': stock_code,
            'stock_name': stock_name,
            'match_score': match_score,
            'buy_date': buy_date,
            'buy_price': buy_price,
            'features': features,
            'match_details': match_details,
            'predictions': predictions,
            'kline_data': kline_data
        }
        
        return jsonify({
            'success': True,
            'message': 'æ·±åº¦åˆ†ææ•°æ®è·å–æˆåŠŸ',
            'data': result_data
        })
        
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"[analyze_stock_detail] âŒ æ·±åº¦åˆ†æå¤±è´¥: {error_detail}")
        return jsonify({
            'success': False,
            'message': f'æ·±åº¦åˆ†æå¤±è´¥: {str(e)}'
        }), 500


@app.route('/api/get_analysis/<stock_code>', methods=['GET'])
@require_login
def get_analysis(stock_code):
    """è·å–æŒ‡å®šè‚¡ç¥¨çš„åˆ†æç»“æœAPI"""
    try:
        result = analyzer.get_analysis_result(stock_code)
        
        if result is None:
            return jsonify({
                'success': False,
                'message': f'è‚¡ç¥¨ {stock_code} å°šæœªåˆ†æ',
                'result': None
            })
        
        # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„æ ¼å¼
        analysis_data = {
            'stock_info': result.get('stock_info'),
            'interval': result.get('interval'),
            'analyzed_at': result.get('analyzed_at').strftime('%Y-%m-%d %H:%M:%S') if result.get('analyzed_at') else None
        }
        
        if analysis_data['stock_info'] and 'æ·»åŠ æ—¶é—´' in analysis_data['stock_info']:
            if isinstance(analysis_data['stock_info']['æ·»åŠ æ—¶é—´'], datetime):
                analysis_data['stock_info']['æ·»åŠ æ—¶é—´'] = analysis_data['stock_info']['æ·»åŠ æ—¶é—´'].strftime('%Y-%m-%d %H:%M:%S')
        
        return jsonify({
            'success': True,
            'result': analysis_data
        })
        
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"è·å–åˆ†æç»“æœé”™è¯¯: {error_detail}")
        return jsonify({
            'success': False,
            'message': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}'
        }), 500


@app.route('/api/train_features', methods=['POST'])
@require_login
def train_features():
    init_analyzer()  # ç¡®ä¿åˆ†æå™¨å·²åˆå§‹åŒ–
    """è®­ç»ƒç‰¹å¾æ¨¡å‹API"""
    try:
        result = analyzer.train_features()
        
        # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„æ ¼å¼
        if result.get('common_features'):
            common_features = {}
            for feature_name, stats in result['common_features'].items():
                common_features[feature_name] = {
                    'å‡å€¼': float(stats['å‡å€¼']),
                    'ä¸­ä½æ•°': float(stats['ä¸­ä½æ•°']),
                    'æœ€å°å€¼': float(stats['æœ€å°å€¼']),
                    'æœ€å¤§å€¼': float(stats['æœ€å¤§å€¼']),
                    'æ ‡å‡†å·®': float(stats['æ ‡å‡†å·®']),
                    'æ ·æœ¬æ•°': int(stats['æ ·æœ¬æ•°'])
                }
            result['common_features'] = common_features
        
        return jsonify(result)
        
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"è®­ç»ƒç‰¹å¾é”™è¯¯: {error_detail}")
        return jsonify({
            'success': False,
            'message': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}'
        }), 500


@app.route('/api/get_progress', methods=['GET'])
@require_login
def get_progress():
    """è·å–å½“å‰è¿›åº¦API"""
    # æ·»åŠ  CORS å’Œç¼“å­˜æ§åˆ¶å¤´
    response_headers = {
        'Cache-Control': 'no-cache, no-store, must-revalidate',
        'Pragma': 'no-cache',
        'Expires': '0'
    }
    
    # åœ¨ Vercel serverless ç¯å¢ƒä¸­ï¼Œä» Redis è¯»å–è¿›åº¦ï¼ˆRenderç¯å¢ƒä½¿ç”¨æœ¬åœ°è¿›åº¦ï¼‰
    if is_vercel and not is_render:
        scan_id = request.args.get('scan_id')
        
        # è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯
        current_user = get_current_user()
        username = current_user.get('username', 'anonymous') if current_user else 'anonymous'
        
        import scan_progress_store
        
        # å¦‚æœæä¾›äº† scan_idï¼Œç›´æ¥è·å–
        if scan_id:
            try:
                progress = scan_progress_store.get_scan_progress(scan_id)
                if progress:
                    # éªŒè¯è¿›åº¦æ˜¯å¦å±äºå½“å‰ç”¨æˆ·ï¼ˆå¤šç”¨æˆ·éš”ç¦»ï¼‰
                    progress_username = progress.get('username', 'anonymous')
                    if progress_username != username:
                        print(f"[get_progress] âš ï¸ ç”¨æˆ· {username} å°è¯•è®¿é—®å…¶ä»–ç”¨æˆ· {progress_username} çš„æ‰«æè¿›åº¦: {scan_id}")
                        # è¿”å›ç©ºé—²çŠ¶æ€ï¼Œè€Œä¸æ˜¯é”™è¯¯ï¼Œé¿å…å‰ç«¯æ˜¾ç¤ºé”™è¯¯
                        response = jsonify({
                            'success': True,
                            'progress': {
                                'type': None,
                                'current': 0,
                                'total': 0,
                                'status': 'ç©ºé—²',
                                'detail': 'æ— æƒè®¿é—®æ­¤æ‰«æä»»åŠ¡',
                                'percentage': 0,
                                'found': 0
                            }
                        })
                        for key, value in response_headers.items():
                            response.headers[key] = value
                        return response
                    
                    response = jsonify({
                        'success': True,
                        'progress': progress
                    })
                    for key, value in response_headers.items():
                        response.headers[key] = value
                    return response
            except Exception as e:
                print(f"[get_progress] ä» Redis è¯»å–è¿›åº¦å¤±è´¥: {e}")
        
        # å¦‚æœæ²¡æœ‰æä¾› scan_idï¼Œå°è¯•æŸ¥æ‰¾å½“å‰ç”¨æˆ·çš„æœ€æ–°æ‰«æä»»åŠ¡
        # scan_id æ ¼å¼: username_timestamp_uuid
        # ç”±äº Redis ä¸æ”¯æŒæ¨¡å¼åŒ¹é…ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªé”®æ¥å­˜å‚¨ç”¨æˆ·çš„æœ€æ–° scan_id
        try:
            latest_scan_key = f'latest_scan:{username}'
            if hasattr(scan_progress_store, '_upstash_redis_get'):
                latest_scan_id = scan_progress_store._upstash_redis_get(latest_scan_key)
                if latest_scan_id:
                    progress = scan_progress_store.get_scan_progress(latest_scan_id)
                    if progress:
                        # éªŒè¯è¿›åº¦æ˜¯å¦å±äºå½“å‰ç”¨æˆ·
                        progress_username = progress.get('username', 'anonymous')
                        if progress_username == username:
                            # æ£€æŸ¥çŠ¶æ€æ˜¯å¦ä¸ºæ´»è·ƒï¼ˆä¸æ˜¯"ç©ºé—²"æˆ–"å·²å®Œæˆ"ï¼‰
                            status = progress.get('status', 'ç©ºé—²')
                            if status not in ['ç©ºé—²', 'å·²å®Œæˆ', 'å·²åœæ­¢', 'é”™è¯¯']:
                                response = jsonify({
                                    'success': True,
                                    'progress': progress
                                })
                                for key, value in response_headers.items():
                                    response.headers[key] = value
                                return response
        except Exception as e:
            print(f"[get_progress] æŸ¥æ‰¾æœ€æ–°æ‰«æä»»åŠ¡å¤±è´¥: {e}")
        
        # å¦‚æœæ²¡æœ‰æä¾› scan_id æˆ–æ‰¾ä¸åˆ°è¿›åº¦ï¼Œè¿”å›ç©ºé—²çŠ¶æ€
        response = jsonify({
            'success': True,
            'progress': {
                'type': None,
                'current': 0,
                'total': 0,
                'status': 'ç©ºé—²',
                'detail': '',
                'percentage': 0,
                'found': 0
            }
        })
        for key, value in response_headers.items():
            response.headers[key] = value
        return response
    
    try:
        # ä¼˜åŒ–ï¼šå¦‚æœanalyzerå·²åˆå§‹åŒ–ï¼Œç›´æ¥ä½¿ç”¨ï¼Œé¿å…é‡å¤åˆå§‹åŒ–å¯¼è‡´é˜»å¡
        if analyzer is None:
            # å¿«é€Ÿåˆå§‹åŒ–ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å›é»˜è®¤å€¼
            try:
                init_analyzer()
            except Exception as e:
                print(f"[get_progress] åˆå§‹åŒ–analyzerå¤±è´¥: {e}")
                # åˆå§‹åŒ–å¤±è´¥æ—¶è¿”å›é»˜è®¤å€¼ï¼Œä¸é˜»å¡
                response = jsonify({
                    'success': True,
                    'progress': {
                        'type': None,
                        'current': 0,
                        'total': 0,
                        'status': 'ç©ºé—²',
                        'detail': 'åˆ†æå™¨æœªåˆå§‹åŒ–',
                        'percentage': 0,
                        'found': 0
                    }
                })
                for key, value in response_headers.items():
                    response.headers[key] = value
                return response
        
        # æ£€æŸ¥ analyzer æ˜¯å¦å·²åˆå§‹åŒ–
        if analyzer is None:
            print("[get_progress] analyzer æœªåˆå§‹åŒ–ï¼Œè¿”å›é»˜è®¤å€¼")
            response = jsonify({
                'success': True,
                'progress': {
                    'type': None,
                    'current': 0,
                    'total': 0,
                    'status': 'ç©ºé—²',
                    'detail': '',
                    'percentage': 0,
                    'found': 0
                }
            })
            for key, value in response_headers.items():
                response.headers[key] = value
            return response
        
        # è·å–è¿›åº¦ä¿¡æ¯ï¼ˆæ·»åŠ å¼‚å¸¸ä¿æŠ¤ï¼‰
        try:
            progress = analyzer.get_progress() if hasattr(analyzer, 'get_progress') else {}
            if not isinstance(progress, dict):
                print(f"[get_progress] progress ä¸æ˜¯å­—å…¸ç±»å‹: {type(progress)}")
                progress = {'type': None, 'current': 0, 'total': 0, 'status': 'ç©ºé—²', 'detail': '', 'percentage': 0, 'found': 0}
            
            # ã€ä¸å¯å˜ã€‘æ‰¾åˆ°ä¸€åªæ˜¾ç¤ºä¸€åªï¼šfound>0 æ—¶è‹¥ candidates ä¸ºç©ºï¼Œä» analyzer.progress ç›´æ¥è¡¥å…¨ï¼Œä¿è¯å®æ—¶æ˜¾ç¤º
            if (progress.get('found') or 0) > 0 and (not progress.get('candidates') or len(progress.get('candidates', [])) == 0):
                raw = getattr(analyzer, 'progress', None) or {}
                if isinstance(raw, dict) and raw.get('candidates'):
                    progress['candidates'] = list(raw['candidates'])
            
            import json
            import math
            import numpy as np
            
            def _safe_float(v):
                """å°†å¯èƒ½ä¸º nan/inf çš„æ•°å€¼è½¬ä¸º Noneï¼Œä¿è¯ JSON å¯åºåˆ—åŒ–"""
                if v is None: return None
                if hasattr(pd, 'isna') and pd.isna(v): return None
                try:
                    f = float(v)
                    return None if (math.isnan(f) or math.isinf(f)) else f
                except (TypeError, ValueError): return None
            
            # ã€ä¸å¯å˜ã€‘candidates å¿…é¡»è¿”å›ç»™å‰ç«¯ï¼Œä¸èƒ½æ¸…ç©ºã€‚è§ æ‰«ææ˜¾ç¤ºä¸å¯å˜é€»è¾‘.md
            if progress.get('candidates'):
                cleaned_candidates = []
                for candidate in progress['candidates']:
                    try:
                        cleaned = {}
                        for key, value in (candidate or {}).items():
                            if key in ('ç‰¹å¾', 'æ ¸å¿ƒç‰¹å¾åŒ¹é…'):
                                continue
                            if isinstance(value, (np.integer, np.int64, np.int32)):
                                cleaned[key] = int(value)
                            elif isinstance(value, (np.floating, np.float64, np.float32)):
                                cleaned[key] = _safe_float(value) if (hasattr(pd, 'isna') and pd.isna(value)) else _safe_float(float(value))
                            elif hasattr(pd, 'isna') and pd.isna(value):
                                cleaned[key] = None
                            elif hasattr(value, 'isoformat') and callable(getattr(value, 'isoformat', None)):
                                try:
                                    cleaned[key] = value.isoformat()[:19] if value is not None and not (hasattr(pd, 'isna') and pd.isna(value)) else None
                                except Exception:
                                    cleaned[key] = str(value) if value is not None else None
                            elif isinstance(value, (int, float)):
                                cleaned[key] = _safe_float(value) if isinstance(value, float) else value
                            else:
                                cleaned[key] = value
                        # äºŒæ¬¡æ¸…ç†ï¼šé˜²æ­¢é—æ¼çš„ nan/inf å¯¼è‡´ JSON åºåˆ—åŒ–å¤±è´¥
                        for k in list(cleaned.keys()):
                            v = cleaned[k]
                            if isinstance(v, float) and (math.isnan(v) or math.isinf(v)):
                                cleaned[k] = None
                        cleaned_candidates.append(cleaned)
                    except Exception as ex:
                        cleaned_candidates.append({
                            'è‚¡ç¥¨ä»£ç ': str((candidate or {}).get('è‚¡ç¥¨ä»£ç ') or (candidate or {}).get('code') or ''),
                            'è‚¡ç¥¨åç§°': str((candidate or {}).get('è‚¡ç¥¨åç§°') or (candidate or {}).get('name') or ''),
                            'åŒ¹é…åº¦': _safe_float((candidate or {}).get('åŒ¹é…åº¦') or (candidate or {}).get('match_score') or 0) or 0,
                            'æœ€ä½³ä¹°ç‚¹æ—¥æœŸ': (str((candidate or {}).get('æœ€ä½³ä¹°ç‚¹æ—¥æœŸ') or (candidate or {}).get('buy_date') or ''))[:10],
                        })
                progress['candidates'] = cleaned_candidates
            
            try:
                json.dumps(progress, default=str)
            except (TypeError, ValueError) as e:
                print(f"[get_progress] åºåˆ—åŒ–æµ‹è¯•å¤±è´¥: {e}ï¼Œå°è¯•åªä¿ç•™ candidates æ ‡é‡å­—æ®µ")
                # ä¸ç›´æ¥æ¸…ç©ºï¼šå°è¯•åªä¿ç•™å¯åºåˆ—åŒ–æ ‡é‡ï¼Œä¿è¯å®æ—¶æ˜¾ç¤º
                try:
                    simple = []
                    for c in progress.get('candidates', []):
                        simple.append({
                            'è‚¡ç¥¨ä»£ç ': str(c.get('è‚¡ç¥¨ä»£ç ') or c.get('code') or ''),
                            'è‚¡ç¥¨åç§°': str(c.get('è‚¡ç¥¨åç§°') or c.get('name') or ''),
                            'åŒ¹é…åº¦': _safe_float(c.get('åŒ¹é…åº¦') or c.get('match_score') or 0) or 0,
                            'æœ€ä½³ä¹°ç‚¹æ—¥æœŸ': str(c.get('æœ€ä½³ä¹°ç‚¹æ—¥æœŸ') or c.get('buy_date') or '')[:10],
                            'æœ€ä½³ä¹°ç‚¹ä»·æ ¼': _safe_float(c.get('æœ€ä½³ä¹°ç‚¹ä»·æ ¼') or c.get('buy_price')),
                            'å½“å‰ä»·æ ¼': _safe_float(c.get('å½“å‰ä»·æ ¼') or c.get('current_price')),
                            'å¸‚å€¼': _safe_float(c.get('å¸‚å€¼')) if (c.get('å¸‚å€¼') is not None and isinstance(c.get('å¸‚å€¼'), (int, float))) else (_safe_float(c.get('market_cap')) if (c.get('market_cap') is not None and isinstance(c.get('market_cap'), (int, float))) else None),
                        })
                    progress['candidates'] = simple
                    json.dumps(progress, default=str)
                except Exception as ex2:
                    print(f"[get_progress] è­¦å‘Š: candidates ç®€åŒ–åºåˆ—åŒ–ä»å¤±è´¥ï¼Œå·²æ¸…ç©ºã€‚{ex2}")
                    progress['candidates'] = []
            
            response = jsonify({
                'success': True,
                'progress': progress
            })
            for key, value in response_headers.items():
                response.headers[key] = value
            return response
        except AttributeError as e:
            # analyzer æœªåˆå§‹åŒ–æˆ– get_progress æ–¹æ³•ä¸å­˜åœ¨
            print(f"[get_progress] AttributeError: {e}")
            return jsonify({
                'success': True,
                'progress': {
                    'type': None,
                    'current': 0,
                    'total': 0,
                    'status': 'ç©ºé—²',
                    'detail': '',
                    'percentage': 0,
                    'found': 0
                }
            })
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"[get_progress] é”™è¯¯: {error_detail}")
        # å³ä½¿å‡ºé”™ï¼Œä¹Ÿè¿”å›æˆåŠŸå“åº”ï¼ˆä½†å¸¦é”™è¯¯çŠ¶æ€ï¼‰ï¼Œé¿å…å‰ç«¯ä¸æ–­é‡è¯•
        return jsonify({
            'success': True,
            'progress': {
                'type': None,
                'current': 0,
                'total': 0,
                'status': 'é”™è¯¯',
                'detail': f'è·å–è¿›åº¦å¤±è´¥: {str(e)}',
                'percentage': 0,
                'found': 0
            },
            'error': str(e) if is_vercel else None  # ä»…åœ¨ Vercel ç¯å¢ƒä¸­è¿”å›é”™è¯¯è¯¦æƒ…
        })


def _normalize_trained_at(val):
    """å°† trained_at è½¬ä¸º YYYY-MM-DD æ˜¾ç¤ºï¼›æ— æ•ˆåˆ™è¿”å› Noneã€‚"""
    if not val:
        return None
    s = str(val).strip()
    if not s:
        return None
    # ISO: 2026-01-24T09:15:41... æˆ– 2026-01-24
    if len(s) >= 10 and s[4] == '-' and s[7] == '-':
        return s[:10]
    return None

def _parse_date_from_model_filename(filename):
    """ä» trained_model_*_YYYYMMDD_HHMMSS.json è§£ææ—¥æœŸï¼Œè¿”å› YYYY-MM-DD æˆ– Noneã€‚"""
    import re
    m = re.search(r'_(\d{4})(\d{2})(\d{2})_(\d{6})\.json$', filename)
    if m:
        return f"{m.group(1)}-{m.group(2)}-{m.group(3)}"
    return None

@app.route('/api/list_models', methods=['GET'])
@require_login
def list_models():
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ¨¡å‹æ–‡ä»¶"""
    try:
        import os
        import json
        from datetime import datetime
        
        project_root = os.path.dirname(os.path.abspath(__file__))
        model_files = []
        
        # æŸ¥æ‰¾ trained_model*.json ä¸ model*.jsonï¼ˆæ’é™¤ model_comparisonã€model_structureï¼‰
        exclude = {'model_comparison.json', 'model_structure.json'}
        for filename in os.listdir(project_root):
            if not filename.endswith('.json'):
                continue
            if filename in exclude:
                continue
            if filename.startswith('trained_model') or filename.startswith('model'):
                filepath = os.path.join(project_root, filename)
                try:
                    # è¯»å–æ¨¡å‹æ–‡ä»¶è·å–åŸºæœ¬ä¿¡æ¯
                    with open(filepath, 'r', encoding='utf-8') as f:
                        model_data = json.load(f)
                    
                    buy_features = model_data.get('buy_features', {})
                    common_features = buy_features.get('common_features', {})
                    raw_at = model_data.get('trained_at') or buy_features.get('trained_at')
                    trained_at = _normalize_trained_at(raw_at)
                    if not trained_at:
                        trained_at = _parse_date_from_model_filename(filename)
                    if not trained_at:
                        trained_at = 'æœªçŸ¥'
                    bull_stocks = model_data.get('bull_stocks', [])
                    mtime = os.path.getmtime(filepath)
                    
                    model_info = {
                        'filename': filename,
                        'trained_at': trained_at,
                        'feature_count': len(common_features),
                        'stock_count': len(bull_stocks),
                        'is_current': filename == _current_model_file,
                        '_mtime': mtime,
                        '_sort_date': trained_at if trained_at != 'æœªçŸ¥' else None
                    }
                    model_files.append(model_info)
                except Exception as e:
                    print(f"[list_models] è¯»å– {filename} å¤±è´¥: {e}")
                    mtime = os.path.getmtime(filepath) if os.path.exists(filepath) else 0
                    model_files.append({
                        'filename': filename,
                        'trained_at': 'æœªçŸ¥',
                        'feature_count': 0,
                        'stock_count': 0,
                        'is_current': filename == _current_model_file,
                        '_mtime': mtime,
                        '_sort_date': None,
                        'error': str(e)
                    })
        
        # æ’åºï¼šå½“å‰æ¨¡å‹ç½®é¡¶ï¼Œå…¶ä½™æŒ‰æ—¥æœŸä»æ–°åˆ°æ—§ï¼Œå†æŒ‰æ–‡ä»¶å
        def _sort_key(m):
            is_cur = 0 if m['is_current'] else 1
            sd = m.get('_sort_date')
            date_str = sd if sd else None
            if not date_str:
                mtime = m.get('_mtime', 0)
                date_str = datetime.fromtimestamp(mtime).strftime('%Y-%m-%d') if mtime else '1970-01-01'
            parts = [int(x) for x in date_str.split('-')]
            # æ—¥æœŸä»æ–°åˆ°æ—§ï¼š(-å¹´,-æœˆ,-æ—¥)
            return (is_cur, -parts[0], -parts[1], -parts[2], m['filename'])
        
        model_files.sort(key=_sort_key)
        for m in model_files:
            m.pop('_mtime', None)
            m.pop('_sort_date', None)
        
        return jsonify({
            'success': True,
            'models': model_files,
            'current_model': _current_model_file
        })
    except Exception as e:
        import traceback
        print(f"[list_models] é”™è¯¯: {traceback.format_exc()}")
        return jsonify({
            'success': False,
            'message': f'è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {str(e)}'
        }), 500

@app.route('/api/switch_model', methods=['POST'])
@require_login
def switch_model():
    """åˆ‡æ¢ä½¿ç”¨çš„æ¨¡å‹æ–‡ä»¶"""
    global analyzer, _current_model_file, _model_last_loaded_mtime
    try:
        data = request.get_json() or {}
        model_filename = data.get('model_filename', '').strip()
        
        if not model_filename:
            return jsonify({
                'success': False,
                'message': 'è¯·æŒ‡å®šæ¨¡å‹æ–‡ä»¶å'
            }), 400
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        import os
        project_root = os.path.dirname(os.path.abspath(__file__))
        model_path = os.path.join(project_root, model_filename)
        
        if not os.path.exists(model_path):
            return jsonify({
                'success': False,
                'message': f'æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_filename}'
            }), 404
        
        # åˆ‡æ¢æ¨¡å‹
        _current_model_file = model_filename
        analyzer = None  # æ¸…ç©ºç¼“å­˜ï¼Œè¿«ä½¿é‡æ–°åŠ è½½
        _model_last_loaded_mtime = 0  # é‡ç½® mtime
        
        # é‡æ–°åŠ è½½æ¨¡å‹
        a = init_analyzer()
        if a is None:
            return jsonify({
                'success': False,
                'message': 'æ¨¡å‹åŠ è½½å¤±è´¥'
            }), 500
        
        buy_n = len(a.trained_features.get('common_features', {})) if a.trained_features else 0
        sell_n = len(a.trained_sell_features.get('common_features', {})) if a.trained_sell_features else 0
        
        return jsonify({
            'success': True,
            'message': f'å·²åˆ‡æ¢åˆ°æ¨¡å‹: {model_filename}',
            'current_model': _current_model_file,
            'buy_features': buy_n,
            'sell_features': sell_n
        })
    except Exception as e:
        import traceback
        print(f"[switch_model] é”™è¯¯: {traceback.format_exc()}")
        return jsonify({
            'success': False,
            'message': f'åˆ‡æ¢æ¨¡å‹å¤±è´¥: {str(e)}'
        }), 500

@app.route('/api/delete_model', methods=['POST'])
@require_login
def delete_model():
    """åˆ é™¤æ¨¡å‹æ–‡ä»¶"""
    global analyzer, _current_model_file, _model_last_loaded_mtime
    try:
        data = request.get_json() or {}
        model_filename = data.get('model_filename', '').strip()
        
        if not model_filename:
            return jsonify({
                'success': False,
                'message': 'è¯·æŒ‡å®šæ¨¡å‹æ–‡ä»¶å'
            }), 400
        
        # ä¸å…è®¸åˆ é™¤é»˜è®¤æ¨¡å‹ trained_model.json
        if model_filename == 'trained_model.json':
            return jsonify({
                'success': False,
                'message': 'ä¸èƒ½åˆ é™¤é»˜è®¤æ¨¡å‹ trained_model.json'
            }), 400
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        import os
        project_root = os.path.dirname(os.path.abspath(__file__))
        model_path = os.path.join(project_root, model_filename)
        
        if not os.path.exists(model_path):
            return jsonify({
                'success': False,
                'message': f'æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_filename}'
            }), 404
        
        # å¦‚æœåˆ é™¤çš„æ˜¯å½“å‰æ¨¡å‹ï¼Œå…ˆåˆ‡æ¢åˆ°é»˜è®¤æ¨¡å‹
        was_current_model = model_filename == _current_model_file
        if was_current_model:
            _current_model_file = 'trained_model.json'
            analyzer = None
            _model_last_loaded_mtime = 0
            # é‡æ–°åŠ è½½é»˜è®¤æ¨¡å‹
            a = init_analyzer()
            if a is None:
                return jsonify({
                    'success': False,
                    'message': 'åˆ é™¤å½“å‰æ¨¡å‹åï¼Œåˆ‡æ¢åˆ°é»˜è®¤æ¨¡å‹å¤±è´¥'
                }), 500
        
        # åˆ é™¤æ–‡ä»¶
        try:
            os.remove(model_path)
            print(f"[delete_model] âœ… å·²åˆ é™¤æ¨¡å‹æ–‡ä»¶: {model_filename}")
        except Exception as e:
            return jsonify({
                'success': False,
                'message': f'åˆ é™¤æ–‡ä»¶å¤±è´¥: {str(e)}'
            }), 500
        
        return jsonify({
            'success': True,
            'message': f'æ¨¡å‹ {model_filename} å·²åˆ é™¤',
            'current_model': _current_model_file,
            'switched_to_default': was_current_model
        })
    except Exception as e:
        import traceback
        print(f"[delete_model] é”™è¯¯: {traceback.format_exc()}")
        return jsonify({
            'success': False,
            'message': f'åˆ é™¤æ¨¡å‹å¤±è´¥: {str(e)}'
        }), 500

@app.route('/api/reload_model', methods=['GET', 'POST'])
@require_login
def reload_model():
    """å¼ºåˆ¶é‡æ–°åŠ è½½å½“å‰æ¨¡å‹ï¼ˆç”¨äºé‡è®­åæ— éœ€é‡å¯æœåŠ¡ï¼‰"""
    global analyzer
    try:
        analyzer = None  # æ¸…ç©ºç¼“å­˜ï¼Œè¿«ä½¿ init_analyzer é‡æ–°ä»ç£ç›˜åŠ è½½
        a = init_analyzer()
        if a is None:
            return jsonify({'success': False, 'message': 'æ¨¡å‹åŠ è½½å¤±è´¥'}), 500
        buy_n = len(a.trained_features.get('common_features', {})) if a.trained_features else 0
        sell_n = len(a.trained_sell_features.get('common_features', {})) if a.trained_sell_features else 0
        return jsonify({
            'success': True,
            'message': 'æ¨¡å‹å·²é‡æ–°åŠ è½½',
            'current_model': _current_model_file,
            'buy_features': buy_n,
            'sell_features': sell_n
        })
    except Exception as e:
        import traceback
        print(f"reload_model é”™è¯¯: {traceback.format_exc()}")
        return jsonify({'success': False, 'message': str(e)}), 500


@app.route('/api/save_model', methods=['POST'])
@require_login
def save_model():
    """ä¿å­˜æ¨¡å‹åˆ°æ–‡ä»¶API"""
    try:
        init_analyzer()  # ç¡®ä¿åˆ†æå™¨å·²åˆå§‹åŒ–
        success = analyzer.save_model('trained_model.json')
        if success:
            return jsonify({
                'success': True,
                'message': 'æ¨¡å‹å·²ä¿å­˜åˆ° trained_model.json'
            })
        else:
            return jsonify({
                'success': False,
                'message': 'ä¿å­˜æ¨¡å‹å¤±è´¥'
            }), 500
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"ä¿å­˜æ¨¡å‹é”™è¯¯: {error_detail}")
        return jsonify({
            'success': False,
            'message': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}'
        }), 500

@app.route('/api/get_trained_features', methods=['GET'])
@require_login
def get_trained_features():
    """è·å–è®­ç»ƒå¥½çš„ç‰¹å¾æ¨¡æ¿API"""
    try:
        init_analyzer()  # ç¡®ä¿åˆ†æå™¨å·²åˆå§‹åŒ–
        trained = analyzer.get_trained_features()
        
        print(f"[get_trained_features] trained æ˜¯å¦ä¸º None: {trained is None}")
        if trained is not None:
            print(f"[get_trained_features] trained æœ‰ common_features: {trained.get('common_features') is not None}")
            if trained.get('common_features'):
                print(f"[get_trained_features] common_features æ•°é‡: {len(trained.get('common_features', {}))}")
        
        if trained is None:
            print("[get_trained_features] è¿”å›ï¼šæ¨¡å‹ä¸å­˜åœ¨")
            return jsonify({
                'success': False,
                'message': 'å°šæœªè®­ç»ƒç‰¹å¾æ¨¡å‹',
                'common_features': None,
                'match_score_ready': False,
                'max_match_score': 0.0
            })
        
        # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„æ ¼å¼
        result = {
            'success': True,
            'sample_count': trained.get('sample_count', 0),
            'trained_at': trained.get('trained_at').strftime('%Y-%m-%d %H:%M:%S') if trained.get('trained_at') else None,
            'sample_stocks': trained.get('sample_stocks', []),
            'common_features': {}
        }
        
        if trained.get('common_features'):
            for feature_name, stats in trained['common_features'].items():
                result['common_features'][feature_name] = {
                    'å‡å€¼': float(stats['å‡å€¼']),
                    'ä¸­ä½æ•°': float(stats['ä¸­ä½æ•°']),
                    'æœ€å°å€¼': float(stats['æœ€å°å€¼']),
                    'æœ€å¤§å€¼': float(stats['æœ€å¤§å€¼']),
                    'æ ‡å‡†å·®': float(stats['æ ‡å‡†å·®']),
                    'æ ·æœ¬æ•°': int(stats['æ ·æœ¬æ•°'])
                }
        
        print(f"[get_trained_features] è¿”å› common_features æ•°é‡: {len(result['common_features'])}")
        
        # æ£€æŸ¥åŒ¹é…åº¦çŠ¶æ€
        try:
            is_ready, max_score = analyzer._check_match_score()
            result['match_score_ready'] = is_ready
            result['max_match_score'] = max_score
        except Exception as e:
            print(f"[get_trained_features] æ£€æŸ¥åŒ¹é…åº¦çŠ¶æ€å¤±è´¥: {e}")
            result['match_score_ready'] = False
            result['max_match_score'] = 0.0
        
        return jsonify(result)
        
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"è·å–è®­ç»ƒç‰¹å¾é”™è¯¯: {error_detail}")
        return jsonify({
            'success': False,
            'message': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}',
            'common_features': None,
            'match_score_ready': False,
            'max_match_score': 0.0
        }), 500


@app.route('/api/find_sell_points', methods=['POST'])
@require_login
def find_sell_points():
    init_analyzer()  # ç¡®ä¿åˆ†æå™¨å·²åˆå§‹åŒ–
    """æŸ¥æ‰¾å–ç‚¹API"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({
                'success': False,
                'message': 'è¯·æ±‚æ•°æ®ä¸ºç©º',
                'sell_points': []
            }), 400
        
        stock_code = (data.get('code') or '').strip()
        buy_date = data.get('buy_date', '').strip()
        buy_price = float(data.get('buy_price', 0))
        search_weeks = int(data.get('search_weeks', 20))
        match_threshold = float(data.get('match_threshold', 0.85))
        
        if not stock_code:
            return jsonify({
                'success': False,
                'message': 'è‚¡ç¥¨ä»£ç ä¸èƒ½ä¸ºç©º',
                'sell_points': []
            }), 400
        
        if not buy_date:
            return jsonify({
                'success': False,
                'message': 'ä¹°å…¥æ—¥æœŸä¸èƒ½ä¸ºç©º',
                'sell_points': []
            }), 400
        
        if buy_price <= 0:
            return jsonify({
                'success': False,
                'message': 'ä¹°å…¥ä»·æ ¼å¿…é¡»å¤§äº0',
                'sell_points': []
            }), 400
        
        # æŸ¥æ‰¾å–ç‚¹
        result = analyzer.find_sell_points(
            stock_code,
            buy_date=buy_date,
            buy_price=buy_price,
            search_weeks=search_weeks,
            match_threshold=match_threshold
        )
        
        # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„æ ¼å¼
        if result.get('success') and result.get('sell_points'):
            sell_points = []
            for sp in result['sell_points']:
                sell_point = {
                    'æ—¥æœŸ': str(sp.get('æ—¥æœŸ', '')),
                    'ä»·æ ¼': float(sp.get('ä»·æ ¼', 0)) if sp.get('ä»·æ ¼') is not None else 0,
                    'æ”¶ç›˜ä»·': float(sp.get('æ”¶ç›˜ä»·', 0)) if sp.get('æ”¶ç›˜ä»·') is not None else 0,
                    'åŒ¹é…åº¦': float(sp.get('åŒ¹é…åº¦', 0)) if sp.get('åŒ¹é…åº¦') is not None else 0,
                    'ç´¯è®¡æ¶¨å¹…': float(sp.get('ç´¯è®¡æ¶¨å¹…', 0)) if sp.get('ç´¯è®¡æ¶¨å¹…') is not None else 0,
                    'ç¿»å€å€æ•°': float(sp.get('ç¿»å€å€æ•°', 0)) if sp.get('ç¿»å€å€æ•°') is not None else 0,
                    'ä¹°å…¥åå‘¨æ•°': int(sp.get('ä¹°å…¥åå‘¨æ•°', 0)) if sp.get('ä¹°å…¥åå‘¨æ•°') is not None else 0,
                    '1å‘¨åå›è°ƒ': float(sp.get('1å‘¨åå›è°ƒ', 0)) if sp.get('1å‘¨åå›è°ƒ') is not None else None,
                    '2å‘¨åå›è°ƒ': float(sp.get('2å‘¨åå›è°ƒ', 0)) if sp.get('2å‘¨åå›è°ƒ') is not None else None
                }
                sell_points.append(sell_point)
            
            return jsonify({
                'success': True,
                'message': result.get('message', ''),
                'sell_points': sell_points,
                'buy_date': result.get('buy_date', ''),
                'buy_price': result.get('buy_price', 0)
            })
        else:
            return jsonify({
                'success': False,
                'message': result.get('message', 'æŸ¥æ‰¾å–ç‚¹å¤±è´¥'),
                'sell_points': []
            })
    
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"æŸ¥æ‰¾å–ç‚¹APIå‡ºé”™: {error_detail}")
        return jsonify({
            'success': False,
            'message': f'æŸ¥æ‰¾å–ç‚¹å¤±è´¥: {str(e)}',
            'sell_points': []
        }), 500


@app.route('/api/scan_all_stocks', methods=['POST'])
@require_login
def scan_all_stocks():
    """æ‰«ææ‰€æœ‰Aè‚¡API"""
    try:
        # ç¡®ä¿åˆ†æå™¨å·²åˆå§‹åŒ–ï¼ˆåœ¨ try å—å†…ï¼Œä»¥ä¾¿æ•è·å¼‚å¸¸ï¼‰
        try:
            init_analyzer()
        except Exception as init_error:
            import traceback
            error_detail = traceback.format_exc()
            print(f"[scan_all_stocks] âŒ åˆå§‹åŒ–åˆ†æå™¨å¤±è´¥: {error_detail}")
            return jsonify({
                'success': False,
                'message': f'åˆå§‹åŒ–åˆ†æå™¨å¤±è´¥: {str(init_error)}',
                'error_type': 'init_error',
                'error_detail': error_detail
            }), 500
        
        # æ£€æŸ¥åˆ†æå™¨æ˜¯å¦åˆå§‹åŒ–æˆåŠŸ
        if analyzer is None or analyzer.fetcher is None:
            return jsonify({
                'success': False,
                'message': 'åˆ†æå™¨æœªåˆå§‹åŒ–æˆ–åˆå§‹åŒ–å¤±è´¥',
                'error_type': 'analyzer_not_initialized'
            }), 500
        # è·å–ç”¨æˆ·ä¿¡æ¯å’Œç­‰çº§
        user = get_current_user()
        if not user:
            return jsonify({
                'success': False,
                'message': 'è¯·å…ˆç™»å½•'
            }), 401
        
        username = user.get('username', 'anonymous')
        user_tier = get_user_tier()
        
        # å…è´¹ç”¨æˆ·ä¸å…è®¸æ‰‹åŠ¨æ‰«æï¼Œåªèƒ½æŸ¥çœ‹è‡ªåŠ¨æ‰«æçš„ç»“æœ
        if user_tier == 'free':
            return jsonify({
                'success': False,
                'message': 'å…è´¹ç”¨æˆ·æ— éœ€æ‰‹åŠ¨æ‰«æï¼Œç³»ç»Ÿæ¯å¤©ä¸‹åˆ3:00è‡ªåŠ¨æ‰«æï¼Œæ‚¨å¯ä»¥ç›´æ¥æŸ¥çœ‹ç»“æœã€‚',
                'error_code': 'AUTO_SCAN_ONLY'
            }), 403
        
        # VIPç”¨æˆ·å’Œè¶…çº§ç”¨æˆ·å¯ä»¥æ‰‹åŠ¨æ‰«æ
        scan_config = get_scan_config()
        
        # VIPç”¨æˆ·å’Œè¶…çº§ç”¨æˆ·ï¼šæ— æ‰«æé™åˆ¶ï¼ˆæ— é™æ¬¡æ‰«æï¼‰
        # VIPç”¨æˆ·å·²ç»ç§»é™¤äº†æ¯æ—¥æ‰«ææ¬¡æ•°é™åˆ¶ï¼Œå¯ä»¥æ— é™æ¬¡æ‰‹åŠ¨æ‰«æ
        
        data = request.get_json() or {}
        min_match_score = float(data.get('min_match_score', 0.93))  # é»˜è®¤0.93ï¼Œæ›´ä¸¥æ ¼ï¼›è‹¥è¿‡å°‘å¯è°ƒä½
        max_market_cap = float(data.get('max_market_cap', 100.0))
        # âœ… å…³é”®ï¼šæ‰“å°æ¥æ”¶åˆ°çš„å¸‚å€¼å‚æ•°ï¼Œç¡®ä¿æ­£ç¡®ä¼ é€’
        print(f"[scan_all_stocks] æ¥æ”¶åˆ°çš„æ‰«æå‚æ•°: min_match_score={min_match_score}, max_market_cap={max_market_cap}, å‚æ•°ç±»å‹: {type(max_market_cap)}")
        limit = data.get('limit')
        scan_date = (data.get('scan_date') or '').strip() if isinstance(data.get('scan_date'), str) else data.get('scan_date')
        scan_session = (data.get('scan_session') or 'close').strip() if isinstance(data.get('scan_session'), str) else data.get('scan_session')
        if limit:
            limit = int(limit)
        
        # æ‰«æå‰æ£€æŸ¥æ•°æ®å®Œæ•´æ€§ï¼ˆä»…æ£€æŸ¥ï¼Œä¸é˜»æ­¢æ‰«æï¼‰
        print(f"\n[scan_all_stocks] æ£€æŸ¥æ•°æ®å®Œæ•´æ€§ï¼ˆæ‰«ææ—¥æœŸ: {scan_date or 'ä»Šå¤©'}ï¼‰...")
        freshness = check_data_freshness(scan_date)
        
        # å¦‚æœæ•°æ®ä¸¥é‡ä¸è¶³ï¼ˆè¶…è¿‡50%è¿‡æœŸï¼‰ï¼Œç»™å‡ºè­¦å‘Šä½†ä¸é˜»æ­¢æ‰«æ
        if not freshness['fresh']:
            outdated_pct = (freshness['outdated_count'] / freshness['total'] * 100) if freshness['total'] > 0 else 100
            print(f"[scan_all_stocks] âš ï¸  æ•°æ®ä¸è¶³è­¦å‘Š")
            print(f"   - è¿‡æœŸæ•°æ®: {freshness['outdated_count']}/{freshness['total']} ({outdated_pct:.1f}%)")
            print(f"   - æœ€æ–°æ•°æ®æ—¥æœŸ: {freshness.get('latest_data_date', 'æœªçŸ¥')}")
            print(f"   - ç›®æ ‡æ‰«ææ—¥æœŸ: {scan_date or 'ä»Šå¤©'}")
            print(f"   - æ³¨æ„ï¼šæ‰«æå°†ä»…ä½¿ç”¨æœ¬åœ°æ•°æ®ï¼Œç¼ºå°‘æ•°æ®çš„è‚¡ç¥¨å°†è¢«è·³è¿‡")
            
            # å¦‚æœè¶…è¿‡50%çš„æ•°æ®è¿‡æœŸï¼Œå»ºè®®å…ˆä¸‹è½½æ•°æ®
            if outdated_pct > 50:
                print(f"[scan_all_stocks] âš ï¸  è¶…è¿‡50%çš„æ•°æ®è¿‡æœŸï¼Œå¼ºçƒˆå»ºè®®å…ˆä¸‹è½½æ•°æ®")
        else:
            print(f"[scan_all_stocks] âœ… æ•°æ®å®Œæ•´æ€§æ£€æŸ¥é€šè¿‡")
            print(f"   - è¿‡æœŸæ•°æ®: {freshness['outdated_count']}/{freshness['total']}")
            print(f"   - æœ€æ–°æ•°æ®æ—¥æœŸ: {freshness.get('latest_data_date', 'æœªçŸ¥')}")
        
        # å¹¶è¡Œå¤„ç†é…ç½®ï¼ˆé»˜è®¤å¯ç”¨ï¼Œæå‡æ‰«æé€Ÿåº¦ï¼‰
        use_parallel = data.get('use_parallel', True)  # é»˜è®¤å¯ç”¨å¹¶è¡Œå¤„ç†
        # æœ¬åœ°ç¯å¢ƒï¼šä½¿ç”¨æ›´å¤šçº¿ç¨‹æå‡é€Ÿåº¦ï¼›Renderç¯å¢ƒï¼šå¹³è¡¡æ€§èƒ½å’Œå†…å­˜ä½¿ç”¨
        if is_local:
            default_workers = 50  # æœ¬åœ°ç¯å¢ƒé»˜è®¤50çº¿ç¨‹ï¼ŒåŠ é€Ÿæ‰«æ
        elif is_render:
            default_workers = 20
        else:
            default_workers = 10
        max_workers = int(data.get('max_workers', default_workers))
        if is_local:
            if max_workers > 80:
                max_workers = 80
                print(f"[scan_all_stocks] âš ï¸ æœ¬åœ°çº¿ç¨‹æ•°å·²é™åˆ¶ä¸º80")
        else:
            if max_workers > 30:
                max_workers = 30
                print(f"[scan_all_stocks] âš ï¸ çº¿ç¨‹æ•°å·²é™åˆ¶ä¸º30ï¼Œé¿å…å†…å­˜æº¢å‡º")
        
        # VIPç”¨æˆ·è‡ªå®šä¹‰å‚æ•°ï¼ˆç¬¬äºŒé˜¶æ®µåŠŸèƒ½ï¼‰
        exclude_st = data.get('exclude_st', True)  # é»˜è®¤æ’é™¤STè‚¡ç¥¨
        exclude_suspended = data.get('exclude_suspended', True)  # é»˜è®¤æ’é™¤åœç‰Œè‚¡ç¥¨ï¼ˆæš‚ä¸æ”¯æŒï¼Œé¢„ç•™ï¼‰
        industry_filter = data.get('industry_filter', '').strip()  # è¡Œä¸šç­›é€‰ï¼ˆæš‚ä¸æ”¯æŒï¼Œé¢„ç•™ï¼‰
        custom_stock_pool = data.get('custom_stock_pool', '').strip()  # è‡ªå®šä¹‰è‚¡ç¥¨æ± ï¼ˆæš‚ä¸æ”¯æŒï¼Œé¢„ç•™ï¼‰
        
        # åœ¨ Vercel serverless ç¯å¢ƒä¸­ï¼Œä½¿ç”¨åˆ†æ‰¹å¤„ç†æ–¹æ¡ˆï¼ˆRenderç¯å¢ƒä½¿ç”¨æœ¬åœ°å¹¶è¡Œå¤„ç†ï¼‰
        if is_vercel and not is_render:
            import uuid
            import scan_progress_store
            
            # è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯ï¼Œç¡®ä¿æ¯ä¸ªç”¨æˆ·çš„æ‰«æä»»åŠ¡ç‹¬ç«‹
            current_user = get_current_user()
            username = current_user.get('username', 'anonymous') if current_user else 'anonymous'
            
            # ç”Ÿæˆæ‰«æä»»åŠ¡IDï¼ŒåŒ…å«ç”¨æˆ·åå‰ç¼€ï¼Œç¡®ä¿å¤šç”¨æˆ·å¹¶å‘æ—¶ä¸ä¼šå†²çª
            # æ ¼å¼: username_timestamp_uuid
            import time as time_module
            timestamp = int(time_module.time())
            unique_id = str(uuid.uuid4())[:8]  # ä½¿ç”¨ UUID çš„å‰8ä½ï¼Œå‡å°‘é•¿åº¦
            scan_id = f"{username}_{timestamp}_{unique_id}"
            
            print(f"[scan_all_stocks] ç”Ÿæˆæ‰«æä»»åŠ¡ID: {scan_id} (ç”¨æˆ·: {username})")
            
            # è·å–è‚¡ç¥¨åˆ—è¡¨ï¼Œè®¡ç®—æ‰¹æ¬¡
            if analyzer is None:
                return jsonify({
                    'success': False,
                    'message': 'åˆ†æå™¨æœªåˆå§‹åŒ–'
                }), 500
            
            if not hasattr(analyzer, 'fetcher') or analyzer.fetcher is None:
                return jsonify({
                    'success': False,
                    'message': 'æ•°æ®è·å–å™¨æœªåˆå§‹åŒ–'
                }), 500
            
            # æå‰åˆ›å»ºåˆå§‹è¿›åº¦ï¼ˆæ ‡è®°ä¸º"å‡†å¤‡ä¸­"ï¼‰ï¼Œè¿™æ ·å³ä½¿è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥ï¼Œå‰ç«¯ä¹Ÿèƒ½æ£€æµ‹åˆ°æ‰«æä»»åŠ¡
            import scan_progress_store
            import time
            try:
                preparing_progress = {
                    'type': 'scan',
                    'scan_id': scan_id,
                    'username': username,
                    'user_tier': user_tier,
                    'is_auto_scan': False,
                    'current': 0,
                    'total': 0,  # æš‚æ—¶ä¸º0ï¼Œè·å–è‚¡ç¥¨åˆ—è¡¨åæ›´æ–°
                    'status': 'å‡†å¤‡ä¸­',
                    'detail': 'æ­£åœ¨è·å–è‚¡ç¥¨åˆ—è¡¨...',
                    'percentage': 0,
                    'found': 0,
                    'batch': 0,
                    'total_batches': 0,  # æš‚æ—¶ä¸º0ï¼Œè·å–è‚¡ç¥¨åˆ—è¡¨åæ›´æ–°
                    'min_match_score': min_match_score,
                    'max_market_cap': max_market_cap,
                    'candidates': [],
                    'start_time': time.time()
                }
                scan_progress_store.save_scan_progress(scan_id, preparing_progress)
                
                # ä¿å­˜ç”¨æˆ·çš„æœ€æ–° scan_idï¼ˆç”¨äºåç»­æŸ¥æ‰¾ï¼‰
                try:
                    latest_scan_key = f'latest_scan:{username}'
                    if hasattr(scan_progress_store, '_upstash_redis_set'):
                        scan_progress_store._upstash_redis_set(latest_scan_key, scan_id, ttl=86400)  # 24å°æ—¶TTL
                except Exception as e:
                    print(f"[scan_all_stocks] âš ï¸ ä¿å­˜æœ€æ–° scan_id å¤±è´¥: {e}")
                
                print(f"[scan_all_stocks] âœ… å·²åˆ›å»ºåˆå§‹è¿›åº¦ï¼ˆå‡†å¤‡ä¸­ï¼‰ï¼Œscan_id: {scan_id}")
            except Exception as e:
                print(f"[scan_all_stocks] âš ï¸ åˆ›å»ºåˆå§‹è¿›åº¦å¤±è´¥ï¼ˆç»§ç»­æ‰§è¡Œï¼‰: {e}")
            
            # æ¯æ¬¡æ‰«æå‰å…ˆæ£€æµ‹ç¼“å­˜æ˜¯å¦å­˜åœ¨ï¼ˆå»ºè®®æ¯æ¬¡ä½¿ç”¨å‰éƒ½æ£€æµ‹ï¼‰
            print("[scan_all_stocks] ğŸ” æ£€æµ‹ç¼“å­˜æ˜¯å¦å­˜åœ¨...")
            cache_exists = False
            cached_stock_count = 0
            cache_status = "æœªçŸ¥"
            try:
                # æ˜ç¡®ä¼ é€’ check_age=Falseï¼Œç¡®ä¿è¿”å› DataFrame æˆ– None
                cached_stocks = analyzer.fetcher._get_stock_list_from_cache(check_age=False)
                if cached_stocks is not None:
                    try:
                        # ç¡®ä¿ cached_stocks æ˜¯ DataFrameï¼Œå¯ä»¥ä½¿ç”¨ len()
                        if hasattr(cached_stocks, '__len__'):
                            cached_stock_count = len(cached_stocks)
                            if cached_stock_count > 0:
                                cache_exists = True
                                cache_status = f"ç¼“å­˜å­˜åœ¨ï¼ˆ{cached_stock_count} åªè‚¡ç¥¨ï¼‰"
                                print(f"[scan_all_stocks] âœ… ç¼“å­˜å­˜åœ¨ï¼Œè‚¡ç¥¨æ•°: {cached_stock_count} åªï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨")
                            else:
                                cache_status = "ç¼“å­˜ä¸ºç©º"
                                print(f"[scan_all_stocks] âš ï¸ ç¼“å­˜å­˜åœ¨ä½†ä¸ºç©ºï¼ˆé•¿åº¦ä¸º0ï¼‰")
                        else:
                            cache_status = "ç¼“å­˜æ•°æ®æ ¼å¼é”™è¯¯ï¼ˆä¸æ˜¯å¯è¿­ä»£å¯¹è±¡ï¼‰"
                            print(f"[scan_all_stocks] âš ï¸ ç¼“å­˜æ•°æ®æ ¼å¼é”™è¯¯: {type(cached_stocks)}")
                    except Exception as len_error:
                        cache_status = f"æ£€æŸ¥ç¼“å­˜é•¿åº¦æ—¶å‡ºé”™: {len_error}"
                        print(f"[scan_all_stocks] âš ï¸ {cache_status}")
                else:
                    cache_status = "ç¼“å­˜ä¸å­˜åœ¨"
                    print(f"[scan_all_stocks] âš ï¸ ç¼“å­˜ä¸å­˜åœ¨ï¼ˆè¿”å› Noneï¼‰")
            except Exception as e:
                import traceback
                error_detail = traceback.format_exc()
                cache_status = f"æ£€æµ‹ç¼“å­˜æ—¶å‡ºé”™: {e}"
                print(f"[scan_all_stocks] âš ï¸ {cache_status}")
                print(f"[scan_all_stocks] é”™è¯¯è¯¦æƒ…: {error_detail}")
            
            # å¦‚æœç¼“å­˜ä¸å­˜åœ¨ï¼Œåªåœ¨äº¤æ˜“æ—¶é—´æ®µå†…ä¸”æ˜¯ Vercel ç¯å¢ƒæ—¶æå‰è¿”å›é”™è¯¯ï¼ˆé¿å…è¶…æ—¶å’Œæ•°æ®ä¸ä¸€è‡´ï¼‰
            # éäº¤æ˜“æ—¶é—´æ®µï¼Œå…è®¸ä» API è·å–æ•°æ®ï¼ˆè™½ç„¶å¯èƒ½æ…¢ï¼Œä½†åº”è¯¥å…è®¸ç”¨æˆ·æ‰«æï¼‰
            if not cache_exists and is_vercel:
                from datetime import datetime, timezone, timedelta
                try:
                    utc_now = datetime.now(timezone.utc)
                    beijing_tz = timezone(timedelta(hours=8))
                    beijing_now = utc_now.astimezone(beijing_tz)
                    current_hour = beijing_now.hour
                    current_minute = beijing_now.minute
                    current_time_str = beijing_now.strftime('%Y-%m-%d %H:%M:%S')
                    
                    # åˆ¤æ–­æ˜¯å¦åœ¨äº¤æ˜“æ—¶é—´ï¼ˆ9:30-11:30, 13:00-15:00ï¼‰
                    is_in_trading_time = (
                        (current_hour == 9 and current_minute >= 30) or
                        (current_hour == 10) or
                        (current_hour == 11 and current_minute <= 30) or
                        (current_hour == 13) or
                        (current_hour == 14) or
                        (current_hour == 15 and current_minute <= 0)
                    )
                    
                    # åªæœ‰åœ¨äº¤æ˜“æ—¶é—´æ®µå†…ï¼Œæ‰æå‰è¿”å›é”™è¯¯ï¼ˆé¿å…è¶…æ—¶å’Œæ•°æ®ä¸ä¸€è‡´ï¼‰
                    # éäº¤æ˜“æ—¶é—´æ®µï¼Œå…è®¸ä» API è·å–æ•°æ®
                    if is_in_trading_time:
                        error_msg = 'âš ï¸ **ç¼“å­˜æœªç”Ÿæˆï¼ˆè‚¡ç¥¨åˆ—è¡¨ç¼“å­˜ä¸å­˜åœ¨ï¼‰**\n\n'
                        error_msg += f'å½“å‰æ—¶é—´: {current_time_str}ï¼ˆäº¤æ˜“æ—¶é—´æ®µå†…ï¼‰\n\n'
                        error_msg += 'ğŸ’¡ **è§£å†³æ–¹æ¡ˆï¼š**\n'
                        error_msg += 'å½“å‰åœ¨äº¤æ˜“æ—¶é—´æ®µå†…ï¼Œæ•°æ®å˜åŒ–é¢‘ç¹ï¼Œå»ºè®®ç­‰å¾…ç¼“å­˜ç”Ÿæˆã€‚\n'
                        error_msg += '**æ–¹æ¡ˆ1ï¼ˆæ¨èï¼‰ï¼š** ç­‰å¾…å‡ åˆ†é’Ÿï¼Œç³»ç»Ÿä¼šåœ¨ä¸‹æ¬¡æ‰«ææ—¶è‡ªåŠ¨åˆ·æ–°ç¼“å­˜\n'
                        error_msg += '**æ–¹æ¡ˆ2ï¼ˆæ‰‹åŠ¨ï¼‰ï¼š** æ‰‹åŠ¨è§¦å‘ç¼“å­˜åˆ·æ–°ï¼šè®¿é—® https://www.daniugu.online/api/refresh_stock_cache?force=true\n'
                        error_msg += '   - æ‰‹åŠ¨åˆ·æ–°å¯èƒ½éœ€è¦30ç§’ï¼Œè¯·è€å¿ƒç­‰å¾…\n'
                        error_msg += '   - åˆ·æ–°æˆåŠŸåï¼Œå†å°è¯•æ‰«æ\n'
                        error_msg += '\nğŸ“Œ **è¯´æ˜ï¼š**\n'
                        error_msg += '- äº¤æ˜“æ—¶é—´æ®µå†…ï¼ˆ9:30-11:30, 13:00-15:00ï¼‰æ•°æ®å˜åŒ–é¢‘ç¹\n'
                        error_msg += '- å»ºè®®ç­‰å¾…ç¼“å­˜ç”Ÿæˆåå†æ‰«æï¼Œé¿å…æ•°æ®ä¸ä¸€è‡´å’Œè¶…æ—¶\n'
                        
                        print(f"[scan_all_stocks] âŒ äº¤æ˜“æ—¶é—´æ®µå†…ç¼“å­˜ä¸å­˜åœ¨ï¼Œæå‰è¿”å›é”™è¯¯ï¼ˆé¿å…è¶…æ—¶å’Œæ•°æ®ä¸ä¸€è‡´ï¼‰")
                        return jsonify({
                            'success': False,
                            'message': error_msg,
                            'cache_exists': False,
                            'current_time': current_time_str,
                            'is_in_trading_time': True
                        }), 400
                    else:
                        # éäº¤æ˜“æ—¶é—´æ®µï¼Œå¦‚æœç¼“å­˜ä¸å­˜åœ¨ï¼Œåœ¨ Vercel ç¯å¢ƒä¸­ä¹Ÿå»ºè®®å…ˆæ‰‹åŠ¨åˆ·æ–°ç¼“å­˜
                        # å› ä¸ºä» API è·å–æ•°æ®åœ¨ Vercel çš„ 10 ç§’é™åˆ¶å†…å¾ˆå¯èƒ½è¶…æ—¶
                        if is_vercel:
                            error_msg = 'âš ï¸ **ç¼“å­˜æœªç”Ÿæˆï¼ˆè‚¡ç¥¨åˆ—è¡¨ç¼“å­˜ä¸å­˜åœ¨ï¼‰**\n\n'
                            error_msg += f'å½“å‰æ—¶é—´: {current_time_str}ï¼ˆéäº¤æ˜“æ—¶é—´æ®µï¼‰\n\n'
                            error_msg += 'ğŸ’¡ **é—®é¢˜åˆ†æï¼š**\n'
                            error_msg += 'éäº¤æ˜“æ—¶é—´æ®µï¼Œç¼“å­˜ä¸å­˜åœ¨ï¼Œä» akshare API è·å–è‚¡ç¥¨åˆ—è¡¨å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼ˆé€šå¸¸éœ€è¦ 10-30 ç§’ï¼‰ã€‚\n'
                            error_msg += 'Vercel ç¯å¢ƒæœ‰ 10 ç§’æ‰§è¡Œæ—¶é—´é™åˆ¶ï¼Œä» API ç›´æ¥è·å–å¾ˆå¯èƒ½è¶…æ—¶å¤±è´¥ã€‚\n\n'
                            error_msg += 'ğŸ’¡ **è§£å†³æ–¹æ¡ˆï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰ï¼š**\n'
                            error_msg += '**æ–¹æ¡ˆ1ï¼ˆå¼ºçƒˆæ¨èï¼‰ï¼š** æ‰‹åŠ¨è§¦å‘ç¼“å­˜åˆ·æ–°ï¼šè®¿é—® https://www.daniugu.online/api/refresh_stock_cache?force=true\n'
                            error_msg += '   - æ‰‹åŠ¨åˆ·æ–°å¯èƒ½éœ€è¦30ç§’ï¼Œä½†è¿™æ˜¯åå°ä»»åŠ¡ï¼Œä¸å—10ç§’é™åˆ¶\n'
                            error_msg += '   - åˆ·æ–°æˆåŠŸåï¼ˆçº¦30ç§’åï¼‰ï¼Œå†å°è¯•æ‰«æ\n'
                            error_msg += '   - åˆ·æ–°åï¼Œä¸‹æ¬¡æ‰«æä¼šä½¿ç”¨ç¼“å­˜ï¼Œé€Ÿåº¦å¾ˆå¿«\n\n'
                            error_msg += '**æ–¹æ¡ˆ2ï¼š** ç­‰å¾…åˆ°äº¤æ˜“æ—¶é—´æ®µï¼ˆ9:30-11:30, 13:00-15:00ï¼‰åé‡è¯•\n'
                            error_msg += '   - äº¤æ˜“æ—¶é—´æ®µå†…ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨åˆ·æ–°ç¼“å­˜ï¼ˆä¸­åˆ11:30ï¼Œä¸‹åˆ15:00ï¼‰\n\n'
                            error_msg += '**æ–¹æ¡ˆ3ï¼š** å°è¯•ä» API è·å–ï¼ˆå¯èƒ½è¶…æ—¶ï¼Œä¸å»ºè®®ï¼‰\n'
                            error_msg += '   - å¦‚æœä»ç„¶æƒ³å°è¯•ï¼Œå¯ä»¥ç¨åé‡è¯•\n'
                            error_msg += '   - ä½†å¦‚æœè¶…æ—¶ï¼Œå»ºè®®ä½¿ç”¨æ–¹æ¡ˆ1æ‰‹åŠ¨åˆ·æ–°ç¼“å­˜\n\n'
                            error_msg += 'ğŸ“Œ **è¯´æ˜ï¼š**\n'
                            error_msg += '- Vercel ç¯å¢ƒæœ‰ 10 ç§’æ‰§è¡Œæ—¶é—´é™åˆ¶\n'
                            error_msg += '- ä» akshare API è·å–è‚¡ç¥¨åˆ—è¡¨é€šå¸¸éœ€è¦ 10-30 ç§’\n'
                            error_msg += '- å› æ­¤å»ºè®®å…ˆæ‰‹åŠ¨åˆ·æ–°ç¼“å­˜ï¼Œå†å°è¯•æ‰«æ\n'
                            
                            print(f"[scan_all_stocks] âŒ éäº¤æ˜“æ—¶é—´æ®µç¼“å­˜ä¸å­˜åœ¨ï¼ˆVercelç¯å¢ƒï¼‰ï¼Œå»ºè®®å…ˆæ‰‹åŠ¨åˆ·æ–°ç¼“å­˜ï¼ˆé¿å…è¶…æ—¶ï¼‰")
                            return jsonify({
                                'success': False,
                                'message': error_msg,
                                'cache_exists': False,
                                'current_time': current_time_str,
                                'is_in_trading_time': False,
                                'is_vercel': True,
                                'suggestion': 'æ‰‹åŠ¨åˆ·æ–°ç¼“å­˜'
                            }), 400
                        else:
                            # æœ¬åœ°ç¯å¢ƒï¼Œå…è®¸ä» API è·å–æ•°æ®ï¼ˆè™½ç„¶å¯èƒ½æ…¢ï¼Œä½†åº”è¯¥å…è®¸ç”¨æˆ·æ‰«æï¼‰
                            print(f"[scan_all_stocks] âš ï¸ éäº¤æ˜“æ—¶é—´æ®µç¼“å­˜ä¸å­˜åœ¨ï¼ˆæœ¬åœ°ç¯å¢ƒï¼‰ï¼Œå°†ä» API è·å–æ•°æ®ï¼ˆå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œä½†å…è®¸æ‰«æï¼‰")
                except Exception as e:
                    print(f"[scan_all_stocks] âš ï¸ æ£€æŸ¥äº¤æ˜“æ—¶é—´æ—¶å‡ºé”™: {e}ï¼Œç»§ç»­æ‰§è¡Œï¼ˆä» API è·å–æ•°æ®ï¼‰")
            
            try:
                import time as time_module
                scan_start_time = time_module.time()
                
                # æ ¹æ®ç¼“å­˜çŠ¶æ€æ˜¾ç¤ºä¸åŒçš„æç¤ºä¿¡æ¯
                # æ³¨æ„ï¼šget_all_stocks å†…éƒ¨å·²å®ç°æ™ºèƒ½ç¼“å­˜æ£€æŸ¥ï¼Œåœ¨äº¤æ˜“æ—¶é—´æ®µå†…ä¼šè‡ªåŠ¨åˆ·æ–°è¿‡æœŸç¼“å­˜
                if cache_exists:
                    print("[scan_all_stocks] æ­£åœ¨ä»ç¼“å­˜è·å–è‚¡ç¥¨åˆ—è¡¨ï¼ˆå¦‚æœè¿‡æœŸä¼šè‡ªåŠ¨åˆ·æ–°ï¼‰...")
                    status_msg = f"æ­£åœ¨ä»ç¼“å­˜è·å–è‚¡ç¥¨æ•°æ®ï¼ˆ{cached_stock_count} åªè‚¡ç¥¨ï¼Œäº¤æ˜“æ—¶é—´æ®µå†…ä¼šè‡ªåŠ¨åˆ·æ–°è¿‡æœŸç¼“å­˜ï¼‰..."
                else:
                    print("[scan_all_stocks] æ­£åœ¨ä» API è·å–è‚¡ç¥¨åˆ—è¡¨...")
                    status_msg = "æ­£åœ¨è·å–è‚¡ç¥¨æ•°æ®ï¼ˆä» APIï¼‰..."
                
                # åœ¨ Vercel ç¯å¢ƒä¸­ï¼Œä½¿ç”¨æ›´çŸ­çš„è¶…æ—¶æ—¶é—´ï¼ˆé¿å…è¶…è¿‡æ‰§è¡Œæ—¶é—´é™åˆ¶ï¼‰
                # get_all_stocks å†…éƒ¨ä¼šæ ¹æ®ç¯å¢ƒè‡ªåŠ¨è°ƒæ•´è¶…æ—¶å’Œé‡è¯•æ¬¡æ•°ï¼Œå¹¶ä¸”ä¼šæ™ºèƒ½æ£€æŸ¥ç¼“å­˜å¹´é¾„
                # æ³¨æ„ï¼šå³ä½¿åœ¨éäº¤æ˜“æ—¶é—´æ®µå…è®¸ä» API è·å–ï¼ŒVercel ç¯å¢ƒä»æœ‰ 10 ç§’é™åˆ¶ï¼Œå¯èƒ½è¶…æ—¶
                # Vercel ä¸­ï¼šè¶…æ—¶5ç§’ï¼ˆç•™å‡º5ç§’ç»™å…¶ä»–å¤„ç†ï¼‰ï¼Œåªå°è¯•1æ¬¡ï¼›æœ¬åœ°ï¼šè¶…æ—¶15ç§’ï¼Œæœ€å¤šé‡è¯•3æ¬¡
                # äº¤æ˜“æ—¶é—´æ®µå†…ï¼Œå¦‚æœç¼“å­˜è¶…è¿‡5åˆ†é’Ÿï¼Œä¼šè‡ªåŠ¨ä»APIè·å–æœ€æ–°æ•°æ®
                # éäº¤æ˜“æ—¶é—´æ®µï¼Œå¦‚æœç¼“å­˜ä¸å­˜åœ¨ï¼Œä¼šå°è¯•ä» API è·å–ï¼ˆä½†å¯èƒ½è¶…æ—¶ï¼Œå»ºè®®å…ˆæ‰‹åŠ¨åˆ·æ–°ç¼“å­˜ï¼‰
                stock_list = analyzer.fetcher.get_all_stocks(timeout=5 if is_vercel else 15, max_retries=1 if is_vercel else 3)
                
                elapsed = time_module.time() - scan_start_time
                if cache_exists:
                    print(f"[scan_all_stocks] âœ… ä»ç¼“å­˜è·å–æˆåŠŸï¼Œè‚¡ç¥¨æ•°: {len(stock_list) if stock_list is not None else 0}, è€—æ—¶ {elapsed:.2f}ç§’")
                else:
                    print(f"[scan_all_stocks] âœ… ä» API è·å–æˆåŠŸï¼Œè‚¡ç¥¨æ•°: {len(stock_list) if stock_list is not None else 0}, è€—æ—¶ {elapsed:.2f}ç§’")
            except Exception as e:
                import traceback
                error_detail = traceback.format_exc()
                print(f"[scan_all_stocks] âŒ è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {error_detail}")
                
                # æ£€æŸ¥å½“å‰æ—¶é—´å’Œç¼“å­˜çŠ¶æ€ï¼Œæä¾›æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
                from datetime import datetime, timezone, timedelta
                try:
                    utc_now = datetime.now(timezone.utc)
                    beijing_tz = timezone(timedelta(hours=8))
                    beijing_now = utc_now.astimezone(beijing_tz)
                    current_time_str = beijing_now.strftime('%Y-%m-%d %H:%M:%S')
                    current_hour = beijing_now.hour
                    current_minute = beijing_now.minute
                    is_in_trading_time = (
                        (current_hour == 9 and current_minute >= 30) or
                        (current_hour == 10) or
                        (current_hour == 11 and current_minute <= 30) or
                        (current_hour == 13) or
                        (current_hour == 14) or
                        (current_hour == 15 and current_minute <= 0)
                    )
                except Exception:
                    current_time_str = "æœªçŸ¥"
                    is_in_trading_time = False
                
                # æ£€æŸ¥ç¼“å­˜æ˜¯å¦å­˜åœ¨
                cache_exists_check = False
                try:
                    cached_stocks_check = analyzer.fetcher._get_stock_list_from_cache(check_age=False)
                    if cached_stocks_check is not None and len(cached_stocks_check) > 0:
                        cache_exists_check = True
                except Exception:
                    pass
                
                error_msg = f'è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {str(e)}\n\n'
                error_msg += f'å½“å‰æ—¶é—´: {current_time_str}\n'
                error_msg += f'æ—¶é—´æ®µ: {"äº¤æ˜“æ—¶é—´æ®µå†…" if is_in_trading_time else "éäº¤æ˜“æ—¶é—´æ®µ"}\n'
                error_msg += f'ç¼“å­˜çŠ¶æ€: {"å­˜åœ¨" if cache_exists_check else "ä¸å­˜åœ¨"}\n\n'
                
                error_msg += 'âš ï¸ **é—®é¢˜åˆ†æï¼š**\n'
                if not cache_exists_check:
                    error_msg += 'ç¼“å­˜ä¸å­˜åœ¨ï¼Œä» API è·å–æ•°æ®æ—¶å¤±è´¥æˆ–è¶…æ—¶ã€‚\n\n'
                    if is_in_trading_time:
                        error_msg += 'ğŸ’¡ **è§£å†³æ–¹æ¡ˆï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰ï¼š**\n'
                        error_msg += '**æ–¹æ¡ˆ1ï¼ˆæ¨èï¼‰ï¼š** æ‰‹åŠ¨è§¦å‘ç¼“å­˜åˆ·æ–°ï¼šè®¿é—® https://www.daniugu.online/api/refresh_stock_cache?force=true\n'
                        error_msg += '   - æ‰‹åŠ¨åˆ·æ–°å¯èƒ½éœ€è¦30ç§’ï¼Œè¯·è€å¿ƒç­‰å¾…\n'
                        error_msg += '   - åˆ·æ–°æˆåŠŸåï¼Œå†å°è¯•æ‰«æ\n\n'
                        error_msg += '**æ–¹æ¡ˆ2ï¼š** ç­‰å¾…å‡ åˆ†é’Ÿåé‡è¯•ï¼ˆç³»ç»Ÿå¯èƒ½æ­£åœ¨åˆ·æ–°ç¼“å­˜ï¼‰\n\n'
                    else:
                        error_msg += 'ğŸ’¡ **è§£å†³æ–¹æ¡ˆï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰ï¼š**\n'
                        error_msg += '**æ–¹æ¡ˆ1ï¼ˆæ¨èï¼‰ï¼š** æ‰‹åŠ¨è§¦å‘ç¼“å­˜åˆ·æ–°ï¼šè®¿é—® https://www.daniugu.online/api/refresh_stock_cache?force=true\n'
                        error_msg += '   - æ‰‹åŠ¨åˆ·æ–°å¯èƒ½éœ€è¦30ç§’ï¼Œè¯·è€å¿ƒç­‰å¾…\n'
                        error_msg += '   - åˆ·æ–°æˆåŠŸåï¼Œå†å°è¯•æ‰«æ\n\n'
                        error_msg += '**æ–¹æ¡ˆ2ï¼š** ç­‰å¾…åˆ°äº¤æ˜“æ—¶é—´æ®µï¼ˆ9:30-11:30, 13:00-15:00ï¼‰åé‡è¯•\n'
                        error_msg += '   - äº¤æ˜“æ—¶é—´æ®µå†…ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨åˆ·æ–°ç¼“å­˜\n\n'
                        error_msg += '**æ–¹æ¡ˆ3ï¼š** ç¨åé‡è¯•ï¼ˆå¯èƒ½æ˜¯ç½‘ç»œé—®é¢˜ï¼‰\n\n'
                else:
                    error_msg += 'ç¼“å­˜å­˜åœ¨ï¼Œä½†ä» API è·å–æ•°æ®æ—¶å¤±è´¥ï¼ˆå¯èƒ½æ˜¯ç½‘ç»œé—®é¢˜æˆ– akshare æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼‰ã€‚\n\n'
                    error_msg += 'ğŸ’¡ **è§£å†³æ–¹æ¡ˆï¼š**\n'
                    error_msg += '**æ–¹æ¡ˆ1ï¼ˆæ¨èï¼‰ï¼š** ç¨åé‡è¯•ï¼ˆå¯èƒ½æ˜¯ç½‘ç»œæ³¢åŠ¨ï¼‰\n\n'
                    error_msg += '**æ–¹æ¡ˆ2ï¼š** æ‰‹åŠ¨è§¦å‘ç¼“å­˜åˆ·æ–°ï¼šè®¿é—® https://www.daniugu.online/api/refresh_stock_cache?force=true\n'
                    error_msg += '   - æ‰‹åŠ¨åˆ·æ–°å¯èƒ½éœ€è¦30ç§’ï¼Œè¯·è€å¿ƒç­‰å¾…\n'
                    error_msg += '   - åˆ·æ–°æˆåŠŸåï¼Œå†å°è¯•æ‰«æ\n\n'
                
                error_msg += 'ğŸ“Œ **å¯èƒ½çš„åŸå› ï¼š**\n'
                if is_vercel:
                    error_msg += '1. è¶…æ—¶ï¼ˆVercel å‡½æ•°æ‰§è¡Œæ—¶é—´é™åˆ¶ä¸º 10 ç§’ï¼Œä» akshare API è·å–æ•°æ®å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼‰\n'
                    error_msg += '2. ç½‘ç»œè¿æ¥é—®é¢˜ï¼ˆVercel ç¯å¢ƒç½‘ç»œé™åˆ¶ï¼‰\n'
                    error_msg += '3. akshare æœåŠ¡æš‚æ—¶ä¸å¯ç”¨\n'
                else:
                    error_msg += '1. ç½‘ç»œè¿æ¥é—®é¢˜\n'
                    error_msg += '2. akshare æœåŠ¡æš‚æ—¶ä¸å¯ç”¨\n'
                    error_msg += '3. è¶…æ—¶ï¼ˆè·å–æ•°æ®å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼‰\n'
                
                return jsonify({
                    'success': False,
                    'message': error_msg,
                    'cache_exists': cache_exists_check,
                    'is_in_trading_time': is_in_trading_time,
                    'current_time': current_time_str,
                    'error_type': str(type(e).__name__)
                }), 500
            
            if stock_list is None or len(stock_list) == 0:
                print(f"[scan_all_stocks] âŒ è‚¡ç¥¨åˆ—è¡¨ä¸ºç©º: stock_list={stock_list}, len={len(stock_list) if stock_list is not None else 0}")
                
                # æ£€æŸ¥å½“å‰æ—¶é—´ï¼Œåˆ¤æ–­æ˜¯å¦åœ¨äº¤æ˜“æ—¶é—´æ®µ
                from datetime import datetime, timezone, timedelta
                try:
                    utc_now = datetime.now(timezone.utc)
                    beijing_tz = timezone(timedelta(hours=8))
                    beijing_now = utc_now.astimezone(beijing_tz)
                    current_time_str = beijing_now.strftime('%Y-%m-%d %H:%M:%S')
                    current_hour = beijing_now.hour
                    current_minute = beijing_now.minute
                    is_in_trading_time = (
                        (current_hour == 9 and current_minute >= 30) or
                        (current_hour == 10) or
                        (current_hour == 11 and current_minute <= 30) or
                        (current_hour == 13) or
                        (current_hour == 14) or
                        (current_hour == 15 and current_minute <= 0)
                    )
                except Exception as e:
                    print(f"[scan_all_stocks] âš ï¸ è·å–å½“å‰æ—¶é—´å¤±è´¥: {e}")
                    is_in_trading_time = False
                    current_time_str = "æœªçŸ¥"
                
                # æ£€æŸ¥ç¼“å­˜æ˜¯å¦å­˜åœ¨
                cache_exists = False
                try:
                    cached_stocks = analyzer.fetcher._get_stock_list_from_cache(check_age=False)
                    if cached_stocks is not None and len(cached_stocks) > 0:
                        cache_exists = True
                        print(f"[scan_all_stocks] âš ï¸ ç¼“å­˜ä¸­å­˜åœ¨è‚¡ç¥¨åˆ—è¡¨ï¼Œä½† get_all_stocks è¿”å›ä¸ºç©ºï¼Œå¯èƒ½æ˜¯ API è°ƒç”¨å¤±è´¥")
                    else:
                        print(f"[scan_all_stocks] âš ï¸ ç¼“å­˜ä¸­ä¸å­˜åœ¨è‚¡ç¥¨åˆ—è¡¨")
                except Exception as e:
                    print(f"[scan_all_stocks] âš ï¸ æ£€æŸ¥ç¼“å­˜æ—¶å‡ºé”™: {e}")
                
                error_msg = 'æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨\n\n'
                error_msg += f'å½“å‰æ—¶é—´: {current_time_str}\n'
                error_msg += f'æ—¶é—´æ®µ: {"äº¤æ˜“æ—¶é—´æ®µå†…" if is_in_trading_time else "éäº¤æ˜“æ—¶é—´æ®µ"}\n'
                error_msg += f'ç¼“å­˜çŠ¶æ€: {"å­˜åœ¨" if cache_exists else "ä¸å­˜åœ¨"}\n\n'
                
                if not cache_exists:
                    if is_in_trading_time:
                        error_msg += 'âš ï¸ **é—®é¢˜åˆ†æï¼š**\n'
                        error_msg += 'å½“å‰åœ¨äº¤æ˜“æ—¶é—´æ®µå†…ï¼Œç¼“å­˜ä¸å­˜åœ¨ï¼Œä» API è·å–æ•°æ®æ—¶è¶…æ—¶æˆ–å¤±è´¥ã€‚\n\n'
                        error_msg += 'ğŸ’¡ **è§£å†³æ–¹æ¡ˆï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰ï¼š**\n'
                        error_msg += '**æ–¹æ¡ˆ1ï¼ˆæ¨èï¼‰ï¼š** æ‰‹åŠ¨è§¦å‘ç¼“å­˜åˆ·æ–°ï¼šè®¿é—® https://www.daniugu.online/api/refresh_stock_cache?force=true\n'
                        error_msg += '   - æ‰‹åŠ¨åˆ·æ–°å¯èƒ½éœ€è¦30ç§’ï¼Œè¯·è€å¿ƒç­‰å¾…\n'
                        error_msg += '   - åˆ·æ–°æˆåŠŸåï¼Œå†å°è¯•æ‰«æ\n\n'
                        error_msg += '**æ–¹æ¡ˆ2ï¼š** ç­‰å¾…å‡ åˆ†é’Ÿåé‡è¯•ï¼ˆç³»ç»Ÿå¯èƒ½æ­£åœ¨åˆ·æ–°ç¼“å­˜ï¼‰\n\n'
                    else:
                        error_msg += 'âš ï¸ **é—®é¢˜åˆ†æï¼š**\n'
                        error_msg += 'å½“å‰ä¸åœ¨äº¤æ˜“æ—¶é—´æ®µï¼Œç¼“å­˜ä¸å­˜åœ¨ï¼Œä» API è·å–æ•°æ®æ—¶è¶…æ—¶æˆ–å¤±è´¥ã€‚\n'
                        error_msg += 'éäº¤æ˜“æ—¶é—´æ®µï¼Œakshare API å¯èƒ½å“åº”è¾ƒæ…¢ï¼Œå¯¼è‡´è¶…æ—¶ã€‚\n\n'
                        error_msg += 'ğŸ’¡ **è§£å†³æ–¹æ¡ˆï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰ï¼š**\n'
                        error_msg += '**æ–¹æ¡ˆ1ï¼ˆæ¨èï¼‰ï¼š** æ‰‹åŠ¨è§¦å‘ç¼“å­˜åˆ·æ–°ï¼šè®¿é—® https://www.daniugu.online/api/refresh_stock_cache?force=true\n'
                        error_msg += '   - æ‰‹åŠ¨åˆ·æ–°å¯èƒ½éœ€è¦30ç§’ï¼Œè¯·è€å¿ƒç­‰å¾…\n'
                        error_msg += '   - åˆ·æ–°æˆåŠŸåï¼Œå†å°è¯•æ‰«æ\n\n'
                        error_msg += '**æ–¹æ¡ˆ2ï¼š** ç­‰å¾…åˆ°äº¤æ˜“æ—¶é—´æ®µï¼ˆ9:30-11:30, 13:00-15:00ï¼‰åé‡è¯•\n'
                        error_msg += '   - äº¤æ˜“æ—¶é—´æ®µå†…ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨åˆ·æ–°ç¼“å­˜\n\n'
                        error_msg += '**æ–¹æ¡ˆ3ï¼š** ç¨åé‡è¯•ï¼ˆå¯èƒ½æ˜¯ç½‘ç»œé—®é¢˜ï¼‰\n\n'
                else:
                    error_msg += 'âš ï¸ **é—®é¢˜åˆ†æï¼š**\n'
                    error_msg += 'ç¼“å­˜å­˜åœ¨ï¼Œä½†ä» API è·å–æ•°æ®æ—¶å¤±è´¥ï¼ˆå¯èƒ½æ˜¯ç½‘ç»œé—®é¢˜æˆ– akshare æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼‰ã€‚\n\n'
                    error_msg += 'ğŸ’¡ **è§£å†³æ–¹æ¡ˆï¼š**\n'
                    error_msg += '**æ–¹æ¡ˆ1ï¼ˆæ¨èï¼‰ï¼š** ç¨åé‡è¯•ï¼ˆå¯èƒ½æ˜¯ç½‘ç»œæ³¢åŠ¨æˆ– akshare æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼‰\n\n'
                    error_msg += '**æ–¹æ¡ˆ2ï¼š** æ‰‹åŠ¨è§¦å‘ç¼“å­˜åˆ·æ–°ï¼šè®¿é—® https://www.daniugu.online/api/refresh_stock_cache?force=true\n'
                    error_msg += '   - æ‰‹åŠ¨åˆ·æ–°å¯èƒ½éœ€è¦30ç§’ï¼Œè¯·è€å¿ƒç­‰å¾…\n'
                    error_msg += '   - åˆ·æ–°æˆåŠŸåï¼Œå†å°è¯•æ‰«æ\n\n'
                
                error_msg += 'ğŸ“Œ **æŠ€æœ¯è¯´æ˜ï¼š**\n'
                if is_vercel:
                    error_msg += '- Vercel ç¯å¢ƒæœ‰ 10 ç§’æ‰§è¡Œæ—¶é—´é™åˆ¶\n'
                    error_msg += '- ä» akshare API è·å–è‚¡ç¥¨åˆ—è¡¨å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´\n'
                    error_msg += '- å¦‚æœç¼“å­˜ä¸å­˜åœ¨ï¼Œä» API è·å–å¯èƒ½è¶…æ—¶\n'
                error_msg += '- å»ºè®®åœ¨äº¤æ˜“æ—¶é—´æ®µï¼ˆ9:30-11:30, 13:00-15:00ï¼‰ä½¿ç”¨ï¼Œæ­¤æ—¶ç¼“å­˜ä¼šè‡ªåŠ¨åˆ·æ–°\n'
                
                return jsonify({
                    'success': False,
                    'message': error_msg,
                    'cache_exists': cache_exists,
                    'is_in_trading_time': is_in_trading_time,
                    'current_time': current_time_str,
                    'suggestion': 'æ‰‹åŠ¨åˆ·æ–°ç¼“å­˜' if not cache_exists else 'ç¨åé‡è¯•'
                }), 500
            
            # VIPç”¨æˆ·è‡ªå®šä¹‰ç­›é€‰ï¼šæ’é™¤STè‚¡ç¥¨
            if exclude_st:
                # è·å–è‚¡ç¥¨åç§°åˆ—ï¼ˆå¯èƒ½æ˜¯ 'name' æˆ– 'åç§°'ï¼‰
                name_col = None
                for col in stock_list.columns:
                    col_lower = str(col).lower()
                    if 'name' in col_lower or 'åç§°' in col:
                        name_col = col
                        break
                if name_col:
                    stock_list = stock_list[~stock_list[name_col].astype(str).str.contains('ST', na=False)]
                    print(f"[scan_all_stocks] æ’é™¤STè‚¡ç¥¨åï¼Œå‰©ä½™è‚¡ç¥¨æ•°: {len(stock_list)}")
            
            # VIPç”¨æˆ·è‡ªå®šä¹‰ç­›é€‰ï¼šè‡ªå®šä¹‰è‚¡ç¥¨æ± ï¼ˆå¦‚æœæŒ‡å®šï¼‰
            if custom_stock_pool:
                try:
                    stock_codes = [code.strip() for code in custom_stock_pool.split(',') if code.strip()]
                    if stock_codes:
                        # è·å–è‚¡ç¥¨ä»£ç åˆ—
                        code_col = None
                        for col in stock_list.columns:
                            col_lower = str(col).lower()
                            if 'code' in col_lower or 'ä»£ç ' in col:
                                code_col = col
                                break
                        if code_col:
                            # åªä¿ç•™æŒ‡å®šä»£ç çš„è‚¡ç¥¨ï¼ˆå»é™¤å‰ç¼€å’Œåç¼€ï¼ŒåªåŒ¹é…6ä½æ•°å­—ï¼‰
                            filtered_list = stock_list[stock_list[code_col].astype(str).str.replace(r'\.(SZ|SH)$', '', regex=True).str.replace(r'[^0-9]', '', regex=True).isin([code.replace('.SZ', '').replace('.SH', '').replace(r'[^0-9]', '') for code in stock_codes])]
                            if len(filtered_list) > 0:
                                stock_list = filtered_list
                                print(f"[scan_all_stocks] ä½¿ç”¨è‡ªå®šä¹‰è‚¡ç¥¨æ± ï¼Œè‚¡ç¥¨æ•°: {len(stock_list)}")
                            else:
                                print(f"[scan_all_stocks] âš ï¸ è‡ªå®šä¹‰è‚¡ç¥¨æ± æœªæ‰¾åˆ°åŒ¹é…çš„è‚¡ç¥¨")
                except Exception as e:
                    print(f"[scan_all_stocks] âš ï¸ å¤„ç†è‡ªå®šä¹‰è‚¡ç¥¨æ± å¤±è´¥: {e}")
            
            # VIPç”¨æˆ·è‡ªå®šä¹‰ç­›é€‰ï¼šè¡Œä¸šç­›é€‰ï¼ˆæš‚ä¸æ”¯æŒï¼Œé¢„ç•™æ¥å£ï¼‰
            # TODO: å®ç°è¡Œä¸šç­›é€‰åŠŸèƒ½ï¼ˆéœ€è¦è·å–è‚¡ç¥¨è¡Œä¸šä¿¡æ¯ï¼‰
            if industry_filter:
                print(f"[scan_all_stocks] âš ï¸ è¡Œä¸šç­›é€‰åŠŸèƒ½æš‚æœªå®ç°ï¼Œå‚æ•°: {industry_filter}")
            
            # VIPç”¨æˆ·è‡ªå®šä¹‰ç­›é€‰ï¼šæ’é™¤åœç‰Œè‚¡ç¥¨ï¼ˆæš‚ä¸æ”¯æŒï¼Œé¢„ç•™æ¥å£ï¼‰
            # TODO: å®ç°åœç‰Œè‚¡ç¥¨åˆ¤æ–­ï¼ˆéœ€è¦å®æ—¶æŸ¥è¯¢è‚¡ç¥¨çŠ¶æ€ï¼‰
            if exclude_suspended:
                print(f"[scan_all_stocks] âš ï¸ æ’é™¤åœç‰Œè‚¡ç¥¨åŠŸèƒ½æš‚æœªå®ç°")
            
            total_stocks = len(stock_list)
            if limit:
                stock_list = stock_list.head(limit)
                total_stocks = min(total_stocks, limit)
            
            # æ ¹æ®ç”¨æˆ·ç­‰çº§è·å–æ‰«æé…ç½®
            scan_config = get_scan_config()
            batch_size = scan_config['batch_size']
            total_batches = (total_stocks + batch_size - 1) // batch_size  # å‘ä¸Šå–æ•´
            
            # åˆå§‹åŒ–æ‰«æè¿›åº¦å¹¶ä¿å­˜åˆ° Redis
            import time
            initial_progress = {
                'type': 'scan',
                'scan_id': scan_id,
                'username': username,  # æ·»åŠ ç”¨æˆ·åï¼Œç”¨äºå¤šç”¨æˆ·éš”ç¦»
                'user_tier': user_tier,  # æ·»åŠ ç”¨æˆ·ç­‰çº§ï¼Œç”¨äºåˆ¤æ–­æ˜¯å¦éœ€è¦ä¿å­˜å†å²è®°å½•
                'is_auto_scan': False,  # æ ‡è®°ä¸ºæ‰‹åŠ¨æ‰«æï¼ˆVIPç”¨æˆ·æ‰‹åŠ¨æ‰«æï¼‰
                'current': 0,
                'total': total_stocks,
                'status': 'å‡†å¤‡ä¸­',
                'detail': f'å‡†å¤‡æ‰«æ {total_stocks} åªè‚¡ç¥¨ï¼ˆåˆ† {total_batches} æ‰¹ï¼‰...',
                'percentage': 0,
                'found': 0,
                'batch': 0,
                'total_batches': total_batches,
                'min_match_score': min_match_score,
                'max_market_cap': max_market_cap,
                'candidates': [],
                'start_time': time.time()
            }
            scan_progress_store.save_scan_progress(scan_id, initial_progress)
            
            # ä¿å­˜ç”¨æˆ·çš„æœ€æ–° scan_idï¼ˆç”¨äºåç»­æŸ¥æ‰¾ï¼‰
            try:
                latest_scan_key = f'latest_scan:{username}'
                if hasattr(scan_progress_store, '_upstash_redis_set'):
                    scan_progress_store._upstash_redis_set(latest_scan_key, scan_id, ttl=86400)  # 24å°æ—¶TTL
            except Exception as e:
                print(f"[scan_all_stocks] âš ï¸ ä¿å­˜æœ€æ–° scan_id å¤±è´¥: {e}")
            
            # VIPç”¨æˆ·æ— é™åˆ¶æ‰«æï¼Œä¸éœ€è¦è®°å½•æ‰«ææ¬¡æ•°ï¼ˆå·²ç§»é™¤é™åˆ¶ï¼‰
            # ä½†å¯ä»¥ä¿ç•™è®°å½•åŠŸèƒ½ç”¨äºç»Ÿè®¡ï¼ˆä¸é™åˆ¶æ‰«æï¼‰
            if user_tier == 'premium':
                # VIPç”¨æˆ·ï¼šå¯é€‰è®°å½•ç»Ÿè®¡ä¿¡æ¯ï¼ˆä¸å½±å“æ‰«ææƒé™ï¼‰
                print(f"[scan_all_stocks] VIPç”¨æˆ· {username} å¼€å§‹æ‰«æï¼ˆæ— é™åˆ¶ï¼‰")
            
            # å¤„ç†ç¬¬ä¸€æ‰¹ï¼ˆåœ¨è¯·æ±‚ä¸­åŒæ­¥å¤„ç†ï¼Œé¿å…è¶…æ—¶ï¼‰
            try:
                # è·å–ç‰¹å¾æ¨¡æ¿
                if analyzer.trained_features is None:
                    return jsonify({
                        'success': False,
                        'message': 'å°šæœªè®­ç»ƒç‰¹å¾æ¨¡å‹ï¼Œè¯·å…ˆè®­ç»ƒ'
                    }), 400
                
                common_features = analyzer.trained_features.get('common_features', {})
                if len(common_features) == 0:
                    return jsonify({
                        'success': False,
                        'message': 'ç‰¹å¾æ¨¡æ¿ä¸ºç©º'
                    }), 400
                
                # è·å–æ‰«æé…ç½®
                scan_config = get_scan_config()
                
                # å¤„ç†ç¬¬ä¸€æ‰¹è‚¡ç¥¨
                from vercel_scan_helper import process_scan_batch_vercel
                first_batch = stock_list.head(batch_size)
                batch_result = process_scan_batch_vercel(
                    analyzer, first_batch, common_features, scan_id, 1, total_batches, 
                    total_stocks, min_match_score, max_market_cap, 0, [], scan_config
                )
                
                return jsonify({
                    'success': True,
                    'scan_id': scan_id,
                    'message': f'æ‰«æå·²å¼€å§‹ï¼ˆå…± {total_batches} æ‰¹ï¼‰ï¼Œå·²å¤„ç†ç¬¬ 1 æ‰¹',
                    'progress': batch_result.get('progress', {}),
                    'batch': 1,
                    'total_batches': total_batches,
                    'has_more': total_batches > 1
                })
            except Exception as e:
                import traceback
                error_detail = traceback.format_exc()
                print(f"å¤„ç†ç¬¬ä¸€æ‰¹å¤±è´¥: {error_detail}")
                # æ›´æ–°è¿›åº¦ä¸ºå¤±è´¥çŠ¶æ€
                error_progress = initial_progress.copy()
                error_progress['status'] = 'å¤±è´¥'
                error_progress['detail'] = f'æ‰«æå¤±è´¥: {str(e)[:100]}'
                scan_progress_store.save_scan_progress(scan_id, error_progress)
                return jsonify({
                    'success': False,
                    'message': f'æ‰«æå¯åŠ¨å¤±è´¥: {str(e)}'
                }), 500
        
        # æœ¬åœ°ç¯å¢ƒï¼šä½¿ç”¨åŸæ¥çš„æ–¹å¼ï¼ˆåå°çº¿ç¨‹ï¼‰
        # åœ¨åå°çº¿ç¨‹ä¸­æ‰§è¡Œæ‰«æï¼ˆé¿å…é˜»å¡ï¼‰
        import threading
        
        def run_scan():
            try:
                import time as time_module
                start_time = time_module.time()
                max_scan_time = 3600 * 2  # æœ€å¤§æ‰«ææ—¶é—´ï¼š2å°æ—¶
                
                print(f"\nğŸ”„ å¼€å§‹æ‰«æï¼ŒåŒ¹é…åº¦é˜ˆå€¼: {min_match_score:.3f}")
                
                # åªæ‰§è¡Œä¸€æ¬¡æ‰«æï¼Œä¸å†è‡ªåŠ¨è°ƒæ•´é˜ˆå€¼
                # æœ¬åœ°ç¯å¢ƒï¼šé»˜è®¤ä¼˜å…ˆä½¿ç”¨ç¼“å­˜ï¼ˆç¨³å®šã€å¯å¤ç°ï¼‰ï¼Œéœ€è¦å¼ºåˆ¶åˆ·æ–°æ—¶å†ç”±å‰ç«¯ä¼ å‚æ§åˆ¶
                force_refresh = bool(data.get('force_refresh', False))
                # âœ… å…³é”®ï¼šæœ¬åœ°ç¯å¢ƒé»˜è®¤ä¸¥æ ¼åªä½¿ç”¨æœ¬åœ°ç¼“å­˜ï¼Œé¿å…ç½‘ç»œä¸‹è½½å¯¼è‡´é€Ÿåº¦æ…¢
                strict_local_only = data.get('strict_local_only', None)  # Noneè¡¨ç¤ºè‡ªåŠ¨åˆ¤æ–­
                result = analyzer.scan_all_stocks(
                    min_match_score=min_match_score,
                    max_market_cap=max_market_cap,
                    limit=limit,
                    use_parallel=use_parallel,
                    max_workers=max_workers,
                    scan_date=scan_date,
                    scan_session=scan_session,
                    force_refresh=force_refresh,
                    strict_local_only=strict_local_only  # âœ… ä¼ é€’ä¸¥æ ¼æœ¬åœ°æ¨¡å¼å‚æ•°
                )
                
                # å¦‚æœè¢«åœæ­¢ï¼Œç›´æ¥ä¿å­˜ç»“æœ
                if result.get('stopped', False):
                    analyzer.scan_results = result
                    found_count = result.get('found_count', 0)
                    print(f"\nâœ… æ‰«æå·²åœæ­¢ï¼Œç»“æœå·²ä¿å­˜ï¼ˆæ‰¾åˆ° {found_count} åªè‚¡ç¥¨ï¼‰")
                    # æ›´æ–°è¿›åº¦çŠ¶æ€ä¸ºå·²åœæ­¢ï¼ˆå·²ç»åœ¨scan_all_stocksä¸­è®¾ç½®ï¼Œè¿™é‡Œç¡®ä¿ä¸€è‡´æ€§ï¼‰
                    analyzer.progress['status'] = 'å·²åœæ­¢'
                    analyzer.progress['detail'] = f'æ‰«æå·²åœæ­¢: æ‰¾åˆ° {found_count} åªç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨'
                    analyzer.progress['found'] = found_count
                    analyzer.progress['last_update_time'] = time_module.time()
                else:
                    # ä¿å­˜æ‰«æç»“æœ
                    analyzer.scan_results = result
                    found_count = result.get('found_count', 0)
                    print(f"\nğŸ“Š æ‰«æå®Œæˆï¼Œæ‰¾åˆ° {found_count} åªè‚¡ç¥¨ï¼ˆé˜ˆå€¼: {min_match_score:.3f}ï¼‰")
                    
                    # ç¡®ä¿æ‰«æå®Œæˆåï¼Œæ›´æ–°è¿›åº¦çŠ¶æ€ä¸º"å®Œæˆ"
                    if analyzer.progress.get('status') != 'å·²åœæ­¢':
                        analyzer.progress['status'] = 'å®Œæˆ'
                        analyzer.progress['percentage'] = 100.0
                        analyzer.progress['detail'] = f'æ‰«æå®Œæˆ: æ‰¾åˆ° {found_count} åªç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨'
                        analyzer.progress['found'] = found_count
                        analyzer.progress['last_update_time'] = time_module.time()
                    
                    print(f"\nâœ… æ‰«æå®Œæˆï¼Œæœ€ç»ˆçŠ¶æ€: {analyzer.progress.get('status')}")
                    
            except Exception as e:
                import traceback
                error_detail = traceback.format_exc()
                print(f"æ‰«æè¿‡ç¨‹å‡ºé”™: {error_detail}")
                # å³ä½¿å‡ºé”™ï¼Œä¹Ÿå°è¯•ä¿å­˜å½“å‰ç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
                if hasattr(analyzer, 'scan_results') and analyzer.scan_results:
                    pass  # ç»“æœå·²ä¿å­˜
                # å‡ºé”™æ—¶ä¹Ÿè¦æ›´æ–°çŠ¶æ€
                if analyzer.progress.get('status') != 'å·²åœæ­¢':
                    analyzer.progress['status'] = 'å¤±è´¥'
                    analyzer.progress['detail'] = f'æ‰«æå‡ºé”™: {str(e)[:50]}'
                    analyzer.progress['last_update_time'] = time_module.time()
        
        # å¯åŠ¨æ‰«æçº¿ç¨‹
        scan_thread = threading.Thread(target=run_scan)
        scan_thread.daemon = True
        scan_thread.start()
        
        return jsonify({
            'success': True,
            'message': 'æ‰«æå·²å¼€å§‹ï¼Œè¯·é€šè¿‡è¿›åº¦APIæŸ¥çœ‹è¿›åº¦'
        })
        
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"æ‰«ææ‰€æœ‰è‚¡ç¥¨é”™è¯¯: {error_detail}")
        return jsonify({
            'success': False,
            'message': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}'
        }), 500


@app.route('/api/continue_scan', methods=['POST'])
@require_login
def continue_scan():
    """ç»§ç»­æ‰«æä¸‹ä¸€æ‰¹æ¬¡ï¼ˆVercel ç¯å¢ƒï¼‰"""
    try:
        # è®°å½•è¯·æ±‚ä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        data = request.get_json() or {}
        scan_id = data.get('scan_id')
        print(f"[continue_scan] æ”¶åˆ°è¯·æ±‚: scan_id={scan_id}, ç”¨æˆ·={get_current_user().get('username') if get_current_user() else 'None'}")
        
        if not is_vercel:
            return jsonify({
                'success': False,
                'message': 'æ­¤APIä»…åœ¨ Vercel ç¯å¢ƒä¸­å¯ç”¨'
            }), 400
        
        if not scan_id:
            return jsonify({
                'success': False,
                'message': 'ç¼ºå°‘ scan_id å‚æ•°'
            }), 400
        
        # è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯ï¼Œç”¨äºéªŒè¯æƒé™
        current_user = get_current_user()
        current_username = current_user.get('username', 'anonymous') if current_user else 'anonymous'
        
        # ä»scan_idä¸­æå–ç”¨æˆ·åï¼ˆæ ¼å¼: username_timestamp_uuidï¼‰
        # è¿™æ ·å³ä½¿sessionæœ‰é—®é¢˜ï¼Œä¹Ÿèƒ½æ­£ç¡®éªŒè¯
        scan_id_parts = scan_id.split('_', 1)  # åˆ†å‰²ç”¨æˆ·åå’Œå…¶ä½™éƒ¨åˆ†
        scan_id_username = scan_id_parts[0] if scan_id_parts else 'unknown'
        
        print(f"[continue_scan] scan_id={scan_id}, scan_idä¸­çš„ç”¨æˆ·å={scan_id_username}, å½“å‰ç”¨æˆ·={current_username}")
        
        import scan_progress_store
        from vercel_scan_helper import process_scan_batch_vercel
        
        # è·å–å½“å‰è¿›åº¦
        progress = scan_progress_store.get_scan_progress(scan_id)
        if not progress:
            # æä¾›æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
            print(f"âš ï¸ æ‰¾ä¸åˆ°æ‰«æä»»åŠ¡ scan_id={scan_id} (scan_idä¸­çš„ç”¨æˆ·: {scan_id_username}, å½“å‰ç”¨æˆ·: {current_username})")
            print(f"   å¯èƒ½åŸå› ï¼š1) Redis æ•°æ®è¿‡æœŸï¼ˆTTL 24å°æ—¶ï¼‰ 2) scan_id é”™è¯¯ 3) Redis è¿æ¥é—®é¢˜ 4) æ•°æ®ä¿å­˜å¤±è´¥")
            
            # å°è¯•æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–ç›¸å…³çš„æ‰«æä»»åŠ¡ï¼ˆå¯èƒ½æ˜¯åŒä¸€ä¸ªç”¨æˆ·çš„å¦ä¸€ä¸ªæ‰«æï¼‰
            # è¿™é‡Œæˆ‘ä»¬æä¾›ä¸€ä¸ªæ›´å‹å¥½çš„é”™è¯¯æ¶ˆæ¯ï¼Œå¹¶å»ºè®®ç”¨æˆ·é‡æ–°å¼€å§‹æ‰«æ
            # è¿”å›400è€Œä¸æ˜¯404ï¼Œå› ä¸ºè·¯ç”±å­˜åœ¨ï¼Œåªæ˜¯æ•°æ®ä¸å­˜åœ¨
            return jsonify({
                'success': False,
                'message': f'æ‰¾ä¸åˆ°æ‰«æä»»åŠ¡ï¼ˆscan_id: {scan_id}ï¼‰ã€‚å¯èƒ½åŸå› ï¼š1) æ•°æ®å·²è¿‡æœŸï¼ˆè¶…è¿‡24å°æ—¶ï¼‰ 2) ä»»åŠ¡å·²åˆ é™¤ 3) Redisè¿æ¥é—®é¢˜ã€‚éƒ¨åˆ†ç»“æœå¯èƒ½å·²ä¿å­˜ï¼Œè¯·æŸ¥çœ‹æ‰«æç»“æœã€‚å¦‚éœ€è¦ï¼Œè¯·é‡æ–°å¼€å§‹æ‰«æã€‚',
                'error_code': 'SCAN_NOT_FOUND',
                'scan_id': scan_id,
                'retry': False,  # æ ‡è¯†æ˜¯å¦åº”è¯¥é‡è¯•
                'hint': 'æ‰«æä»»åŠ¡å¯èƒ½å·²è¿‡æœŸæˆ–è¢«åˆ é™¤ã€‚å¦‚æœä¹‹å‰æœ‰éƒ¨åˆ†ç»“æœï¼Œè¯·å°è¯•æŸ¥çœ‹æ‰«æç»“æœé¡µé¢ã€‚'
            }), 400
        
        # éªŒè¯æ‰«æä»»åŠ¡æ˜¯å¦å±äºå½“å‰ç”¨æˆ·ï¼ˆå¤šç”¨æˆ·éš”ç¦»ï¼‰
        # ä¼˜å…ˆä½¿ç”¨scan_idä¸­çš„ç”¨æˆ·åè¿›è¡ŒéªŒè¯ï¼Œå› ä¸ºå®ƒæ˜¯åˆ›å»ºæ—¶çš„çœŸå®ç”¨æˆ·åï¼Œä¸ä¼šå—sessionå½±å“
        progress_username = progress.get('username') or scan_id_username
        
        # éªŒè¯é€»è¾‘ï¼š
        # 1. å¦‚æœscan_idä¸­çš„ç”¨æˆ·åå’Œå½“å‰ç”¨æˆ·åŒ¹é…ï¼Œå…è®¸è®¿é—®ï¼ˆæœ€å¸¸è§çš„æƒ…å†µï¼‰
        # 2. å¦‚æœprogressä¸­çš„ç”¨æˆ·åå’Œå½“å‰ç”¨æˆ·åŒ¹é…ï¼Œå…è®¸è®¿é—®ï¼ˆå¤‡ç”¨éªŒè¯ï¼‰
        # 3. å¦‚æœsessionä¸¢å¤±ï¼ˆcurrent_userä¸ºNoneï¼‰ï¼Œä½†scan_idå’Œprogressä¸­çš„ç”¨æˆ·ååŒ¹é…ï¼Œå…è®¸è®¿é—®ï¼ˆå®¹é”™å¤„ç†ï¼‰
        # 4. å¦‚æœscan_idä¸­çš„ç”¨æˆ·åå’Œprogressä¸­çš„ç”¨æˆ·ååŒ¹é…ï¼Œä¹Ÿå…è®¸è®¿é—®ï¼ˆåŒé‡éªŒè¯é€šè¿‡ï¼‰
        
        # å¦‚æœscan_idä¸­çš„ç”¨æˆ·åæ˜¯"unknown"ï¼Œè¯´æ˜scan_idæ ¼å¼ä¸å¯¹ï¼Œä½¿ç”¨ä¼ ç»ŸéªŒè¯æ–¹å¼
        if scan_id_username == 'unknown':
            # ä¼ ç»ŸéªŒè¯ï¼šåªæ£€æŸ¥progressä¸­çš„ç”¨æˆ·åå’Œå½“å‰ç”¨æˆ·
            is_authorized = (progress_username == current_username and current_username != 'anonymous')
        else:
            # æ–°éªŒè¯æ–¹å¼ï¼šä¼˜å…ˆä½¿ç”¨scan_idä¸­çš„ç”¨æˆ·å
            # å¦‚æœå½“å‰ç”¨æˆ·å­˜åœ¨ä¸”åŒ¹é…scan_idä¸­çš„ç”¨æˆ·åï¼Œå…è®¸è®¿é—®
            if current_user and current_username != 'anonymous':
                is_authorized = (scan_id_username == current_username or progress_username == current_username)
            else:
                # å¦‚æœsessionä¸¢å¤±ï¼Œä½†scan_idå’Œprogressä¸­çš„ç”¨æˆ·ååŒ¹é…ï¼Œå…è®¸è®¿é—®ï¼ˆå®¹é”™ï¼‰
                is_authorized = (scan_id_username == progress_username and scan_id_username != 'unknown')
        
        if not is_authorized:
            print(f"âš ï¸ æƒé™éªŒè¯å¤±è´¥: scan_id={scan_id}")
            print(f"   scan_idæ ¼å¼: {scan_id}")
            print(f"   scan_idä¸­çš„ç”¨æˆ·å={scan_id_username}")
            print(f"   è¿›åº¦ä¸­çš„ç”¨æˆ·å={progress_username}")
            print(f"   å½“å‰ç”¨æˆ·={current_username}")
            print(f"   å½“å‰ç”¨æˆ·å¯¹è±¡æ˜¯å¦å­˜åœ¨={current_user is not None}")
            return jsonify({
                'success': False,
                'message': f'æ— æƒè®¿é—®æ­¤æ‰«æä»»åŠ¡ã€‚scan_idä¸­çš„ç”¨æˆ·: {scan_id_username}, å½“å‰ç”¨æˆ·: {current_username}, è¿›åº¦ä¸­çš„ç”¨æˆ·: {progress_username}',
                'error_code': 'ACCESS_DENIED',
                'scan_id': scan_id,
                'scan_id_username': scan_id_username,
                'current_username': current_username,
                'progress_username': progress_username,
                'hint': 'è¯·ç¡®ä¿ä½¿ç”¨ç›¸åŒçš„è´¦å·ç»§ç»­æ‰«æä»»åŠ¡'
            }), 403
        
        # ä½¿ç”¨æ­£ç¡®çš„ç”¨æˆ·åï¼ˆä¼˜å…ˆä½¿ç”¨scan_idä¸­çš„ï¼Œå› ä¸ºå®ƒæ˜¯åˆ›å»ºæ—¶çš„çœŸå®ç”¨æˆ·åï¼‰
        username = scan_id_username if scan_id_username != 'unknown' else (progress_username or current_username)
        print(f"[continue_scan] âœ… æƒé™éªŒè¯é€šè¿‡ï¼Œä½¿ç”¨ç”¨æˆ·å: {username} (scan_id: {scan_id_username}, progress: {progress_username}, current: {current_username})")
        
        # æ£€æŸ¥æ˜¯å¦å·²å®Œæˆ
        if progress.get('status') == 'å®Œæˆ':
            results = scan_progress_store.get_scan_results(scan_id)
            return jsonify({
                'success': True,
                'message': 'æ‰«æå·²å®Œæˆ',
                'progress': progress,
                'results': results,
                'is_complete': True
            })
        
        # åœ¨å¤„ç†æ‰¹æ¬¡ä¹‹å‰ï¼Œå…ˆåˆ·æ–°TTLï¼Œç¡®ä¿è¿›åº¦ä¸ä¼šè¿‡æœŸ
        # è¿™å¾ˆé‡è¦ï¼Œå› ä¸ºåœ¨å¤„ç†æ‰¹æ¬¡æ—¶å¯èƒ½ä¼šèŠ±è´¹è¾ƒé•¿æ—¶é—´
        progress['last_refresh_time'] = time.time()
        progress['username'] = username  # ç¡®ä¿ç”¨æˆ·åæ­£ç¡®
        refresh_success = scan_progress_store.save_scan_progress(scan_id, progress)
        if not refresh_success:
            print(f"âš ï¸ [continue_scan] åˆ·æ–°è¿›åº¦TTLå¤±è´¥ï¼Œä½†ç»§ç»­å¤„ç†ï¼ˆscan_id={scan_id}ï¼‰")
        
        # è·å–å‚æ•°
        batch_num = progress.get('batch', 0) + 1
        total_batches = progress.get('total_batches', 1)
        total_stocks = progress.get('total', 0)
        min_match_score = progress.get('min_match_score', 0.93)
        max_market_cap = progress.get('max_market_cap', 100.0)
        current_idx = progress.get('current', 0)
        existing_candidates = progress.get('candidates', [])
        
        # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ›´å¤šæ‰¹æ¬¡
        if batch_num > total_batches:
            return jsonify({
                'success': True,
                'message': 'æ‰€æœ‰æ‰¹æ¬¡å·²å®Œæˆ',
                'progress': progress,
                'is_complete': True
            })
        
        # è·å–è‚¡ç¥¨åˆ—è¡¨
        init_analyzer()
        stock_list = analyzer.fetcher.get_all_stocks()
        if stock_list is None or len(stock_list) == 0:
            return jsonify({
                'success': False,
                'message': 'æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨'
            }), 500
        
        # è·å–ç‰¹å¾æ¨¡æ¿
        if analyzer.trained_features is None:
            return jsonify({
                'success': False,
                'message': 'å°šæœªè®­ç»ƒç‰¹å¾æ¨¡å‹ï¼Œè¯·å…ˆè®­ç»ƒ'
            }), 400
        
        common_features = analyzer.trained_features.get('common_features', {})
        if len(common_features) == 0:
            return jsonify({
                'success': False,
                'message': 'ç‰¹å¾æ¨¡æ¿ä¸ºç©º'
            }), 400
        
        # æ ¹æ®ç”¨æˆ·ç­‰çº§è·å–æ‰«æé…ç½®
        scan_config = get_scan_config()
        batch_size = scan_config['batch_size']
        start_idx = (batch_num - 1) * batch_size
        end_idx = min(start_idx + batch_size, total_stocks)
        
        if start_idx >= total_stocks:
            return jsonify({
                'success': True,
                'message': 'æ‰€æœ‰æ‰¹æ¬¡å·²å®Œæˆ',
                'progress': progress,
                'is_complete': True
            })
        
        # è·å–å½“å‰æ‰¹æ¬¡è‚¡ç¥¨
        current_batch = stock_list.iloc[start_idx:end_idx]
        
        # å¤„ç†æ‰¹æ¬¡
        batch_result = process_scan_batch_vercel(
            analyzer, current_batch, common_features, scan_id, batch_num, total_batches,
            total_stocks, min_match_score, max_market_cap, start_idx, existing_candidates
        )
        
        return jsonify({
            'success': True,
            'message': f'ç¬¬ {batch_num}/{total_batches} æ‰¹å¤„ç†å®Œæˆ',
            'progress': batch_result.get('progress', {}),
            'batch': batch_num,
            'total_batches': total_batches,
            'has_more': not batch_result.get('is_complete', False),
            'is_complete': batch_result.get('is_complete', False)
        })
    
    except KeyError as e:
        # å¤„ç†æ•°æ®æ ¼å¼é”™è¯¯
        import traceback
        error_detail = traceback.format_exc()
        print(f"ç»§ç»­æ‰«ææ•°æ®æ ¼å¼é”™è¯¯: {error_detail}")
        return jsonify({
            'success': False,
            'message': f'æ•°æ®æ ¼å¼é”™è¯¯: {str(e)}',
            'error_code': 'DATA_FORMAT_ERROR'
        }), 400
        
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"ç»§ç»­æ‰«æé”™è¯¯: {error_detail}")
        return jsonify({
            'success': False,
            'message': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}'
        }), 500


@app.route('/api/stop_scan', methods=['POST'])
@require_login
def stop_scan():
    """åœæ­¢æ‰«æAPI"""
    try:
        # åœ¨ Vercel ç¯å¢ƒä¸­ï¼Œæ›´æ–° Redis ä¸­çš„è¿›åº¦çŠ¶æ€
        if is_vercel:
            data = request.get_json() or {}
            scan_id = data.get('scan_id')
            
            print(f"[stop_scan] Vercel ç¯å¢ƒï¼Œæ”¶åˆ°åœæ­¢è¯·æ±‚ï¼Œscan_id: {scan_id}")
            
            if scan_id:
                try:
                    # è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯ï¼Œç”¨äºéªŒè¯æƒé™
                    current_user = get_current_user()
                    username = current_user.get('username', 'anonymous') if current_user else 'anonymous'
                    
                    import scan_progress_store
                    progress = scan_progress_store.get_scan_progress(scan_id)
                    if progress:
                        # éªŒè¯æ‰«æä»»åŠ¡æ˜¯å¦å±äºå½“å‰ç”¨æˆ·ï¼ˆå¤šç”¨æˆ·éš”ç¦»ï¼‰
                        progress_username = progress.get('username', 'anonymous')
                        if progress_username != username:
                            print(f"[stop_scan] âš ï¸ ç”¨æˆ· {username} å°è¯•åœæ­¢å…¶ä»–ç”¨æˆ· {progress_username} çš„æ‰«æä»»åŠ¡: {scan_id}")
                            return jsonify({
                                'success': False,
                                'message': 'æ— æƒåœæ­¢æ­¤æ‰«æä»»åŠ¡ï¼ˆä¸å±äºå½“å‰ç”¨æˆ·ï¼‰',
                                'error_code': 'ACCESS_DENIED',
                                'scan_id': scan_id
                            }), 403
                        
                        progress['status'] = 'å·²åœæ­¢'
                        progress['detail'] = 'æ‰«æå·²åœæ­¢ï¼ˆç”¨æˆ·è¯·æ±‚ï¼‰'
                        import time
                        progress['last_update_time'] = time.time()
                        scan_progress_store.save_scan_progress(scan_id, progress)
                        print(f"[stop_scan] âœ… æˆåŠŸåœæ­¢æ‰«æä»»åŠ¡: {scan_id} (ç”¨æˆ·: {username})")
                        return jsonify({
                            'success': True,
                            'message': 'åœæ­¢æ‰«æè¯·æ±‚å·²å‘é€',
                            'scan_id': scan_id
                        })
                    else:
                        print(f"[stop_scan] âš ï¸ æ‰¾ä¸åˆ°æ‰«æä»»åŠ¡: {scan_id} (ç”¨æˆ·: {username})")
                        return jsonify({
                            'success': False,
                            'message': f'æ‰¾ä¸åˆ°æ‰«æä»»åŠ¡ï¼ˆscan_id: {scan_id}ï¼‰ï¼Œå¯èƒ½å·²è¿‡æœŸæˆ–å·²å®Œæˆ'
                        }), 404
                except Exception as e:
                    import traceback
                    error_detail = traceback.format_exc()
                    print(f"[stop_scan] âŒ åœæ­¢æ‰«ææ—¶å‡ºé”™: {error_detail}")
                    return jsonify({
                        'success': False,
                        'message': f'åœæ­¢æ‰«æå¤±è´¥: {str(e)}'
                    }), 500
            else:
                # å¦‚æœæ²¡æœ‰æä¾› scan_idï¼Œå°è¯•ä»å½“å‰çª—å£çš„å…¨å±€å˜é‡è·å–
                print(f"[stop_scan] âš ï¸ æœªæä¾› scan_idï¼Œå°è¯•æŸ¥æ‰¾å½“å‰æ‰«æä»»åŠ¡...")
                # åœ¨ Vercel ç¯å¢ƒä¸­ï¼Œå¦‚æœæ²¡æœ‰ scan_idï¼Œæ— æ³•åœæ­¢ç‰¹å®šçš„æ‰«æ
                # ä½†æˆ‘ä»¬å¯ä»¥è¿”å›ä¸€ä¸ªå‹å¥½çš„é”™è¯¯æ¶ˆæ¯
                return jsonify({
                    'success': False,
                    'message': 'æœªæä¾›æ‰«æä»»åŠ¡IDï¼ˆscan_idï¼‰ï¼Œæ— æ³•åœæ­¢æ‰«æã€‚è¯·åˆ·æ–°é¡µé¢åé‡è¯•ã€‚'
                }), 400
        
        # æœ¬åœ°ç¯å¢ƒ
        init_analyzer()  # ç¡®ä¿åˆ†æå™¨å·²åˆå§‹åŒ–
        
        if analyzer is None:
            return jsonify({
                'success': False,
                'message': 'åˆ†æå™¨æœªåˆå§‹åŒ–'
            }), 500
        
        if not hasattr(analyzer, 'stop_scanning'):
            return jsonify({
                'success': False,
                'message': 'åˆ†æå™¨ä¸æ”¯æŒåœæ­¢æ‰«æåŠŸèƒ½'
            }), 500
        
        analyzer.stop_scanning()
        print(f"[stop_scan] âœ… æœ¬åœ°ç¯å¢ƒï¼Œå·²å‘é€åœæ­¢æ‰«æè¯·æ±‚")
        return jsonify({
            'success': True,
            'message': 'åœæ­¢æ‰«æè¯·æ±‚å·²å‘é€'
        })
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"[stop_scan] âŒ åœæ­¢æ‰«æé”™è¯¯: {error_detail}")
        return jsonify({
            'success': False,
            'message': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}',
            'error_detail': error_detail if not is_vercel else None  # Vercel ç¯å¢ƒä¸è¿”å›è¯¦ç»†é”™è¯¯
        }), 500


@app.route('/api/find_buy_points', methods=['POST'])
@require_login
def find_buy_points():
    init_analyzer()  # ç¡®ä¿åˆ†æå™¨å·²åˆå§‹åŒ–
    """æŸ¥æ‰¾ä¹°ç‚¹API"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({
                'success': False,
                'message': 'è¯·æ±‚æ•°æ®ä¸ºç©º',
                'buy_points': []
            }), 400
        
        stock_code = (data.get('code') or '').strip()
        tolerance = float(data.get('tolerance', 0.3))
        search_years = int(data.get('search_years', 5))  # é»˜è®¤æœç´¢5å¹´å†å²
        
        if not stock_code:
            return jsonify({
                'success': False,
                'message': 'è‚¡ç¥¨ä»£ç ä¸èƒ½ä¸ºç©º',
                'buy_points': []
            }), 400
        
        if len(stock_code) != 6 or not stock_code.isdigit():
            return jsonify({
                'success': False,
                'message': 'è‚¡ç¥¨ä»£ç å¿…é¡»æ˜¯6ä½æ•°å­—',
                'buy_points': []
            }), 400
        
        # è·å–è‚¡ç¥¨åç§°
        stock_name = analyzer._get_stock_name(stock_code)
        if stock_name is None or stock_name == '':
            # å¦‚æœè·å–å¤±è´¥ï¼Œå°è¯•ä»å·²åŠ è½½çš„å¤§ç‰›è‚¡åˆ—è¡¨ä¸­æŸ¥æ‰¾
            for stock in analyzer.bull_stocks:
                if stock.get('ä»£ç ') == stock_code:
                    stock_name = stock.get('åç§°', stock_code)
                    break
            # å¦‚æœè¿˜æ˜¯æ‰¾ä¸åˆ°ï¼Œä½¿ç”¨ä»£ç ä½œä¸ºåç§°
            if stock_name is None or stock_name == '':
                stock_name = stock_code
                print(f"âš ï¸ æ— æ³•è·å– {stock_code} çš„è‚¡ç¥¨åç§°ï¼Œä½¿ç”¨ä»£ç ä½œä¸ºåç§°")
        
        # æŸ¥æ‰¾å†å²ä¹°ç‚¹ï¼ˆç”¨äºæµ‹è¯•ç³»ç»Ÿå‡†ç¡®æ€§ï¼‰
        # ä½¿ç”¨åŒ¹é…åº¦é˜ˆå€¼0.95ï¼ˆä¸è®­ç»ƒæ¨¡å‹ä¸€è‡´ï¼‰
        match_threshold = float(data.get('match_threshold', 0.95))
        result = analyzer.find_buy_points(
            stock_code, 
            tolerance=tolerance, 
            search_years=search_years,
            match_threshold=match_threshold
        )
        
        # åœ¨è¿”å›ç»“æœä¸­æ·»åŠ è‚¡ç¥¨åç§°
        if result.get('success'):
            result['stock_code'] = stock_code
            result['stock_name'] = stock_name
        
        # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„æ ¼å¼
        if result.get('success') and result.get('buy_points'):
            buy_points = []
            for bp in result['buy_points']:
                buy_point = {
                    'æ—¥æœŸ': str(bp.get('æ—¥æœŸ', '')),
                    'ä»·æ ¼': float(bp.get('ä»·æ ¼', 0)) if bp.get('ä»·æ ¼') is not None else 0,
                    'åŒ¹é…åº¦': float(bp.get('åŒ¹é…åº¦', 0)) if bp.get('åŒ¹é…åº¦') is not None else 0,
                    # 4å‘¨è¡¨ç°
                    'ä¹°å…¥å4å‘¨æ¶¨å¹…': float(bp.get('ä¹°å…¥å4å‘¨æ¶¨å¹…', 0)) if bp.get('ä¹°å…¥å4å‘¨æ¶¨å¹…') is not None else None,
                    # æœ€ä½³å–ç‚¹ä¿¡æ¯
                    'æœ€ä½³å–ç‚¹ä»·æ ¼': float(bp.get('æœ€ä½³å–ç‚¹ä»·æ ¼')) if bp.get('æœ€ä½³å–ç‚¹ä»·æ ¼') is not None else None,
                    'æœ€ä½³å–ç‚¹æ—¥æœŸ': str(bp.get('æœ€ä½³å–ç‚¹æ—¥æœŸ', '')) if bp.get('æœ€ä½³å–ç‚¹æ—¥æœŸ') else None,
                    'æœ€ä½³å–ç‚¹å‘¨æ•°': int(bp.get('æœ€ä½³å–ç‚¹å‘¨æ•°')) if bp.get('æœ€ä½³å–ç‚¹å‘¨æ•°') is not None else None,
                    'å–ç‚¹ç±»å‹': str(bp.get('å–ç‚¹ç±»å‹', '')) if bp.get('å–ç‚¹ç±»å‹') else None,
                    'æ­¢æŸä»·æ ¼': float(bp.get('æ­¢æŸä»·æ ¼')) if bp.get('æ­¢æŸä»·æ ¼') is not None else None,
                    '4å‘¨æ˜¯å¦ç›ˆåˆ©': bool(bp.get('4å‘¨æ˜¯å¦ç›ˆåˆ©', False)) if bp.get('4å‘¨æ˜¯å¦ç›ˆåˆ©') is not None else None,
                    '4å‘¨æ˜¯å¦ç¿»å€': bool(bp.get('4å‘¨æ˜¯å¦ç¿»å€', False)) if bp.get('4å‘¨æ˜¯å¦ç¿»å€') is not None else None,
                    # 10å‘¨è¡¨ç°
                    'ä¹°å…¥å10å‘¨æ¶¨å¹…': float(bp.get('ä¹°å…¥å10å‘¨æ¶¨å¹…', 0)) if bp.get('ä¹°å…¥å10å‘¨æ¶¨å¹…') is not None else None,
                    '10å‘¨æ˜¯å¦ç›ˆåˆ©': bool(bp.get('10å‘¨æ˜¯å¦ç›ˆåˆ©', False)) if bp.get('10å‘¨æ˜¯å¦ç›ˆåˆ©') is not None else None,
                    '10å‘¨æ˜¯å¦ç¿»å€': bool(bp.get('10å‘¨æ˜¯å¦ç¿»å€', False)) if bp.get('10å‘¨æ˜¯å¦ç¿»å€') is not None else None,
                    '10å‘¨å†…æœ€å¤§æ¶¨å¹…': float(bp.get('10å‘¨å†…æœ€å¤§æ¶¨å¹…', 0)) if bp.get('10å‘¨å†…æœ€å¤§æ¶¨å¹…') is not None else None,
                    # 20å‘¨è¡¨ç°
                    'ä¹°å…¥å20å‘¨æ¶¨å¹…': float(bp.get('ä¹°å…¥å20å‘¨æ¶¨å¹…', 0)) if bp.get('ä¹°å…¥å20å‘¨æ¶¨å¹…') is not None else None,
                    '20å‘¨æ˜¯å¦ç›ˆåˆ©': bool(bp.get('20å‘¨æ˜¯å¦ç›ˆåˆ©', False)) if bp.get('20å‘¨æ˜¯å¦ç›ˆåˆ©') is not None else None,
                    # æœ€ä½³ä¹°ç‚¹æ ‡è®°
                    'æ˜¯å¦æœ€ä½³ä¹°ç‚¹': bool(bp.get('æ˜¯å¦æœ€ä½³ä¹°ç‚¹', False))
                }
                buy_points.append(buy_point)
            result['buy_points'] = buy_points
        
        # ç¡®ä¿è¿”å›ç»Ÿè®¡ä¿¡æ¯å’ŒåŒ¹é…åº¦ä¿¡æ¯ï¼ˆå³ä½¿æ²¡æœ‰æ‰¾åˆ°ä¹°ç‚¹ï¼‰
        if result.get('success'):
            if 'statistics' not in result or not result.get('statistics'):
                result['statistics'] = {
                    'total': len(result.get('buy_points', [])),
                    'best_buy_points': sum(1 for bp in result.get('buy_points', []) if bp.get('æ˜¯å¦æœ€ä½³ä¹°ç‚¹', False)),
                    'profitable_4w': sum(1 for bp in result.get('buy_points', []) if bp.get('4å‘¨æ˜¯å¦ç›ˆåˆ©', False)),
                    'profitable_10w': sum(1 for bp in result.get('buy_points', []) if bp.get('10å‘¨æ˜¯å¦ç›ˆåˆ©', False))
                }
            # ä¿ç•™åŒ¹é…åº¦ä¿¡æ¯
            if 'max_match_score' not in result:
                result['max_match_score'] = result.get('max_match_score', 0)
            if 'avg_match_score' not in result:
                result['avg_match_score'] = result.get('avg_match_score', 0)
        
        return jsonify(result)
        
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"æŸ¥æ‰¾ä¹°ç‚¹é”™è¯¯: {error_detail}")
        return jsonify({
            'success': False,
            'message': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}',
            'buy_points': []
        }), 500


@app.route('/api/get_scan_progress', methods=['GET'])
@require_login
def get_scan_progress():
    """è·å–æ‰«æè¿›åº¦API"""
    try:
        init_analyzer()  # ç¡®ä¿åˆ†æå™¨å·²åˆå§‹åŒ–
        
        # æ£€æŸ¥ analyzer æ˜¯å¦å·²åˆå§‹åŒ–
        if analyzer is None:
            return jsonify({
                'type': 'scan',
                'current': 0,
                'total': 0,
                'status': 'ç©ºé—²',
                'detail': '',
                'percentage': 0,
                'found': 0
            })
        
        # ä½¿ç”¨ get_progress() æ–¹æ³•ï¼Œè€Œä¸æ˜¯ç›´æ¥è®¿é—® progress å±æ€§
        progress = analyzer.get_progress().copy()
        
        # æ·»åŠ æœ€åæ›´æ–°æ—¶é—´ï¼Œç”¨äºæ£€æµ‹æ˜¯å¦å¡ä½
        if 'last_update_time' in progress:
            import time
            last_update = progress['last_update_time']
            current_time = time.time()
            time_since_update = current_time - last_update
            
            progress['time_since_last_update'] = round(time_since_update, 1)  # è·ç¦»æœ€åæ›´æ–°çš„ç§’æ•°
            
            # å¦‚æœè¶…è¿‡30ç§’æ²¡æœ‰æ›´æ–°ï¼Œæ ‡è®°ä¸ºå¯èƒ½å¡ä½
            if time_since_update > 30:
                progress['status'] = 'å¯èƒ½å¡ä½'
                progress['warning'] = f'å·²è¶…è¿‡ {int(time_since_update)} ç§’æœªæ›´æ–°ï¼Œå½“å‰è‚¡ç¥¨: {progress.get("current_stock", "æœªçŸ¥")}'
        
        return jsonify(progress)
    except AttributeError as e:
        # analyzer æœªåˆå§‹åŒ–æˆ–æ–¹æ³•ä¸å­˜åœ¨
        print(f"è·å–æ‰«æè¿›åº¦é”™è¯¯ (AttributeError): {e}")
        return jsonify({
            'type': 'scan',
            'current': 0,
            'total': 0,
            'status': 'ç©ºé—²',
            'detail': '',
            'percentage': 0,
            'found': 0
        })
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"è·å–æ‰«æè¿›åº¦é”™è¯¯: {error_detail}")
        return jsonify({
            'type': 'scan',
            'current': 0,
            'total': 0,
            'status': 'é”™è¯¯',
            'detail': f'è·å–è¿›åº¦å¤±è´¥: {str(e)}',
            'percentage': 0,
            'found': 0,
            'error_detail': error_detail if is_vercel else None  # ä»…åœ¨ Vercel ç¯å¢ƒä¸­è¿”å›è¯¦ç»†é”™è¯¯
        })

@app.route('/api/get_scan_debug_log', methods=['GET'])
@require_login
def get_scan_debug_log():
    """è·å–æ‰«æè°ƒè¯•æ—¥å¿—API"""
    try:
        import os
        log_file = 'scan_debug.log'
        
        if not os.path.exists(log_file):
            return jsonify({
                'success': False,
                'message': 'æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨',
                'logs': []
            })
        
        # è¯»å–æœ€å100è¡Œæ—¥å¿—
        with open(log_file, 'r', encoding='utf-8') as f:
            lines = f.readlines()
            last_lines = lines[-100:] if len(lines) > 100 else lines
        
        return jsonify({
            'success': True,
            'logs': last_lines,
            'total_lines': len(lines)
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'è¯»å–æ—¥å¿—å¤±è´¥: {str(e)}',
            'logs': []
        }), 500

@app.route('/api/get_scan_results', methods=['GET'])
@require_login
def get_scan_results():
    """è·å–æ‰«æç»“æœAPI"""
    try:
        # è·å–ç”¨æˆ·ä¿¡æ¯å’Œç­‰çº§
        user = get_current_user()
        if not user:
            return jsonify({
                'success': False,
                'message': 'è¯·å…ˆç™»å½•',
                'candidates': []
            }), 401
        
        user_tier = get_user_tier()
        scan_config = get_scan_config()
        
        # æ£€æŸ¥ç»“æœæŸ¥çœ‹æ—¶é—´é™åˆ¶
        from scan_limit_helper import check_result_view_time
        can_view, view_error = check_result_view_time(user_tier, scan_config)
        if not can_view:
            return jsonify({
                'success': False,
                'message': view_error,
                'error_code': 'VIEW_TIME_LIMIT',
                'candidates': []
            }), 403
        
        # åœ¨ Vercel ç¯å¢ƒä¸­ï¼Œä» Redis è¯»å–ç»“æœ
        if is_vercel:
            import scan_progress_store
            from scan_limit_helper import get_beijing_time
            
            scan_id = request.args.get('scan_id') or request.args.get('scanId')
            
            # å¦‚æœæ²¡æœ‰æä¾› scan_idï¼Œå°è¯•æŸ¥æ‰¾æœ€æ–°çš„è‡ªåŠ¨æ‰«æç»“æœ
            if not scan_id and user_tier in ['free', 'premium']:
                # æŸ¥æ‰¾ä»Šå¤©è¯¥ç”¨æˆ·ç­‰çº§çš„æœ€æ–°è‡ªåŠ¨æ‰«æä»»åŠ¡
                beijing_now = get_beijing_time()
                today_str = beijing_now.strftime('%Y-%m-%d')
                
                # è‡ªåŠ¨æ‰«æçš„ scan_id æ ¼å¼: auto_{user_tier}_{timestamp}_{uuid}
                # æˆ‘ä»¬éœ€è¦æŸ¥æ‰¾æ‰€æœ‰ä»¥ auto_{user_tier}_ å¼€å¤´çš„æ‰«æä»»åŠ¡
                # ç”±äº Redis ä¸æ”¯æŒæ¨¡å¼åŒ¹é…ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªå›ºå®šçš„é”®æ¥å­˜å‚¨ä»Šå¤©çš„è‡ªåŠ¨æ‰«æID
                auto_scan_key = f'auto_scan_{user_tier}_{today_str}'
                auto_scan_id = scan_progress_store._upstash_redis_get(auto_scan_key) if hasattr(scan_progress_store, '_upstash_redis_get') else None
                
                if auto_scan_id:
                    scan_id = auto_scan_id
                    print(f"[get_scan_results] æ‰¾åˆ°ä»Šå¤©çš„è‡ªåŠ¨æ‰«æä»»åŠ¡: {scan_id} (ç”¨æˆ·ç­‰çº§: {user_tier})")
            
            if scan_id:
                # è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯ï¼Œç”¨äºéªŒè¯æƒé™
                current_user = get_current_user()
                username = current_user.get('username', 'anonymous') if current_user else 'anonymous'
                
                import scan_progress_store
                results = scan_progress_store.get_scan_results(scan_id)
                if results:
                    # éªŒè¯ç»“æœæ˜¯å¦å±äºå½“å‰ç”¨æˆ·ï¼ˆä»è¿›åº¦ä¸­è·å–ç”¨æˆ·åï¼‰
                    progress = scan_progress_store.get_scan_progress(scan_id)
                    if progress:
                        progress_username = progress.get('username', 'anonymous')
                        if progress_username != username:
                            print(f"[get_scan_results] âš ï¸ ç”¨æˆ· {username} å°è¯•è®¿é—®å…¶ä»–ç”¨æˆ· {progress_username} çš„æ‰«æç»“æœ: {scan_id}")
                            return jsonify({
                                'success': False,
                                'message': 'æ— æƒè®¿é—®æ­¤æ‰«æç»“æœï¼ˆä¸å±äºå½“å‰ç”¨æˆ·ï¼‰',
                                'error_code': 'ACCESS_DENIED',
                                'candidates': []
                            }), 403
                    
                    return jsonify({
                        'success': True,
                        'message': results.get('message', 'æ‰«æå®Œæˆ'),
                        'candidates': results.get('candidates', []),
                        'found_count': results.get('found_count', 0),
                        'total_scanned': results.get('total_scanned', 0),
                        'scan_id': scan_id
                    })
                else:
                    # å¦‚æœæ‰¾ä¸åˆ°ç»“æœï¼Œå°è¯•ä»è¿›åº¦ä¸­è·å–å€™é€‰è‚¡ç¥¨
                    progress = scan_progress_store.get_scan_progress(scan_id)
                    if progress:
                        # éªŒè¯è¿›åº¦æ˜¯å¦å±äºå½“å‰ç”¨æˆ·
                        progress_username = progress.get('username', 'anonymous')
                        if progress_username != username:
                            print(f"[get_scan_results] âš ï¸ ç”¨æˆ· {username} å°è¯•è®¿é—®å…¶ä»–ç”¨æˆ· {progress_username} çš„æ‰«æè¿›åº¦: {scan_id}")
                            return jsonify({
                                'success': False,
                                'message': 'æ— æƒè®¿é—®æ­¤æ‰«æè¿›åº¦ï¼ˆä¸å±äºå½“å‰ç”¨æˆ·ï¼‰',
                                'error_code': 'ACCESS_DENIED',
                                'candidates': []
                            }), 403
                        
                        if progress.get('candidates'):
                            return jsonify({
                                'success': True,
                                'message': 'æ‰«æè¿›è¡Œä¸­ï¼Œè¿”å›å½“å‰å·²æ‰¾åˆ°çš„è‚¡ç¥¨',
                                'candidates': progress.get('candidates', []),
                                'found_count': len(progress.get('candidates', [])),
                                'total_scanned': progress.get('current', 0),
                                'scan_id': scan_id
                            })
            
            return jsonify({
                'success': False,
                'message': 'æœªæä¾› scan_id æˆ–æ‰¾ä¸åˆ°æ‰«æç»“æœ',
                'candidates': []
            })
        
        # æœ¬åœ°ç¯å¢ƒï¼šä» analyzer è·å–ç»“æœ
        scan_results = getattr(analyzer, 'scan_results', None)
        
        # å¦‚æœscan_resultsä¸ºç©ºï¼Œå°è¯•ä»progressä¸­è·å–candidates
        if scan_results is None:
            progress = analyzer.get_progress() if hasattr(analyzer, 'get_progress') else {}
            if progress and progress.get('candidates'):
                # ä»è¿›åº¦ä¸­æ„å»ºç»“æœ
                candidates = progress.get('candidates', [])
                scan_results = {
                    'success': True,
                    'message': 'æ‰«æå®Œæˆ',
                    'candidates': candidates,
                    'found_count': len(candidates),
                    'total_scanned': progress.get('current', progress.get('total', 0))
                }
            else:
                return jsonify({
                    'success': False,
                    'message': 'å°šæœªå¼€å§‹æ‰«ææˆ–æ‰«ææœªå®Œæˆ',
                    'candidates': []
                })
        
        # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„æ ¼å¼
        if scan_results.get('candidates'):
            for candidate in scan_results['candidates']:
                # ç¡®ä¿æ‰€æœ‰æ•°å€¼éƒ½æ˜¯å¯åºåˆ—åŒ–çš„
                if 'ç‰¹å¾' in candidate:
                    features = candidate['ç‰¹å¾']
                    for key, value in list(features.items()):
                        if isinstance(value, (np.integer, np.int64, np.int32)):
                            features[key] = int(value)
                        elif isinstance(value, (np.floating, np.float64, np.float32)):
                            features[key] = float(value) if not pd.isna(value) else None
                        elif pd.isna(value):
                            features[key] = None
                
                if 'æ ¸å¿ƒç‰¹å¾åŒ¹é…' in candidate:
                    core_match = candidate['æ ¸å¿ƒç‰¹å¾åŒ¹é…']
                    for key, value in list(core_match.items()):
                        if isinstance(value, (np.integer, np.int64, np.int32)):
                            core_match[key] = int(value)
                        elif isinstance(value, (np.floating, np.float64, np.float32)):
                            core_match[key] = float(value) if not pd.isna(value) else None
                        elif pd.isna(value):
                            core_match[key] = None
        
        return jsonify(scan_results)
        
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"è·å–æ‰«æç»“æœé”™è¯¯: {error_detail}")
        return jsonify({
            'success': False,
            'message': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}'
        }), 500


@app.route('/api/get_free_user_scan_results', methods=['GET'])
@require_login
def get_free_user_scan_results():
    """è·å–å…è´¹ç”¨æˆ·çš„æ‰«æç»“æœï¼ˆæ ¹æ®å½“å‰æ—¶é—´è‡ªåŠ¨é€‰æ‹©ï¼‰"""
    try:
        # è·å–ç”¨æˆ·ä¿¡æ¯å’Œç­‰çº§
        user = get_current_user()
        if not user:
            return jsonify({
                'success': False,
                'message': 'è¯·å…ˆç™»å½•',
                'results': []
            }), 401
        
        user_tier = get_user_tier()
        
        # åªæœ‰å…è´¹ç”¨æˆ·å¯ä»¥æŸ¥çœ‹æ­¤æ¥å£
        if user_tier != 'free':
            return jsonify({
                'success': False,
                'message': 'æ­¤æ¥å£ä»…é™å…è´¹ç”¨æˆ·ä½¿ç”¨',
                'results': []
            }), 403
        
        # è·å–åŒ—äº¬æ—¶é—´
        from scan_limit_helper import get_beijing_time
        from datetime import timedelta
        import scan_progress_store
        
        beijing_now = get_beijing_time()
        current_hour = beijing_now.hour
        current_date = beijing_now.strftime('%Y-%m-%d')
        
        results = []
        
        # å¦‚æœ12ç‚¹å‰è¿›å…¥ï¼Œæ˜¾ç¤ºæ˜¨å¤©ä¸‹åˆå’Œä¸­åˆçš„ç»“æœ
        # å¦‚æœ12ç‚¹åè¿›å…¥ï¼Œæ˜¾ç¤ºå½“å¤©ä¸­åˆå’Œå‰ä¸€å¤©ä¸‹åˆçš„ç»“æœ
        if current_hour < 12:
            # 12ç‚¹å‰ï¼šæ˜¾ç¤ºæ˜¨å¤©ä¸‹åˆå’Œä¸­åˆçš„ç»“æœ
            yesterday = (beijing_now - timedelta(days=1)).strftime('%Y-%m-%d')
            
            # è·å–æ˜¨å¤©ä¸‹åˆçš„æ‰«æç»“æœ
            afternoon_result = scan_progress_store.get_global_scan_results('afternoon', yesterday)
            if afternoon_result:
                results.append({
                    'scan_type': 'afternoon',
                    'scan_date': yesterday,
                    'scan_time': '15:00',
                    'title': f'{yesterday} ä¸‹åˆ3:00æ‰«æç»“æœ',
                    'result': afternoon_result
                })
            
            # è·å–æ˜¨å¤©ä¸­åˆçš„æ‰«æç»“æœ
            noon_result = scan_progress_store.get_global_scan_results('noon', yesterday)
            if noon_result:
                results.append({
                    'scan_type': 'noon',
                    'scan_date': yesterday,
                    'scan_time': '11:30',
                    'title': f'{yesterday} ä¸­åˆ11:30æ‰«æç»“æœ',
                    'result': noon_result
                })
        else:
            # 12ç‚¹åï¼šæ˜¾ç¤ºå½“å¤©ä¸­åˆå’Œå‰ä¸€å¤©ä¸‹åˆçš„ç»“æœ
            # è·å–å½“å¤©ä¸­åˆçš„æ‰«æç»“æœ
            noon_result = scan_progress_store.get_global_scan_results('noon', current_date)
            if noon_result:
                results.append({
                    'scan_type': 'noon',
                    'scan_date': current_date,
                    'scan_time': '11:30',
                    'title': f'{current_date} ä¸­åˆ11:30æ‰«æç»“æœ',
                    'result': noon_result
                })
            
            # è·å–å‰ä¸€å¤©ä¸‹åˆçš„æ‰«æç»“æœ
            yesterday = (beijing_now - timedelta(days=1)).strftime('%Y-%m-%d')
            afternoon_result = scan_progress_store.get_global_scan_results('afternoon', yesterday)
            if afternoon_result:
                results.append({
                    'scan_type': 'afternoon',
                    'scan_date': yesterday,
                    'scan_time': '15:00',
                    'title': f'{yesterday} ä¸‹åˆ3:00æ‰«æç»“æœ',
                    'result': afternoon_result
                })
        
        return jsonify({
            'success': True,
            'message': f'æ‰¾åˆ° {len(results)} ç»„æ‰«æç»“æœ',
            'results': results,
            'current_time': beijing_now.strftime('%Y-%m-%d %H:%M:%S')
        })
        
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"è·å–å…è´¹ç”¨æˆ·æ‰«æç»“æœé”™è¯¯: {error_detail}")
        return jsonify({
            'success': False,
            'message': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}',
            'results': []
        }), 500


@app.route('/api/scan_v2', methods=['POST'])
@require_login
def scan_v2():
    """ä½¿ç”¨V2æ¨¡å‹æ‰«æå¤§ç‰›è‚¡API"""
    try:
        init_v2_model()  # ç¡®ä¿V2æ¨¡å‹å·²åˆå§‹åŒ–
        
        if v2_model is None or not v2_model.feature_template:
            return jsonify({
                'success': False,
                'message': 'V2æ¨¡å‹æœªåˆå§‹åŒ–æˆ–æœªè®­ç»ƒ'
            }), 500
        
        data = request.get_json() or {}
        min_match_score = float(data.get('min_match_score', 0.90))
        min_bottom_score = int(data.get('min_bottom_score', 2))
        min_launch_score = int(data.get('min_launch_score', 2))
        limit = int(data.get('limit', 20))
        
        print(f"\nğŸš€ V2æ¨¡å‹æ‰«æå¼€å§‹...")
        print(f"   åŒ¹é…åº¦é˜ˆå€¼: {min_match_score}")
        print(f"   åº•éƒ¨è“„åŠ¿å¾—åˆ†é˜ˆå€¼: {min_bottom_score}")
        print(f"   å¯åŠ¨ä¿¡å·å¾—åˆ†é˜ˆå€¼: {min_launch_score}")
        
        # åŠ è½½è‚¡ç¥¨åˆ—è¡¨
        cache_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'cache')
        stock_list_path = os.path.join(cache_dir, 'stock_list_all.json')
        
        if not os.path.exists(stock_list_path):
            return jsonify({
                'success': False,
                'message': 'è‚¡ç¥¨åˆ—è¡¨ç¼“å­˜ä¸å­˜åœ¨'
            }), 500
        
        with open(stock_list_path, 'r', encoding='utf-8') as f:
            stock_list = json.load(f)
        
        candidates = []
        weekly_cache_dir = os.path.join(cache_dir, 'weekly_kline')
        
        for stock_info in stock_list:
            code = stock_info.get('code', '')
            name = stock_info.get('name', '')
            
            # æ’é™¤STå’ŒåŒ—äº¤æ‰€
            if 'ST' in name.upper() or code.startswith('8') or code.startswith('9'):
                continue
            
            csv_path = os.path.join(weekly_cache_dir, f'{code}.csv')
            if not os.path.exists(csv_path):
                continue
            
            try:
                weekly_df = pd.read_csv(csv_path)
                if len(weekly_df) < 50:
                    continue
                
                idx = len(weekly_df) - 1
                volume_col = 'å‘¨æˆäº¤é‡' if 'å‘¨æˆäº¤é‡' in weekly_df.columns else 'æˆäº¤é‡'
                
                features = v2_model.extract_features(weekly_df, idx, volume_col)
                
                if features:
                    score = v2_model.calculate_score(features)
                    bottom = features.get('åº•éƒ¨è“„åŠ¿å¾—åˆ†', 0)
                    launch = features.get('å¯åŠ¨ä¿¡å·å¾—åˆ†', 0)
                    
                    if score >= min_match_score and bottom >= min_bottom_score and launch >= min_launch_score:
                        candidates.append({
                            'ä»£ç ': code,
                            'åç§°': name,
                            'åŒ¹é…åº¦': round(score, 3),
                            'ä»·æ ¼': round(weekly_df['æ”¶ç›˜'].iloc[idx], 2),
                            'åº•éƒ¨å¾—åˆ†': bottom,
                            'å¯åŠ¨å¾—åˆ†': launch,
                            'å‡çº¿å¤šå¤´': features.get('å‡çº¿å¤šå¤´', 0),
                            'OBVè¶‹åŠ¿': round(features.get('OBVè¶‹åŠ¿', 0), 2),
                            'è¿‘æœŸé‡‘å‰': features.get('è¿‘æœŸé‡‘å‰', 0),
                            'çªç ´20å‘¨é«˜ç‚¹': features.get('çªç ´20å‘¨é«˜ç‚¹', 0),
                            'å½“å‘¨é‡æ¯”': round(features.get('å½“å‘¨é‡æ¯”', 0), 2),
                        })
            except Exception:
                continue
        
        # æŒ‰ç»¼åˆå¾—åˆ†æ’åº
        candidates.sort(key=lambda x: (x['åº•éƒ¨å¾—åˆ†'] + x['å¯åŠ¨å¾—åˆ†'], x['åŒ¹é…åº¦']), reverse=True)
        top_candidates = candidates[:limit]
        
        print(f"âœ… V2æ‰«æå®Œæˆ: æ‰¾åˆ° {len(candidates)} åªå€™é€‰ï¼Œè¿”å›å‰ {len(top_candidates)} åª")
        
        return jsonify({
            'success': True,
            'message': f'æ‰¾åˆ° {len(candidates)} åªç¬¦åˆæ¡ä»¶çš„ä¸ªè‚¡',
            'total': len(candidates),
            'candidates': top_candidates,
            'model_info': {
                'model_type': 'bull_stock_v2',
                'feature_count': len(v2_model.feature_template),
                'sample_stocks': v2_model.sample_stocks
            }
        })
        
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"V2æ‰«æé”™è¯¯: {error_detail}")
        return jsonify({
            'success': False,
            'message': f'æ‰«æå¤±è´¥: {str(e)}'
        }), 500


@app.route('/api/scan_reversal_stocks', methods=['POST'])
@require_login
def scan_reversal_stocks():
    """æœç´¢ä¸Šå‘¨é˜´çº¿+æœ¬å‘¨é˜³çº¿çš„åè½¬ä¸ªè‚¡API"""
    init_analyzer()  # ç¡®ä¿åˆ†æå™¨å·²åˆå§‹åŒ–
    try:
        # è·å–è¯·æ±‚å‚æ•°
        data = request.get_json() or {}
        market_cap_max = float(data.get('market_cap_max', 100.0))  # é»˜è®¤100äº¿
        
        # åœ¨åå°çº¿ç¨‹ä¸­æ‰§è¡Œæ‰«æï¼ˆé¿å…é˜»å¡ï¼‰
        import threading
        
        def run_reversal_scan():
            try:
                print(f"\nğŸ” å¼€å§‹æœç´¢ï¼šä¸Šå‘¨é˜´çº¿+æœ¬å‘¨é˜³çº¿çš„åè½¬ä¸ªè‚¡ï¼ˆå¸‚å€¼ < {market_cap_max}äº¿å…ƒï¼‰...")
                
                # è·å–æ‰€æœ‰è‚¡ç¥¨åˆ—è¡¨
                stock_list = analyzer.fetcher.get_all_stocks()
                if stock_list is None or len(stock_list) == 0:
                    analyzer.reversal_scan_results = {
                        'success': False,
                        'message': 'æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨',
                        'stocks': []
                    }
                    return
                
                total_stocks = len(stock_list)
                candidates = []
                
                # æ›´æ–°è¿›åº¦
                analyzer.progress = {
                    'type': 'reversal_scan',
                    'current': 0,
                    'total': total_stocks,
                    'status': 'è¿›è¡Œä¸­',
                    'detail': 'å¼€å§‹æœç´¢åè½¬ä¸ªè‚¡...',
                    'percentage': 0,
                    'found': 0
                }
                
                import time as time_module
                for idx, (_, row) in enumerate(stock_list.iterrows(), 1):
                    # æ£€æŸ¥æ˜¯å¦è¢«åœæ­¢
                    if hasattr(analyzer, 'stop_scan') and analyzer.stop_scan:
                        analyzer.progress['status'] = 'å·²åœæ­¢'
                        break
                    
                    stock_code = str(row['code']) if 'code' in row else str(row.iloc[0])
                    stock_name = str(row['name']) if 'name' in row else stock_code
                    
                    # æ›´æ–°è¿›åº¦
                    if idx % 10 == 0 or idx == total_stocks:
                        percentage = (idx / total_stocks) * 100
                        analyzer.progress['current'] = idx
                        analyzer.progress['percentage'] = round(percentage, 1)
                        analyzer.progress['detail'] = f'æ­£åœ¨æ‰«æ {stock_code} {stock_name}... ({idx}/{total_stocks}) | å·²æ‰¾åˆ°: {len(candidates)} åª'
                        analyzer.progress['found'] = len(candidates)
                        analyzer.progress['last_update_time'] = time_module.time()
                        print(f"[è¿›åº¦] {percentage:.1f}% - {idx}/{total_stocks} - å·²æ‰¾åˆ°: {len(candidates)} åª")
                    
                    try:
                        # è·å–å‘¨Kçº¿æ•°æ®ï¼ˆè‡³å°‘éœ€è¦5å‘¨ä»¥è®¡ç®—5å‘¨å‡çº¿ï¼‰
                        weekly_df = analyzer.fetcher.get_weekly_kline(stock_code, period="3m")
                        if weekly_df is None or len(weekly_df) < 5:
                            continue
                        
                        # è·å–æœ€æ–°ä¸¤å‘¨çš„æ•°æ®
                        last_week = weekly_df.iloc[-2]  # ä¸Šå‘¨
                        this_week = weekly_df.iloc[-1]  # æœ¬å‘¨
                        
                        # åˆ¤æ–­ä¸Šå‘¨æ˜¯å¦ä¸ºé˜´çº¿ï¼ˆæ”¶ç›˜ä»· < å¼€ç›˜ä»·ï¼‰
                        last_week_open = float(last_week.get('å¼€ç›˜', 0))
                        last_week_close = float(last_week.get('æ”¶ç›˜', 0))
                        last_week_is_negative = last_week_close < last_week_open
                        
                        # åˆ¤æ–­æœ¬å‘¨æ˜¯å¦ä¸ºé˜³çº¿ï¼ˆæ”¶ç›˜ä»· > å¼€ç›˜ä»·ï¼‰
                        this_week_open = float(this_week.get('å¼€ç›˜', 0))
                        this_week_close = float(this_week.get('æ”¶ç›˜', 0))
                        this_week_is_positive = this_week_close > this_week_open
                        
                        # åˆ¤æ–­æ˜¯å¦æ­¢è·Œï¼ˆæœ¬å‘¨æ”¶ç›˜ä»· >= ä¸Šå‘¨æ”¶ç›˜ä»·ï¼Œæˆ–è€…æœ¬å‘¨æ¶¨å¹… > 0ï¼‰
                        this_week_change = float(this_week.get('æ¶¨è·Œå¹…', 0))
                        is_reversal = this_week_close >= last_week_close or this_week_change > 0
                        
                        # è®¡ç®—5å‘¨å‡çº¿ï¼ˆMA5ï¼‰
                        ma5_series = TechnicalAnalysis.calculate_ma(weekly_df, period=5)
                        if ma5_series is None or len(ma5_series) == 0:
                            continue
                        
                        # è·å–æœ¬å‘¨çš„5å‘¨å‡çº¿å€¼
                        ma5_value = ma5_series.iloc[-1]
                        if pd.isna(ma5_value) or ma5_value <= 0:
                            continue
                        
                        # åˆ¤æ–­æœ¬å‘¨æ”¶ç›˜ä»·æ˜¯å¦åœ¨5å‘¨å‡çº¿ä¹‹ä¸Š
                        price_above_ma5 = this_week_close > ma5_value
                        
                        # å¦‚æœä¸Šå‘¨æ˜¯é˜´çº¿ï¼Œæœ¬å‘¨æ˜¯é˜³çº¿ï¼Œä¸”æ­¢è·Œï¼Œä¸”è‚¡ä»·åœ¨5å‘¨å‡çº¿ä¹‹ä¸Šï¼Œåˆ™æ£€æŸ¥å¸‚å€¼
                        if last_week_is_negative and this_week_is_positive and is_reversal and price_above_ma5:
                            # æ£€æŸ¥å¸‚å€¼ï¼ˆå¸‚å€¼ < market_cap_maxäº¿ï¼‰
                            # ä½¿ç”¨çº¿ç¨‹å’Œè¶…æ—¶æœºåˆ¶ï¼Œé¿å…é˜»å¡
                            import threading
                            market_cap_result = [None]
                            
                            def fetch_market_cap():
                                try:
                                    market_cap_result[0] = analyzer.fetcher.get_market_cap(stock_code, timeout=2)
                                except Exception:
                                    pass  # é™é»˜å¤±è´¥
                            
                            cap_thread = threading.Thread(target=fetch_market_cap)
                            cap_thread.daemon = True
                            cap_thread.start()
                            cap_thread.join(timeout=2.5)  # æœ€å¤šç­‰å¾…2.5ç§’ï¼Œç»™è¶³å¤Ÿæ—¶é—´è·å–å¸‚å€¼
                            
                            market_cap = None
                            if not cap_thread.is_alive():
                                market_cap = market_cap_result[0]
                            
                            # å¦‚æœå¸‚å€¼è·å–å¤±è´¥æˆ–è¶…æ—¶ï¼Œè·³è¿‡è¯¥è‚¡ç¥¨ï¼ˆæ— æ³•ç¡®è®¤æ˜¯å¦ç¬¦åˆæ¡ä»¶ï¼‰
                            if market_cap is None:
                                continue  # å¸‚å€¼è·å–å¤±è´¥ï¼Œè·³è¿‡
                            
                            # å¦‚æœå¸‚å€¼è·å–æˆåŠŸä¸” >= market_cap_maxï¼Œè·³è¿‡
                            if market_cap >= market_cap_max:
                                continue  # å¸‚å€¼ >= market_cap_maxï¼Œè·³è¿‡
                            
                            last_week_date = str(last_week.get('æ—¥æœŸ', ''))
                            this_week_date = str(this_week.get('æ—¥æœŸ', ''))
                            
                            # è®¡ç®—æ¶¨å¹…
                            last_week_change = float(last_week.get('æ¶¨è·Œå¹…', 0))
                            this_week_change = float(this_week.get('æ¶¨è·Œå¹…', 0))
                            
                            # è®¡ç®—ä»·æ ¼ç›¸å¯¹MA5çš„ç™¾åˆ†æ¯”
                            price_to_ma5_ratio = (this_week_close - ma5_value) / ma5_value * 100
                            
                            # åªæœ‰å¸‚å€¼è·å–æˆåŠŸä¸”å°äºmarket_cap_maxçš„è‚¡ç¥¨æ‰ä¼šè¢«åŠ å…¥ç»“æœ
                            candidates.append({
                                'è‚¡ç¥¨ä»£ç ': stock_code,
                                'è‚¡ç¥¨åç§°': stock_name,
                                'ä¸Šå‘¨æ—¥æœŸ': last_week_date,
                                'ä¸Šå‘¨å¼€ç›˜': round(last_week_open, 2),
                                'ä¸Šå‘¨æ”¶ç›˜': round(last_week_close, 2),
                                'ä¸Šå‘¨æ¶¨è·Œå¹…': round(last_week_change, 2),
                                'æœ¬å‘¨æ—¥æœŸ': this_week_date,
                                'æœ¬å‘¨å¼€ç›˜': round(this_week_open, 2),
                                'æœ¬å‘¨æ”¶ç›˜': round(this_week_close, 2),
                                'æœ¬å‘¨æ¶¨è·Œå¹…': round(this_week_change, 2),
                                'å½“å‰ä»·æ ¼': round(this_week_close, 2),
                                '5å‘¨å‡çº¿': round(ma5_value, 2),
                                'ä»·æ ¼ç›¸å¯¹MA5': round(price_to_ma5_ratio, 2),
                                'å¸‚å€¼': round(market_cap, 2)  # æ­¤æ—¶market_capä¸€å®šä¸ä¸ºNone
                            })
                            
                            print(f"âœ… æ‰¾åˆ°åè½¬ä¸ªè‚¡: {stock_code} {stock_name} (ä¸Šå‘¨: {last_week_change:.2f}%, æœ¬å‘¨: {this_week_change:.2f}%, MA5: {ma5_value:.2f}, ä»·æ ¼ç›¸å¯¹MA5: {price_to_ma5_ratio:.2f}%, å¸‚å€¼: {market_cap:.2f}äº¿)")
                    
                    except Exception as e:
                        # å•ä¸ªè‚¡ç¥¨å‡ºé”™ï¼Œç»§ç»­æ‰«æä¸‹ä¸€ä¸ª
                        if idx % 100 == 0:
                            print(f"âš ï¸ {stock_code} æ‰«æå‡ºé”™: {str(e)[:50]}")
                        continue
                
                # æ‰«æå®Œæˆ
                analyzer.reversal_scan_results = {
                    'success': True,
                    'message': f'æ‰«æå®Œæˆï¼Œæ‰¾åˆ° {len(candidates)} åªåè½¬ä¸ªè‚¡',
                    'stocks': candidates,
                    'total_scanned': total_stocks,
                    'found_count': len(candidates),
                    'market_cap_max': market_cap_max,
                    'conditions': {
                        'ä¸Šå‘¨é˜´çº¿': 'æ”¶ç›˜ä»· < å¼€ç›˜ä»·',
                        'æœ¬å‘¨é˜³çº¿': 'æ”¶ç›˜ä»· > å¼€ç›˜ä»·',
                        'æœ¬å‘¨æ­¢è·Œ': 'æœ¬å‘¨æ”¶ç›˜ä»· â‰¥ ä¸Šå‘¨æ”¶ç›˜ä»·ï¼Œæˆ–æœ¬å‘¨æ¶¨å¹… > 0',
                        'è‚¡ä»·åœ¨MA5ä¹‹ä¸Š': 'å½“å‰ä»·æ ¼ > 5å‘¨å‡çº¿',
                        'å¸‚å€¼é™åˆ¶': f'å¸‚å€¼ < {market_cap_max}äº¿å…ƒ'
                    }
                }
                
                # æ›´æ–°è¿›åº¦ä¸ºå®Œæˆ
                analyzer.progress['status'] = 'å®Œæˆ'
                analyzer.progress['percentage'] = 100.0
                analyzer.progress['current'] = total_stocks
                analyzer.progress['found'] = len(candidates)
                analyzer.progress['detail'] = f'æ‰«æå®Œæˆ: æ‰¾åˆ° {len(candidates)} åªåè½¬ä¸ªè‚¡'
                analyzer.progress['last_update_time'] = time_module.time()
                
                print(f"\nâœ… åè½¬ä¸ªè‚¡æ‰«æå®Œæˆï¼æ‰¾åˆ° {len(candidates)} åªç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨")
                
            except Exception as e:
                import traceback
                error_detail = traceback.format_exc()
                print(f"åè½¬ä¸ªè‚¡æ‰«æè¿‡ç¨‹å‡ºé”™: {error_detail}")
                analyzer.reversal_scan_results = {
                    'success': False,
                    'message': f'æ‰«æå‡ºé”™: {str(e)}',
                    'stocks': []
                }
                analyzer.progress['status'] = 'å¤±è´¥'
                analyzer.progress['detail'] = f'æ‰«æå‡ºé”™: {str(e)[:50]}'
        
        # å¯åŠ¨æ‰«æçº¿ç¨‹
        scan_thread = threading.Thread(target=run_reversal_scan)
        scan_thread.daemon = True
        scan_thread.start()
        
        return jsonify({
            'success': True,
            'message': 'åè½¬ä¸ªè‚¡æ‰«æå·²å¼€å§‹ï¼Œè¯·é€šè¿‡è¿›åº¦APIæŸ¥çœ‹è¿›åº¦'
        })
        
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"åè½¬ä¸ªè‚¡æ‰«æé”™è¯¯: {error_detail}")
        return jsonify({
            'success': False,
            'message': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}'
        }), 500


@app.route('/api/get_reversal_scan_results', methods=['GET'])
@require_login
def get_reversal_scan_results():
    """è·å–åè½¬ä¸ªè‚¡æ‰«æç»“æœAPI"""
    try:
        init_analyzer()  # ç¡®ä¿åˆ†æå™¨å·²åˆå§‹åŒ–
        results = getattr(analyzer, 'reversal_scan_results', None)
        
        if results is None:
            return jsonify({
                'success': False,
                'message': 'æš‚æ— æ‰«æç»“æœ',
                'stocks': []
            })
        
        return jsonify(results)
        
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"è·å–åè½¬ä¸ªè‚¡æ‰«æç»“æœé”™è¯¯: {error_detail}")
        return jsonify({
            'success': False,
            'message': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}',
            'stocks': []
        }), 500

@app.route('/api/export_scan_results', methods=['POST'])
@require_login
def export_scan_results():
    """å¯¼å‡ºæ‰«æç»“æœAPIï¼ˆæ”¯æŒExcel/CSV/JSONæ ¼å¼ï¼‰- VIPä¸“äº«åŠŸèƒ½"""
    try:
        import pandas as pd
        import json as json_module
        from datetime import datetime
        import io
        
        # è·å–ç”¨æˆ·ä¿¡æ¯å’Œç­‰çº§
        user = get_current_user()
        if not user:
            return jsonify({
                'success': False,
                'message': 'è¯·å…ˆç™»å½•'
            }), 401
        
        user_tier = get_user_tier()
        
        # æ£€æŸ¥ç”¨æˆ·ç­‰çº§ï¼ˆä»…VIPå’Œè¶…çº§ç”¨æˆ·å¯ä»¥å¯¼å‡ºï¼‰
        if user_tier != 'premium' and user_tier != 'super':
            is_super = user.get('is_super', False)
            if not is_super:
                return jsonify({
                    'success': False,
                    'message': 'å¯¼å‡ºåŠŸèƒ½ä»…é™VIPç”¨æˆ·ä½¿ç”¨ï¼Œè¯·å‡çº§ä¸ºVIPä¼šå‘˜'
                }), 403
        
        data = request.get_json() or {}
        
        # è·å–å‚æ•°
        export_format = data.get('format', 'excel').lower()  # excel, csv, json
        scan_id = data.get('scan_id') or request.args.get('scan_id')
        candidates = data.get('candidates', [])
        
        # å¦‚æœæ²¡æœ‰æä¾›candidatesï¼Œå°è¯•ä»scan_idè·å–
        if not candidates and scan_id and is_vercel:
            import scan_progress_store
            results = scan_progress_store.get_scan_results(scan_id)
            if results:
                candidates = results.get('candidates', [])
        
        # å¦‚æœè¿˜æ˜¯æ²¡æœ‰æ•°æ®ï¼Œè¿”å›é”™è¯¯
        if not candidates:
            return jsonify({
                'success': False,
                'message': 'æ²¡æœ‰å¯å¯¼å‡ºçš„æ•°æ®ï¼Œè¯·å…ˆæ‰«æè‚¡ç¥¨æˆ–æä¾›æ‰«æç»“æœ'
            }), 400
        
        # è½¬æ¢ä¸ºDataFrameï¼ˆå¤„ç†ä¸åŒçš„æ•°æ®æ ¼å¼ï¼‰
        df_data = []
        for candidate in candidates:
            # å¤„ç†ä¸¤ç§æ•°æ®æ ¼å¼ï¼š{'code': '...', 'name': '...'} æˆ– {'è‚¡ç¥¨ä»£ç ': '...', 'è‚¡ç¥¨åç§°': '...'}
            row = {
                'è‚¡ç¥¨ä»£ç ': candidate.get('code') or candidate.get('è‚¡ç¥¨ä»£ç ', ''),
                'è‚¡ç¥¨åç§°': candidate.get('name') or candidate.get('è‚¡ç¥¨åç§°', ''),
                'åŒ¹é…åº¦': float(candidate.get('match_score') or candidate.get('åŒ¹é…åº¦') or 0),
                'ä¹°ç‚¹ä»·æ ¼': float(candidate.get('buy_price') or candidate.get('ä¹°ç‚¹ä»·æ ¼') or candidate.get('æœ€ä½³ä¹°ç‚¹ä»·æ ¼') or 0),
                'ä¹°ç‚¹æ—¥æœŸ': candidate.get('buy_date') or candidate.get('ä¹°ç‚¹æ—¥æœŸ') or candidate.get('æœ€ä½³ä¹°ç‚¹æ—¥æœŸ') or '',
                'å½“å‰ä»·æ ¼': float(candidate.get('current_price') or candidate.get('å½“å‰ä»·æ ¼') or 0),
                'å¸‚å€¼(äº¿)': float(candidate.get('market_cap') or candidate.get('å¸‚å€¼') or candidate.get('å¸‚å€¼(äº¿)') or 0),
            }
            
            # å¯é€‰å­—æ®µ
            if candidate.get('gain_4w') is not None or candidate.get('4å‘¨æ¶¨å¹…') is not None:
                row['4å‘¨æ¶¨å¹…(%)'] = float(candidate.get('gain_4w') or candidate.get('4å‘¨æ¶¨å¹…') or 0)
            if candidate.get('gain_10w') is not None or candidate.get('10å‘¨æ¶¨å¹…') is not None:
                row['10å‘¨æ¶¨å¹…(%)'] = float(candidate.get('gain_10w') or candidate.get('10å‘¨æ¶¨å¹…') or 0)
            if candidate.get('gain_20w') is not None or candidate.get('20å‘¨æ¶¨å¹…') is not None:
                row['20å‘¨æ¶¨å¹…(%)'] = float(candidate.get('gain_20w') or candidate.get('20å‘¨æ¶¨å¹…') or 0)
            if candidate.get('max_gain_10w') is not None or candidate.get('æœ€å¤§æ¶¨å¹…') is not None:
                row['æœ€å¤§æ¶¨å¹…(%)'] = float(candidate.get('max_gain_10w') or candidate.get('æœ€å¤§æ¶¨å¹…') or 0)
            if candidate.get('stop_loss_price') is not None or candidate.get('æ­¢æŸä»·æ ¼') is not None:
                row['æ­¢æŸä»·æ ¼'] = float(candidate.get('stop_loss_price') or candidate.get('æ­¢æŸä»·æ ¼') or 0)
            if candidate.get('best_sell_price') is not None or candidate.get('æœ€ä½³å–ç‚¹ä»·æ ¼') is not None:
                row['æœ€ä½³å–ç‚¹ä»·æ ¼'] = float(candidate.get('best_sell_price') or candidate.get('æœ€ä½³å–ç‚¹ä»·æ ¼') or 0)
            if candidate.get('best_sell_date') is not None or candidate.get('æœ€ä½³å–ç‚¹æ—¥æœŸ') is not None:
                row['æœ€ä½³å–ç‚¹æ—¥æœŸ'] = candidate.get('best_sell_date') or candidate.get('æœ€ä½³å–ç‚¹æ—¥æœŸ') or ''
            
            df_data.append(row)
        
        df = pd.DataFrame(df_data)
        
        # æŒ‰åŒ¹é…åº¦æ’åº
        if 'åŒ¹é…åº¦' in df.columns and len(df) > 0:
            df = df.sort_values('åŒ¹é…åº¦', ascending=False)
        
        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        if export_format == 'excel':
            # Excelæ ¼å¼
            filename = f'æ‰«æç»“æœ_{timestamp}.xlsx'
            output = io.BytesIO()
            
            # ä½¿ç”¨openpyxlå¼•æ“
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                df.to_excel(writer, index=False, sheet_name='æ‰«æç»“æœ')
            
            output.seek(0)
            
            return send_file(
                output,
                mimetype='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
                as_attachment=True,
                download_name=filename
            )
            
        elif export_format == 'csv':
            # CSVæ ¼å¼
            filename = f'æ‰«æç»“æœ_{timestamp}.csv'
            output = io.StringIO()
            df.to_csv(output, index=False, encoding='utf-8-sig')  # utf-8-sigç”¨äºExcelæ­£ç¡®è¯†åˆ«ä¸­æ–‡
            csv_content = output.getvalue()
            output.close()
            
            # åˆ›å»ºBytesIOå¯¹è±¡
            output_bytes = io.BytesIO()
            output_bytes.write(csv_content.encode('utf-8-sig'))
            output_bytes.seek(0)
            
            return send_file(
                output_bytes,
                mimetype='text/csv; charset=utf-8',
                as_attachment=True,
                download_name=filename
            )
            
        elif export_format == 'json':
            # JSONæ ¼å¼
            filename = f'æ‰«æç»“æœ_{timestamp}.json'
            output = io.BytesIO()
            
            # è½¬æ¢ä¸ºJSONï¼ˆç¡®ä¿å¯ä»¥åºåˆ—åŒ–ï¼‰
            json_data = df.to_dict(orient='records')
            json_str = json_module.dumps(json_data, ensure_ascii=False, indent=2, default=str)
            output.write(json_str.encode('utf-8'))
            output.seek(0)
            
            return send_file(
                output,
                mimetype='application/json; charset=utf-8',
                as_attachment=True,
                download_name=filename
            )
        else:
            return jsonify({
                'success': False,
                'message': f'ä¸æ”¯æŒçš„å¯¼å‡ºæ ¼å¼: {export_format}ï¼Œæ”¯æŒæ ¼å¼: excel, csv, json'
            }), 400
            
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"å¯¼å‡ºæ‰«æç»“æœé”™è¯¯: {error_detail}")
        return jsonify({
            'success': False,
            'message': f'å¯¼å‡ºå¤±è´¥: {str(e)}'
        }), 500


@app.route('/api/get_vip_scan_history', methods=['GET'])
@require_login
def get_vip_scan_history():
    """è·å–VIPç”¨æˆ·æ‰«æå†å²è®°å½•ï¼ˆ30å¤©ï¼‰- VIPä¸“äº«åŠŸèƒ½"""
    try:
        import json as json_module
        from scan_limit_helper import get_beijing_time
        from datetime import timedelta
        import scan_progress_store
        
        # è·å–ç”¨æˆ·ä¿¡æ¯å’Œç­‰çº§
        user = get_current_user()
        if not user:
            return jsonify({
                'success': False,
                'message': 'è¯·å…ˆç™»å½•'
            }), 401
        
        user_tier = get_user_tier()
        username = user.get('username', 'anonymous')
        
        # æ£€æŸ¥ç”¨æˆ·ç­‰çº§ï¼ˆä»…VIPå’Œè¶…çº§ç”¨æˆ·å¯ä»¥æŸ¥çœ‹å†å²è®°å½•ï¼‰
        if user_tier != 'premium' and user_tier != 'super':
            is_super = user.get('is_super', False)
            if not is_super:
                return jsonify({
                    'success': False,
                    'message': 'å†å²è®°å½•åŠŸèƒ½ä»…é™VIPç”¨æˆ·ä½¿ç”¨ï¼Œè¯·å‡çº§ä¸ºVIPä¼šå‘˜'
                }), 403
        
        beijing_now = get_beijing_time()
        history_results = []
        
        # è·å–æœ€è¿‘30å¤©çš„æ‰«æå†å²
        for i in range(30):
            date = (beijing_now - timedelta(days=i))
            date_str = date.strftime('%Y-%m-%d')
            
            # æŸ¥æ‰¾è¯¥ç”¨æˆ·çš„æ‰«æç»“æœï¼ˆæ ¼å¼ï¼šuser_scan_history:{username}:{date}ï¼‰
            user_scan_key = f'user_scan_history:{username}:{date_str}'
            
            if is_vercel:
                # Vercelç¯å¢ƒï¼šä»Redisè·å–
                scan_ids = []
                try:
                    # å°è¯•è·å–è¯¥ç”¨æˆ·å½“å¤©çš„æ‰€æœ‰æ‰«æIDåˆ—è¡¨
                    scan_ids_data = scan_progress_store._upstash_redis_get(user_scan_key) if hasattr(scan_progress_store, '_upstash_redis_get') else None
                    if scan_ids_data:
                        if isinstance(scan_ids_data, list):
                            scan_ids = scan_ids_data
                        elif isinstance(scan_ids_data, str):
                            try:
                                scan_ids = json_module.loads(scan_ids_data)
                            except:
                                scan_ids = [scan_ids_data]
                        else:
                            scan_ids = [scan_ids_data]
                except Exception as e:
                    print(f"[get_vip_scan_history] è·å–æ‰«æIDåˆ—è¡¨å¤±è´¥: {e}")
                    scan_ids = []
                
                # è·å–æ¯ä¸ªæ‰«æçš„ç»“æœ
                for scan_id in scan_ids[:5]:  # æ¯å¤©æœ€å¤šæ˜¾ç¤º5æ¬¡æ‰«æ
                    if not scan_id:
                        continue
                    results = scan_progress_store.get_scan_results(scan_id)
                    if results:
                        progress = scan_progress_store.get_scan_progress(scan_id)
                        if progress and progress.get('username') == username:
                            # æ ¼å¼åŒ–æ—¶é—´
                            scan_time = progress.get('last_update_time') or progress.get('completed_at', '')
                            if isinstance(scan_time, (int, float)):
                                from datetime import datetime
                                scan_time_str = datetime.fromtimestamp(scan_time).strftime('%Y-%m-%d %H:%M:%S') if scan_time > 1000000000 else ''
                            else:
                                scan_time_str = str(scan_time)
                            
                            history_results.append({
                                'date': date_str,
                                'scan_id': scan_id,
                                'found_count': results.get('found_count', 0),
                                'total_scanned': results.get('total_scanned', 0),
                                'scan_time': scan_time_str,
                                'completed_at': results.get('completed_at', scan_time_str),
                                'candidates_count': len(results.get('candidates', [])),
                                'candidates': results.get('candidates', [])[:10]  # åªè¿”å›å‰10åªè‚¡ç¥¨
                            })
            else:
                # æœ¬åœ°ç¯å¢ƒï¼šä»æ–‡ä»¶è¯»å–ï¼ˆTODO: å®ç°æœ¬åœ°å†å²è®°å½•å­˜å‚¨ï¼‰
                pass
        
        # æŒ‰æ—¥æœŸå’Œæ‰«ææ—¶é—´æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
        history_results.sort(key=lambda x: (x.get('date', ''), x.get('scan_time', '')), reverse=True)
        
        return jsonify({
            'success': True,
            'message': f'æ‰¾åˆ° {len(history_results)} æ¡å†å²è®°å½•',
            'history': history_results,
            'total_days': 7
        })
        
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"è·å–VIPæ‰«æå†å²é”™è¯¯: {error_detail}")
        return jsonify({
            'success': False,
            'message': f'è·å–å†å²è®°å½•å¤±è´¥: {str(e)}',
            'history': []
        }), 500


@app.route('/api/add_to_watchlist', methods=['POST'])
@require_login
def add_to_watchlist():
    """æ·»åŠ åˆ°å…³æ³¨åˆ—è¡¨ï¼ˆVIPä¸“äº«åŠŸèƒ½ï¼‰"""
    try:
        import watchlist_store
        
        # è·å–ç”¨æˆ·ä¿¡æ¯å’Œç­‰çº§
        user = get_current_user()
        if not user:
            return jsonify({
                'success': False,
                'message': 'è¯·å…ˆç™»å½•'
            }), 401
        
        user_tier = get_user_tier()
        username = user.get('username', 'anonymous')
        
        # æ£€æŸ¥ç”¨æˆ·ç­‰çº§ï¼ˆä»…VIPå’Œè¶…çº§ç”¨æˆ·å¯ä»¥ä½¿ç”¨å…³æ³¨åˆ—è¡¨ï¼‰
        if user_tier != 'premium' and user_tier != 'super':
            is_super = user.get('is_super', False)
            if not is_super:
                return jsonify({
                    'success': False,
                    'message': 'å…³æ³¨åˆ—è¡¨åŠŸèƒ½ä»…é™VIPç”¨æˆ·ä½¿ç”¨ï¼Œè¯·å‡çº§ä¸ºVIPä¼šå‘˜'
                }), 403
        
        data = request.get_json() or {}
        stock_info = data.get('stock_info', {})
        
        if not stock_info:
            return jsonify({
                'success': False,
                'message': 'è‚¡ç¥¨ä¿¡æ¯ä¸èƒ½ä¸ºç©º'
            }), 400
        
        # æ·»åŠ åˆ°å…³æ³¨åˆ—è¡¨
        success = watchlist_store.add_to_watchlist(username, stock_info)
        
        if success:
            return jsonify({
                'success': True,
                'message': 'å·²æ·»åŠ åˆ°å…³æ³¨åˆ—è¡¨'
            })
        else:
            # æ£€æŸ¥æ˜¯å¦æ˜¯å·²å­˜åœ¨æˆ–å·²è¾¾åˆ°ä¸Šé™
            watchlist = watchlist_store.get_watchlist(username)
            if len(watchlist) >= 50:
                return jsonify({
                    'success': False,
                    'message': 'å…³æ³¨åˆ—è¡¨å·²æ»¡ï¼ˆæœ€å¤š50åªè‚¡ç¥¨ï¼‰ï¼Œè¯·å…ˆåˆ é™¤ä¸€äº›è‚¡ç¥¨'
                }), 400
            else:
                return jsonify({
                    'success': False,
                    'message': 'è¯¥è‚¡ç¥¨å·²åœ¨å…³æ³¨åˆ—è¡¨ä¸­'
                }), 400
        
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"[add_to_watchlist] âŒ æ·»åŠ å…³æ³¨åˆ—è¡¨å¤±è´¥: {error_detail}")
        return jsonify({
            'success': False,
            'message': f'æ·»åŠ å…³æ³¨åˆ—è¡¨å¤±è´¥: {str(e)}'
        }), 500


@app.route('/api/remove_from_watchlist', methods=['POST'])
@require_login
def remove_from_watchlist():
    """ä»å…³æ³¨åˆ—è¡¨åˆ é™¤ï¼ˆVIPä¸“äº«åŠŸèƒ½ï¼‰"""
    try:
        import watchlist_store
        
        # è·å–ç”¨æˆ·ä¿¡æ¯å’Œç­‰çº§
        user = get_current_user()
        if not user:
            return jsonify({
                'success': False,
                'message': 'è¯·å…ˆç™»å½•'
            }), 401
        
        user_tier = get_user_tier()
        username = user.get('username', 'anonymous')
        
        # æ£€æŸ¥ç”¨æˆ·ç­‰çº§ï¼ˆä»…VIPå’Œè¶…çº§ç”¨æˆ·å¯ä»¥ä½¿ç”¨å…³æ³¨åˆ—è¡¨ï¼‰
        if user_tier != 'premium' and user_tier != 'super':
            is_super = user.get('is_super', False)
            if not is_super:
                return jsonify({
                    'success': False,
                    'message': 'å…³æ³¨åˆ—è¡¨åŠŸèƒ½ä»…é™VIPç”¨æˆ·ä½¿ç”¨ï¼Œè¯·å‡çº§ä¸ºVIPä¼šå‘˜'
                }), 403
        
        data = request.get_json() or {}
        stock_code = (data.get('stock_code') or '').strip()
        
        if not stock_code:
            return jsonify({
                'success': False,
                'message': 'è‚¡ç¥¨ä»£ç ä¸èƒ½ä¸ºç©º'
            }), 400
        
        # ä»å…³æ³¨åˆ—è¡¨åˆ é™¤
        success = watchlist_store.remove_from_watchlist(username, stock_code)
        
        if success:
            return jsonify({
                'success': True,
                'message': 'å·²ä»å…³æ³¨åˆ—è¡¨åˆ é™¤'
            })
        else:
            return jsonify({
                'success': False,
                'message': 'åˆ é™¤å¤±è´¥'
            }), 400
        
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"[remove_from_watchlist] âŒ åˆ é™¤å…³æ³¨åˆ—è¡¨å¤±è´¥: {error_detail}")
        return jsonify({
            'success': False,
            'message': f'åˆ é™¤å…³æ³¨åˆ—è¡¨å¤±è´¥: {str(e)}'
        }), 500


@app.route('/api/get_watchlist', methods=['GET'])
@require_login
def get_watchlist():
    """è·å–å…³æ³¨åˆ—è¡¨ï¼ˆVIPä¸“äº«åŠŸèƒ½ï¼‰"""
    try:
        import watchlist_store
        
        # è·å–ç”¨æˆ·ä¿¡æ¯å’Œç­‰çº§
        user = get_current_user()
        if not user:
            return jsonify({
                'success': False,
                'message': 'è¯·å…ˆç™»å½•'
            }), 401
        
        user_tier = get_user_tier()
        username = user.get('username', 'anonymous')
        
        # æ£€æŸ¥ç”¨æˆ·ç­‰çº§ï¼ˆä»…VIPå’Œè¶…çº§ç”¨æˆ·å¯ä»¥ä½¿ç”¨å…³æ³¨åˆ—è¡¨ï¼‰
        if user_tier != 'premium' and user_tier != 'super':
            is_super = user.get('is_super', False)
            if not is_super:
                return jsonify({
                    'success': False,
                    'message': 'å…³æ³¨åˆ—è¡¨åŠŸèƒ½ä»…é™VIPç”¨æˆ·ä½¿ç”¨ï¼Œè¯·å‡çº§ä¸ºVIPä¼šå‘˜'
                }), 403
        
        # è·å–å…³æ³¨åˆ—è¡¨
        watchlist = watchlist_store.get_watchlist(username)
        
        # å¯é€‰ï¼šæ›´æ–°å½“å‰ä»·æ ¼ï¼ˆå¦‚æœéœ€è¦ï¼‰
        # è¿™é‡Œæš‚æ—¶ä¸æ›´æ–°ï¼Œç”¨æˆ·å¯ä»¥åœ¨æŸ¥çœ‹æ—¶æ‰‹åŠ¨åˆ·æ–°
        
        return jsonify({
            'success': True,
            'message': f'æ‰¾åˆ° {len(watchlist)} åªå…³æ³¨çš„è‚¡ç¥¨',
            'watchlist': watchlist,
            'count': len(watchlist),
            'max_count': 50
        })
        
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"[get_watchlist] âŒ è·å–å…³æ³¨åˆ—è¡¨å¤±è´¥: {error_detail}")
        return jsonify({
            'success': False,
            'message': f'è·å–å…³æ³¨åˆ—è¡¨å¤±è´¥: {str(e)}',
            'watchlist': []
        }), 500


@app.route('/api/set_price_alert', methods=['POST'])
@require_login
def set_price_alert():
    """è®¾ç½®ä»·æ ¼é¢„è­¦ï¼ˆVIPä¸“äº«åŠŸèƒ½ï¼‰"""
    try:
        import watchlist_store
        
        # è·å–ç”¨æˆ·ä¿¡æ¯å’Œç­‰çº§
        user = get_current_user()
        if not user:
            return jsonify({
                'success': False,
                'message': 'è¯·å…ˆç™»å½•'
            }), 401
        
        user_tier = get_user_tier()
        username = user.get('username', 'anonymous')
        
        # æ£€æŸ¥ç”¨æˆ·ç­‰çº§ï¼ˆä»…VIPå’Œè¶…çº§ç”¨æˆ·å¯ä»¥ä½¿ç”¨ä»·æ ¼é¢„è­¦ï¼‰
        if user_tier != 'premium' and user_tier != 'super':
            is_super = user.get('is_super', False)
            if not is_super:
                return jsonify({
                    'success': False,
                    'message': 'ä»·æ ¼é¢„è­¦åŠŸèƒ½ä»…é™VIPç”¨æˆ·ä½¿ç”¨ï¼Œè¯·å‡çº§ä¸ºVIPä¼šå‘˜'
                }), 403
        
        data = request.get_json() or {}
        stock_code = (data.get('stock_code') or '').strip()
        stock_name = data.get('stock_name', '').strip()
        price_high = data.get('price_high')  # ä»·æ ¼ä¸Šé™ï¼ˆå¯é€‰ï¼‰
        price_low = data.get('price_low')  # ä»·æ ¼ä¸‹é™ï¼ˆå¯é€‰ï¼‰
        
        if not stock_code:
            return jsonify({
                'success': False,
                'message': 'è‚¡ç¥¨ä»£ç ä¸èƒ½ä¸ºç©º'
            }), 400
        
        if price_high is None and price_low is None:
            return jsonify({
                'success': False,
                'message': 'è¯·è‡³å°‘è®¾ç½®ä»·æ ¼ä¸Šé™æˆ–ä¸‹é™'
            }), 400
        
        # æ„å»ºé¢„è­¦ä¿¡æ¯
        alert_info = {
            'stock_code': stock_code,
            'stock_name': stock_name,
            'price_high': float(price_high) if price_high is not None else None,
            'price_low': float(price_low) if price_low is not None else None
        }
        
        # ä¿å­˜ä»·æ ¼é¢„è­¦
        success = watchlist_store.save_price_alert(username, alert_info)
        
        if success:
            return jsonify({
                'success': True,
                'message': 'ä»·æ ¼é¢„è­¦è®¾ç½®æˆåŠŸ'
            })
        else:
            return jsonify({
                'success': False,
                'message': 'ä»·æ ¼é¢„è­¦è®¾ç½®å¤±è´¥'
            }), 500
        
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"[set_price_alert] âŒ è®¾ç½®ä»·æ ¼é¢„è­¦å¤±è´¥: {error_detail}")
        return jsonify({
            'success': False,
            'message': f'è®¾ç½®ä»·æ ¼é¢„è­¦å¤±è´¥: {str(e)}'
        }), 500


@app.route('/api/get_price_alerts', methods=['GET'])
@require_login
def get_price_alerts():
    """è·å–ä»·æ ¼é¢„è­¦åˆ—è¡¨ï¼ˆVIPä¸“äº«åŠŸèƒ½ï¼‰"""
    try:
        import watchlist_store
        
        # è·å–ç”¨æˆ·ä¿¡æ¯å’Œç­‰çº§
        user = get_current_user()
        if not user:
            return jsonify({
                'success': False,
                'message': 'è¯·å…ˆç™»å½•'
            }), 401
        
        user_tier = get_user_tier()
        username = user.get('username', 'anonymous')
        
        # æ£€æŸ¥ç”¨æˆ·ç­‰çº§ï¼ˆä»…VIPå’Œè¶…çº§ç”¨æˆ·å¯ä»¥ä½¿ç”¨ä»·æ ¼é¢„è­¦ï¼‰
        if user_tier != 'premium' and user_tier != 'super':
            is_super = user.get('is_super', False)
            if not is_super:
                return jsonify({
                    'success': False,
                    'message': 'ä»·æ ¼é¢„è­¦åŠŸèƒ½ä»…é™VIPç”¨æˆ·ä½¿ç”¨ï¼Œè¯·å‡çº§ä¸ºVIPä¼šå‘˜'
                }), 403
        
        # è·å–ä»·æ ¼é¢„è­¦åˆ—è¡¨
        alerts = watchlist_store.get_price_alerts(username)
        
        return jsonify({
            'success': True,
            'message': f'æ‰¾åˆ° {len(alerts)} ä¸ªä»·æ ¼é¢„è­¦',
            'alerts': alerts,
            'count': len(alerts)
        })
        
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"[get_price_alerts] âŒ è·å–ä»·æ ¼é¢„è­¦å¤±è´¥: {error_detail}")
        return jsonify({
            'success': False,
            'message': f'è·å–ä»·æ ¼é¢„è­¦å¤±è´¥: {str(e)}',
            'alerts': []
        }), 500


@app.route('/api/remove_price_alert', methods=['POST'])
@require_login
def remove_price_alert():
    """åˆ é™¤ä»·æ ¼é¢„è­¦ï¼ˆVIPä¸“äº«åŠŸèƒ½ï¼‰"""
    try:
        import watchlist_store
        
        # è·å–ç”¨æˆ·ä¿¡æ¯å’Œç­‰çº§
        user = get_current_user()
        if not user:
            return jsonify({
                'success': False,
                'message': 'è¯·å…ˆç™»å½•'
            }), 401
        
        user_tier = get_user_tier()
        username = user.get('username', 'anonymous')
        
        # æ£€æŸ¥ç”¨æˆ·ç­‰çº§ï¼ˆä»…VIPå’Œè¶…çº§ç”¨æˆ·å¯ä»¥ä½¿ç”¨ä»·æ ¼é¢„è­¦ï¼‰
        if user_tier != 'premium' and user_tier != 'super':
            is_super = user.get('is_super', False)
            if not is_super:
                return jsonify({
                    'success': False,
                    'message': 'ä»·æ ¼é¢„è­¦åŠŸèƒ½ä»…é™VIPç”¨æˆ·ä½¿ç”¨ï¼Œè¯·å‡çº§ä¸ºVIPä¼šå‘˜'
                }), 403
        
        data = request.get_json() or {}
        stock_code = (data.get('stock_code') or '').strip()
        
        if not stock_code:
            return jsonify({
                'success': False,
                'message': 'è‚¡ç¥¨ä»£ç ä¸èƒ½ä¸ºç©º'
            }), 400
        
        # åˆ é™¤ä»·æ ¼é¢„è­¦
        success = watchlist_store.remove_price_alert(username, stock_code)
        
        if success:
            return jsonify({
                'success': True,
                'message': 'ä»·æ ¼é¢„è­¦å·²åˆ é™¤'
            })
        else:
            return jsonify({
                'success': False,
                'message': 'åˆ é™¤å¤±è´¥'
            }), 400
        
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"[remove_price_alert] âŒ åˆ é™¤ä»·æ ¼é¢„è­¦å¤±è´¥: {error_detail}")
        return jsonify({
            'success': False,
            'message': f'åˆ é™¤ä»·æ ¼é¢„è­¦å¤±è´¥: {str(e)}'
        }), 500


@app.route('/api/search_stock', methods=['POST'])
@require_login
def search_stock():
    """ä¸ªè‚¡æ£€ç´¢API - æ ¹æ®ä»£ç æˆ–åç§°æœç´¢è‚¡ç¥¨"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({
                'success': False,
                'message': 'è¯·æ±‚æ•°æ®ä¸ºç©º'
            }), 400
        
        search_keyword = (data.get('keyword') or '').strip()
        if not search_keyword:
            return jsonify({
                'success': False,
                'message': 'è¯·è¾“å…¥è‚¡ç¥¨ä»£ç æˆ–åç§°'
            }), 400
        
        init_analyzer()
        if analyzer is None or analyzer.fetcher is None:
            return jsonify({
                'success': False,
                'message': 'åˆ†æå™¨æœªåˆå§‹åŒ–'
            }), 500
        
        # è·å–æ‰€æœ‰è‚¡ç¥¨åˆ—è¡¨
        stock_list = analyzer.fetcher.get_all_stocks(timeout=15, max_retries=3)
        if stock_list is None or len(stock_list) == 0:
            return jsonify({
                'success': False,
                'message': 'æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨'
            }), 500
        
        # æœç´¢åŒ¹é…çš„è‚¡ç¥¨
        results = []
        search_keyword_lower = search_keyword.lower()
        
        for _, row in stock_list.iterrows():
            code = str(row.get('code', '')).strip()
            name = str(row.get('name', '')).strip()
            
            # åŒ¹é…ä»£ç æˆ–åç§°
            if (search_keyword_lower in code.lower() or 
                search_keyword_lower in name.lower()):
                results.append({
                    'code': code,
                    'name': name
                })
                
                # é™åˆ¶è¿”å›ç»“æœæ•°é‡ï¼Œé¿å…è¿‡å¤š
                if len(results) >= 50:
                    break
        
        return jsonify({
            'success': True,
            'results': results,
            'count': len(results),
            'keyword': search_keyword
        })
        
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"ä¸ªè‚¡æ£€ç´¢é”™è¯¯: {error_detail}")
        return jsonify({
            'success': False,
            'message': f'æ£€ç´¢å¤±è´¥: {str(e)}'
        }), 500


@app.route('/api/refresh_stock_cache', methods=['GET', 'POST'])
def refresh_stock_cache():
    """
    åˆ·æ–°è‚¡ç¥¨åˆ—è¡¨ç¼“å­˜çš„ Cron Job ç«¯ç‚¹
    
    æ³¨æ„ï¼šç”±äº Vercel Hobby è´¦æˆ·é™åˆ¶æ¯å¤©åªèƒ½è¿è¡Œä¸€æ¬¡ cron jobï¼Œ
    å› æ­¤é…ç½®ä¸ºæ¯ä¸ªäº¤æ˜“æ—¥ 9:25ï¼ˆå¼€ç›˜å‰ï¼‰è‡ªåŠ¨åˆ·æ–°ä¸€æ¬¡ã€‚
    
    å¦‚æœéœ€è¦æ›´é¢‘ç¹çš„åˆ·æ–°ï¼ˆå¦‚äº¤æ˜“æ—¶é—´æ®µå†…æ¯5åˆ†é’Ÿï¼‰ï¼Œå¯ä»¥ï¼š
    1. æ‰‹åŠ¨è®¿é—® /api/refresh_stock_cache?force=true
    2. ä½¿ç”¨å¤–éƒ¨æœåŠ¡ï¼ˆå¦‚ GitHub Actionsã€UptimeRobotï¼‰å®šæœŸè°ƒç”¨æ­¤API
    3. å‡çº§åˆ° Vercel Pro è®¡åˆ’ä»¥è§£é”æ›´å¤š cron job åŠŸèƒ½
    
    ä¹Ÿå…è®¸æ‰‹åŠ¨è§¦å‘åˆ·æ–°ï¼ˆæ— éœ€ç™»å½•ï¼Œå»ºè®®åœ¨äº¤æ˜“æ—¶é—´æ®µä½¿ç”¨ï¼‰
    """
    try:
        from datetime import datetime, timezone, timedelta
        
        def get_beijing_time():
            """è·å–åŒ—äº¬æ—¶é—´ï¼ˆUTC+8ï¼‰"""
            utc_now = datetime.now(timezone.utc)
            beijing_tz = timezone(timedelta(hours=8))
            beijing_now = utc_now.astimezone(beijing_tz)
            return beijing_now
        
        def is_trading_time(beijing_now):
            """
            åˆ¤æ–­æ˜¯å¦åœ¨äº¤æ˜“æ—¶é—´æ®µï¼ˆ9:30-11:30, 13:00-15:00ï¼‰æˆ–ç›˜åæ—¶é—´ï¼ˆ15:05ï¼‰
            ä¹Ÿå…è®¸åœ¨å¼€ç›˜å‰ï¼ˆ9:25ï¼‰æ‰§è¡Œï¼Œå› ä¸ºHobbyè´¦æˆ·é™åˆ¶æ¯å¤©åªèƒ½è¿è¡Œä¸€æ¬¡cron job
            """
            current_hour = beijing_now.hour
            current_minute = beijing_now.minute
            
            # å¼€ç›˜å‰ï¼š9:25ï¼ˆå…è®¸æ‰§è¡Œï¼Œå› ä¸ºcron jobåœ¨è¿™ä¸ªæ—¶é—´è¿è¡Œï¼‰
            if current_hour == 9 and current_minute == 25:
                return True
            
            # ä¸Šåˆäº¤æ˜“æ—¶é—´ï¼š9:30-11:30
            if current_hour == 9 and current_minute >= 30:
                return True
            if current_hour == 10:
                return True
            if current_hour == 11 and current_minute <= 30:
                return True
            
            # ä¸‹åˆäº¤æ˜“æ—¶é—´ï¼š13:00-15:00
            if current_hour == 13 or current_hour == 14:
                return True
            if current_hour == 15 and current_minute == 0:
                return True
            
            # ç›˜åæ—¶é—´ï¼š15:05ï¼ˆå…è®¸æ‰‹åŠ¨è§¦å‘ï¼‰
            if current_hour == 15 and current_minute == 5:
                return True
            
            return False
        
        beijing_now = get_beijing_time()
        current_time_str = beijing_now.strftime('%Y-%m-%d %H:%M:%S')
        
        # æ£€æŸ¥æ˜¯å¦åœ¨äº¤æ˜“æ—¶é—´æˆ–ç›˜åæ—¶é—´ï¼ˆå¦‚æœä¸æ˜¯ï¼Œä»ç„¶å…è®¸æ‰‹åŠ¨è§¦å‘ï¼Œä½†ç»™å‡ºè­¦å‘Šï¼‰
        is_in_trading_time = is_trading_time(beijing_now)
        force_refresh = request.args.get('force', '').lower() == 'true' or request.get_json(silent=True) and request.get_json().get('force', False)
        
        if not is_in_trading_time and not force_refresh:
            return jsonify({
                'success': False,
                'message': f'å½“å‰æ—¶é—´ä¸åœ¨å…è®¸çš„æ‰§è¡Œæ—¶é—´ï¼ˆå½“å‰æ—¶é—´: {current_time_str}ï¼‰\n\nå…è®¸çš„æ—¶é—´ï¼š\n- 9:25ï¼ˆå¼€ç›˜å‰ï¼Œè‡ªåŠ¨cron jobï¼‰\n- 9:30-11:30, 13:00-15:00ï¼ˆäº¤æ˜“æ—¶é—´æ®µï¼Œéœ€æ‰‹åŠ¨è§¦å‘ï¼‰\n- 15:05ï¼ˆç›˜åï¼Œéœ€æ‰‹åŠ¨è§¦å‘ï¼‰\n\nå¦‚éœ€å¼ºåˆ¶åˆ·æ–°ï¼Œè¯·ä½¿ç”¨ ?force=true å‚æ•°',
                'current_time': current_time_str,
                'allowed_times': {
                    'auto_cron': '9:25ï¼ˆå¼€ç›˜å‰ï¼Œæ¯å¤©ä¸€æ¬¡ï¼‰',
                    'trading_hours': '9:30-11:30, 13:00-15:00ï¼ˆéœ€æ‰‹åŠ¨è§¦å‘æˆ–ä½¿ç”¨å¤–éƒ¨æœåŠ¡ï¼‰',
                    'after_market': '15:05ï¼ˆç›˜åï¼Œéœ€æ‰‹åŠ¨è§¦å‘ï¼‰'
                },
                'note': 'ç”±äº Vercel Hobby è´¦æˆ·é™åˆ¶æ¯å¤©åªèƒ½è¿è¡Œä¸€æ¬¡ cron jobï¼Œäº¤æ˜“æ—¶é—´æ®µå†…çš„åˆ·æ–°éœ€è¦æ‰‹åŠ¨è§¦å‘æˆ–ä½¿ç”¨å¤–éƒ¨æœåŠ¡',
                'force_refresh': False
            }), 200
        
        print(f"[refresh_stock_cache] å¼€å§‹åˆ·æ–°è‚¡ç¥¨åˆ—è¡¨ç¼“å­˜ - æ—¶é—´: {current_time_str}")
        
        # ç¡®ä¿åˆ†æå™¨å·²åˆå§‹åŒ–
        init_analyzer()
        
        if analyzer is None or analyzer.fetcher is None:
            return jsonify({
                'success': False,
                'message': 'åˆ†æå™¨æœªåˆå§‹åŒ–',
                'current_time': current_time_str
            }), 500
        
        # ä» akshare API è·å–è‚¡ç¥¨åˆ—è¡¨ï¼ˆåå°ä»»åŠ¡å¯ä»¥ä½¿ç”¨æ›´é•¿çš„è¶…æ—¶ï¼‰
        print("[refresh_stock_cache] ä» akshare API è·å–è‚¡ç¥¨åˆ—è¡¨...")
        # æ³¨æ„ï¼šè¿™æ˜¯åå° Cron Job ä»»åŠ¡ï¼Œå…è®¸ä½¿ç”¨æ›´é•¿çš„è¶…æ—¶æ—¶é—´
        # ç›´æ¥è°ƒç”¨ akshare APIï¼Œä¸ä½¿ç”¨ get_all_stocks çš„é™åˆ¶ï¼ˆå› ä¸ºå®ƒä¼šè‡ªåŠ¨é™åˆ¶ Vercel ç¯å¢ƒçš„è¶…æ—¶ï¼‰
        # æ·»åŠ é‡è¯•æœºåˆ¶ï¼Œæœ€å¤šé‡è¯•3æ¬¡ï¼Œå¤„ç†ç½‘ç»œè¿æ¥é”™è¯¯ï¼ˆå¦‚ ConnectionResetErrorï¼‰
        import akshare as ak
        import threading
        import time as time_module
        import traceback
        
        max_retries = 3
        retry_delay = 2  # é‡è¯•é—´éš”ï¼ˆç§’ï¼‰
        timeout = 30  # å•æ¬¡å°è¯•çš„è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        stock_list = None
        
        for attempt in range(max_retries):
            try:
                result = [None]
                error = [None]
                start_time = time_module.time()
                
                def fetch_stocks():
                    try:
                        if attempt > 0:
                            print(f"[refresh_stock_cache] é‡è¯•ç¬¬ {attempt + 1}/{max_retries} æ¬¡ï¼Œè°ƒç”¨ ak.stock_info_a_code_name()...")
                        else:
                            print("[refresh_stock_cache] å¼€å§‹è°ƒç”¨ ak.stock_info_a_code_name()...")
                        result[0] = ak.stock_info_a_code_name()
                        elapsed = time_module.time() - start_time
                        print(f"[refresh_stock_cache] âœ… ak.stock_info_a_code_name() è°ƒç”¨æˆåŠŸï¼Œè€—æ—¶ {elapsed:.2f}ç§’")
                    except Exception as e:
                        error[0] = e
                        elapsed = time_module.time() - start_time
                        error_type = type(e).__name__
                        print(f"[refresh_stock_cache] âŒ è°ƒç”¨å¤±è´¥ï¼ˆè€—æ—¶ {elapsed:.2f}ç§’ï¼Œé”™è¯¯ç±»å‹: {error_type}ï¼‰: {e}")
                        if attempt < max_retries - 1:
                            print(f"[refresh_stock_cache] é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
                
                fetch_thread = threading.Thread(target=fetch_stocks)
                fetch_thread.daemon = True
                fetch_thread.start()
                fetch_thread.join(timeout=timeout)
                
                elapsed_total = time_module.time() - start_time
                
                if fetch_thread.is_alive():
                    print(f"[refresh_stock_cache] â±ï¸ è·å–è¶…æ—¶ï¼ˆ>{timeout}ç§’ï¼Œå®é™…è€—æ—¶ {elapsed_total:.2f}ç§’ï¼‰")
                    if attempt < max_retries - 1:
                        print(f"[refresh_stock_cache] ç­‰å¾… {retry_delay} ç§’åé‡è¯•...")
                        time_module.sleep(retry_delay)
                        continue  # é‡è¯•
                    else:
                        return jsonify({
                            'success': False,
                            'message': f'è·å–è‚¡ç¥¨åˆ—è¡¨è¶…æ—¶ï¼ˆ>{timeout}ç§’ï¼‰ï¼Œå·²é‡è¯• {max_retries} æ¬¡ï¼Œè¯·ç¨åé‡è¯•',
                            'current_time': current_time_str,
                            'retries': max_retries,
                            'error_type': 'timeout'
                        }), 500
                
                if error[0]:
                    error_type = type(error[0]).__name__
                    error_msg_str = str(error[0])
                    is_network_error = (
                        'Connection' in error_type or 
                        'Connection' in error_msg_str or
                        'reset' in error_msg_str.lower() or
                        'aborted' in error_msg_str.lower() or
                        'timeout' in error_msg_str.lower() or
                        '104' in error_msg_str  # Connection reset by peer (104)
                    )
                    
                    print(f"[refresh_stock_cache] âŒ è·å–å‡ºé”™ï¼ˆè€—æ—¶ {elapsed_total:.2f}ç§’ï¼Œé”™è¯¯ç±»å‹: {error_type}ï¼Œç½‘ç»œé”™è¯¯: {is_network_error}ï¼‰: {error[0]}")
                    
                    if is_network_error and attempt < max_retries - 1:
                        print(f"[refresh_stock_cache] ç½‘ç»œè¿æ¥é”™è¯¯ï¼Œç­‰å¾… {retry_delay} ç§’åé‡è¯•ï¼ˆç¬¬ {attempt + 1}/{max_retries} æ¬¡ï¼‰...")
                        time_module.sleep(retry_delay)
                        continue  # é‡è¯•
                    else:
                        # æœ€åä¸€æ¬¡å°è¯•æˆ–éç½‘ç»œé”™è¯¯ï¼Œè¿”å›é”™è¯¯
                        if is_network_error:
                            error_message = f'ç½‘ç»œè¿æ¥é”™è¯¯: {error_msg_str}\n\nå·²é‡è¯• {attempt + 1} æ¬¡ï¼Œä»ç„¶å¤±è´¥ã€‚\n\nğŸ’¡ **è§£å†³æ–¹æ¡ˆï¼š**\n1. ç¨åé‡è¯•ï¼ˆå¯èƒ½æ˜¯ç½‘ç»œæ³¢åŠ¨æˆ– akshare æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼‰\n2. ç­‰å¾…ä¸€æ®µæ—¶é—´åå†è¯•ï¼ˆå»ºè®®ç­‰å¾… 1-2 åˆ†é’Ÿåé‡è¯•ï¼‰\n3. å¦‚æœé—®é¢˜æŒç»­ï¼Œå¯èƒ½æ˜¯ akshare æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åå†è¯•'
                        else:
                            error_message = f'è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {error_msg_str}'
                        
                        return jsonify({
                            'success': False,
                            'message': error_message,
                            'current_time': current_time_str,
                            'retries': attempt + 1,
                            'error_type': error_type,
                            'is_network_error': is_network_error
                        }), 500
                
                if result[0] is None or len(result[0]) == 0:
                    print(f"[refresh_stock_cache] âš ï¸ è¿”å›ç»“æœä¸ºç©ºï¼ˆè€—æ—¶ {elapsed_total:.2f}ç§’ï¼‰")
                    if attempt < max_retries - 1:
                        print(f"[refresh_stock_cache] ç­‰å¾… {retry_delay} ç§’åé‡è¯•...")
                        time_module.sleep(retry_delay)
                        continue  # é‡è¯•
                    else:
                        return jsonify({
                            'success': False,
                            'message': f'è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: è¿”å›ç»“æœä¸ºç©ºï¼ˆå·²é‡è¯• {max_retries} æ¬¡ï¼‰',
                            'current_time': current_time_str,
                            'retries': max_retries,
                            'error_type': 'empty_result'
                        }), 500
                
                # æˆåŠŸè·å–åˆ°æ•°æ®ï¼Œè·³å‡ºé‡è¯•å¾ªç¯
                stock_list = result[0]
                break
                
            except Exception as e:
                error_type = type(e).__name__
                error_detail = traceback.format_exc()
                print(f"[refresh_stock_cache] âŒ å¤–å±‚å¼‚å¸¸ï¼ˆç¬¬ {attempt + 1}/{max_retries} æ¬¡ï¼‰: {error_detail}")
                
                if attempt < max_retries - 1:
                    print(f"[refresh_stock_cache] ç­‰å¾… {retry_delay} ç§’åé‡è¯•...")
                    time_module.sleep(retry_delay)
                    continue  # é‡è¯•
                else:
                    return jsonify({
                        'success': False,
                        'message': f'åˆ·æ–°è‚¡ç¥¨åˆ—è¡¨ç¼“å­˜å¤±è´¥: {str(e)}ï¼ˆå·²é‡è¯• {max_retries} æ¬¡ï¼‰',
                        'current_time': current_time_str,
                        'retries': max_retries,
                        'error_type': error_type,
                        'error_detail': error_detail
                    }), 500
        
        if stock_list is None:
            return jsonify({
                'success': False,
                'message': f'è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: æ‰€æœ‰é‡è¯•å‡å¤±è´¥ï¼ˆå·²é‡è¯• {max_retries} æ¬¡ï¼‰',
                'current_time': current_time_str,
                'retries': max_retries,
                'error_type': 'all_retries_failed'
            }), 500
        
        # æˆåŠŸè·å–åˆ°è‚¡ç¥¨åˆ—è¡¨ï¼Œå¼€å§‹ä¿å­˜åˆ°ç¼“å­˜
        try:
            # å°†è‚¡ç¥¨åˆ—è¡¨ä¿å­˜åˆ°ç¼“å­˜
            print(f"[refresh_stock_cache] è·å–åˆ° {len(stock_list)} åªè‚¡ç¥¨ï¼Œå¼€å§‹ä¿å­˜åˆ°ç¼“å­˜...")
            
            # è®¡ç®—æ•°æ®å¤§å°ï¼ˆç”¨äºè°ƒè¯•ï¼‰
            try:
                import json
                import pandas as pd
                stock_data = stock_list.to_dict('records')
                stock_json = json.dumps(stock_data, default=str, ensure_ascii=False)
                data_size_mb = len(stock_json.encode('utf-8')) / (1024 * 1024)
                print(f"[refresh_stock_cache] æ•°æ®å¤§å°: {data_size_mb:.2f} MB ({len(stock_json)} å­—ç¬¦)")
            except Exception as size_error:
                print(f"[refresh_stock_cache] âš ï¸ è®¡ç®—æ•°æ®å¤§å°å¤±è´¥: {size_error}")
                data_size_mb = None
            
            cache_success = analyzer.fetcher._save_stock_list_to_cache(stock_list)
            if cache_success:
                print(f"[refresh_stock_cache] âœ… è‚¡ç¥¨åˆ—è¡¨å·²ä¿å­˜åˆ°ç¼“å­˜")
                # æ›´æ–°åˆ†æå™¨çš„è‚¡ç¥¨åˆ—è¡¨
                analyzer.fetcher.stock_list = stock_list
                
                return jsonify({
                    'success': True,
                    'message': f'è‚¡ç¥¨åˆ—è¡¨ç¼“å­˜å·²åˆ·æ–°ï¼ˆ{len(stock_list)} åªè‚¡ç¥¨ï¼‰',
                    'stock_count': len(stock_list),
                    'current_time': current_time_str,
                    'cache_ttl': '24å°æ—¶',
                    'data_size_mb': round(data_size_mb, 2) if data_size_mb else None
                }), 200
            else:
                print(f"[refresh_stock_cache] âŒ ä¿å­˜åˆ°ç¼“å­˜å¤±è´¥ï¼Œä½†å·²è·å–è‚¡ç¥¨åˆ—è¡¨")
                # å³ä½¿ä¿å­˜å¤±è´¥ï¼Œä¹Ÿæ›´æ–°åˆ†æå™¨çš„è‚¡ç¥¨åˆ—è¡¨ï¼ˆå¯ä»¥åœ¨å½“å‰è¯·æ±‚ä¸­ä½¿ç”¨ï¼‰
                analyzer.fetcher.stock_list = stock_list
                
                # æ£€æŸ¥ Redis å’Œ Vercel KV çš„å¯ç”¨æ€§
                redis_available = bool(os.environ.get('UPSTASH_REDIS_REST_URL') and os.environ.get('UPSTASH_REDIS_REST_TOKEN'))
                vercel_kv_available = False
                try:
                    from vercel_kv import kv
                    vercel_kv_available = True
                except ImportError:
                    pass
                
                error_message = f'è·å–è‚¡ç¥¨åˆ—è¡¨æˆåŠŸï¼ˆ{len(stock_list)} åªè‚¡ç¥¨ï¼‰ï¼Œä½†ä¿å­˜åˆ°ç¼“å­˜å¤±è´¥ã€‚'
                if data_size_mb and data_size_mb > 10:
                    error_message += f'\n\nâš ï¸ æ•°æ®è¾ƒå¤§ï¼ˆ{data_size_mb:.2f} MBï¼‰ï¼Œå¯èƒ½è¶…è¿‡å­˜å‚¨é™åˆ¶ã€‚'
                if not redis_available and not vercel_kv_available:
                    error_message += '\n\nâš ï¸ Redis å’Œ Vercel KV å‡ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒå˜é‡é…ç½®ã€‚'
                elif not redis_available:
                    error_message += '\n\nâš ï¸ Redis ä¸å¯ç”¨ï¼Œå·²å°è¯•ä½¿ç”¨ Vercel KVã€‚'
                elif not vercel_kv_available:
                    error_message += '\n\nâš ï¸ Vercel KV ä¸å¯ç”¨ï¼Œå·²å°è¯•ä½¿ç”¨ Redisã€‚'
                else:
                    error_message += '\n\nğŸ’¡ å¯èƒ½çš„åŸå› ï¼š\n1. ç½‘ç»œè¿æ¥é—®é¢˜\n2. æ•°æ®è¿‡å¤§\n3. å­˜å‚¨æœåŠ¡æš‚æ—¶ä¸å¯ç”¨\n\nè¯·ç¨åé‡è¯•æˆ–æ£€æŸ¥ Vercel æ—¥å¿—ã€‚'
                
                return jsonify({
                    'success': False,
                    'message': error_message,
                    'stock_count': len(stock_list),
                    'current_time': current_time_str,
                    'cache_saved': False,
                    'error_type': 'cache_save_failed',
                    'data_size_mb': round(data_size_mb, 2) if data_size_mb else None,
                    'redis_available': redis_available,
                    'vercel_kv_available': vercel_kv_available
                }), 500
            
        except Exception as e:
            import traceback
            error_detail = traceback.format_exc()
            print(f"[refresh_stock_cache] âŒ ä¿å­˜è‚¡ç¥¨åˆ—è¡¨åˆ°ç¼“å­˜æ—¶å¼‚å¸¸: {error_detail}")
            return jsonify({
                'success': False,
                'message': f'ä¿å­˜è‚¡ç¥¨åˆ—è¡¨åˆ°ç¼“å­˜æ—¶å¼‚å¸¸: {str(e)}',
                'error': error_detail,
                'current_time': current_time_str
            }), 500
            
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"[refresh_stock_cache] âŒ é”™è¯¯: {error_detail}")
        from datetime import datetime, timezone, timedelta
        try:
            utc_now = datetime.now(timezone.utc)
            beijing_tz = timezone(timedelta(hours=8))
            beijing_now = utc_now.astimezone(beijing_tz)
            current_time_str = beijing_now.strftime('%Y-%m-%d %H:%M:%S')
        except:
            current_time_str = 'unknown'
        
        return jsonify({
            'success': False,
            'message': f'åˆ·æ–°è‚¡ç¥¨åˆ—è¡¨ç¼“å­˜å¤±è´¥: {str(e)}',
            'error': error_detail,
            'current_time': current_time_str
        }), 500


@app.route('/api/get_weekly_kline_for_stock', methods=['POST'])
@require_login
def get_weekly_kline_for_stock():
    """è·å–æŒ‡å®šè‚¡ç¥¨çš„å‘¨Kçº¿æ•°æ®ï¼ˆç”¨äºåœ¨åè½¬ä¸ªè‚¡ç»“æœä¸­æ˜¾ç¤ºï¼‰"""
    init_analyzer()
    try:
        data = request.json
        stock_code = data.get('code', '').strip()
        
        if not stock_code:
            return jsonify({'error': 'è¯·è¾“å…¥è‚¡ç¥¨ä»£ç '}), 400
        
        # è·å–å‘¨Kçº¿æ•°æ®
        weekly_df = analyzer.fetcher.get_weekly_kline(stock_code, period="2y")
        if weekly_df is None or len(weekly_df) == 0:
            return jsonify({'error': 'æ— æ³•è·å–å‘¨Kçº¿æ•°æ®'}), 500
        
        # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
        ma5 = TechnicalAnalysis.calculate_ma(weekly_df, period=5) if len(weekly_df) >= 5 else None
        ma10 = TechnicalAnalysis.calculate_ma(weekly_df, period=10) if len(weekly_df) >= 10 else None
        ma20 = TechnicalAnalysis.calculate_ma(weekly_df, period=20) if len(weekly_df) >= 20 else None
        ma60 = TechnicalAnalysis.calculate_ma(weekly_df, period=60) if len(weekly_df) >= 60 else None
        
        # å‡†å¤‡æ•°æ®
        dates = []
        kline_data = []
        volumes = []
        ma5_data = []
        ma10_data = []
        ma20_data = []
        ma60_data = []
        
        for i in range(len(weekly_df)):
            row = weekly_df.iloc[i]
            dates.append(str(row['æ—¥æœŸ']))
            kline_data.append([
                float(row['å¼€ç›˜']),
                float(row['æ”¶ç›˜']),
                float(row['æœ€ä½']),
                float(row['æœ€é«˜'])
            ])
            volumes.append(float(row.get('å‘¨æˆäº¤é‡', row.get('æˆäº¤é‡', 0))))
            
            # å‡çº¿æ•°æ®
            ma5_data.append(float(ma5.iloc[i]) if ma5 is not None and i < len(ma5) and pd.notna(ma5.iloc[i]) else None)
            ma10_data.append(float(ma10.iloc[i]) if ma10 is not None and i < len(ma10) and pd.notna(ma10.iloc[i]) else None)
            ma20_data.append(float(ma20.iloc[i]) if ma20 is not None and i < len(ma20) and pd.notna(ma20.iloc[i]) else None)
            ma60_data.append(float(ma60.iloc[i]) if ma60 is not None and i < len(ma60) and pd.notna(ma60.iloc[i]) else None)
        
        # è·å–è‚¡ç¥¨åç§°
        stock_list = analyzer.fetcher.get_all_stocks()
        stock_name = stock_code
        if stock_list is not None:
            stock_row = stock_list[stock_list['code'] == stock_code]
            if len(stock_row) > 0:
                stock_name = stock_row.iloc[0]['name']
        
        return jsonify({
            'code': stock_code,
            'name': stock_name,
            'dates': dates,
            'kline': kline_data,
            'volumes': volumes,
            'ma5': ma5_data,
            'ma10': ma10_data,
            'ma20': ma20_data,
            'ma60': ma60_data
        })
    except Exception as e:
        import traceback
        return jsonify({'error': f'è·å–å‘¨Kçº¿æ•°æ®å¤±è´¥: {str(e)}'}), 500


# ==================== KDJæ¨¡å¼æ‰«æ ====================

def calculate_kdj(df, n=9, m1=3, m2=3):
    """
    è®¡ç®—KDJæŒ‡æ ‡
    :param df: Kçº¿æ•°æ®ï¼Œå¿…é¡»åŒ…å« 'æœ€é«˜', 'æœ€ä½', 'æ”¶ç›˜' åˆ—
    :param n: RSVå‘¨æœŸï¼Œé»˜è®¤9
    :param m1: Kå€¼å¹³æ»‘å‘¨æœŸï¼Œé»˜è®¤3
    :param m2: Då€¼å¹³æ»‘å‘¨æœŸï¼Œé»˜è®¤3
    :return: DataFrameæ·»åŠ  K, D, J åˆ—
    """
    if df is None or len(df) < n:
        return None
    
    df = df.copy()
    
    # è®¡ç®—Næ—¥å†…æœ€é«˜ä»·å’Œæœ€ä½ä»·
    df['HHV'] = df['æœ€é«˜'].rolling(window=n, min_periods=1).max()
    df['LLV'] = df['æœ€ä½'].rolling(window=n, min_periods=1).min()
    
    # è®¡ç®—RSV
    df['RSV'] = (df['æ”¶ç›˜'] - df['LLV']) / (df['HHV'] - df['LLV'] + 0.0001) * 100
    
    # è®¡ç®—Kå€¼ï¼ˆä½¿ç”¨SMAå¹³æ»‘ï¼‰
    # K = 2/3 * å‰ä¸€æ—¥K + 1/3 * RSV
    k_values = []
    d_values = []
    k = 50  # åˆå§‹Kå€¼
    d = 50  # åˆå§‹Då€¼
    
    for rsv in df['RSV']:
        k = (m1 - 1) / m1 * k + 1 / m1 * rsv
        d = (m2 - 1) / m2 * d + 1 / m2 * k
        k_values.append(k)
        d_values.append(d)
    
    df['K'] = k_values
    df['D'] = d_values
    df['J'] = 3 * df['K'] - 2 * df['D']
    
    # æ¸…ç†ä¸´æ—¶åˆ—
    df = df.drop(columns=['HHV', 'LLV', 'RSV'], errors='ignore')
    
    return df


def get_latest_kdj(df, n=9, m1=3, m2=3):
    """
    è·å–æœ€æ–°çš„KDJå€¼
    :return: dict {'K': x, 'D': y, 'J': z} æˆ– None
    """
    df_with_kdj = calculate_kdj(df, n, m1, m2)
    if df_with_kdj is None or len(df_with_kdj) == 0:
        return None
    
    last_row = df_with_kdj.iloc[-1]
    return {
        'K': round(last_row['K'], 2),
        'D': round(last_row['D'], 2),
        'J': round(last_row['J'], 2)
    }


# KDJæ‰«æè¿›åº¦å­˜å‚¨
kdj_scan_progress = {
    'status': 'idle',  # idle, running, completed, stopped
    'processed': 0,
    'total': 0,
    'found': 0,
    'percentage': 0,
    'current_stock': '',
    'message': '',
    'candidates': [],
    'threshold': 20,
    'limit': 50
}
kdj_scan_stop_flag = False


@app.route('/api/scan_kdj', methods=['POST'])
@require_login
def scan_kdj():
    """
    KDJæ¨¡å¼æ‰«æAPIï¼ˆå¯åŠ¨æ‰«æï¼‰
    ç­›é€‰æ—¥KDJã€å‘¨KDJã€æœˆKDJçš„Kã€Dã€Jå€¼éƒ½åœ¨æŒ‡å®šé˜ˆå€¼ä»¥ä¸‹çš„ä¸ªè‚¡
    """
    global kdj_scan_progress, kdj_scan_stop_flag
    
    try:
        data = request.get_json() or {}
        threshold = float(data.get('threshold', 20))  # KDJé˜ˆå€¼ï¼Œé»˜è®¤20
        limit = int(data.get('limit', 50))  # è¿”å›æ•°é‡é™åˆ¶
        max_workers = int(data.get('max_workers', 10))  # å¹¶å‘çº¿ç¨‹æ•°ï¼Œé»˜è®¤10ï¼ˆRenderç¯å¢ƒå»ºè®®5-10ï¼‰
        
        # Renderç¯å¢ƒè‡ªåŠ¨è°ƒæ•´çº¿ç¨‹æ•°
        if is_render:
            max_workers = min(max_workers, 10)  # Renderå…è´¹ç‰ˆé™åˆ¶
        
        # é‡ç½®è¿›åº¦å’Œåœæ­¢æ ‡å¿—
        kdj_scan_stop_flag = False
        kdj_scan_progress = {
            'status': 'running',
            'processed': 0,
            'total': 0,
            'found': 0,
            'percentage': 0,
            'current_stock': '',
            'message': 'æ­£åœ¨åˆå§‹åŒ–...',
            'candidates': [],
            'threshold': threshold,
            'limit': limit
        }
        
        print(f"\nğŸ” KDJæ¨¡å¼æ‰«æå¼€å§‹...")
        print(f"   é˜ˆå€¼: K,D,J < {threshold}")
        print(f"   å¹¶å‘çº¿ç¨‹æ•°: {max_workers}")
        
        # å¯åŠ¨åå°çº¿ç¨‹æ‰§è¡Œæ‰«æ
        import threading
        scan_thread = threading.Thread(target=_kdj_scan_worker, args=(threshold, limit, max_workers))
        scan_thread.daemon = True
        scan_thread.start()
        
        return jsonify({
            'success': True,
            'message': 'KDJæ‰«æå·²å¯åŠ¨'
        })
        
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"KDJæ‰«æå¯åŠ¨é”™è¯¯: {error_detail}")
        return jsonify({
            'success': False,
            'message': f'æ‰«æå¯åŠ¨å¤±è´¥: {str(e)}'
        }), 500


def _load_daily_kline_from_cache(code, cache_dir):
    """ä»æœ¬åœ°ç¼“å­˜åŠ è½½æ—¥Kçº¿æ•°æ®"""
    csv_path = os.path.join(cache_dir, 'daily_kline', f'{code}.csv')
    if os.path.exists(csv_path):
        try:
            df = pd.read_csv(csv_path)
            if 'æ—¥æœŸ' in df.columns:
                df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
                df = df.dropna(subset=['æ—¥æœŸ']).sort_values('æ—¥æœŸ').reset_index(drop=True)
            return df
        except Exception:
            return None
    return None


def _load_weekly_kline_from_cache(code, cache_dir):
    """ä»æœ¬åœ°ç¼“å­˜åŠ è½½å‘¨Kçº¿æ•°æ®"""
    csv_path = os.path.join(cache_dir, 'weekly_kline', f'{code}.csv')
    json_path = os.path.join(cache_dir, 'weekly_kline', f'{code}.json')
    
    if os.path.exists(csv_path):
        try:
            df = pd.read_csv(csv_path)
            if 'æ—¥æœŸ' in df.columns:
                df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
                df = df.dropna(subset=['æ—¥æœŸ']).sort_values('æ—¥æœŸ').reset_index(drop=True)
            return df
        except Exception:
            pass
    
    if os.path.exists(json_path):
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            df = pd.DataFrame(data)
            if 'æ—¥æœŸ' in df.columns:
                df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
                df = df.dropna(subset=['æ—¥æœŸ']).sort_values('æ—¥æœŸ').reset_index(drop=True)
            return df
        except Exception:
            pass
    
    return None


def _generate_monthly_kline_from_daily(daily_df):
    """ä»æ—¥Kçº¿ç”ŸæˆæœˆKçº¿æ•°æ®"""
    if daily_df is None or len(daily_df) < 30:
        return None
    
    try:
        df = daily_df.copy()
        
        # ç¡®ä¿æ—¥æœŸåˆ—æ˜¯datetimeç±»å‹
        if 'æ—¥æœŸ' not in df.columns:
            return None
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
        df = df.dropna(subset=['æ—¥æœŸ'])
        
        # æå–å¹´æœˆ
        df['å¹´æœˆ'] = df['æ—¥æœŸ'].dt.to_period('M')
        
        # æŒ‰æœˆèšåˆ
        monthly_data = []
        for period, group in df.groupby('å¹´æœˆ'):
            monthly_data.append({
                'æ—¥æœŸ': period.to_timestamp(),
                'å¼€ç›˜': group['å¼€ç›˜'].iloc[0],
                'æ”¶ç›˜': group['æ”¶ç›˜'].iloc[-1],
                'æœ€é«˜': group['æœ€é«˜'].max(),
                'æœ€ä½': group['æœ€ä½'].min(),
                'æˆäº¤é‡': group['æˆäº¤é‡'].sum() if 'æˆäº¤é‡' in group.columns else 0
            })
        
        monthly_df = pd.DataFrame(monthly_data)
        monthly_df = monthly_df.sort_values('æ—¥æœŸ').reset_index(drop=True)
        return monthly_df
    except Exception:
        return None


def _kdj_scan_worker(threshold, limit, max_workers=10):
    """KDJæ‰«æå·¥ä½œçº¿ç¨‹ - ä½¿ç”¨æœ¬åœ°ç¼“å­˜æ•°æ®ï¼Œå¹¶è¡Œå¤„ç†"""
    global kdj_scan_progress, kdj_scan_stop_flag
    
    try:
        from concurrent.futures import ThreadPoolExecutor, as_completed
        import threading
        
        # è·å–è‚¡ç¥¨åˆ—è¡¨
        cache_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'cache')
        stock_list_path = os.path.join(cache_dir, 'stock_list_all.json')
        
        if os.path.exists(stock_list_path):
            with open(stock_list_path, 'r', encoding='utf-8') as f:
                stock_list = json.load(f)
        else:
            kdj_scan_progress['status'] = 'completed'
            kdj_scan_progress['message'] = 'æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨ï¼Œè¯·å…ˆä¸‹è½½æœ¬åœ°æ•°æ®'
            return
        
        candidates = []
        candidates_lock = threading.Lock()  # çº¿ç¨‹é”
        total = len(stock_list)
        kdj_scan_progress['total'] = total
        kdj_scan_progress['message'] = f'ä½¿ç”¨æœ¬åœ°ç¼“å­˜æ•°æ®å¹¶è¡Œæ‰«æä¸­... ({max_workers} çº¿ç¨‹)'
        
        processed_count = 0
        processed_lock = threading.Lock()  # è¿›åº¦æ›´æ–°é”
        
        def process_single_stock(stock_info):
            """å¤„ç†å•åªè‚¡ç¥¨"""
            nonlocal processed_count
            
            if kdj_scan_stop_flag:
                return None
            
            if isinstance(stock_info, dict):
                code = stock_info.get('code', stock_info.get('è‚¡ç¥¨ä»£ç ', ''))
                name = stock_info.get('name', stock_info.get('è‚¡ç¥¨åç§°', ''))
            else:
                return None
            
            # æ’é™¤STå’ŒåŒ—äº¤æ‰€
            if 'ST' in name.upper() or code.startswith('8') or code.startswith('9'):
                with processed_lock:
                    processed_count += 1
                    kdj_scan_progress['processed'] = processed_count
                    kdj_scan_progress['percentage'] = round(processed_count / total * 100, 1)
                return None
            
            try:
                # ä»æœ¬åœ°ç¼“å­˜è·å–æ—¥Kçº¿æ•°æ®
                daily_df = _load_daily_kline_from_cache(code, cache_dir)
                if daily_df is None or len(daily_df) < 30:
                    with processed_lock:
                        processed_count += 1
                        kdj_scan_progress['processed'] = processed_count
                        kdj_scan_progress['percentage'] = round(processed_count / total * 100, 1)
                    return None
                
                # è®¡ç®—æ—¥KDJ
                daily_kdj = get_latest_kdj(daily_df, 9, 3, 3)
                if daily_kdj is None:
                    with processed_lock:
                        processed_count += 1
                        kdj_scan_progress['processed'] = processed_count
                        kdj_scan_progress['percentage'] = round(processed_count / total * 100, 1)
                    return None
                
                # å¿«é€Ÿç­›é€‰ï¼šå¦‚æœæ—¥KDJä¸æ»¡è¶³æ¡ä»¶ï¼Œè·³è¿‡
                if daily_kdj['K'] >= threshold or daily_kdj['D'] >= threshold or daily_kdj['J'] >= threshold:
                    with processed_lock:
                        processed_count += 1
                        kdj_scan_progress['processed'] = processed_count
                        kdj_scan_progress['percentage'] = round(processed_count / total * 100, 1)
                    return None
                
                # ä»æœ¬åœ°ç¼“å­˜è·å–å‘¨Kçº¿æ•°æ®
                weekly_df = _load_weekly_kline_from_cache(code, cache_dir)
                if weekly_df is None or len(weekly_df) < 20:
                    with processed_lock:
                        processed_count += 1
                        kdj_scan_progress['processed'] = processed_count
                        kdj_scan_progress['percentage'] = round(processed_count / total * 100, 1)
                    return None
                
                # è®¡ç®—å‘¨KDJ
                weekly_kdj = get_latest_kdj(weekly_df, 9, 3, 3)
                if weekly_kdj is None:
                    with processed_lock:
                        processed_count += 1
                        kdj_scan_progress['processed'] = processed_count
                        kdj_scan_progress['percentage'] = round(processed_count / total * 100, 1)
                    return None
                
                # æ£€æŸ¥å‘¨KDJ
                if weekly_kdj['K'] >= threshold or weekly_kdj['D'] >= threshold or weekly_kdj['J'] >= threshold:
                    with processed_lock:
                        processed_count += 1
                        kdj_scan_progress['processed'] = processed_count
                        kdj_scan_progress['percentage'] = round(processed_count / total * 100, 1)
                    return None
                
                # ä»æ—¥Kçº¿ç”ŸæˆæœˆKçº¿æ•°æ®
                monthly_df = _generate_monthly_kline_from_daily(daily_df)
                if monthly_df is None or len(monthly_df) < 12:
                    with processed_lock:
                        processed_count += 1
                        kdj_scan_progress['processed'] = processed_count
                        kdj_scan_progress['percentage'] = round(processed_count / total * 100, 1)
                    return None
                
                # è®¡ç®—æœˆKDJ
                monthly_kdj = get_latest_kdj(monthly_df, 9, 3, 3)
                if monthly_kdj is None:
                    with processed_lock:
                        processed_count += 1
                        kdj_scan_progress['processed'] = processed_count
                        kdj_scan_progress['percentage'] = round(processed_count / total * 100, 1)
                    return None
                
                # æ£€æŸ¥æœˆKDJ
                if monthly_kdj['K'] >= threshold or monthly_kdj['D'] >= threshold or monthly_kdj['J'] >= threshold:
                    with processed_lock:
                        processed_count += 1
                        kdj_scan_progress['processed'] = processed_count
                        kdj_scan_progress['percentage'] = round(processed_count / total * 100, 1)
                    return None
                
                # å…¨éƒ¨é€šè¿‡ï¼åˆ›å»ºå€™é€‰å¯¹è±¡
                current_price = float(daily_df.iloc[-1]['æ”¶ç›˜'])
                
                candidate = {
                    'è‚¡ç¥¨ä»£ç ': code,
                    'è‚¡ç¥¨åç§°': name,
                    'å½“å‰ä»·æ ¼': round(current_price, 2),
                    'æ—¥K': daily_kdj['K'],
                    'æ—¥D': daily_kdj['D'],
                    'æ—¥J': daily_kdj['J'],
                    'å‘¨K': weekly_kdj['K'],
                    'å‘¨D': weekly_kdj['D'],
                    'å‘¨J': weekly_kdj['J'],
                    'æœˆK': monthly_kdj['K'],
                    'æœˆD': monthly_kdj['D'],
                    'æœˆJ': monthly_kdj['J'],
                    'KDJå¹³å‡': round((daily_kdj['K'] + daily_kdj['D'] + weekly_kdj['K'] + weekly_kdj['D'] + monthly_kdj['K'] + monthly_kdj['D']) / 6, 2)
                }
                
                # æ›´æ–°è¿›åº¦
                with processed_lock:
                    processed_count += 1
                    kdj_scan_progress['processed'] = processed_count
                    kdj_scan_progress['percentage'] = round(processed_count / total * 100, 1)
                    kdj_scan_progress['current_stock'] = f"{code} {name}"
                
                print(f"   âœ… {code} {name}: æ—¥KDJ({daily_kdj['K']:.1f},{daily_kdj['D']:.1f},{daily_kdj['J']:.1f}) "
                      f"å‘¨KDJ({weekly_kdj['K']:.1f},{weekly_kdj['D']:.1f},{weekly_kdj['J']:.1f}) "
                      f"æœˆKDJ({monthly_kdj['K']:.1f},{monthly_kdj['D']:.1f},{monthly_kdj['J']:.1f})")
                
                return candidate
                
            except Exception as e:
                with processed_lock:
                    processed_count += 1
                    kdj_scan_progress['processed'] = processed_count
                    kdj_scan_progress['percentage'] = round(processed_count / total * 100, 1)
                return None
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†
        print(f"\nğŸš€ å¼€å§‹å¹¶è¡ŒKDJæ‰«æ ({max_workers} çº¿ç¨‹)...")
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = {executor.submit(process_single_stock, stock_info): stock_info for stock_info in stock_list}
            
            for future in as_completed(futures):
                if kdj_scan_stop_flag:
                    executor.shutdown(wait=False, cancel_futures=True)
                    kdj_scan_progress['status'] = 'stopped'
                    kdj_scan_progress['message'] = 'æ‰«æå·²åœæ­¢'
                    break
                
                candidate = future.result()
                if candidate:
                    with candidates_lock:
                        candidates.append(candidate)
                        kdj_scan_progress['found'] = len(candidates)
                        # åªä¿ç•™æœ€æ–°çš„å€™é€‰åˆ—è¡¨ï¼ˆé¿å…å†…å­˜è¿‡å¤§ï¼‰
                        if len(candidates) <= limit * 2:
                            kdj_scan_progress['candidates'] = candidates.copy()
        
        # æŒ‰KDJå¹³å‡å€¼æ’åºï¼ˆè¶Šå°è¶Šè¶…å–ï¼‰
        candidates.sort(key=lambda x: x['KDJå¹³å‡'])
        
        # é™åˆ¶è¿”å›æ•°é‡
        if limit > 0:
            candidates = candidates[:limit]
        
        # æ›´æ–°æœ€ç»ˆç»“æœ
        if not kdj_scan_stop_flag:
            kdj_scan_progress['status'] = 'completed'
        kdj_scan_progress['candidates'] = candidates
        kdj_scan_progress['found'] = len(candidates)
        kdj_scan_progress['message'] = f'æ‰«æå®Œæˆï¼Œæ‰¾åˆ° {len(candidates)} åªç¬¦åˆæ¡ä»¶çš„ä¸ªè‚¡'
        
        print(f"\nâœ… KDJæ¨¡å¼æ‰«æå®Œæˆ: å…±æ‰¾åˆ° {len(candidates)} åªç¬¦åˆæ¡ä»¶çš„ä¸ªè‚¡")
        
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"KDJæ‰«æå·¥ä½œçº¿ç¨‹é”™è¯¯: {error_detail}")
        kdj_scan_progress['status'] = 'completed'
        kdj_scan_progress['message'] = f'æ‰«æå‡ºé”™: {str(e)}'


@app.route('/api/get_kdj_scan_progress', methods=['GET'])
@require_login
def get_kdj_scan_progress():
    """è·å–KDJæ‰«æè¿›åº¦"""
    global kdj_scan_progress
    return jsonify({
        'success': True,
        'status': kdj_scan_progress['status'],
        'processed': kdj_scan_progress['processed'],
        'total': kdj_scan_progress['total'],
        'found': kdj_scan_progress['found'],
        'percentage': kdj_scan_progress['percentage'],
        'current_stock': kdj_scan_progress['current_stock'],
        'message': kdj_scan_progress['message'],
        'threshold': kdj_scan_progress['threshold']
    })


@app.route('/api/get_kdj_scan_results', methods=['GET'])
@require_login
def get_kdj_scan_results():
    """è·å–KDJæ‰«æç»“æœ"""
    global kdj_scan_progress
    return jsonify({
        'success': True,
        'data': kdj_scan_progress['candidates'],
        'count': len(kdj_scan_progress['candidates']),
        'threshold': kdj_scan_progress['threshold'],
        'status': kdj_scan_progress['status'],
        'message': kdj_scan_progress['message']
    })


@app.route('/api/stop_kdj_scan', methods=['POST'])
@require_login
def stop_kdj_scan():
    """åœæ­¢KDJæ‰«æ"""
    global kdj_scan_stop_flag
    kdj_scan_stop_flag = True
    return jsonify({
        'success': True,
        'message': 'KDJæ‰«æåœæ­¢è¯·æ±‚å·²å‘é€'
    })


if __name__ == '__main__':
    import os
    import time
    
    # åœ¨ Render ç¯å¢ƒä¸­ï¼Œæ£€æŸ¥å¹¶ä¸‹è½½è‚¡ç¥¨æ•°æ®ï¼ˆå¦‚æœé…ç½®äº†ï¼‰
    if is_render or os.environ.get('STOCK_DATA_URL'):
        try:
            cache_dir = 'cache'
            stock_data_dir = 'stock_data'
            
            # æ£€æŸ¥æ•°æ®æ˜¯å¦å­˜åœ¨
            cache_exists = os.path.exists(cache_dir) and os.listdir(cache_dir) if os.path.exists(cache_dir) else False
            stock_exists = os.path.exists(stock_data_dir) and os.listdir(stock_data_dir) if os.path.exists(stock_data_dir) else False
            
            if not cache_exists and not stock_exists:
                data_url = os.environ.get('STOCK_DATA_URL')
                if data_url:
                    print("=" * 80)
                    print("ğŸ“¥ æ£€æµ‹åˆ° Render ç¯å¢ƒï¼Œå¼€å§‹ä¸‹è½½è‚¡ç¥¨æ•°æ®...")
                    print("=" * 80)
                    try:
                        from download_stock_data import main as download_main
                        download_main()
                    except Exception as e:
                        print(f"âš ï¸  ä¸‹è½½æ•°æ®å¤±è´¥: {e}")
                        print("   å°†ä½¿ç”¨ç½‘ç»œå®æ—¶è·å–æ•°æ®")
                else:
                    print("âš ï¸  æœªè®¾ç½® STOCK_DATA_URLï¼Œå°†ä½¿ç”¨ç½‘ç»œå®æ—¶è·å–æ•°æ®")
            else:
                print("âœ… è‚¡ç¥¨æ•°æ®å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½")
        except Exception as e:
            print(f"âš ï¸  æ•°æ®æ£€æŸ¥å¤±è´¥: {e}ï¼Œç»§ç»­å¯åŠ¨åº”ç”¨")
    
    # æ£€æµ‹æ˜¯å¦åœ¨Renderæˆ–å…¶ä»–äº‘å¹³å°ç¯å¢ƒ
    # Render é€šå¸¸ä¼šè®¾ç½® PORT ç¯å¢ƒå˜é‡ï¼Œå¦‚æœè®¾ç½®äº† PORTï¼Œè¯´æ˜åœ¨äº‘ç¯å¢ƒ
    port_env = os.environ.get('PORT')
    is_port_set = port_env is not None
    
    is_render = (
        os.environ.get('RENDER') == 'true' or
        os.environ.get('RENDER_SERVICE_NAME') is not None or
        os.environ.get('RENDER_SERVICE_ID') is not None or
        os.environ.get('RENDER_EXTERNAL_URL') is not None or
        os.environ.get('RENDER_EXTERNAL_HOSTNAME') is not None
    )
    is_vercel = (
        os.environ.get('VERCEL') == '1' or 
        os.environ.get('VERCEL_ENV') is not None or
        os.environ.get('VERCEL_URL') is not None
    )
    # å¦‚æœ PORT ç¯å¢ƒå˜é‡è¢«è®¾ç½®ï¼ˆé€šå¸¸æ˜¯äº‘å¹³å°ï¼‰ï¼Œæˆ–è€…æ£€æµ‹åˆ° Render/Vercelï¼Œè®¤ä¸ºæ˜¯äº‘ç¯å¢ƒ
    is_cloud = is_render or is_vercel or is_port_set
    
    # æ”¯æŒRenderç­‰å¹³å°ï¼šä»ç¯å¢ƒå˜é‡è·å–ç«¯å£ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤ç«¯å£5002
    port = int(os.environ.get('PORT', 5002))
    
    # åªåœ¨æœ¬åœ°ç¯å¢ƒæ£€æŸ¥å¹¶é‡Šæ”¾ç«¯å£ï¼ˆäº‘å¹³å°ä¸éœ€è¦ï¼‰
    if not is_cloud:
        import socket
        import subprocess
        
        # æ£€æŸ¥å¹¶é‡Šæ”¾ç«¯å£5002ï¼ˆåªç»ˆæ­¢å ç”¨ç«¯å£çš„è¿›ç¨‹ï¼Œé¿å… pkill è¯¯æ€å½“å‰å¯åŠ¨è¿›ç¨‹ï¼‰
        port = 5002
        
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.settimeout(1)
        result = sock.connect_ex(('127.0.0.1', port))
        sock.close()
        
        if result == 0:
            # ç«¯å£è¢«å ç”¨ï¼Œå¼ºåˆ¶é‡Šæ”¾
            print(f"âš ï¸  ç«¯å£{port}è¢«å ç”¨ï¼Œæ­£åœ¨å¼ºåˆ¶é‡Šæ”¾...")
            try:
                # æ–¹æ³•1: ä½¿ç”¨lsofæŸ¥æ‰¾å¹¶ç»ˆæ­¢
                if os.name == 'posix':  # Unix/Linux/Mac
                    result = subprocess.run(['lsof', '-ti', f':{port}'], 
                                          capture_output=True, text=True, timeout=2)
                    if result.returncode == 0 and result.stdout.strip():
                        pids = result.stdout.strip().split('\n')
                        for pid in pids:
                            try:
                                os.kill(int(pid), 9)
                                print(f"   âœ… å·²ç»ˆæ­¢è¿›ç¨‹ {pid}")
                            except Exception as e:
                                print(f"   âš ï¸  ç»ˆæ­¢è¿›ç¨‹{pid}å¤±è´¥: {e}")
                        time.sleep(1)
                        
                        # å†æ¬¡æ£€æŸ¥ç«¯å£æ˜¯å¦å·²é‡Šæ”¾
                        sock2 = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
                        sock2.settimeout(1)
                        result2 = sock2.connect_ex(('127.0.0.1', port))
                        sock2.close()
                        if result2 == 0:
                            print(f"   âŒ ç«¯å£{port}ä»è¢«å ç”¨ï¼Œè¯·æ‰‹åŠ¨æ£€æŸ¥")
                        else:
                            print(f"   âœ… ç«¯å£{port}å·²æˆåŠŸé‡Šæ”¾")
            except Exception as e:
                print(f"   âš ï¸  é‡Šæ”¾ç«¯å£å¤±è´¥: {e}")
    else:
        # äº‘ç¯å¢ƒï¼šè·³è¿‡ç«¯å£æ£€æŸ¥
        print("âš ï¸  æ£€æµ‹åˆ°äº‘ç¯å¢ƒï¼ˆRender/Vercelï¼‰ï¼Œè·³è¿‡æœ¬åœ°ç«¯å£æ£€æŸ¥å’Œé‡Šæ”¾ã€‚")
    
    print("=" * 80)
    print("å¤§ç‰›è‚¡åˆ†æå™¨Webç•Œé¢")
    print("=" * 80)
    
    print(f"è®¿é—®åœ°å€: http://0.0.0.0:{port}")
    print("=" * 80)
    
    # ä½¿ç”¨waitressæœåŠ¡å™¨ï¼ˆé¿å…macOSä¸Šçš„Werkzeugé”™è¯¯ï¼‰
    try:
        from waitress import serve
        print("ä½¿ç”¨WaitressæœåŠ¡å™¨å¯åŠ¨...")
        serve(app, host='0.0.0.0', port=port, threads=4)
    except ImportError:
        # å¦‚æœwaitressä¸å¯ç”¨ï¼Œä½¿ç”¨Flaskå¼€å‘æœåŠ¡å™¨
        print("âš ï¸  Waitressä¸å¯ç”¨ï¼Œä½¿ç”¨Flaskå¼€å‘æœåŠ¡å™¨...")
        # å¢åŠ è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼Œé¿å…é•¿æ—¶é—´æ‰«æä»»åŠ¡è¶…æ—¶
        import werkzeug.serving
        werkzeug.serving.WSGIRequestHandler.timeout = 60  # è®¾ç½®60ç§’è¶…æ—¶
        # ç›‘å¬æ‰€æœ‰ç½‘ç»œæ¥å£ï¼Œå…è®¸è¿œç¨‹è®¿é—®
        # å…³é—­debugæ¨¡å¼ï¼Œé¿å…è‡ªåŠ¨é‡å¯å¯¼è‡´çš„é—®é¢˜
        app.run(host='0.0.0.0', port=port, debug=False, threaded=True, use_reloader=False)

