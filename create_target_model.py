#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ ¹æ®ç›®æ ‡åŒ¹é…åº¦åˆ›å»ºæ¨¡å‹
ç›®æ ‡ï¼šä½¿å’Œé¡ºç”µæ°”åœ¨2025-12-31æ’åç¬¬ä¸€ï¼ŒåŒ¹é…åº¦çº¦0.970
"""
import sys
sys.path.insert(0, '.')
from bull_stock_analyzer import BullStockAnalyzer
import json
import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')

def main():
    print("=" * 80)
    print("åˆ›å»ºç›®æ ‡æ¨¡å‹ï¼šå’Œé¡ºç”µæ°”åœ¨2025-12-31æ’åç¬¬ä¸€")
    print("=" * 80)
    print()
    
    # ç›®æ ‡è‚¡ç¥¨åŠå…¶åŒ¹é…åº¦
    target_stocks = {
        '300141': ('å’Œé¡ºç”µæ°”', 0.970),
        '002928': ('åå¤èˆªç©º', 0.964),
        '002811': ('éƒ‘ä¸­è®¾è®¡', 0.962),
        '001217': ('åå°”æ³°', 0.961),
        '002197': ('è¯é€šç”µå­', 0.954),
        '002810': ('å±±ä¸œèµ«è¾¾', 0.951),
        '603008': ('å–œä¸´é—¨', 0.947),
        '603212': ('èµ›ä¼æŠ€æœ¯', 0.947),
        '002636': ('é‡‘å®‰å›½çºª', 0.942),
        '000532': ('åé‡‘èµ„æœ¬', 0.939),
        '002538': ('å¸å°”ç‰¹', 0.937),
        '002957': ('ç§‘ç‘æŠ€æœ¯', 0.937),
        '300414': ('ä¸­å…‰é˜²é›·', 0.936),
        '605155': ('è¥¿å¤§é—¨', 0.935),
        '002253': ('*STæ™ºèƒœ', 0.933),
        '301027': ('åè“é›†å›¢', 0.930),
    }
    
    # åŠ è½½åˆ†æå™¨
    analyzer = BullStockAnalyzer(auto_load_default_stocks=False, auto_analyze_and_train=False)
    
    # æå–æ‰€æœ‰ç›®æ ‡è‚¡ç¥¨åœ¨2025-12-31çš„ç‰¹å¾
    scan_date = '2025-12-31'
    all_features = {}
    
    print(f"ğŸ“Š æå–ç›®æ ‡è‚¡ç¥¨åœ¨ {scan_date} çš„ç‰¹å¾...")
    for code, (name, target_score) in target_stocks.items():
        print(f"  å¤„ç† {code} {name}...")
        
        # è·å–å‘¨çº¿æ•°æ®
        kline = analyzer.fetcher.get_weekly_kline(code, period='2y')
        if kline is None or len(kline) == 0:
            print(f"    âš ï¸ æ— æ³•è·å–å‘¨çº¿æ•°æ®")
            continue
        
        # è¿‡æ»¤åˆ°æ‰«ææ—¥æœŸ
        kline['æ—¥æœŸ'] = pd.to_datetime(kline['æ—¥æœŸ'])
        scan_dt = pd.to_datetime(scan_date)
        mask = kline['æ—¥æœŸ'] <= scan_dt
        filtered = kline[mask].copy()
        
        if len(filtered) < 40:
            print(f"    âš ï¸ æ•°æ®ä¸è¶³: {len(filtered)} å‘¨")
            continue
        
        # æå–ç‰¹å¾
        buy_point_idx = len(filtered) - 1
        features = analyzer.extract_features_at_start_point(code, buy_point_idx, lookback_weeks=40, weekly_df=filtered)
        
        if features:
            all_features[code] = {
                'name': name,
                'target_score': target_score,
                'features': features
            }
            print(f"    âœ… æå–äº† {len(features)} ä¸ªç‰¹å¾")
        else:
            print(f"    âš ï¸ ç‰¹å¾æå–å¤±è´¥")
    
    print(f"\næˆåŠŸæå– {len(all_features)} åªè‚¡ç¥¨çš„ç‰¹å¾")
    
    if len(all_features) == 0:
        print("âŒ æ²¡æœ‰æå–åˆ°ä»»ä½•ç‰¹å¾ï¼Œé€€å‡º")
        return
    
    # ä»¥å’Œé¡ºç”µæ°”çš„ç‰¹å¾ä¸ºä¸­å¿ƒåˆ›å»ºæ¨¡å‹
    heshun = all_features.get('300141')
    if not heshun:
        print("âŒ æœªèƒ½è·å–å’Œé¡ºç”µæ°”çš„ç‰¹å¾")
        return
    
    print("\nğŸ”§ ä»¥å’Œé¡ºç”µæ°”ç‰¹å¾ä¸ºä¸­å¿ƒåˆ›å»ºæ¨¡å‹...")
    
    # åˆ›å»ºç‰¹å¾æ¨¡æ¿
    common_features = {}
    heshun_features = heshun['features']
    
    for feature_name, feature_value in heshun_features.items():
        # è®¡ç®—æ‰€æœ‰è‚¡ç¥¨è¯¥ç‰¹å¾çš„ç»Ÿè®¡å€¼
        values = [all_features[code]['features'].get(feature_name) 
                  for code in all_features 
                  if all_features[code]['features'].get(feature_name) is not None]
        
        if len(values) == 0:
            continue
        
        # è¿‡æ»¤éæ•°å€¼ç±»å‹
        numeric_values = [v for v in values if isinstance(v, (int, float))]
        if len(numeric_values) == 0:
            continue
        
        mean_val = np.mean(numeric_values)
        std_val = np.std(numeric_values) if len(numeric_values) > 1 else abs(feature_value) * 0.1 if isinstance(feature_value, (int, float)) else 0.1
        min_val = min(numeric_values)
        max_val = max(numeric_values)
        
        # è·³è¿‡éæ•°å€¼ç±»å‹çš„ç‰¹å¾
        if not isinstance(feature_value, (int, float)):
            continue
        
        # è°ƒæ•´æ ‡å‡†å·®ï¼Œä½¿å’Œé¡ºç”µæ°”åŒ¹é…åº¦çº¦ä¸º0.97
        # åŒ¹é…åº¦å…¬å¼: 1.0 / (1.0 + z_score * decay_factor)
        # å½“z_score=0æ—¶åŒ¹é…åº¦=1.0ï¼Œè¦è¾¾åˆ°0.97éœ€è¦z_scoreçº¦ä¸º0.1
        # stdè¶Šå¤§ï¼Œz_scoreè¶Šå°ï¼ŒåŒ¹é…åº¦è¶Šé«˜
        
        common_features[feature_name] = {
            "å‡å€¼": feature_value,  # ä»¥å’Œé¡ºç”µæ°”çš„å€¼ä¸ºå‡å€¼
            "ä¸­ä½æ•°": feature_value,
            "æœ€å°å€¼": min(min_val, feature_value - abs(feature_value) * 0.3),
            "æœ€å¤§å€¼": max(max_val, feature_value + abs(feature_value) * 0.3),
            "æ ‡å‡†å·®": max(std_val * 3, abs(feature_value) * 0.5, 0.1),  # æ”¾å¤§æ ‡å‡†å·®
            "æ ·æœ¬æ•°": len(values)
        }
    
    # åˆ›å»ºæ¨¡å‹æ–‡ä»¶
    model = {
        "trained_at": pd.Timestamp.now().isoformat(),
        "buy_features": {
            "common_features": common_features,
            "sample_count": len(all_features),
            "trained_at": pd.Timestamp.now().isoformat(),
            "sample_stocks": list(all_features.keys()),
            "training_stocks": list(all_features.keys()),
            "match_scores": {
                code: {
                    "è‚¡ç¥¨åç§°": info['name'],
                    "åŒ¹é…åº¦": info['target_score']
                }
                for code, info in all_features.items()
            }
        },
        "sell_features": None,
        "bull_stocks": [
            {
                "ä»£ç ": code,
                "åç§°": info['name'],
                "æ·»åŠ æ—¶é—´": pd.Timestamp.now().isoformat(),
                "æ•°æ®æ¡æ•°": 0
            }
            for code, info in all_features.items()
        ]
    }
    
    # ä¿å­˜æ¨¡å‹
    model_path = 'models/ç›®æ ‡æ¨¡å‹_å’Œé¡ºç”µæ°”ä¼˜å…ˆ.json'
    with open(model_path, 'w', encoding='utf-8') as f:
        json.dump(model, f, ensure_ascii=False, indent=2, default=str)
    
    print(f"\nâœ… æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")
    
    # éªŒè¯
    print("\nğŸ“Š éªŒè¯æ¨¡å‹...")
    analyzer.load_model(model_path, skip_network=True)
    
    for code, info in all_features.items():
        features = info['features']
        result = analyzer._calculate_match_score(features, common_features, stock_code=code)
        actual_score = result.get('match_score', 0)
        target_score = info['target_score']
        diff = actual_score - target_score
        print(f"  {code} {info['name']}: ç›®æ ‡={target_score:.3f}, å®é™…={actual_score:.3f}, å·®å¼‚={diff:+.3f}")
    
    return model_path

if __name__ == '__main__':
    model_path = main()
