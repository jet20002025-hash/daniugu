#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é‡æ–°è®­ç»ƒæ¨¡å‹ï¼Œæ’é™¤è¡¨ç°å·®çš„è‚¡ç¥¨ï¼ˆåˆå¯Œä¸­å›½ã€åç«‹è‚¡ä»½ï¼‰
åŸºäº11æœˆ21æ—¥æ‰«æå‡ºçš„è¡¨ç°å¥½çš„è‚¡ç¥¨é‡æ–°è®­ç»ƒ
"""
import sys
sys.path.insert(0, '.')
from bull_stock_analyzer import BullStockAnalyzer
import json
import os
from datetime import datetime

def main():
    print("=" * 100)
    print("ğŸš€ é‡æ–°è®­ç»ƒæ¨¡å‹ï¼ˆæ’é™¤è¡¨ç°å·®çš„è‚¡ç¥¨ï¼šåˆå¯Œä¸­å›½ã€åç«‹è‚¡ä»½ï¼‰")
    print("=" * 100)
    
    # 1. è¯»å–å½“å‰è®­ç»ƒæ¨¡å‹ï¼Œè·å–22åªè‚¡ç¥¨åˆ—è¡¨
    print("\nğŸ“– è¯»å–å½“å‰è®­ç»ƒæ¨¡å‹ï¼Œè·å–22åªè‚¡ç¥¨åˆ—è¡¨...")
    trained_model_path = 'trained_model.json'
    if not os.path.exists(trained_model_path):
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶ {trained_model_path}")
        return
    
    with open(trained_model_path, 'r', encoding='utf-8') as f:
        model_data = json.load(f)
    
    buy_features = model_data.get('buy_features', {})
    all_22_stocks = buy_features.get('training_stocks', [])
    
    if len(all_22_stocks) != 22:
        print(f"âš ï¸ è­¦å‘Šï¼šè®­ç»ƒè‚¡ç¥¨æ•°ä¸æ˜¯22åªï¼Œè€Œæ˜¯ {len(all_22_stocks)} åª")
        print(f"ç»§ç»­ä½¿ç”¨è¿™ {len(all_22_stocks)} åªè‚¡ç¥¨è¿›è¡Œè®­ç»ƒ...")
    
    print(f"è®­ç»ƒè‚¡ç¥¨æ•°: {len(all_22_stocks)} åª")
    print(f"è‚¡ç¥¨åˆ—è¡¨: {', '.join(all_22_stocks)}")
    
    # åªæ’é™¤åç«‹è‚¡ä»½ï¼ˆåˆå¯Œä¸­å›½çš„ä¹°ç‚¹åœ¨2025å¹´10æœˆå·¦å³ï¼Œä¸æ˜¯11æœˆ21æ—¥ï¼Œå¯ä»¥è®­ç»ƒï¼‰
    exclude_stocks = ['603038']  # åªæ’é™¤åç«‹è‚¡ä»½
    training_stocks = [s for s in all_22_stocks if s not in exclude_stocks]
    
    print(f"\næ’é™¤è‚¡ç¥¨: {', '.join(exclude_stocks)} (è¡¨ç°å·®)")
    print(f"ç”¨äºè®­ç»ƒçš„è‚¡ç¥¨: {len(training_stocks)} åªï¼ˆåŒ…å«åˆå¯Œä¸­å›½ï¼Œä½†éœ€è¦æ‰¾åˆ°2025å¹´10æœˆå·¦å³çš„ä¹°ç‚¹ï¼‰")
    
    if len(training_stocks) < 3:
        print(f"\nâŒ é”™è¯¯ï¼šç”¨äºè®­ç»ƒçš„è‚¡ç¥¨æ•°é‡å¤ªå°‘ï¼ˆ{len(training_stocks)}åªï¼‰ï¼Œæ— æ³•è®­ç»ƒæ¨¡å‹")
        return
    
    # 2. åˆ›å»ºåˆ†æå™¨
    print("\nğŸ”§ åˆå§‹åŒ–åˆ†æå™¨...")
    analyzer = BullStockAnalyzer(auto_load_default_stocks=False, auto_analyze_and_train=False)
    
    # æ¸…ç©ºç°æœ‰æ•°æ®
    analyzer.analysis_results = {}
    analyzer.trained_features = None
    analyzer.bull_stocks = []
    
    # 3. åˆ†ææ‰€æœ‰è‚¡ç¥¨ï¼Œæ‰¾åˆ°æœ€ä½³ä¹°ç‚¹
    # å¯¹äºåˆå¯Œä¸­å›½ï¼ˆ603122ï¼‰ï¼Œéœ€è¦æ‰¾åˆ°2025å¹´10æœˆå·¦å³çš„ä¹°ç‚¹
    # å¯¹äºå…¶ä»–è‚¡ç¥¨ï¼ŒæŸ¥æ‰¾å†å²æœ€ä½³ä¹°ç‚¹ï¼ˆ8å‘¨å†…æ¶¨å¹…è¾¾åˆ°300%ï¼‰
    print("\n" + "=" * 100)
    print("ğŸ“Š æ­¥éª¤1: åˆ†ææ‰€æœ‰è‚¡ç¥¨ï¼Œæ‰¾åˆ°æœ€ä½³ä¹°ç‚¹")
    print("=" * 100)
    
    valid_stocks = []
    
    for i, stock_code in enumerate(training_stocks, 1):
        stock_name = analyzer._get_stock_name(stock_code) or stock_code
        print(f"\n[{i}/{len(training_stocks)}] å¤„ç† {stock_code} {stock_name}...")
        
        try:
            # è·å–å‘¨Kçº¿æ•°æ®
            weekly_df = analyzer.fetcher.get_weekly_kline(stock_code, period="3y")
            
            if weekly_df is None or len(weekly_df) < 8:
                print(f"  âš ï¸ æ— æ³•è·å–è¶³å¤Ÿçš„å‘¨çº¿æ•°æ®")
                continue
            
            # å¯¹äºåˆå¯Œä¸­å›½ï¼ˆ603122ï¼‰ï¼Œéœ€è¦æ‰¾åˆ°2025å¹´10æœˆå·¦å³çš„ä¹°ç‚¹
            if stock_code == '603122':
                print(f"  ğŸ“ åˆå¯Œä¸­å›½ï¼šæŸ¥æ‰¾2025å¹´10æœˆå·¦å³çš„ä¹°ç‚¹...")
                import pandas as pd
                from datetime import datetime, timedelta
                
                # æ‰¾åˆ°2025å¹´10æœˆå¯¹åº”çš„å‘¨Kçº¿
                target_date_start = datetime(2025, 10, 1).date()
                target_date_end = datetime(2025, 10, 31).date()
                
                if 'æ—¥æœŸ' in weekly_df.columns:
                    weekly_df['æ—¥æœŸ_date'] = pd.to_datetime(weekly_df['æ—¥æœŸ']).dt.date
                    
                    # æŸ¥æ‰¾10æœˆèŒƒå›´å†…çš„å‘¨Kçº¿
                    october_indices = []
                    for j in range(len(weekly_df)):
                        week_date = weekly_df.iloc[j]['æ—¥æœŸ_date']
                        if target_date_start <= week_date <= target_date_end:
                            october_indices.append(j)
                    
                    if not october_indices:
                        print(f"  âš ï¸ æœªæ‰¾åˆ°2025å¹´10æœˆçš„å‘¨Kçº¿æ•°æ®")
                        continue
                    
                    # åœ¨10æœˆèŒƒå›´å†…æŸ¥æ‰¾æœ€ä½³ä¹°ç‚¹ï¼ˆ8å‘¨å†…æ¶¨å¹…è¾¾åˆ°300%ï¼‰
                    valid_intervals = []
                    for start_idx in october_indices:
                        if start_idx + 8 > len(weekly_df):
                            continue
                        start_price = float(weekly_df.iloc[start_idx]['æ”¶ç›˜'])
                        interval_df = weekly_df.iloc[start_idx:min(start_idx + 9, len(weekly_df))]
                        max_price = float(interval_df['æœ€é«˜'].max())
                        gain = (max_price - start_price) / start_price * 100
                        
                        if gain >= 300.0:
                            valid_intervals.append({
                                'èµ·ç‚¹ç´¢å¼•': start_idx,
                                'ç»ˆç‚¹ç´¢å¼•': min(start_idx + 8, len(weekly_df) - 1),
                                'æ¶¨å¹…': gain,
                                'å‘¨æ•°': min(8, len(weekly_df) - start_idx - 1)
                            })
                    
                    if not valid_intervals:
                        print(f"  âš ï¸ åœ¨2025å¹´10æœˆæœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„ä¹°ç‚¹ï¼ˆ8å‘¨å†…æ¶¨å¹…>=300%ï¼‰")
                        # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œä½¿ç”¨10æœˆç¬¬ä¸€ä¸ªå‘¨Kçº¿ä½œä¸ºä¹°ç‚¹
                        best_start_idx = min(october_indices)
                        print(f"  ğŸ’¡ ä½¿ç”¨10æœˆç¬¬ä¸€ä¸ªå‘¨Kçº¿ä½œä¸ºä¹°ç‚¹: ç´¢å¼• {best_start_idx}")
                    else:
                        # æ‰¾åˆ°æ¶¨å¹…æœ€å¤§çš„åŒºé—´
                        best_interval = max(valid_intervals, key=lambda x: x['æ¶¨å¹…'])
                        best_start_idx = best_interval['èµ·ç‚¹ç´¢å¼•']
                else:
                    print(f"  âš ï¸ å‘¨Kçº¿æ•°æ®æ ¼å¼é”™è¯¯")
                    continue
            else:
                # å¯¹äºå…¶ä»–è‚¡ç¥¨ï¼ŒæŸ¥æ‰¾å†å²æœ€ä½³ä¹°ç‚¹ï¼ˆ8å‘¨å†…æ¶¨å¹…è¾¾åˆ°300%ï¼‰
                valid_intervals = []
                for start_idx in range(len(weekly_df) - 8):
                    for end_idx in range(start_idx + 1, min(start_idx + 9, len(weekly_df))):
                        start_price = float(weekly_df.iloc[start_idx]['æ”¶ç›˜'])
                        interval_df = weekly_df.iloc[start_idx:end_idx]
                        max_price = float(interval_df['æœ€é«˜'].max())
                        gain = (max_price - start_price) / start_price * 100
                        
                        if gain >= 300.0:
                            valid_intervals.append({
                                'èµ·ç‚¹ç´¢å¼•': start_idx,
                                'ç»ˆç‚¹ç´¢å¼•': end_idx,
                                'æ¶¨å¹…': gain,
                                'å‘¨æ•°': end_idx - start_idx
                            })
                
                if not valid_intervals:
                    print(f"  âš ï¸ æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„ä¹°ç‚¹ï¼ˆ8å‘¨å†…æ¶¨å¹…>=300%ï¼‰")
                    continue
                
                # æ‰¾åˆ°æ¶¨å¹…æœ€å¤§çš„åŒºé—´
                best_interval = max(valid_intervals, key=lambda x: x['æ¶¨å¹…'])
                best_start_idx = best_interval['èµ·ç‚¹ç´¢å¼•']
            
            # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ•°æ®ï¼ˆè‡³å°‘20å‘¨ï¼‰
            if best_start_idx < 20:
                print(f"  âš ï¸ èµ·ç‚¹ç´¢å¼• {best_start_idx} < 20ï¼Œæ•°æ®ä¸è¶³ï¼Œè·³è¿‡")
                continue
            
            # æ ¹æ®å®é™…å¯ç”¨å‘¨æ•°è°ƒæ•´lookback_weeks
            actual_lookback = min(best_start_idx, 40)
            
            # æå–ç‰¹å¾
            features = analyzer.extract_features_at_start_point(
                stock_code, best_start_idx, lookback_weeks=actual_lookback, weekly_df=weekly_df
            )
            
            if not features:
                print(f"  âš ï¸ æ— æ³•æå–ç‰¹å¾")
                continue
            
            # è·å–ä¹°ç‚¹æ—¥æœŸå’Œä»·æ ¼
            buy_date = weekly_df.iloc[best_start_idx]['æ—¥æœŸ']
            if hasattr(buy_date, 'strftime'):
                buy_date_str = buy_date.strftime('%Y-%m-%d')
            else:
                buy_date_str = str(buy_date)
            buy_price = float(weekly_df.iloc[best_start_idx]['æ”¶ç›˜'])
            
            # è®°å½•å…³é”®ç‰¹å¾ï¼ˆç”¨äºä¿¡æ¯å±•ç¤ºï¼‰
            profit_chips = features.get('ç›ˆåˆ©ç­¹ç æ¯”ä¾‹')
            chip_concentration_90 = features.get('90%æˆæœ¬é›†ä¸­åº¦')
            price_position = features.get('ä»·æ ¼ç›¸å¯¹ä½ç½®')
            
            # è®¡ç®—æ¶¨å¹…ï¼ˆå¦‚æœæ˜¯åˆå¯Œä¸­å›½ä¸”æ²¡æœ‰æ‰¾åˆ°300%æ¶¨å¹…çš„åŒºé—´ï¼Œä½¿ç”¨åç»­8å‘¨çš„æœ€å¤§æ¶¨å¹…ï¼‰
            if stock_code == '603122' and 'best_interval' not in locals():
                # è®¡ç®—åç»­8å‘¨çš„æœ€å¤§æ¶¨å¹…
                if best_start_idx + 8 < len(weekly_df):
                    start_price = buy_price
                    interval_df = weekly_df.iloc[best_start_idx:best_start_idx + 8]
                    max_price = float(interval_df['æœ€é«˜'].max())
                    gain = (max_price - start_price) / start_price * 100
                    weeks = 8
                else:
                    gain = 0
                    weeks = 0
            else:
                gain = best_interval['æ¶¨å¹…']
                weeks = best_interval['å‘¨æ•°']
            
            print(f"  âœ… æ‰¾åˆ°æœ€ä½³ä¹°ç‚¹: {buy_date_str}, ä»·æ ¼: {buy_price:.2f}, æ¶¨å¹…: {gain:.2f}%")
            print(f"     ç›ˆåˆ©ç­¹ç æ¯”ä¾‹: {profit_chips:.2f}%, 90%æˆæœ¬é›†ä¸­åº¦: {chip_concentration_90:.2f}%, ä»·æ ¼ç›¸å¯¹ä½ç½®: {price_position:.2f}%")
            
            # æ·»åŠ åˆ°åˆ†æç»“æœ
            analyzer.analysis_results[stock_code] = {
                'stock_info': {
                    'ä»£ç ': stock_code,
                    'åç§°': stock_name
                },
                'interval': {
                    'èµ·ç‚¹ç´¢å¼•': best_start_idx,
                    'èµ·ç‚¹æ—¥æœŸ': buy_date_str,
                    'èµ·ç‚¹ä»·æ ¼': round(buy_price, 2),
                    'æ¶¨å¹…': round(gain, 2),
                    'å‘¨æ•°': weeks
                },
                'features': features  # ç‰¹å¾å°†åœ¨train_featuresä¸­æå–
            }
            
            valid_stocks.append(stock_code)
                
        except Exception as e:
            print(f"  âŒ å¤„ç† {stock_code} æ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            continue
    
    print(f"\nâœ… æˆåŠŸåˆ†æ {len(valid_stocks)} åªè‚¡ç¥¨")
    
    if len(valid_stocks) == 0:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„è®­ç»ƒæ ·æœ¬ï¼Œæ— æ³•è®­ç»ƒæ¨¡å‹")
        return
    
    # 4. è®­ç»ƒæ¨¡å‹ï¼ˆä½¿ç”¨è°ƒæ•´æƒé‡åçš„å‚æ•°ï¼Œå¹¶è¿›ä¸€æ­¥å¼ºåŒ–å…³é”®ç‰¹å¾ï¼‰
    print("\n" + "=" * 100)
    print("ğŸ¯ æ­¥éª¤3: è®­ç»ƒæ¨¡å‹ï¼ˆè¿›ä¸€æ­¥å¼ºåŒ–å…³é”®ç‰¹å¾ï¼‰")
    print("=" * 100)
    print("æ ¸å¿ƒç‰¹å¾ï¼ˆæƒé‡4.0ï¼‰ï¼šç›ˆåˆ©ç­¹ç æ¯”ä¾‹ã€ä»·æ ¼ç›¸å¯¹ä½ç½®ã€90%æˆæœ¬é›†ä¸­åº¦")
    print("æ™®é€šç‰¹å¾ï¼ˆæƒé‡1.0ï¼‰ï¼šå…¶ä»–ç‰¹å¾")
    print("è®­ç»ƒæ ·æœ¬ï¼šåªä½¿ç”¨è¡¨ç°å¥½çš„è‚¡ç¥¨ï¼ˆæ’é™¤åˆå¯Œä¸­å›½ã€åç«‹è‚¡ä»½ç­‰è¡¨ç°å·®çš„è‚¡ç¥¨ï¼‰")
    
    train_result = analyzer.train_features()
    
    if train_result.get('success'):
        print("\n" + "=" * 100)
        print("âœ… æ¨¡å‹è®­ç»ƒæˆåŠŸï¼")
        print("=" * 100)
        
        # ä¿å­˜æ¨¡å‹
        output_file = 'trained_model_exclude_bad.json'
        analyzer.save_model(output_file)
        print(f"\næ¨¡å‹å·²ä¿å­˜åˆ°: {output_file}")
        
        # åŒæ—¶ä¿å­˜ä¸ºä¼˜åŒ–æ¨¡å‹
        import shutil
        models_dir = 'models'
        if not os.path.exists(models_dir):
            os.makedirs(models_dir, exist_ok=True)
        optimized_model_path = os.path.join(models_dir, 'ä¼˜åŒ–æ¨¡å‹.json')
        shutil.copy(output_file, optimized_model_path)
        print(f"æ¨¡å‹å·²å¤åˆ¶åˆ°: {optimized_model_path}")
        
        # éªŒè¯è®­ç»ƒç»“æœ
        print("\n" + "=" * 100)
        print("ğŸ“Š æ­¥éª¤3: éªŒè¯è®­ç»ƒç»“æœ")
        print("=" * 100)
        
        match_scores_info = train_result.get('match_scores', {})
        all_pass = train_result.get('all_pass', False)
        
        if match_scores_info:
            print(f"\nè®­ç»ƒæ ·æœ¬åŒ¹é…åº¦ï¼ˆç›®æ ‡ï¼šæ‰€æœ‰æ ·æœ¬ >= 0.95ï¼‰:")
            for stock_code, match_info in match_scores_info.items():
                stock_name = match_info.get('è‚¡ç¥¨åç§°', stock_code)
                total_match = match_info.get('åŒ¹é…åº¦', 0)
                is_pass = match_info.get('è¾¾æ ‡', False)
                
                status = "âœ…" if is_pass else "âš ï¸"
                print(f"{status} {stock_code} {stock_name}: {total_match:.3f}")
            
            all_match_values = [m.get('åŒ¹é…åº¦', 0) for m in match_scores_info.values()]
            avg_match = sum(all_match_values) / len(all_match_values) if all_match_values else 0
            min_match = min(all_match_values) if all_match_values else 0
            max_match = max(all_match_values) if all_match_values else 0
            above_095 = sum(1 for m in match_scores_info.values() if m.get('è¾¾æ ‡', False))
            
            print(f"\nğŸ“ˆ åŒ¹é…åº¦ç»Ÿè®¡:")
            print(f"   å¹³å‡åŒ¹é…åº¦: {avg_match:.3f}")
            print(f"   æœ€ä½åŒ¹é…åº¦: {min_match:.3f}")
            print(f"   æœ€é«˜åŒ¹é…åº¦: {max_match:.3f}")
            print(f"   åŒ¹é…åº¦>=0.95: {above_095}/{len(match_scores_info)} åª")
            
            if above_095 == len(match_scores_info):
                print(f"\nâœ… æ‰€æœ‰ {len(match_scores_info)} åªè‚¡ç¥¨çš„åŒ¹é…åº¦éƒ½ >= 0.95ï¼")
            else:
                print(f"\nâš ï¸ æœ‰ {len(match_scores_info) - above_095} åªè‚¡ç¥¨çš„åŒ¹é…åº¦ < 0.95")
        
        # ä¿å­˜è®­ç»ƒç»“æœæ‘˜è¦
        summary = {
            'è®­ç»ƒæ—¶é—´': datetime.now().isoformat(),
            'è®­ç»ƒæ ·æœ¬æ•°': len(analyzer.analysis_results),
            'è®­ç»ƒè‚¡ç¥¨': list(analyzer.analysis_results.keys()),
            'æ’é™¤è‚¡ç¥¨': exclude_stocks,
            'ç‰¹å¾æ•°é‡': len(analyzer.trained_features.get('common_features', {})) if analyzer.trained_features else 0,
            'è®­ç»ƒç»“æœ': {
                'success': train_result.get('success', False),
                'message': train_result.get('message', ''),
                'sample_count': train_result.get('sample_count', 0),
                'all_pass': train_result.get('all_pass', False),
                'iterations': train_result.get('iterations', 0)
            },
            'åŒ¹é…åº¦ç»Ÿè®¡': {
                'å¹³å‡åŒ¹é…åº¦': round(avg_match, 3) if match_scores_info else 0,
                'æœ€ä½åŒ¹é…åº¦': round(min_match, 3) if match_scores_info else 0,
                'æœ€é«˜åŒ¹é…åº¦': round(max_match, 3) if match_scores_info else 0,
                'åŒ¹é…åº¦>=0.95æ•°é‡': above_095 if match_scores_info else 0,
                'æ€»æ ·æœ¬æ•°': len(match_scores_info) if match_scores_info else len(analyzer.analysis_results)
            } if match_scores_info else {}
        }
        
        summary_file = 'retrain_exclude_bad_summary.json'
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        
        print(f"\nè®­ç»ƒæ‘˜è¦å·²ä¿å­˜åˆ°: {summary_file}")
        
    else:
        print("\n" + "=" * 100)
        print("âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥")
        print("=" * 100)
        print(f"é”™è¯¯ä¿¡æ¯: {train_result.get('message', 'æœªçŸ¥é”™è¯¯')}")

if __name__ == '__main__':
    main()
