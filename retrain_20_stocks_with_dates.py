#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„20åªè‚¡ç¥¨åŠå…¶æœ€ä½³ä¹°ç‚¹æ—¥æœŸé‡æ–°è®­ç»ƒæ¨¡å‹
"""

import sys
import json
from datetime import datetime
from bull_stock_analyzer import BullStockAnalyzer

def main():
    print("=" * 80)
    print("ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„20åªè‚¡ç¥¨åŠå…¶æœ€ä½³ä¹°ç‚¹æ—¥æœŸé‡æ–°è®­ç»ƒæ¨¡å‹")
    print("=" * 80)
    
    # ç”¨æˆ·æŒ‡å®šçš„è‚¡ç¥¨ä»£ç å’Œæœ€ä½³ä¹°ç‚¹æ—¥æœŸ
    training_stocks = [
        {'code': '300489', 'buy_date': '2024-09-18'},
        {'code': '300377', 'buy_date': '2024-09-19'},
        {'code': '000062', 'buy_date': '2024-08-14'},
        {'code': '688656', 'buy_date': '2024-10-23'},
        {'code': '688585', 'buy_date': '2025-06-30'},
        {'code': '300436', 'buy_date': '2025-07-03'},
        {'code': '001331', 'buy_date': '2025-12-04'},
        {'code': '002094', 'buy_date': '2024-09-24'},
        {'code': '300251', 'buy_date': '2025-02-05'},
        {'code': '688165', 'buy_date': '2024-11-04'},
        {'code': '301292', 'buy_date': '2025-09-29'},
        {'code': '605225', 'buy_date': '2025-08-14'},
        {'code': '300077', 'buy_date': '2024-09-27'},
        {'code': '688108', 'buy_date': '2025-08-06'},
        {'code': '603268', 'buy_date': '2024-09-25'},
        {'code': '300204', 'buy_date': '2025-05-20'},
        {'code': '002969', 'buy_date': '2025-12-08'},
        {'code': '603122', 'buy_date': '2025-10-27'},
        {'code': '000759', 'buy_date': '2025-12-02'},
        {'code': '002628', 'buy_date': '2024-09-24'},
    ]
    
    # åˆå§‹åŒ–åˆ†æå™¨
    analyzer = BullStockAnalyzer(auto_load_default_stocks=False, auto_analyze_and_train=False)
    
    # æå–æ‰€æœ‰è‚¡ç¥¨çš„ç‰¹å¾
    all_features_list = []
    stock_codes = []
    
    print(f"\nğŸ“Š å¼€å§‹æå– {len(training_stocks)} åªè‚¡ç¥¨çš„æœ€ä½³ä¹°ç‚¹ç‰¹å¾...")
    
    for idx, stock_info in enumerate(training_stocks, 1):
        stock_code = stock_info['code']
        buy_date = stock_info['buy_date']
        stock_codes.append(stock_code)
        
        print(f"\n[{idx}/{len(training_stocks)}] å¤„ç† {stock_code} (æœ€ä½³ä¹°ç‚¹: {buy_date})")
        
        try:
            # ä½¿ç”¨æ—¥çº¿æ•°æ®ï¼Œèšåˆä¸ºå‘¨çº¿æ•°æ®ï¼Œç„¶åæå–ç‰¹å¾ï¼ˆæä¾›æ›´å¤šå†å²æ•°æ®ï¼‰
            print(f"  ğŸ“Š è·å–æ—¥Kçº¿æ•°æ®...")
            daily_df = analyzer.fetcher.get_daily_kline(stock_code, period="3y")
            if daily_df is None or len(daily_df) == 0:
                print(f"  âš ï¸ æ— æ³•è·å– {stock_code} çš„æ—¥Kçº¿æ•°æ®ï¼Œè·³è¿‡")
                continue
            
            # å¤„ç†æ—¥æœŸåˆ—
            if 'æ—¥æœŸ' in daily_df.columns:
                daily_df['æ—¥æœŸ'] = pd.to_datetime(daily_df['æ—¥æœŸ'])
                daily_df = daily_df.sort_values('æ—¥æœŸ').reset_index(drop=True)
            
            # æ‰¾åˆ°æœ€ä½³ä¹°ç‚¹æ—¥æœŸå¯¹åº”çš„ç´¢å¼•ï¼ˆæ—¥çº¿æ•°æ®ï¼Œç²¾ç¡®åŒ¹é…ï¼‰
            from datetime import datetime as dt
            buy_date_obj = dt.strptime(buy_date, '%Y-%m-%d').date()
            buy_idx_daily = None
            
            for i in range(len(daily_df)):
                row_date = daily_df.iloc[i]['æ—¥æœŸ']
                if isinstance(row_date, pd.Timestamp):
                    row_date = row_date.date()
                elif isinstance(row_date, str):
                    row_date = dt.strptime(row_date, '%Y-%m-%d').date()
                else:
                    continue
                
                # ç²¾ç¡®åŒ¹é…æ—¥æœŸï¼ˆæ—¥çº¿æ•°æ®å¯ä»¥ç²¾ç¡®åŒ¹é…ï¼‰
                if row_date == buy_date_obj:
                    buy_idx_daily = i
                    break
            
            if buy_idx_daily is None:
                print(f"  âš ï¸ åœ¨æ—¥Kçº¿æ•°æ®ä¸­æ‰¾ä¸åˆ° {buy_date} å¯¹åº”çš„æ—¥æœŸï¼Œè·³è¿‡")
                continue
            
            # è·å–è¯¥æ—¥æœŸçš„æ”¶ç›˜ä»·ä½œä¸ºæœ€ä½³ä¹°ç‚¹ä»·æ ¼
            buy_price = float(daily_df.iloc[buy_idx_daily]['æ”¶ç›˜'])
            actual_date = daily_df.iloc[buy_idx_daily]['æ—¥æœŸ']
            if isinstance(actual_date, pd.Timestamp):
                actual_date_str = actual_date.strftime('%Y-%m-%d')
            else:
                actual_date_str = str(actual_date)
            
            print(f"  âœ… æ‰¾åˆ°ä¹°ç‚¹: æ—¥æœŸ {actual_date_str}, ä»·æ ¼ {buy_price:.2f} å…ƒ")
            print(f"  ğŸ“Š ä¹°ç‚¹å‰å¯ç”¨æ•°æ®: {buy_idx_daily} ä¸ªäº¤æ˜“æ—¥ï¼ˆçº¦ {buy_idx_daily // 5} å‘¨ï¼‰")
            
            # å°†æ—¥çº¿æ•°æ®èšåˆä¸ºå‘¨çº¿æ•°æ®ï¼ˆä»æœ€æ—©æ•°æ®åˆ°ä¹°ç‚¹æ—¥æœŸï¼‰
            print(f"  ğŸ“Š å°†æ—¥çº¿æ•°æ®èšåˆä¸ºå‘¨çº¿æ•°æ®...")
            daily_to_use = daily_df.iloc[:buy_idx_daily + 1].copy()  # åŒ…å«ä¹°ç‚¹å½“æ—¥
            
            # èšåˆä¸ºå‘¨çº¿æ•°æ®
            weekly_df = analyzer.fetcher._aggregate_daily_to_weekly(daily_to_use)
            
            if weekly_df is None or len(weekly_df) == 0:
                print(f"  âš ï¸ èšåˆå‘¨çº¿æ•°æ®å¤±è´¥ï¼Œè·³è¿‡")
                continue
            
            # æ‰¾åˆ°ä¹°ç‚¹æ—¥æœŸå¯¹åº”çš„å‘¨çº¿ç´¢å¼•
            buy_idx_weekly = None
            for i in range(len(weekly_df)):
                row_date = weekly_df.iloc[i]['æ—¥æœŸ']
                if isinstance(row_date, pd.Timestamp):
                    row_date = row_date.date()
                elif isinstance(row_date, str):
                    row_date = dt.strptime(row_date, '%Y-%m-%d').date()
                else:
                    continue
                
                # å…è®¸æ—¥æœŸåŒ¹é…æœ‰ä¸€å®šçš„å®¹å·®ï¼ˆÂ±7å¤©ï¼‰ï¼Œå› ä¸ºå‘¨Kçº¿çš„æ—¥æœŸå¯èƒ½æ˜¯å‘¨å†…ä»»æ„ä¸€å¤©
                if abs((row_date - buy_date_obj).days) <= 7:
                    buy_idx_weekly = i
                    break
            
            if buy_idx_weekly is None:
                print(f"  âš ï¸ åœ¨èšåˆçš„å‘¨Kçº¿æ•°æ®ä¸­æ‰¾ä¸åˆ° {buy_date} å¯¹åº”çš„æ—¥æœŸï¼Œè·³è¿‡")
                continue
            
            print(f"  âœ… å‘¨çº¿æ•°æ®: å…± {len(weekly_df)} å‘¨ï¼Œä¹°ç‚¹ç´¢å¼•: {buy_idx_weekly}")
            print(f"  ğŸ“Š ä¹°ç‚¹å‰å¯ç”¨å‘¨æ•°: {buy_idx_weekly} å‘¨")
            
            # ä¼˜åŒ–ç‰¹å¾èµ·ç‚¹é€‰æ‹©é€»è¾‘ï¼šä¼˜å…ˆä¿è¯æœ‰è¶³å¤Ÿçš„å†å²æ•°æ®
            # ç­–ç•¥1ï¼šå°è¯•æŸ¥æ‰¾æˆäº¤é‡çªå¢ç‚¹ï¼ˆä½†è¦æ±‚è‡³å°‘æœ‰5å‘¨å†å²æ•°æ®ï¼‰
            volume_surge_idx = analyzer.find_volume_surge_point(
                stock_code, buy_idx_weekly, weekly_df=weekly_df,
                min_volume_ratio=2.0, lookback_weeks=min(40, buy_idx_weekly)
            )
            
            # ç­–ç•¥2ï¼šå¦‚æœæ‰¾åˆ°æˆäº¤é‡çªå¢ç‚¹ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿå†å²æ•°æ®
            if volume_surge_idx is not None and volume_surge_idx >= 5:
                # æˆäº¤é‡çªå¢ç‚¹æœ‰è‡³å°‘5å‘¨å†å²æ•°æ®ï¼Œå¯ä»¥ä½¿ç”¨
                feature_start_idx = volume_surge_idx
            else:
                # ç­–ç•¥3ï¼šä½¿ç”¨ä¹°ç‚¹å‰å°½å¯èƒ½å¤šçš„å‘¨æ•°ï¼Œä½†è‡³å°‘ä¿ç•™5å‘¨å†å²æ•°æ®
                # ä¼˜å…ˆä½¿ç”¨20å‘¨ï¼Œå¦‚æœä¸å¤Ÿåˆ™ä½¿ç”¨æ‰€æœ‰å¯ç”¨æ•°æ®ï¼ˆè‡³å°‘5å‘¨ï¼‰
                preferred_weeks = min(20, buy_idx_weekly - 5)  # ä¿ç•™è‡³å°‘5å‘¨å†å²æ•°æ®
                if preferred_weeks >= 5:
                    feature_start_idx = max(0, buy_idx_weekly - preferred_weeks)
                else:
                    # å¦‚æœä¹°ç‚¹å‰æ•°æ®ä¸è¶³20å‘¨ï¼Œä½¿ç”¨æ‰€æœ‰å¯ç”¨æ•°æ®ï¼ˆè‡³å°‘5å‘¨ï¼‰
                    feature_start_idx = max(0, buy_idx_weekly - max(5, buy_idx_weekly - 5))
            
            # è®¡ç®—å®é™…å¯ç”¨çš„å†å²å‘¨æ•°
            available_weeks = buy_idx_weekly - feature_start_idx
            
            # ç¡®ä¿è‡³å°‘æœ‰5å‘¨å†å²æ•°æ®ï¼ˆå¦‚æœæ•°æ®ä¸è¶³ï¼Œä½¿ç”¨æ‰€æœ‰å¯ç”¨æ•°æ®ï¼‰
            if available_weeks < 5:
                feature_start_idx = max(0, buy_idx_weekly - max(5, buy_idx_weekly))
                available_weeks = buy_idx_weekly - feature_start_idx
            
            # å¦‚æœä»ç„¶ä¸è¶³5å‘¨ï¼Œè‡³å°‘ä½¿ç”¨1å‘¨ï¼ˆå…è®¸æå–éƒ¨åˆ†ç‰¹å¾ï¼‰
            if available_weeks < 1:
                feature_start_idx = max(0, buy_idx_weekly - 1)
                available_weeks = buy_idx_weekly - feature_start_idx
            
            lookback_weeks = min(40, available_weeks)  # ä½¿ç”¨å®é™…å¯ç”¨çš„å‘¨æ•°ï¼Œæœ€å¤š40å‘¨
            
            print(f"  ğŸ“ ç‰¹å¾æå–èµ·ç‚¹: ç´¢å¼• {feature_start_idx} (ä¹°ç‚¹å‰ {available_weeks} å‘¨ï¼Œå›çœ‹ {lookback_weeks} å‘¨)")
            
            # å¦‚æœå†å²æ•°æ®ä¸è¶³ï¼Œå…ˆå°è¯•æå‰ä¹°ç‚¹æ—¥æœŸ
            if available_weeks < 5:
                print(f"  âš ï¸ {stock_code} å†å²æ•°æ®ä¸è¶³ï¼ˆåªæœ‰{available_weeks}å‘¨ï¼‰ï¼Œå°è¯•æå‰ä¹°ç‚¹æ—¥æœŸ...")
                should_retry = True
            else:
                should_retry = False
                # æå–ç‰¹å¾ï¼ˆä½¿ç”¨å‘¨çº¿æ•°æ®ï¼Œä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
                try:
                    features = analyzer.extract_features_at_start_point(
                        stock_code, feature_start_idx, lookback_weeks=lookback_weeks, weekly_df=weekly_df
                    )
                except Exception as e:
                    print(f"  âš ï¸ æå–ç‰¹å¾æ—¶å‡ºé”™: {e}")
                    import traceback
                    traceback.print_exc()
                    features = None
                    should_retry = True
            
            # å¦‚æœç‰¹å¾æå–å¤±è´¥æˆ–æ•°æ®ä¸è¶³ï¼Œå°è¯•æå‰ä¹°ç‚¹æ—¥æœŸ
            if should_retry or (features is None or len(features) == 0):
                if features is None or len(features) == 0:
                    print(f"  âš ï¸ æ— æ³•æå– {stock_code} çš„ç‰¹å¾ï¼Œå°è¯•æå‰ä¹°ç‚¹æ—¥æœŸ...")
                else:
                    print(f"  âš ï¸ {stock_code} å†å²æ•°æ®ä¸è¶³ï¼ˆåªæœ‰{available_weeks}å‘¨ï¼‰ï¼Œå°è¯•æå‰ä¹°ç‚¹æ—¥æœŸ...")
                
                # å°è¯•æå‰ä¹°ç‚¹æ—¥æœŸï¼ˆæœ€å¤šæå‰7å¤©ï¼Œä½†åœ¨ä¸€å‘¨å†…ï¼‰
                from datetime import timedelta
                retry_success = False
                
                for days_back in range(1, 8):  # æå‰1-7å¤©
                    try_buy_date_obj = buy_date_obj - timedelta(days=days_back)
                    try_buy_date_str = try_buy_date_obj.strftime('%Y-%m-%d')
                    
                    # é‡æ–°æŸ¥æ‰¾ä¹°ç‚¹æ—¥æœŸå¯¹åº”çš„ç´¢å¼•ï¼ˆæ—¥çº¿æ•°æ®ï¼‰
                    try_buy_idx_daily = None
                    for i in range(len(daily_df)):
                        row_date = daily_df.iloc[i]['æ—¥æœŸ']
                        if isinstance(row_date, pd.Timestamp):
                            row_date = row_date.date()
                        elif isinstance(row_date, str):
                            row_date = dt.strptime(row_date, '%Y-%m-%d').date()
                        else:
                            continue
                        
                        if row_date == try_buy_date_obj:
                            try_buy_idx_daily = i
                            break
                    
                    if try_buy_idx_daily is None:
                        continue
                    
                    # é‡æ–°èšåˆå‘¨çº¿æ•°æ®
                    daily_to_use_retry = daily_df.iloc[:try_buy_idx_daily + 1].copy()
                    weekly_df_retry = analyzer.fetcher._aggregate_daily_to_weekly(daily_to_use_retry)
                    
                    if weekly_df_retry is None or len(weekly_df_retry) == 0:
                        continue
                    
                    # æ‰¾åˆ°ä¹°ç‚¹æ—¥æœŸå¯¹åº”çš„å‘¨çº¿ç´¢å¼•
                    try_buy_idx_weekly = None
                    for i in range(len(weekly_df_retry)):
                        row_date = weekly_df_retry.iloc[i]['æ—¥æœŸ']
                        if isinstance(row_date, pd.Timestamp):
                            row_date = row_date.date()
                        elif isinstance(row_date, str):
                            row_date = dt.strptime(row_date, '%Y-%m-%d').date()
                        else:
                            continue
                        
                        if abs((row_date - try_buy_date_obj).days) <= 7:
                            try_buy_idx_weekly = i
                            break
                    
                    if try_buy_idx_weekly is None:
                        continue
                    
                    # é‡æ–°é€‰æ‹©ç‰¹å¾èµ·ç‚¹
                    volume_surge_idx_retry = analyzer.find_volume_surge_point(
                        stock_code, try_buy_idx_weekly, weekly_df=weekly_df_retry,
                        min_volume_ratio=2.0, lookback_weeks=min(40, try_buy_idx_weekly)
                    )
                    
                    if volume_surge_idx_retry is not None and volume_surge_idx_retry >= 5:
                        feature_start_idx_retry = volume_surge_idx_retry
                    else:
                        if try_buy_idx_weekly >= 25:
                            feature_start_idx_retry = try_buy_idx_weekly - 20
                        elif try_buy_idx_weekly >= 10:
                            feature_start_idx_retry = try_buy_idx_weekly - 5
                        else:
                            feature_start_idx_retry = 0
                    
                    available_weeks_retry = try_buy_idx_weekly - feature_start_idx_retry
                    if available_weeks_retry < 1:
                        feature_start_idx_retry = max(0, try_buy_idx_weekly - 1)
                        available_weeks_retry = try_buy_idx_weekly - feature_start_idx_retry
                    
                    lookback_weeks_retry = min(40, available_weeks_retry)
                    
                    # å°è¯•æå–ç‰¹å¾
                    try:
                        features_retry = analyzer.extract_features_at_start_point(
                            stock_code, feature_start_idx_retry, lookback_weeks=lookback_weeks_retry, weekly_df=weekly_df_retry
                        )
                        
                        if features_retry is not None and len(features_retry) > 0:
                            print(f"  âœ… æå‰ {days_back} å¤©åæˆåŠŸæå–ç‰¹å¾ï¼ˆæ–°ä¹°ç‚¹æ—¥æœŸ: {try_buy_date_str}ï¼‰")
                            features = features_retry
                            buy_idx_weekly = try_buy_idx_weekly
                            feature_start_idx = feature_start_idx_retry
                            actual_date_str = try_buy_date_str
                            buy_price = float(daily_df.iloc[try_buy_idx_daily]['æ”¶ç›˜'])
                            retry_success = True
                            break
                    except Exception:
                        continue
                
                if not retry_success:
                    print(f"  âš ï¸ å³ä½¿æå‰ä¹°ç‚¹æ—¥æœŸä¹Ÿæ— æ³•æå– {stock_code} çš„ç‰¹å¾ï¼Œè·³è¿‡")
                    continue
            
            # æ·»åŠ è‚¡ç¥¨ä»£ç å’Œä¹°ç‚¹ä¿¡æ¯
            features['_stock_code'] = stock_code
            features['_buy_date'] = actual_date_str
            features['_buy_price'] = buy_price
            features['_buy_idx'] = buy_idx_weekly  # ä½¿ç”¨å‘¨çº¿ç´¢å¼•
            features['è‚¡ç¥¨ä»£ç '] = stock_code
            features['è‚¡ç¥¨åç§°'] = analyzer._get_stock_name(stock_code) or stock_code
            
            all_features_list.append(features)
            print(f"  âœ… æˆåŠŸæå–ç‰¹å¾ï¼Œå…± {len(features)} ä¸ªç‰¹å¾")
            
            # å°†ç‰¹å¾æ•°æ®æ”¾å…¥analysis_resultsä¸­ï¼Œä¾›train_featuresä½¿ç”¨
            # ä½¿ç”¨å‘¨çº¿ç´¢å¼•ï¼ˆfeature_start_idxå’Œbuy_idx_weeklyéƒ½æ˜¯å‘¨çº¿ç´¢å¼•ï¼‰
            # åŒæ—¶ä¿å­˜èšåˆçš„å‘¨çº¿æ•°æ®ï¼Œä¾›train_featuresé˜¶æ®µä½¿ç”¨
            analyzer.analysis_results[stock_code] = {
                'interval': {
                    'èµ·ç‚¹ç´¢å¼•': feature_start_idx,  # å‘¨çº¿ç´¢å¼•
                    'ç»ˆç‚¹ç´¢å¼•': buy_idx_weekly,  # å‘¨çº¿ç´¢å¼•
                    'æ¶¨å¹…': 0,  # è¿™é‡Œä¸éœ€è¦å®é™…æ¶¨å¹…ï¼Œåªæ˜¯å ä½
                    'å‘¨æ•°': buy_idx_weekly - feature_start_idx
                },
                'features': features,
                '_weekly_df': weekly_df  # ä¿å­˜èšåˆçš„å‘¨çº¿æ•°æ®ï¼Œä¾›train_featuresé˜¶æ®µä½¿ç”¨
            }
            
        except Exception as e:
            print(f"  âŒ å¤„ç† {stock_code} æ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            continue
    
    if len(all_features_list) == 0:
        print("\nâŒ æ²¡æœ‰æˆåŠŸæå–ä»»ä½•è‚¡ç¥¨çš„ç‰¹å¾ï¼Œæ— æ³•è®­ç»ƒæ¨¡å‹")
        return
    
    print(f"\nâœ… æˆåŠŸæå– {len(all_features_list)} åªè‚¡ç¥¨çš„ç‰¹å¾")
    print(f"ğŸ“Š å¼€å§‹è®­ç»ƒæ¨¡å‹ï¼Œç›®æ ‡åŒ¹é…åº¦: 0.95...")
    
    # è®­ç»ƒæ¨¡å‹ï¼ˆtrain_featuresä¼šä»analysis_resultsä¸­è¯»å–æ•°æ®ï¼‰
    train_result = analyzer.train_features()
    
    if not train_result.get('success'):
        print(f"\nâŒ è®­ç»ƒå¤±è´¥: {train_result.get('message', 'æœªçŸ¥é”™è¯¯')}")
        return
    
    # train_featureså·²ç»è‡ªåŠ¨è¿­ä»£è®­ç»ƒï¼Œç¡®ä¿æ‰€æœ‰è®­ç»ƒæ ·æœ¬åŒ¹é…åº¦>=0.95
    # è¿™é‡Œåªéœ€è¦éªŒè¯æœ€ç»ˆç»“æœ
    print(f"\nğŸ“Š éªŒè¯æœ€ç»ˆè®­ç»ƒç»“æœ...")
    common_features = analyzer.trained_features.get('common_features')
    match_scores = {}
    
    # ä»train_resultä¸­è·å–åŒ¹é…åº¦ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if train_result.get('match_scores'):
        match_scores = {code: info.get('åŒ¹é…åº¦', 0.0) for code, info in train_result.get('match_scores', {}).items()}
    else:
        # å¦‚æœæ²¡æœ‰ï¼Œé‡æ–°è®¡ç®—
        for features in all_features_list:
            stock_code = features.get('_stock_code')
            match_result = analyzer._calculate_match_score(
                features, common_features, tolerance=0.3, stock_code=stock_code
            )
            match_score = round(float(match_result.get('æ€»åŒ¹é…åº¦', 0.0)), 3)
            match_scores[stock_code] = match_score
    
    # æ˜¾ç¤ºåŒ¹é…åº¦ï¼ˆæŒ‰åŒ¹é…åº¦æ’åºï¼‰
    print(f"\nåŒ¹é…åº¦åˆ—è¡¨ï¼ˆæŒ‰åŒ¹é…åº¦ä»é«˜åˆ°ä½ï¼‰:")
    for code, score in sorted(match_scores.items(), key=lambda x: x[1], reverse=True):
        status = "âœ…" if score >= 0.95 else "âš ï¸"
        print(f"  {status} {code}: {score:.3f}")
    
    # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰è‚¡ç¥¨éƒ½è¾¾åˆ°0.95
    target_score = 0.95
    all_above_095 = train_result.get('all_pass', False) or all(score >= target_score for score in match_scores.values())
    
    if all_above_095:
        print(f"\nâœ… æ‰€æœ‰ {len(match_scores)} åªè‚¡ç¥¨çš„åŒ¹é…åº¦éƒ½è¾¾åˆ° {target_score} ä»¥ä¸Šï¼")
    else:
        below_095 = [code for code, score in match_scores.items() if score < target_score]
        print(f"\nâš ï¸ ä»¥ä¸‹ {len(below_095)} åªè‚¡ç¥¨çš„åŒ¹é…åº¦æœªè¾¾åˆ° {target_score}:")
        for code in sorted(below_095, key=lambda x: match_scores[x]):
            print(f"  {code}: {match_scores[code]:.3f}")
        
        print(f"\nğŸ’¡ æç¤ºï¼šç»è¿‡ {train_result.get('iterations', 1)} æ¬¡è¿­ä»£è®­ç»ƒï¼Œä»æœ‰éƒ¨åˆ†è‚¡ç¥¨çš„åŒ¹é…åº¦æœªè¾¾åˆ°ç›®æ ‡ã€‚")
        print(f"   è¿™å¯èƒ½æ˜¯ç”±äºè¿™äº›è‚¡ç¥¨çš„ç‰¹å¾ä¸è®­ç»ƒæ ·æœ¬å·®å¼‚è¾ƒå¤§ã€‚")
        print(f"   å¯ä»¥è€ƒè™‘ï¼š")
        print(f"   1. å¢åŠ æ›´å¤šç±»ä¼¼çš„è®­ç»ƒæ ·æœ¬")
        print(f"   2. è°ƒæ•´ç‰¹å¾æƒé‡")
        print(f"   3. æ£€æŸ¥ç‰¹å¾æå–é€»è¾‘")
    
    # æ³¨æ„ï¼štrain_featureså·²ç»è‡ªåŠ¨è¿­ä»£è®­ç»ƒï¼Œç¡®ä¿æ‰€æœ‰è®­ç»ƒæ ·æœ¬åŒ¹é…åº¦>=0.95
    # ä¸Šé¢çš„éªŒè¯å·²ç»æ˜¾ç¤ºäº†æœ€ç»ˆç»“æœï¼Œè¿™é‡Œä¸éœ€è¦é‡å¤éªŒè¯
    
    # ä¿å­˜æ¨¡å‹
    model_name = "ç”¨æˆ·æŒ‡å®š20åªè‚¡ç¥¨æ¨¡å‹"
    model_path = f"models/{model_name}.json"
    
    # å‡†å¤‡ä¿å­˜çš„æ•°æ®
    save_data = {
        'model_name': model_name,
        'training_time': datetime.now().isoformat(),
        'training_stocks': stock_codes,
        'stock_buy_points': [
            {
                'stock_code': features.get('_stock_code'),
                'buy_date': features.get('_buy_date'),
                'buy_price': features.get('_buy_price')
            }
            for features in all_features_list
        ],
        'common_features': common_features,
        'match_scores': match_scores,
        'sample_count': len(all_features_list),
        'min_match_score': min(match_scores.values()) if match_scores else 0,
        'max_match_score': max(match_scores.values()) if match_scores else 0,
        'avg_match_score': sum(match_scores.values()) / len(match_scores) if match_scores else 0
    }
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    import os
    os.makedirs('models', exist_ok=True)
    
    with open(model_path, 'w', encoding='utf-8') as f:
        json.dump(save_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")
    print(f"\nğŸ“Š è®­ç»ƒæ‘˜è¦:")
    print(f"  è®­ç»ƒè‚¡ç¥¨æ•°: {len(stock_codes)}")
    print(f"  æˆåŠŸæå–ç‰¹å¾: {len(all_features_list)}")
    print(f"  æœ€ä½åŒ¹é…åº¦: {min(match_scores.values()):.3f}" if match_scores else "  N/A")
    print(f"  æœ€é«˜åŒ¹é…åº¦: {max(match_scores.values()):.3f}" if match_scores else "  N/A")
    print(f"  å¹³å‡åŒ¹é…åº¦: {sum(match_scores.values()) / len(match_scores):.3f}" if match_scores else "  N/A")
    
    # ä¿å­˜è®­ç»ƒæ‘˜è¦
    summary_path = f"retrain_20_stocks_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(summary_path, 'w', encoding='utf-8') as f:
        json.dump(save_data, f, ensure_ascii=False, indent=2)
    print(f"  è®­ç»ƒæ‘˜è¦å·²ä¿å­˜åˆ°: {summary_path}")

if __name__ == '__main__':
    import pandas as pd
    main()
