#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸‹è½½ä»2022å¹´å¼€å§‹çš„æ‰€æœ‰Aè‚¡ä¸ªè‚¡æ•°æ®ï¼ˆæ—¥K + å‘¨Kï¼‰
ä½¿ç”¨æ–°æµªè´¢ç»APIï¼Œdatalen æ‹‰è¶³è¦†ç›– 2022 è‡³ä»Šï¼Œåªä¿ç•™ 2022-01-01 åŠä¹‹åçš„æ•°æ®ã€‚

è‹¥é‡ã€Œæ‹’ç»è®¿é—® / IP å°ç¦ã€ï¼Œå¯ç­‰ 5â€“60 åˆ†é’Ÿæˆ–æ¢ç½‘ç»œ/VPN åå†è¯•ã€‚
æ¨èä¼˜å…ˆç”¨ download_all_stocks_2022.pyï¼ˆakshareï¼‰ï¼Œæ”¯æŒ --list-cacheã€‚
"""
import os
import sys
import json
import time
import requests
import pandas as pd
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Optional

# é…ç½®
CACHE_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "cache")
DAILY_DIR = os.path.join(CACHE_DIR, "daily_kline")
WEEKLY_DIR = os.path.join(CACHE_DIR, "weekly_kline")
STOCK_LIST_PATH = os.path.join(CACHE_DIR, "stock_list_all.json")

# 2022-01-01 è‡³ä»Šçº¦ 1000 ä¸ªäº¤æ˜“æ—¥ã€çº¦ 210 å‘¨ï¼Œå¤šæ‹‰ä¸€äº›
DAILY_DATALEN = 1500
WEEKLY_DATALEN = 300

MAX_WORKERS = 10
RETRY_TIMES = 3
CUTOFF_DATE = "2022-01-01"

session = requests.Session()
session.trust_env = False
session.headers.update({"User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)"})


def get_sina_daily_kline(code: str, datalen: int = DAILY_DATALEN) -> Optional[pd.DataFrame]:
    symbol = f"sh{code}" if code.startswith("6") else f"sz{code}"
    url = f"https://quotes.sina.cn/cn/api/jsonp_v2.php/data/CN_MarketDataService.getKLineData?symbol={symbol}&scale=240&datalen={datalen}"
    for attempt in range(RETRY_TIMES):
        try:
            resp = session.get(url, timeout=15)
            if resp.status_code != 200:
                continue
            text = resp.text
            if "data(" not in text:
                continue
            json_str = text.split("data(")[1].rsplit(")", 1)[0]
            data = json.loads(json_str)
            if not data:
                return None
            df = pd.DataFrame(data)
            df = df.rename(columns={
                "day": "æ—¥æœŸ", "open": "å¼€ç›˜", "close": "æ”¶ç›˜",
                "high": "æœ€é«˜", "low": "æœ€ä½", "volume": "æˆäº¤é‡",
            })
            df = df[["æ—¥æœŸ", "å¼€ç›˜", "æ”¶ç›˜", "æœ€é«˜", "æœ€ä½", "æˆäº¤é‡"]]
            df["å¼€ç›˜"] = pd.to_numeric(df["å¼€ç›˜"], errors="coerce")
            df["æ”¶ç›˜"] = pd.to_numeric(df["æ”¶ç›˜"], errors="coerce")
            df["æœ€é«˜"] = pd.to_numeric(df["æœ€é«˜"], errors="coerce")
            df["æœ€ä½"] = pd.to_numeric(df["æœ€ä½"], errors="coerce")
            df["æˆäº¤é‡"] = pd.to_numeric(df["æˆäº¤é‡"], errors="coerce").fillna(0).astype(int)
            return df
        except Exception:
            if attempt < RETRY_TIMES - 1:
                time.sleep(0.3 * (attempt + 1))
    return None


def get_sina_weekly_kline(code: str, datalen: int = WEEKLY_DATALEN) -> Optional[pd.DataFrame]:
    symbol = f"sh{code}" if code.startswith("6") else f"sz{code}"
    url = f"https://quotes.sina.cn/cn/api/jsonp_v2.php/data/CN_MarketDataService.getKLineData?symbol={symbol}&scale=1200&datalen={datalen}"
    for attempt in range(RETRY_TIMES):
        try:
            resp = session.get(url, timeout=15)
            if resp.status_code != 200:
                continue
            text = resp.text
            if "data(" not in text:
                continue
            json_str = text.split("data(")[1].rsplit(")", 1)[0]
            data = json.loads(json_str)
            if not data:
                return None
            df = pd.DataFrame(data)
            df = df.rename(columns={
                "day": "æ—¥æœŸ", "open": "å¼€ç›˜", "close": "æ”¶ç›˜",
                "high": "æœ€é«˜", "low": "æœ€ä½", "volume": "å‘¨æˆäº¤é‡",
            })
            df = df[["æ—¥æœŸ", "å¼€ç›˜", "æ”¶ç›˜", "æœ€é«˜", "æœ€ä½", "å‘¨æˆäº¤é‡"]]
            df["å¼€ç›˜"] = pd.to_numeric(df["å¼€ç›˜"], errors="coerce")
            df["æ”¶ç›˜"] = pd.to_numeric(df["æ”¶ç›˜"], errors="coerce")
            df["æœ€é«˜"] = pd.to_numeric(df["æœ€é«˜"], errors="coerce")
            df["æœ€ä½"] = pd.to_numeric(df["æœ€ä½"], errors="coerce")
            df["å‘¨æˆäº¤é‡"] = pd.to_numeric(df["å‘¨æˆäº¤é‡"], errors="coerce").fillna(0).astype(int)
            return df
        except Exception:
            if attempt < RETRY_TIMES - 1:
                time.sleep(0.3 * (attempt + 1))
    return None


def _filter_2022_onwards(df: pd.DataFrame) -> pd.DataFrame:
    if df is None or len(df) == 0:
        return df
    df = df.copy()
    df["æ—¥æœŸ"] = pd.to_datetime(df["æ—¥æœŸ"], errors="coerce")
    df = df.dropna(subset=["æ—¥æœŸ"])
    df = df[df["æ—¥æœŸ"] >= CUTOFF_DATE].sort_values("æ—¥æœŸ").reset_index(drop=True)
    return df


def process_one(code: str, name: str, force: bool, dry_run: bool = False) -> dict:
    res = {"code": code, "name": name, "daily_ok": False, "weekly_ok": False, "skip": False, "error": None}
    daily_path = os.path.join(DAILY_DIR, f"{code}.csv")
    weekly_path = os.path.join(WEEKLY_DIR, f"{code}.csv")

    def has_2022(path: str) -> bool:
        if not os.path.exists(path):
            return False
        try:
            d = pd.read_csv(path, encoding="utf-8-sig", nrows=5000)
            if "æ—¥æœŸ" not in d.columns or len(d) == 0:
                return False
            d["æ—¥æœŸ"] = pd.to_datetime(d["æ—¥æœŸ"], errors="coerce")
            d = d.dropna(subset=["æ—¥æœŸ"])
            return (d["æ—¥æœŸ"] >= CUTOFF_DATE).any()
        except Exception:
            return False

    if not force and has_2022(daily_path) and has_2022(weekly_path):
        res["skip"] = True
        return res

    try:
        daily = get_sina_daily_kline(code)
        daily = _filter_2022_onwards(daily)
        if daily is not None and len(daily) > 0:
            if not dry_run:
                daily.to_csv(daily_path, index=False, encoding="utf-8-sig")
            res["daily_ok"] = True
        time.sleep(0.02)

        weekly = get_sina_weekly_kline(code)
        weekly = _filter_2022_onwards(weekly)
        if weekly is not None and len(weekly) > 0:
            if not dry_run:
                weekly.to_csv(weekly_path, index=False, encoding="utf-8-sig")
            res["weekly_ok"] = True
    except Exception as e:
        res["error"] = str(e)[:80]
    return res


def main():
    import argparse
    ap = argparse.ArgumentParser(description="ä¸‹è½½ä»2022å¹´å¼€å§‹çš„æ‰€æœ‰Aè‚¡æ—¥K/å‘¨Kï¼ˆæ–°æµªAPIï¼‰")
    ap.add_argument("--force", action="store_true", help="å¼ºåˆ¶è¦†ç›–å·²æœ‰2022+æ•°æ®")
    ap.add_argument("--workers", type=int, default=MAX_WORKERS, help=f"å¹¶å‘æ•°ï¼Œé»˜è®¤{MAX_WORKERS}")
    ap.add_argument("--limit", type=int, default=0, help="ä»…å¤„ç†å‰ N åªï¼ˆ0=å…¨éƒ¨ï¼‰")
    ap.add_argument("--dry-run", action="store_true", help="ä»…è¯•è·‘å‰3åªï¼Œæ‰“å°è°ƒè¯•ä¿¡æ¯")
    args = ap.parse_args()

    os.makedirs(DAILY_DIR, exist_ok=True)
    os.makedirs(WEEKLY_DIR, exist_ok=True)

    if not os.path.exists(STOCK_LIST_PATH):
        print(f"âŒ è‚¡ç¥¨åˆ—è¡¨ä¸å­˜åœ¨: {STOCK_LIST_PATH}")
        print("è¯·å…ˆè¿è¡Œæœ¬åœ°/Web åˆ·æ–°è‚¡ç¥¨åˆ—è¡¨ï¼Œæˆ–ä½¿ç”¨ data_fetcher æ‹‰å–å¹¶ä¿å­˜ã€‚")
        sys.exit(1)

    with open(STOCK_LIST_PATH, "r", encoding="utf-8") as f:
        raw = json.load(f)

    stocks = []
    for item in raw:
        code = item.get("code") or item.get("ä»£ç ", "")
        name = item.get("name") or item.get("åç§°", "")
        if not code:
            continue
        code = str(code).strip()
        if len(code) != 6 or not code.isdigit():
            continue
        stocks.append({"code": code, "name": name or ""})

    if args.limit > 0:
        stocks = stocks[: args.limit]
        print(f"âš ï¸ --limit={args.limit}ï¼Œä»…å¤„ç†å‰ {len(stocks)} åª")
    if args.dry_run:
        stocks = stocks[:3]
        args.force = True  # å¼ºåˆ¶æŠ“å–ï¼Œå¦åˆ™ä¼šå› å·²æœ‰æ•°æ®è€Œè·³è¿‡
        print("âš ï¸ --dry-runï¼šä»…è¯•è·‘å‰ 3 åªï¼Œä¸å†™å…¥æ–‡ä»¶")
    total = len(stocks)
    print("=" * 70)
    print("ğŸ“¥ ä¸‹è½½ä»2022å¹´å¼€å§‹çš„æ‰€æœ‰Aè‚¡ä¸ªè‚¡æ•°æ®ï¼ˆæ–°æµªAPIï¼‰")
    print("=" * 70)
    print(f"è‚¡ç¥¨æ•°: {total}")
    print(f"æ—¥æœŸ: >= {CUTOFF_DATE}")
    print(f"å¹¶å‘: {args.workers}")
    print(f"å¼ºåˆ¶è¦†ç›–: {args.force}")
    print()

    start = time.time()
    done = 0
    daily_ok = 0
    weekly_ok = 0
    skip = 0
    err = 0
    last_report = start

    dry_run = getattr(args, "dry_run", False)
    with ThreadPoolExecutor(max_workers=args.workers) as ex:
        f2s = {ex.submit(process_one, s["code"], s["name"], args.force, dry_run): s for s in stocks}
        for fut in as_completed(f2s):
            s = f2s[fut]
            try:
                r = fut.result()
                if r["skip"]:
                    skip += 1
                else:
                    if r["daily_ok"]:
                        daily_ok += 1
                    if r["weekly_ok"]:
                        weekly_ok += 1
                    if r["error"]:
                        err += 1
            except Exception as e:
                err += 1
            done += 1

            now = time.time()
            if done % 200 == 0 or done == total or (now - last_report) >= 10:
                el = now - start
                speed = done / el if el > 0 else 0
                eta = (total - done) / speed if speed > 0 else 0
                print(f"è¿›åº¦: {done}/{total} ({100*done/total:.1f}%) | "
                      f"æ—¥K: {daily_ok} å‘¨K: {weekly_ok} è·³è¿‡: {skip} é”™è¯¯: {err} | "
                      f"{speed:.1f}åª/s å‰©ä½™çº¦{eta/60:.1f}min", flush=True)
                last_report = now

    el = time.time() - start
    print()
    print("=" * 70)
    print("âœ… å®Œæˆ")
    print("=" * 70)
    print(f"è€—æ—¶: {el/60:.1f} åˆ†é’Ÿ")
    print(f"æ—¥KæˆåŠŸ: {daily_ok} | å‘¨KæˆåŠŸ: {weekly_ok} | è·³è¿‡: {skip} | é”™è¯¯: {err}")
    print()


if __name__ == "__main__":
    main()
