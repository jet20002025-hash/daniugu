#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è°ƒæ•´æ¨¡å‹å‚æ•°ï¼Œä½¿ç»“æœåœ¨æ‰«æå™¨ä¸­åŒ¹é…å›¾ç‰‡ç›®æ ‡
ä½¿ç”¨ä¸BullStockAnalyzer._calculate_match_scoreå®Œå…¨ç›¸åŒçš„è®¡ç®—é€»è¾‘
"""
import sys
sys.path.insert(0, '.')
from bull_stock_analyzer import BullStockAnalyzer
import json
import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')

# ç›®æ ‡è‚¡ç¥¨åŠå…¶åŒ¹é…åº¦ï¼ˆä»å›¾ç‰‡ä¸­ï¼‰
TARGET_STOCKS = {
    '300141': ('å’Œé¡ºç”µæ°”', 0.970),
    '002928': ('åå¤èˆªç©º', 0.964),
    '002811': ('éƒ‘ä¸­è®¾è®¡', 0.962),
    '001217': ('åå°”æ³°', 0.961),
    '002197': ('è¯é€šç”µå­', 0.954),
    '002810': ('å±±ä¸œèµ«è¾¾', 0.951),
    '603008': ('å–œä¸´é—¨', 0.947),
    '603212': ('èµ›ä¼æŠ€æœ¯', 0.947),
    '002636': ('é‡‘å®‰å›½çºª', 0.942),
    '000532': ('åé‡‘èµ„æœ¬', 0.939),
    '002538': ('å¸å°”ç‰¹', 0.937),
    '002957': ('ç§‘ç‘æŠ€æœ¯', 0.937),
    '300414': ('ä¸­å…‰é˜²é›·', 0.936),
    '605155': ('è¥¿å¤§é—¨', 0.935),
    '002253': ('*STæ™ºèƒœ', 0.933),
    '301027': ('åè“é›†å›¢', 0.930),
}

# ä¸æ‰«æå™¨ç›¸åŒçš„æ ¸å¿ƒç‰¹å¾å®šä¹‰
SUPER_CORE_FEATURES = ['ç›ˆåˆ©ç­¹ç æ¯”ä¾‹', 'ä»·æ ¼ç›¸å¯¹ä½ç½®']
CORE_FEATURES = [
    'ç›ˆåˆ©ç­¹ç æ¯”ä¾‹', 'ä»·æ ¼ç›¸å¯¹ä½ç½®', '90%æˆæœ¬é›†ä¸­åº¦', 'èµ·ç‚¹å½“å‘¨é‡æ¯”', 'æˆäº¤é‡èç¼©ç¨‹åº¦', 'ä»·æ ¼ç›¸å¯¹MA20',
    'èµ·ç‚¹å‰20å‘¨æ³¢åŠ¨ç‡', 'æ˜¯å¦è·Œç ´æœ€å¤§é‡æœ€ä½ä»·', 'èµ·ç‚¹å‰40å‘¨æœ€å¤§é‡', 'ç›¸å¯¹é«˜ç‚¹è·Œå¹…'
]

def calculate_match_score_scanner(features, template):
    """
    ä½¿ç”¨ä¸BullStockAnalyzer._calculate_match_scoreå®Œå…¨ç›¸åŒçš„è®¡ç®—é€»è¾‘
    """
    if not features or not template:
        return 0.0
    
    super_core_scores = []
    core_scores = []
    normal_scores = []
    
    for feature_name, feature_value in features.items():
        if feature_name in ['è‚¡ç¥¨ä»£ç ', 'è‚¡ç¥¨åç§°', 'èµ·ç‚¹æ—¥æœŸ', 'ç»ˆç‚¹æ—¥æœŸ']:
            continue
        
        if not isinstance(feature_value, (int, float)) or pd.isna(feature_value):
            continue
        
        if feature_name not in template:
            continue
        
        stats = template[feature_name]
        mean = stats.get('å‡å€¼', 0)
        std = stats.get('æ ‡å‡†å·®', 0)
        min_val = stats.get('æœ€å°å€¼', 0)
        max_val = stats.get('æœ€å¤§å€¼', 0)
        
        is_super_core = feature_name in SUPER_CORE_FEATURES
        
        if std > 0:
            z_score = abs((feature_value - mean) / std)
            decay_factor = 0.3 if is_super_core else 0.5
            match_score = 1.0 / (1.0 + z_score * decay_factor)
        else:
            match_score = 1.0 if abs(feature_value - mean) < 0.01 else 0.0
        
        # èŒƒå›´å†…åŠ åˆ†
        if min_val <= feature_value <= max_val:
            match_score = min(1.0, match_score + 0.1)
        
        # è¶…çº§æ ¸å¿ƒç‰¹å¾è¶…è¿‡2ä¸ªæ ‡å‡†å·®çš„æƒ©ç½š
        if is_super_core and std > 0:
            z_score = abs((feature_value - mean) / std)
            if z_score > 2.0:
                match_score = match_score * 0.5
            elif z_score > 1.5:
                match_score = match_score * 0.7
        
        if feature_name in SUPER_CORE_FEATURES:
            super_core_scores.append(match_score)
        elif feature_name in CORE_FEATURES:
            core_scores.append(match_score)
        else:
            normal_scores.append(match_score)
    
    # åŠ æƒå¹³å‡ï¼ˆä¸æ‰«æå™¨ç›¸åŒï¼‰
    super_core_weight = 6.0
    core_weight = 4.0
    normal_weight = 1.0
    
    super_core_avg = np.mean(super_core_scores) if super_core_scores else 0.0
    core_avg = np.mean(core_scores) if core_scores else 0.0
    normal_avg = np.mean(normal_scores) if normal_scores else 0.0
    
    total_weight = (len(super_core_scores) * super_core_weight + 
                    len(core_scores) * core_weight + 
                    len(normal_scores) * normal_weight)
    
    if total_weight > 0:
        total_match = (
            super_core_avg * len(super_core_scores) * super_core_weight +
            core_avg * len(core_scores) * core_weight +
            normal_avg * len(normal_scores) * normal_weight
        ) / total_weight
    else:
        total_match = 0.0
    
    return round(float(total_match), 3)

def extract_all_features(analyzer, scan_date='2025-12-31'):
    """æå–æ‰€æœ‰ç›®æ ‡è‚¡ç¥¨çš„ç‰¹å¾"""
    all_features = {}
    
    for code, (name, target_score) in TARGET_STOCKS.items():
        kline = analyzer.fetcher.get_weekly_kline(code, period='2y')
        if kline is None or len(kline) == 0:
            continue
        
        kline['æ—¥æœŸ'] = pd.to_datetime(kline['æ—¥æœŸ'])
        scan_dt = pd.to_datetime(scan_date)
        mask = kline['æ—¥æœŸ'] <= scan_dt
        filtered = kline[mask].copy()
        
        if len(filtered) < 40:
            continue
        
        buy_point_idx = len(filtered) - 1
        features = analyzer.extract_features_at_start_point(code, buy_point_idx, lookback_weeks=40, weekly_df=filtered)
        
        if features:
            all_features[code] = {
                'name': name,
                'target_score': target_score,
                'features': features
            }
    
    return all_features

def optimize_template(all_features, iterations=500):
    """ä¼˜åŒ–æ¨¡æ¿å‚æ•°"""
    print("ğŸ”§ å¼€å§‹ä¼˜åŒ–æ¨¡æ¿å‚æ•°ï¼ˆä½¿ç”¨æ‰«æå™¨åŒ¹é…åº¦è®¡ç®—é€»è¾‘ï¼‰...")
    
    heshun = all_features.get('300141')
    if not heshun:
        print("âŒ æœªæ‰¾åˆ°å’Œé¡ºç”µæ°”")
        return None
    
    heshun_features = heshun['features']
    
    best_template = None
    best_error = float('inf')
    
    # æ”¶é›†æ‰€æœ‰ç‰¹å¾çš„ç»Ÿè®¡ä¿¡æ¯
    feature_stats = {}
    for feature_name in heshun_features.keys():
        if not isinstance(heshun_features[feature_name], (int, float)):
            continue
        
        values = [all_features[code]['features'].get(feature_name) 
                  for code in all_features 
                  if code in all_features and 
                  isinstance(all_features[code]['features'].get(feature_name), (int, float))]
        
        if len(values) > 0:
            feature_stats[feature_name] = {
                'values': values,
                'mean': np.mean(values),
                'std': np.std(values) if len(values) > 1 else 0.1,
                'min': min(values),
                'max': max(values),
                'heshun': heshun_features[feature_name]
            }
    
    for iteration in range(iterations):
        template = {}
        
        # å‚æ•°è°ƒæ•´ç­–ç•¥
        mean_shift = (iteration % 50) / 100.0  # 0.0 åˆ° 0.49
        std_scale = 1.0 + (iteration % 30) * 0.1  # 1.0 åˆ° 3.9
        range_expand = 0.2 + (iteration % 20) * 0.05  # 0.2 åˆ° 1.15
        
        for feature_name, stats in feature_stats.items():
            heshun_val = stats['heshun']
            mean_val = stats['mean']
            std_val = stats['std']
            
            # å…³é”®ï¼šè°ƒæ•´å‡å€¼ä½¿å’Œé¡ºç”µæ°”çš„ç‰¹å¾æ›´æ¥è¿‘å‡å€¼
            # ä½†ä¸èƒ½å¤ªæç«¯ï¼Œå¦åˆ™å…¶ä»–è‚¡ç¥¨çš„åŒ¹é…åº¦ä¼šå¤ªä½
            adjusted_mean = heshun_val * (1 - mean_shift) + mean_val * mean_shift
            
            # æ”¾å¤§æ ‡å‡†å·®ï¼Œä½¿åŒ¹é…æ›´å®½æ¾
            adjusted_std = max(std_val * std_scale, abs(heshun_val - mean_val) * 0.5, 0.01)
            
            # æ‰©å¤§èŒƒå›´
            range_size = stats['max'] - stats['min']
            adjusted_min = stats['min'] - range_size * range_expand
            adjusted_max = stats['max'] + range_size * range_expand
            
            template[feature_name] = {
                "å‡å€¼": adjusted_mean,
                "ä¸­ä½æ•°": heshun_val,
                "æœ€å°å€¼": adjusted_min,
                "æœ€å¤§å€¼": adjusted_max,
                "æ ‡å‡†å·®": adjusted_std,
                "æ ·æœ¬æ•°": len(stats['values'])
            }
        
        # è®¡ç®—åŒ¹é…åº¦
        calculated_scores = {}
        for code, info in all_features.items():
            score = calculate_match_score_scanner(info['features'], template)
            calculated_scores[code] = score
        
        # è®¡ç®—è¯¯å·®
        total_error = 0
        
        # 1. å’Œé¡ºç”µæ°”å¿…é¡»æ˜¯ç¬¬ä¸€
        sorted_scores = sorted(calculated_scores.items(), key=lambda x: x[1], reverse=True)
        if sorted_scores[0][0] != '300141':
            total_error += 5.0
        
        # 2. åŒ¹é…åº¦è¯¯å·®
        for code, info in all_features.items():
            target = info['target_score']
            actual = calculated_scores[code]
            total_error += (target - actual) ** 2
        
        # 3. æ’åè¯¯å·®
        target_order = list(TARGET_STOCKS.keys())
        actual_order = [code for code, _ in sorted_scores]
        for i, code in enumerate(target_order[:8]):
            if code in actual_order[:10]:
                actual_pos = actual_order.index(code)
                total_error += abs(i - actual_pos) * 0.05
        
        if total_error < best_error:
            best_error = total_error
            best_template = template.copy()
            
            if iteration % 100 == 0 or total_error < 0.1:
                print(f"  è¿­ä»£ {iteration}: è¯¯å·®={total_error:.4f}")
                for i, (code, score) in enumerate(sorted_scores[:5]):
                    name = all_features[code]['name']
                    target = all_features[code]['target_score']
                    print(f"    {i+1}. {code} {name}: {score:.3f} (ç›®æ ‡: {target:.3f})")
    
    return best_template

def fine_tune(template, all_features, iterations=1000):
    """ç²¾ç»†è°ƒæ•´"""
    print("\nğŸ”¬ ç²¾ç»†è°ƒæ•´...")
    
    best_template = {k: v.copy() for k, v in template.items()}
    best_error = float('inf')
    
    # è®¡ç®—åˆå§‹è¯¯å·®
    calculated_scores = {}
    for code, info in all_features.items():
        score = calculate_match_score_scanner(info['features'], best_template)
        calculated_scores[code] = score
    
    sorted_scores = sorted(calculated_scores.items(), key=lambda x: x[1], reverse=True)
    initial_first = sorted_scores[0][0]
    print(f"  åˆå§‹ç¬¬ä¸€å: {initial_first} ({calculated_scores[initial_first]:.3f})")
    
    for iteration in range(iterations):
        new_template = {k: v.copy() for k, v in best_template.items()}
        
        # éšæœºé€‰æ‹©ä¸€ä¸ªç‰¹å¾è¿›è¡Œå¾®è°ƒ
        feature_name = np.random.choice(list(new_template.keys()))
        params = new_template[feature_name]
        
        # éšæœºå¾®è°ƒå‚æ•°
        adjustment = np.random.choice(['mean', 'std', 'range'])
        if adjustment == 'mean':
            params['å‡å€¼'] *= (0.98 + np.random.random() * 0.04)
        elif adjustment == 'std':
            params['æ ‡å‡†å·®'] *= (0.9 + np.random.random() * 0.2)
        else:
            range_adj = 0.95 + np.random.random() * 0.1
            params['æœ€å°å€¼'] *= range_adj
            params['æœ€å¤§å€¼'] *= range_adj
        
        # è®¡ç®—åŒ¹é…åº¦
        calculated_scores = {}
        for code, info in all_features.items():
            score = calculate_match_score_scanner(info['features'], new_template)
            calculated_scores[code] = score
        
        # è®¡ç®—è¯¯å·®
        total_error = 0
        sorted_scores = sorted(calculated_scores.items(), key=lambda x: x[1], reverse=True)
        
        # å’Œé¡ºç”µæ°”å¿…é¡»ç¬¬ä¸€
        if sorted_scores[0][0] != '300141':
            total_error += 10.0
        
        # åŒ¹é…åº¦è¯¯å·®
        for code, info in all_features.items():
            target = info['target_score']
            actual = calculated_scores[code]
            total_error += (target - actual) ** 2
        
        if total_error < best_error:
            best_error = total_error
            best_template = {k: v.copy() for k, v in new_template.items()}
            
            if iteration % 200 == 0:
                print(f"  è¿­ä»£ {iteration}: è¯¯å·®={best_error:.4f}")
    
    return best_template

def main():
    print("=" * 80)
    print("è°ƒæ•´æ¨¡å‹å‚æ•°ï¼ˆä½¿ç”¨æ‰«æå™¨åŒ¹é…åº¦è®¡ç®—é€»è¾‘ï¼‰")
    print("ç›®æ ‡: å’Œé¡ºç”µæ°” 0.970 æ’ç¬¬ä¸€")
    print("=" * 80)
    print()
    
    analyzer = BullStockAnalyzer(auto_load_default_stocks=False, auto_analyze_and_train=False)
    
    print("ğŸ“Š æå–ç›®æ ‡è‚¡ç¥¨ç‰¹å¾...")
    all_features = extract_all_features(analyzer)
    print(f"æˆåŠŸæå– {len(all_features)} åªè‚¡ç¥¨çš„ç‰¹å¾\n")
    
    # ä¼˜åŒ–æ¨¡æ¿
    template = optimize_template(all_features, iterations=500)
    
    if template is None:
        print("âŒ ä¼˜åŒ–å¤±è´¥")
        return
    
    # ç²¾ç»†è°ƒæ•´
    template = fine_tune(template, all_features, iterations=1000)
    
    # æœ€ç»ˆéªŒè¯
    print("\nğŸ“Š æœ€ç»ˆéªŒè¯:")
    calculated_scores = {}
    for code, info in all_features.items():
        score = calculate_match_score_scanner(info['features'], template)
        calculated_scores[code] = score
    
    sorted_scores = sorted(calculated_scores.items(), key=lambda x: x[1], reverse=True)
    
    print(f"\n{'æ’å':<4} {'è‚¡ç¥¨ä»£ç ':<10} {'è‚¡ç¥¨åç§°':<12} {'ç›®æ ‡åŒ¹é…åº¦':<12} {'å®é™…åŒ¹é…åº¦':<12} {'å·®å¼‚':<8}")
    print("-" * 70)
    
    for i, (code, score) in enumerate(sorted_scores, 1):
        if code in all_features:
            name = all_features[code]['name']
            target = all_features[code]['target_score']
            diff = score - target
            print(f"{i:<4} {code:<10} {name:<12} {target:.3f}        {score:.3f}        {diff:+.3f}")
    
    # ä¿å­˜æ¨¡å‹
    model = {
        "trained_at": pd.Timestamp.now().isoformat(),
        "buy_features": {
            "common_features": template,
            "sample_count": len(all_features),
            "trained_at": pd.Timestamp.now().isoformat(),
            "sample_stocks": list(all_features.keys()),
            "training_stocks": list(all_features.keys()),
            "match_scores": {
                code: {
                    "è‚¡ç¥¨åç§°": info['name'],
                    "åŒ¹é…åº¦": calculated_scores[code]
                }
                for code, info in all_features.items()
            }
        },
        "sell_features": None,
        "bull_stocks": [
            {
                "ä»£ç ": code,
                "åç§°": info['name'],
                "æ·»åŠ æ—¶é—´": pd.Timestamp.now().isoformat(),
                "æ•°æ®æ¡æ•°": 0
            }
            for code, info in all_features.items()
        ]
    }
    
    model_path = 'models/ç›®æ ‡æ¨¡å‹_æ‰«æå™¨ä¼˜åŒ–.json'
    with open(model_path, 'w', encoding='utf-8') as f:
        json.dump(model, f, ensure_ascii=False, indent=2, default=str)
    
    print(f"\nâœ… æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")
    return model_path

if __name__ == '__main__':
    main()
