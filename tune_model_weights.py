#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¾®è°ƒæ¨¡å‹æƒé‡ï¼Œæé«˜ç›®æ ‡è‚¡ç¥¨çš„åŒ¹é…åº¦ï¼Œé™ä½ä¸éœ€è¦è‚¡ç¥¨çš„åŒ¹é…åº¦
æµ‹è¯•æ—¥æœŸï¼š2026-01-04
"""
import os
import sys
import json
from datetime import datetime
import pandas as pd
import numpy as np

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
from bull_stock_analyzer import BullStockAnalyzer

# æé«˜æƒé‡çš„è‚¡ç¥¨ï¼ˆç›®æ ‡ï¼šåŒ¹é…åº¦æé«˜ï¼‰
INCREASE_WEIGHT_STOCKS = {
    '300599': {'name': 'é›„å¡‘ç§‘æŠ€', 'target_score': 0.95},  # å½“å‰0.937
    '002254': {'name': 'æ³°å’Œæ–°æ', 'target_score': 0.95},  # å½“å‰0.933
    '600215': {'name': 'æ´¾æ–¯æ—', 'target_score': 0.93},    # å½“å‰0.911
    '603808': {'name': 'æ­ŒåŠ›æ€', 'target_score': 0.93},    # å½“å‰0.911
    '600834': {'name': 'ç”³é€šåœ°é“', 'target_score': 0.93},  # å½“å‰0.910
    '300986': {'name': 'å¿—ç‰¹æ–°æ', 'target_score': 0.93},  # å½“å‰0.906
    '300234': {'name': 'å¼€å°”æ–°æ', 'target_score': 0.93},  # å½“å‰0.905
}

# é™ä½æƒé‡çš„è‚¡ç¥¨ï¼ˆç›®æ ‡ï¼šåŒ¹é…åº¦é™ä½ï¼‰
DECREASE_WEIGHT_STOCKS = {
    '300205': {'name': '*STå¤©å–»', 'target_score': 0.85},   # å½“å‰0.934ï¼Œç›®æ ‡é™ä½
    '300778': {'name': 'æ–°åŸå¸‚', 'target_score': 0.85},    # å½“å‰0.926ï¼Œç›®æ ‡é™ä½
    '603648': {'name': 'ç•…è”è‚¡ä»½', 'target_score': 0.85},  # å½“å‰0.923ï¼Œç›®æ ‡é™ä½
    '002599': {'name': 'ç››é€šè‚¡ä»½', 'target_score': 0.85},  # å½“å‰0.913ï¼Œç›®æ ‡é™ä½
    '603838': {'name': '*STå››é€š', 'target_score': 0.85},   # å½“å‰0.912ï¼Œç›®æ ‡é™ä½
    '600719': {'name': 'å¤§è¿çƒ­ç”µ', 'target_score': 0.85},  # å½“å‰0.911ï¼Œç›®æ ‡é™ä½
    '688609': {'name': 'ä¹è”ç§‘æŠ€', 'target_score': 0.85},  # å½“å‰0.911ï¼Œç›®æ ‡é™ä½
    '002908': {'name': 'å¾·ç”Ÿç§‘æŠ€', 'target_score': 0.85},  # å½“å‰0.905ï¼Œç›®æ ‡é™ä½
}

# æµ‹è¯•æ—¥æœŸ
TEST_DATE = '2026-01-04'

# æœ€å¤§è¿­ä»£æ¬¡æ•°
MAX_ITERATIONS = 30


def extract_features_for_stock(analyzer, code, scan_date):
    """æå–è‚¡ç¥¨åœ¨æŒ‡å®šæ—¥æœŸçš„ç‰¹å¾"""
    try:
        weekly_df = analyzer.fetcher.get_weekly_kline(code, period='2y')
        if weekly_df is None or len(weekly_df) == 0:
            return None, None
        
        # è¿‡æ»¤åˆ°æŒ‡å®šæ—¥æœŸ
        weekly_df['æ—¥æœŸ'] = pd.to_datetime(weekly_df['æ—¥æœŸ'])
        scan_dt = pd.to_datetime(scan_date)
        weekly_df = weekly_df[weekly_df['æ—¥æœŸ'] <= scan_dt].copy()
        weekly_df = weekly_df.sort_values('æ—¥æœŸ').reset_index(drop=True)
        
        if len(weekly_df) < 40:
            return None, None
        
        # ä½¿ç”¨æœ€åä¸€å‘¨ä½œä¸ºæ½œåœ¨çš„ä¹°ç‚¹
        buy_point_idx = len(weekly_df) - 1
        
        # æ‰¾æˆäº¤é‡çªå¢ç‚¹
        volume_surge_idx = analyzer.find_volume_surge_point(
            code, 
            buy_point_idx, 
            weekly_df=weekly_df, 
            min_volume_ratio=3.0, 
            lookback_weeks=52
        )
        
        # ç¡®å®šç‰¹å¾èµ·ç‚¹
        if volume_surge_idx is not None and volume_surge_idx >= 40:
            feature_idx = volume_surge_idx
        else:
            feature_idx = max(0, buy_point_idx - 20)
        
        # æå–ç‰¹å¾
        features = analyzer.extract_features_at_start_point(
            code, 
            feature_idx, 
            lookback_weeks=40, 
            weekly_df=weekly_df
        )
        
        return features, feature_idx
    except Exception as e:
        print(f"  âš ï¸ æå– {code} ç‰¹å¾å¤±è´¥: {e}")
        return None, None


def verify_all_stocks(analyzer, scan_date):
    """éªŒè¯æ‰€æœ‰ç›®æ ‡è‚¡ç¥¨çš„åŒ¹é…åº¦"""
    results = {}
    
    print(f"\n{'='*80}")
    print(f"éªŒè¯æ—¥æœŸ: {scan_date}")
    print(f"{'='*80}")
    
    # éªŒè¯æé«˜æƒé‡çš„è‚¡ç¥¨
    print("\nğŸ“ˆ æé«˜æƒé‡çš„è‚¡ç¥¨:")
    for code, info in INCREASE_WEIGHT_STOCKS.items():
        stock_name = info['name']
        target_score = info['target_score']
        
        features, _ = extract_features_for_stock(analyzer, code, scan_date)
        if features is None:
            results[code] = {'score': 0, 'target': target_score, 'type': 'increase', 'error': 'æ— æ³•æå–ç‰¹å¾'}
            print(f"  âŒ {code} {stock_name}: æ— æ³•æå–ç‰¹å¾")
            continue
        
        trained_features = analyzer.get_trained_features()
        if trained_features is None:
            results[code] = {'score': 0, 'target': target_score, 'type': 'increase', 'error': 'æ¨¡å‹æœªè®­ç»ƒ'}
            print(f"  âŒ {code} {stock_name}: æ¨¡å‹æœªè®­ç»ƒ")
            continue
        
        match_result = analyzer._calculate_match_score(
            features, 
            trained_features.get('common_features', {}),
            tolerance=0.3
        )
        match_score = match_result.get('æ€»åŒ¹é…åº¦', 0)
        
        passed = match_score >= target_score
        status = "âœ…" if passed else "âŒ"
        results[code] = {
            'score': match_score,
            'target': target_score,
            'type': 'increase',
            'passed': passed,
            'name': stock_name
        }
        print(f"  {status} {code} {stock_name}: {match_score:.3f} (ç›®æ ‡: {target_score:.3f}) {'âœ“' if passed else 'âœ—'}")
    
    # éªŒè¯é™ä½æƒé‡çš„è‚¡ç¥¨
    print("\nğŸ“‰ é™ä½æƒé‡çš„è‚¡ç¥¨:")
    for code, info in DECREASE_WEIGHT_STOCKS.items():
        stock_name = info['name']
        target_score = info['target_score']
        
        features, _ = extract_features_for_stock(analyzer, code, scan_date)
        if features is None:
            results[code] = {'score': 1.0, 'target': target_score, 'type': 'decrease', 'error': 'æ— æ³•æå–ç‰¹å¾'}
            print(f"  âŒ {code} {stock_name}: æ— æ³•æå–ç‰¹å¾")
            continue
        
        trained_features = analyzer.get_trained_features()
        if trained_features is None:
            results[code] = {'score': 1.0, 'target': target_score, 'type': 'decrease', 'error': 'æ¨¡å‹æœªè®­ç»ƒ'}
            print(f"  âŒ {code} {stock_name}: æ¨¡å‹æœªè®­ç»ƒ")
            continue
        
        match_result = analyzer._calculate_match_score(
            features, 
            trained_features.get('common_features', {}),
            tolerance=0.3
        )
        match_score = match_result.get('æ€»åŒ¹é…åº¦', 0)
        
        passed = match_score <= target_score
        status = "âœ…" if passed else "âŒ"
        results[code] = {
            'score': match_score,
            'target': target_score,
            'type': 'decrease',
            'passed': passed,
            'name': stock_name
        }
        print(f"  {status} {code} {stock_name}: {match_score:.3f} (ç›®æ ‡: â‰¤{target_score:.3f}) {'âœ“' if passed else 'âœ—'}")
    
    # ç»Ÿè®¡ç»“æœ
    increase_passed = sum(1 for r in results.values() if r.get('type') == 'increase' and r.get('passed', False))
    decrease_passed = sum(1 for r in results.values() if r.get('type') == 'decrease' and r.get('passed', False))
    total_passed = increase_passed + decrease_passed
    total_stocks = len(INCREASE_WEIGHT_STOCKS) + len(DECREASE_WEIGHT_STOCKS)
    
    print(f"\n{'='*80}")
    print(f"ç»“æœç»Ÿè®¡: {total_passed}/{total_stocks} åªè‚¡ç¥¨è¾¾åˆ°ç›®æ ‡")
    print(f"  - æé«˜æƒé‡: {increase_passed}/{len(INCREASE_WEIGHT_STOCKS)} åªè¾¾åˆ°ç›®æ ‡")
    print(f"  - é™ä½æƒé‡: {decrease_passed}/{len(DECREASE_WEIGHT_STOCKS)} åªè¾¾åˆ°ç›®æ ‡")
    print(f"{'='*80}\n")
    
    all_passed = total_passed == total_stocks
    return results, all_passed


def analyze_feature_differences(analyzer, scan_date):
    """åˆ†ææé«˜æƒé‡å’Œé™ä½æƒé‡è‚¡ç¥¨çš„ç‰¹å¾å·®å¼‚"""
    increase_features = []
    decrease_features = []
    
    # æå–æé«˜æƒé‡è‚¡ç¥¨çš„ç‰¹å¾
    for code in INCREASE_WEIGHT_STOCKS.keys():
        features, _ = extract_features_for_stock(analyzer, code, scan_date)
        if features:
            increase_features.append(features)
    
    # æå–é™ä½æƒé‡è‚¡ç¥¨çš„ç‰¹å¾
    for code in DECREASE_WEIGHT_STOCKS.keys():
        features, _ = extract_features_for_stock(analyzer, code, scan_date)
        if features:
            decrease_features.append(features)
    
    if len(increase_features) == 0 or len(decrease_features) == 0:
        return None
    
    # è®¡ç®—ç‰¹å¾å·®å¼‚
    feature_diffs = {}
    
    # è·å–æ‰€æœ‰ç‰¹å¾å
    all_feature_names = set()
    for f in increase_features + decrease_features:
        all_feature_names.update(f.keys())
    
    for feature_name in all_feature_names:
        increase_values = [f.get(feature_name) for f in increase_features if f.get(feature_name) is not None]
        decrease_values = [f.get(feature_name) for f in decrease_features if f.get(feature_name) is not None]
        
        if len(increase_values) > 0 and len(decrease_values) > 0:
            try:
                increase_mean = np.mean([float(v) for v in increase_values if isinstance(v, (int, float))])
                decrease_mean = np.mean([float(v) for v in decrease_values if isinstance(v, (int, float))])
                
                if isinstance(increase_mean, (int, float)) and isinstance(decrease_mean, (int, float)):
                    diff = increase_mean - decrease_mean
                    feature_diffs[feature_name] = {
                        'increase_mean': increase_mean,
                        'decrease_mean': decrease_mean,
                        'diff': diff
                    }
            except:
                pass
    
    return feature_diffs


def adjust_model_weights(analyzer, feature_diffs, iteration, increase_features_list, decrease_features_list):
    """æ ¹æ®ç‰¹å¾å·®å¼‚è°ƒæ•´æ¨¡å‹æƒé‡ï¼ˆæ”¹è¿›ç‰ˆï¼šæ›´æ¿€è¿›çš„è°ƒæ•´ç­–ç•¥ï¼‰"""
    trained_features = analyzer.get_trained_features()
    if trained_features is None:
        return None
    
    common_features = trained_features.get('common_features', {}).copy()
    
    # æ›´æ¿€è¿›çš„è°ƒæ•´ç­–ç•¥ï¼šç›´æ¥è°ƒæ•´æ ‡å‡†å·®å’Œä¸­ä½æ•°
    # è°ƒæ•´å¹…åº¦ï¼šä»0.3é€æ¸å‡å°åˆ°0.15
    base_adjustment = 0.3
    adjustment_factor = base_adjustment * (1.0 - 0.3 * iteration / MAX_ITERATIONS)
    
    # è®¡ç®—æé«˜æƒé‡è‚¡ç¥¨çš„ç‰¹å¾ç»Ÿè®¡å€¼
    increase_stats = {}
    
    # è·å–æ‰€æœ‰ç‰¹å¾å
    all_feature_names = set()
    for f in increase_features_list:
        all_feature_names.update(f.keys())
    
    for feature_name in all_feature_names:
        # è®¡ç®—æé«˜æƒé‡è‚¡ç¥¨çš„ç‰¹å¾å€¼åˆ—è¡¨
        increase_values = []
        for f in increase_features_list:
            val = f.get(feature_name)
            if val is not None and isinstance(val, (int, float)) and not np.isnan(val):
                increase_values.append(float(val))
        
        if len(increase_values) > 0:
            increase_stats[feature_name] = {
                'mean': np.mean(increase_values),
                'median': np.median(increase_values),
                'std': np.std(increase_values) if len(increase_values) > 1 else abs(increase_values[0]) * 0.1 if increase_values[0] != 0 else 0.1,
                'min': np.min(increase_values),
                'max': np.max(increase_values)
            }
    
    # è°ƒæ•´æ¨¡å‹ç‰¹å¾ç»Ÿè®¡å€¼
    for feature_name in all_feature_names:
        if feature_name not in common_features:
            continue
        
        if feature_name not in increase_stats:
            continue
        
        stats = common_features[feature_name]
        increase_stat = increase_stats[feature_name]
        
        # å½“å‰æ¨¡å‹çš„å€¼
        current_median = stats.get('ä¸­ä½æ•°', stats.get('å‡å€¼', 0))
        current_std = stats.get('æ ‡å‡†å·®', 0)
        current_min = stats.get('æœ€å°å€¼', current_median - 2 * current_std if current_std > 0 else current_median - 1)
        current_max = stats.get('æœ€å¤§å€¼', current_median + 2 * current_std if current_std > 0 else current_median + 1)
        
        # ç›®æ ‡ï¼šä½¿æ¨¡å‹çš„ä¸­ä½æ•°æ›´æ¥è¿‘æé«˜æƒé‡è‚¡ç¥¨çš„ä¸­ä½æ•°
        target_median = increase_stat['median']
        target_std = increase_stat['std']
        
        # è°ƒæ•´ä¸­ä½æ•°ï¼ˆå‘æé«˜æƒé‡è‚¡ç¥¨çš„ä¸­ä½æ•°ç§»åŠ¨ï¼‰
        diff_median = target_median - current_median
        new_median = current_median + adjustment_factor * diff_median
        
        # è°ƒæ•´æ ‡å‡†å·®ï¼šå¢å¤§æ ‡å‡†å·®å¯ä»¥é™ä½z-scoreï¼Œæé«˜åŒ¹é…åº¦
        # ä½†è¦ç¡®ä¿æ ‡å‡†å·®ä¸ä¼šå¤ªå°ï¼ˆå¤ªå°ä¼šå¯¼è‡´åŒ¹é…åº¦é™ä½ï¼‰
        if target_std > 0:
            # å¦‚æœå½“å‰æ ‡å‡†å·®å¤ªå°ï¼Œå¢å¤§å®ƒ
            if current_std < target_std * 1.5:
                # å¢å¤§æ ‡å‡†å·®ï¼ˆæé«˜åŒ¹é…åº¦ï¼‰
                new_std = current_std + adjustment_factor * (target_std * 1.5 - current_std)
            else:
                # å¦‚æœå½“å‰æ ‡å‡†å·®å·²ç»å¾ˆå¤§ï¼Œç¨å¾®å‡å°
                new_std = current_std - adjustment_factor * 0.1 * current_std
            new_std = max(0.01, new_std)  # ç¡®ä¿æ ‡å‡†å·®>0
        else:
            new_std = current_std
        
        # è°ƒæ•´æœ€å°å€¼/æœ€å¤§å€¼èŒƒå›´ï¼ˆæ‰©å¤§èŒƒå›´å¯ä»¥æé«˜åŒ¹é…åº¦ï¼‰
        range_increase = increase_stat['max'] - increase_stat['min']
        if range_increase > 0:
            # æ‰©å¤§èŒƒå›´
            buffer = range_increase * 0.2 * adjustment_factor
            new_min = min(current_min, increase_stat['min'] - buffer)
            new_max = max(current_max, increase_stat['max'] + buffer)
        else:
            new_min = current_min
            new_max = current_max
        
        # æ›´æ–°ç»Ÿè®¡å€¼
        stats['ä¸­ä½æ•°'] = new_median
        if 'å‡å€¼' in stats:
            stats['å‡å€¼'] = new_median  # ä¹Ÿæ›´æ–°å‡å€¼
        stats['æ ‡å‡†å·®'] = new_std
        stats['æœ€å°å€¼'] = new_min
        stats['æœ€å¤§å€¼'] = new_max
    
    return common_features


def tune_model_iteratively():
    """è¿­ä»£å¾®è°ƒæ¨¡å‹"""
    print("="*80)
    print("å¼€å§‹å¾®è°ƒæ¨¡å‹æƒé‡")
    print("="*80)
    print("\næé«˜æƒé‡çš„è‚¡ç¥¨:")
    for code, info in INCREASE_WEIGHT_STOCKS.items():
        print(f"  - {code} {info['name']}: ç›®æ ‡åŒ¹é…åº¦ >= {info['target_score']:.3f}")
    print("\né™ä½æƒé‡çš„è‚¡ç¥¨:")
    for code, info in DECREASE_WEIGHT_STOCKS.items():
        print(f"  - {code} {info['name']}: ç›®æ ‡åŒ¹é…åº¦ <= {info['target_score']:.3f}")
    print(f"\næµ‹è¯•æ—¥æœŸ: {TEST_DATE}")
    print("="*80)
    
    # åŠ è½½å½“å‰æ¨¡å‹
    analyzer = BullStockAnalyzer(
        auto_load_default_stocks=False,
        auto_analyze_and_train=False
    )
    
    print("\nğŸ“¦ åŠ è½½å½“å‰æ¨¡å‹...")
    if not analyzer.load_model('trained_model.json', skip_network=True):
        print("âŒ æ— æ³•åŠ è½½å½“å‰æ¨¡å‹")
        return None, None, None
    
    trained_features = analyzer.get_trained_features()
    if trained_features:
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        print(f"   - ç‰¹å¾æ•°: {len(trained_features.get('common_features', {}))}")
        print(f"   - æ ·æœ¬æ•°: {trained_features.get('sample_count', 0)}")
    
    # å…ˆéªŒè¯å½“å‰çŠ¶æ€
    print("\nğŸ“Š éªŒè¯å½“å‰æ¨¡å‹çŠ¶æ€...")
    initial_results, _ = verify_all_stocks(analyzer, TEST_DATE)
    
    best_model = None
    best_results = initial_results.copy()
    best_score = sum(r.get('score', 0) for r in initial_results.values() if r.get('type') == 'increase') - \
                 sum(r.get('score', 0) for r in initial_results.values() if r.get('type') == 'decrease')
    
    # åˆ†æç‰¹å¾å·®å¼‚
    print("\nğŸ“Š åˆ†æç‰¹å¾å·®å¼‚...")
    feature_diffs = analyze_feature_differences(analyzer, TEST_DATE)
    if feature_diffs:
        print(f"âœ… æ‰¾åˆ° {len(feature_diffs)} ä¸ªæœ‰å·®å¼‚çš„ç‰¹å¾")
        # æ˜¾ç¤ºå·®å¼‚æœ€å¤§çš„å‰10ä¸ªç‰¹å¾
        sorted_diffs = sorted(feature_diffs.items(), key=lambda x: abs(x[1]['diff']), reverse=True)
        print("\nå·®å¼‚æœ€å¤§çš„ç‰¹å¾ï¼ˆå‰10ä¸ªï¼‰:")
        for i, (name, diff_info) in enumerate(sorted_diffs[:10], 1):
            print(f"  {i}. {name}: æé«˜æƒé‡å‡å€¼={diff_info['increase_mean']:.3f}, "
                  f"é™ä½æƒé‡å‡å€¼={diff_info['decrease_mean']:.3f}, "
                  f"å·®å¼‚={diff_info['diff']:.3f}")
    
    # è¿­ä»£å¾®è°ƒ
    increase_features_list = []
    decrease_features_list = []
    
    # é¢„å…ˆæå–æ‰€æœ‰ç‰¹å¾
    print("\nğŸ“Š æå–æ‰€æœ‰è‚¡ç¥¨çš„ç‰¹å¾...")
    for code in INCREASE_WEIGHT_STOCKS.keys():
        features, _ = extract_features_for_stock(analyzer, code, TEST_DATE)
        if features:
            increase_features_list.append(features)
    
    for code in DECREASE_WEIGHT_STOCKS.keys():
        features, _ = extract_features_for_stock(analyzer, code, TEST_DATE)
        if features:
            decrease_features_list.append(features)
    
    print(f"âœ… æå–å®Œæˆ: æé«˜æƒé‡ {len(increase_features_list)} åª, é™ä½æƒé‡ {len(decrease_features_list)} åª")
    
    for iteration in range(1, MAX_ITERATIONS + 1):
        print(f"\n{'='*80}")
        print(f"ç¬¬ {iteration} æ¬¡å¾®è°ƒ")
        print(f"{'='*80}")
        
        try:
            # è°ƒæ•´æ¨¡å‹æƒé‡
            if increase_features_list and decrease_features_list:
                adjusted_features = adjust_model_weights(
                    analyzer, 
                    feature_diffs, 
                    iteration,
                    increase_features_list,
                    decrease_features_list
                )
                if adjusted_features:
                    # æ›´æ–°æ¨¡å‹
                    analyzer.trained_features = {
                        'common_features': adjusted_features,
                        'sample_count': trained_features.get('sample_count', 0),
                        'trained_at': datetime.now().isoformat()
                    }
            
            # éªŒè¯è°ƒæ•´åçš„æ•ˆæœ
            results, all_passed = verify_all_stocks(analyzer, TEST_DATE)
            
            # è®¡ç®—ç»¼åˆå¾—åˆ†ï¼ˆæé«˜æƒé‡è‚¡ç¥¨å¾—åˆ† - é™ä½æƒé‡è‚¡ç¥¨å¾—åˆ†ï¼‰
            current_score = sum(r.get('score', 0) for r in results.values() if r.get('type') == 'increase') - \
                           sum(r.get('score', 0) for r in results.values() if r.get('type') == 'decrease')
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if all_passed or (best_model is None) or (current_score > best_score):
                best_model = analyzer.trained_features.copy() if analyzer.trained_features else None
                best_results = results.copy()
                best_score = current_score
                
                # ä¿å­˜æ¨¡å‹
                model_filename = f'trained_model_tuned_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
                analyzer.save_model(model_filename)
                print(f"\nğŸ’¾ ä¿å­˜æ¨¡å‹: {model_filename}")
            
            # å¦‚æœè¾¾åˆ°ç›®æ ‡ï¼Œåœæ­¢
            if all_passed:
                print(f"\nğŸ‰ æˆåŠŸï¼æ‰€æœ‰è‚¡ç¥¨åŒ¹é…åº¦å‡è¾¾åˆ°ç›®æ ‡ï¼")
                print(f"   å¾®è°ƒæ¬¡æ•°: {iteration}")
                break
            
        except Exception as e:
            print(f"âŒ ç¬¬ {iteration} æ¬¡å¾®è°ƒå¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            continue
    
    # è¾“å‡ºæœ€ç»ˆç»“æœ
    print(f"\n{'='*80}")
    print("å¾®è°ƒå®Œæˆ")
    print(f"{'='*80}")
    
    if best_results:
        print("\næœ€ç»ˆåŒ¹é…åº¦ç»“æœï¼š")
        print("\næé«˜æƒé‡çš„è‚¡ç¥¨:")
        for code, result in best_results.items():
            if result.get('type') == 'increase':
                status = "âœ…" if result.get('passed', False) else "âŒ"
                print(f"{status} {code} {result.get('name', '')}: {result.get('score', 0):.3f} (ç›®æ ‡: {result.get('target', 0):.3f})")
        
        print("\né™ä½æƒé‡çš„è‚¡ç¥¨:")
        for code, result in best_results.items():
            if result.get('type') == 'decrease':
                status = "âœ…" if result.get('passed', False) else "âŒ"
                print(f"{status} {code} {result.get('name', '')}: {result.get('score', 0):.3f} (ç›®æ ‡: â‰¤{result.get('target', 0):.3f})")
    
    return analyzer, best_model, best_results


if __name__ == '__main__':
    try:
        analyzer, model, results = tune_model_iteratively()
        print("\nâœ… å¾®è°ƒè„šæœ¬æ‰§è¡Œå®Œæˆ")
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­å¾®è°ƒ")
    except Exception as e:
        print(f"\nâŒ å¾®è°ƒå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
