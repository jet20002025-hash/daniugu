#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Vercel ç¯å¢ƒæ‰«æè¾…åŠ©å‡½æ•°
ç”¨äºåœ¨ Vercel serverless ç¯å¢ƒä¸­åˆ†æ‰¹å¤„ç†æ‰«æä»»åŠ¡
"""
import time
import json
from typing import Dict, List, Any
import pandas as pd
import scan_progress_store


def process_scan_batch_vercel(
    analyzer,
    stock_batch: pd.DataFrame,
    common_features: Dict,
    scan_id: str,
    batch_num: int,
    total_batches: int,
    total_stocks: int,
    min_match_score: float,
    max_market_cap: float,
    start_idx: int,
    existing_candidates: List[Dict],
    scan_config: Dict = None
) -> Dict:
    """
    å¤„ç†ä¸€æ‰¹è‚¡ç¥¨çš„æ‰«æï¼ˆVercel ç¯å¢ƒï¼‰
    :param analyzer: BullStockAnalyzer å®ä¾‹
    :param stock_batch: å½“å‰æ‰¹æ¬¡çš„è‚¡ç¥¨åˆ—è¡¨ï¼ˆDataFrameï¼‰
    :param common_features: å…±åŒç‰¹å¾æ¨¡æ¿
    :param scan_id: æ‰«æä»»åŠ¡ID
    :param batch_num: å½“å‰æ‰¹æ¬¡å·
    :param total_batches: æ€»æ‰¹æ¬¡æ•°
    :param total_stocks: æ€»è‚¡ç¥¨æ•°
    :param min_match_score: æœ€å°åŒ¹é…åº¦é˜ˆå€¼
    :param max_market_cap: æœ€å¤§å¸‚å€¼
    :param start_idx: èµ·å§‹ç´¢å¼•ï¼ˆåœ¨æ€»è‚¡ç¥¨åˆ—è¡¨ä¸­çš„ä½ç½®ï¼‰
    :param existing_candidates: å·²æœ‰å€™é€‰è‚¡ç¥¨åˆ—è¡¨
    :return: æ‰«æç»“æœ
    """
    # è·å–æ‰«æé…ç½®ï¼ˆå¦‚æœæœªæä¾›ï¼Œä½¿ç”¨é»˜è®¤å€¼ï¼‰
    if scan_config is None:
        scan_config = {
            'stock_timeout': 8,
            'batch_delay': 3
        }
    
    # ä»é…ç½®è·å–è¶…æ—¶æ—¶é—´
    max_stock_time = scan_config.get('stock_timeout', 8)
    
    batch_size = len(stock_batch)
    candidates = existing_candidates.copy() if existing_candidates else []
    
    # è·å–åˆ—å
    code_col = None
    name_col = None
    for col in stock_batch.columns:
        col_lower = str(col).lower()
        if 'code' in col_lower or 'ä»£ç ' in col:
            code_col = col
        elif 'name' in col_lower or 'åç§°' in col:
            name_col = col
    
    if code_col is None:
        code_col = stock_batch.columns[0]
    if name_col is None and len(stock_batch.columns) >= 2:
        name_col = stock_batch.columns[1]
    
    # å¼€å§‹å¤„ç†æ‰¹æ¬¡
    batch_start_time = time.time()
    processed_count = 0
    
    for idx, (_, row) in enumerate(stock_batch.iterrows()):
        stock_code_raw = str(row[code_col])
        stock_name = str(row[name_col]) if name_col else stock_code_raw
        current_idx = start_idx + idx + 1
        
        # å¤„ç†è‚¡ç¥¨ä»£ç æ ¼å¼ï¼šakshare éœ€è¦çº¯æ•°å­—ä»£ç ï¼Œå»é™¤ .SZ æˆ– .SH åç¼€å’Œå…¶ä»–å­—ç¬¦
        # ä¾‹å¦‚ï¼š'603597.SH' -> '603597'ï¼Œ'000001.SZ' -> '000001'ï¼Œ'603597.SH ' -> '603597'
        import re
        stock_code = re.sub(r'\.(SZ|SH|sz|sh)$', '', stock_code_raw).strip()
        # åªä¿ç•™æ•°å­—éƒ¨åˆ†ï¼ˆ6ä½æ•°å­—ï¼‰
        stock_code = re.sub(r'[^0-9]', '', stock_code)
        
        # ç‰¹æ®Šå¤„ç†ï¼šç…œé‚¦ç”µåŠ› 603597ï¼ˆç”¨äºè°ƒè¯•å’Œåˆ†æï¼‰
        is_target_stock = (stock_code == '603597')
        if is_target_stock:
            print(f"[vercel_scan_helper] ğŸ” ========== å¼€å§‹å¤„ç†ç…œé‚¦ç”µåŠ› ==========")
            print(f"[vercel_scan_helper] ğŸ” åŸå§‹ä»£ç : {stock_code_raw}")
            print(f"[vercel_scan_helper] ğŸ” å¤„ç†åçš„ä»£ç : {stock_code}")
            print(f"[vercel_scan_helper] ğŸ” è‚¡ç¥¨åç§°: {stock_name}")
        
        # éªŒè¯è‚¡ç¥¨ä»£ç æ ¼å¼ï¼ˆåº”è¯¥æ˜¯6ä½æ•°å­—ï¼‰
        if not stock_code or len(stock_code) != 6 or not stock_code.isdigit():
            if is_target_stock:
                print(f"[vercel_scan_helper] âŒ ç…œé‚¦ç”µåŠ›è‚¡ç¥¨ä»£ç æ ¼å¼é”™è¯¯: {stock_code}ï¼ˆåŸå§‹: {stock_code_raw}ï¼‰")
            continue
        
        try:
            # æ£€æŸ¥è¶…æ—¶ï¼ˆæ ¹æ®ç”¨æˆ·ç­‰çº§ä½¿ç”¨ä¸åŒçš„è¶…æ—¶æ—¶é—´ï¼‰
            stock_start_time = time.time()
            
            # è·å–è‚¡ç¥¨å‘¨çº¿æ•°æ®ï¼ˆæ·»åŠ è¶…æ—¶æœºåˆ¶å’Œè¯¦ç»†æ—¥å¿—ï¼‰
            # ä¿®å¤ï¼šget_weekly_kline çš„å‚æ•°æ˜¯ periodï¼Œä¸æ˜¯ weeks
            # åœ¨ Vercel ç¯å¢ƒä¸­ï¼Œä½¿ç”¨è¶…æ—¶æœºåˆ¶é¿å…é˜»å¡
            weekly_df = None
            weekly_df_error = None
            
            try:
                import threading
                weekly_df_result = [None]
                weekly_df_error_result = [None]
                
                def fetch_weekly_data():
                    try:
                        if is_target_stock:
                            print(f"[vercel_scan_helper] ğŸ” ç…œé‚¦ç”µåŠ›ï¼šå¼€å§‹è°ƒç”¨ get_weekly_klineï¼Œå‚æ•°: period='2y'")
                        # ä¿®å¤å‚æ•°ï¼šä½¿ç”¨ period="2y" è€Œä¸æ˜¯ weeks=100
                        weekly_df_result[0] = analyzer.fetcher.get_weekly_kline(stock_code, period="2y")
                        if is_target_stock:
                            print(f"[vercel_scan_helper] ğŸ” ç…œé‚¦ç”µåŠ›ï¼šget_weekly_kline è¿”å›ç»“æœ: {weekly_df_result[0] is not None}, é•¿åº¦: {len(weekly_df_result[0]) if weekly_df_result[0] is not None else 0}")
                    except Exception as e:
                        weekly_df_error_result[0] = e
                        import traceback
                        error_detail = traceback.format_exc()
                        if is_target_stock:
                            print(f"[vercel_scan_helper] ğŸ” ç…œé‚¦ç”µåŠ›ï¼šè·å–å‘¨Kçº¿æ•°æ®å¼‚å¸¸: {e}")
                            print(f"[vercel_scan_helper] ğŸ” ç…œé‚¦ç”µåŠ›ï¼šé”™è¯¯è¯¦æƒ…: {error_detail}")
                        else:
                            print(f"[vercel_scan_helper] {stock_code} ({stock_name}) è·å–å‘¨Kçº¿æ•°æ®å¼‚å¸¸: {e}")
                
                fetch_thread = threading.Thread(target=fetch_weekly_data)
                fetch_thread.daemon = True
                fetch_thread.start()
                fetch_thread.join(timeout=5)  # æœ€å¤šç­‰å¾…5ç§’ï¼Œç•™å‡ºæ—¶é—´ç»™åç»­å¤„ç†
                
                if fetch_thread.is_alive():
                    # çº¿ç¨‹ä»åœ¨è¿è¡Œï¼Œè¯´æ˜è¶…æ—¶äº†
                    elapsed = time.time() - stock_start_time
                    if is_target_stock:
                        print(f"[vercel_scan_helper] âŒ ç…œé‚¦ç”µåŠ›ï¼šå‘¨Kçº¿æ•°æ®è·å–è¶…æ—¶ï¼ˆ>{elapsed:.1f}ç§’ï¼‰ï¼Œå¯èƒ½åŸå› ï¼šakshare API å“åº”æ…¢æˆ–ç½‘ç»œé—®é¢˜")
                    else:
                        print(f"[vercel_scan_helper] â±ï¸ {stock_code} ({stock_name}) å‘¨Kçº¿æ•°æ®è·å–è¶…æ—¶ï¼ˆ>{elapsed:.1f}ç§’ï¼‰ï¼Œè·³è¿‡")
                    continue
                
                if weekly_df_error_result[0]:
                    weekly_df_error = weekly_df_error_result[0]
                    if is_target_stock:
                        print(f"[vercel_scan_helper] âŒ ç…œé‚¦ç”µåŠ›ï¼šè·å–å‘¨Kçº¿æ•°æ®å¤±è´¥: {weekly_df_error}")
                        print(f"[vercel_scan_helper] âŒ å¯èƒ½åŸå› ï¼š1) akshare API é”™è¯¯ 2) è‚¡ç¥¨ä»£ç æ ¼å¼é—®é¢˜ 3) ç½‘ç»œè¿æ¥é—®é¢˜")
                    else:
                        print(f"[vercel_scan_helper] âŒ {stock_code} ({stock_name}) è·å–å‘¨Kçº¿æ•°æ®å¤±è´¥: {weekly_df_error}")
                    continue
                
                weekly_df = weekly_df_result[0]
            except Exception as e:
                import traceback
                error_detail = traceback.format_exc()
                if is_target_stock:
                    print(f"[vercel_scan_helper] âŒ ç…œé‚¦ç”µåŠ›ï¼šè·å–å‘¨Kçº¿æ•°æ®æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
                    print(f"[vercel_scan_helper] âŒ å¼‚å¸¸è¯¦æƒ…: {error_detail}")
                else:
                    print(f"[vercel_scan_helper] âŒ {stock_code} ({stock_name}) è·å–å‘¨Kçº¿æ•°æ®æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
                continue
            
            if weekly_df is None or len(weekly_df) < 40:
                if is_target_stock:
                    if weekly_df is None:
                        print(f"[vercel_scan_helper] âŒ ç…œé‚¦ç”µåŠ›ï¼šå‘¨Kçº¿æ•°æ®ä¸º Noneï¼Œå¯èƒ½åŸå› ï¼š1) akshare API è¿”å›ç©ºæ•°æ® 2) è‚¡ç¥¨ä»£ç ä¸å­˜åœ¨ 3) API è°ƒç”¨å¤±è´¥")
                    elif len(weekly_df) < 40:
                        print(f"[vercel_scan_helper] âŒ ç…œé‚¦ç”µåŠ›ï¼šå‘¨Kçº¿æ•°æ®ä¸è¶³40æ¡ï¼ˆåªæœ‰ {len(weekly_df)} æ¡ï¼‰ï¼Œéœ€è¦è‡³å°‘40æ¡ç”¨äºç‰¹å¾åˆ†æ")
                else:
                    if weekly_df is None:
                        print(f"[vercel_scan_helper] âš ï¸ {stock_code} ({stock_name}) å‘¨Kçº¿æ•°æ®ä¸º Noneï¼Œè·³è¿‡")
                    elif len(weekly_df) < 40:
                        print(f"[vercel_scan_helper] âš ï¸ {stock_code} ({stock_name}) å‘¨Kçº¿æ•°æ®ä¸è¶³40æ¡ï¼ˆåªæœ‰ {len(weekly_df)} æ¡ï¼‰ï¼Œè·³è¿‡")
                continue
            
            if is_target_stock:
                print(f"[vercel_scan_helper] âœ… ç…œé‚¦ç”µåŠ›ï¼šæˆåŠŸè·å– {len(weekly_df)} æ¡å‘¨Kçº¿æ•°æ®ï¼Œç»§ç»­å¤„ç†...")
            
            # æŸ¥æ‰¾ä¹°ç‚¹
            found_buy_point = False
            for i in range(40, len(weekly_df)):
                # æ£€æŸ¥å•åªè‚¡ç¥¨å¤„ç†æ—¶é—´
                if time.time() - stock_start_time > max_stock_time:
                    if is_target_stock and not found_buy_point:
                        print(f"[vercel_scan_helper] âš ï¸ ç…œé‚¦ç”µåŠ›ï¼šå•åªè‚¡ç¥¨å¤„ç†æ—¶é—´è¶…è¿‡é™åˆ¶ï¼ˆ{max_stock_time}ç§’ï¼‰ï¼Œåœæ­¢æŸ¥æ‰¾ä¹°ç‚¹")
                    break
                
                try:
                    if is_target_stock and i == 40:
                        print(f"[vercel_scan_helper] ğŸ” ç…œé‚¦ç”µåŠ›ï¼šå¼€å§‹æå–ç‰¹å¾ï¼ˆèµ·ç‚¹ç´¢å¼•: {i}, å›çœ‹å‘¨æ•°: 40ï¼‰")
                    
                    features = analyzer.extract_features_at_start_point(
                        stock_code, i, lookback_weeks=40
                    )
                    if features is None:
                        if is_target_stock and i == 40:
                            print(f"[vercel_scan_helper] âš ï¸ ç…œé‚¦ç”µåŠ›ï¼šç‰¹å¾æå–è¿”å› Noneï¼Œå¯èƒ½åŸå› ï¼šæ•°æ®ä¸è¶³æˆ–æå–å¤±è´¥")
                        continue
                    
                    if is_target_stock and i == 40:
                        print(f"[vercel_scan_helper] ğŸ” ç…œé‚¦ç”µåŠ›ï¼šç‰¹å¾æå–æˆåŠŸï¼Œç‰¹å¾æ•°é‡: {len(features) if features else 0}")
                    
                    match_score = analyzer._calculate_match_score(
                        features, common_features, analyzer.tolerance
                    )
                    total_match = match_score.get('æ€»åŒ¹é…åº¦', 0)
                    
                    if is_target_stock and i == 40:
                        print(f"[vercel_scan_helper] ğŸ” ç…œé‚¦ç”µåŠ›ï¼šåŒ¹é…åº¦è®¡ç®—ç»“æœ: {total_match:.4f} (é˜ˆå€¼: {min_match_score})")
                        print(f"[vercel_scan_helper] ğŸ” ç…œé‚¦ç”µåŠ›ï¼š{'âœ… åŒ¹é…åº¦ç¬¦åˆæ¡ä»¶' if total_match >= min_match_score else 'âŒ åŒ¹é…åº¦ä¸ç¬¦åˆæ¡ä»¶ï¼ˆéœ€è¦ >= ' + str(min_match_score) + 'ï¼‰'}")
                    
                    if total_match >= min_match_score:
                        found_buy_point = True
                        # åŒ¹é…åº¦ç¬¦åˆæ¡ä»¶ï¼Œæ£€æŸ¥å¸‚å€¼ï¼ˆå¦‚æœå¸‚å€¼è·å–å¤±è´¥ï¼Œåˆ™è·³è¿‡å¸‚å€¼æ£€æŸ¥ï¼‰
                        market_cap = None
                        market_cap_valid = False
                        
                        # å°è¯•è·å–å¸‚å€¼ï¼ˆä½¿ç”¨è¶…æ—¶æœºåˆ¶ï¼Œé¿å…é˜»å¡ï¼‰
                        try:
                            import threading
                            market_cap_result = [None]
                            
                            def fetch_market_cap():
                                try:
                                    market_cap_result[0] = analyzer.fetcher.get_market_cap(stock_code, timeout=2)
                                except Exception:
                                    pass  # é™é»˜å¤±è´¥
                            
                            cap_thread = threading.Thread(target=fetch_market_cap)
                            cap_thread.daemon = True
                            cap_thread.start()
                            cap_thread.join(timeout=2.5)  # æœ€å¤šç­‰å¾…2.5ç§’
                            
                            if not cap_thread.is_alive():
                                market_cap = market_cap_result[0]
                                if market_cap is not None and market_cap > 0:
                                    market_cap_valid = True
                                    # å¦‚æœå¸‚å€¼è·å–æˆåŠŸï¼Œæ£€æŸ¥æ˜¯å¦ç¬¦åˆæ¡ä»¶
                                    if is_target_stock:
                                        print(f"[vercel_scan_helper] ğŸ” ç…œé‚¦ç”µåŠ›ï¼šå¸‚å€¼è·å–æˆåŠŸ: {market_cap:.2f} äº¿å…ƒ (é™åˆ¶: {max_market_cap} äº¿å…ƒ)")
                                    if market_cap > max_market_cap:
                                        # å¸‚å€¼è¶…è¿‡é™åˆ¶ï¼Œè·³è¿‡è¯¥è‚¡ç¥¨
                                        if is_target_stock:
                                            print(f"[vercel_scan_helper] âŒ ç…œé‚¦ç”µåŠ›ï¼šå¸‚å€¼ {market_cap:.2f} äº¿å…ƒè¶…è¿‡é™åˆ¶ {max_market_cap} äº¿å…ƒï¼Œè¢«è¿‡æ»¤æ‰")
                                        continue
                                    elif is_target_stock:
                                        print(f"[vercel_scan_helper] âœ… ç…œé‚¦ç”µåŠ›ï¼šå¸‚å€¼ {market_cap:.2f} äº¿å…ƒç¬¦åˆæ¡ä»¶ï¼ˆ<= {max_market_cap} äº¿å…ƒï¼‰")
                                elif is_target_stock:
                                    print(f"[vercel_scan_helper] âš ï¸ ç…œé‚¦ç”µåŠ›ï¼šå¸‚å€¼è·å–è¿”å› None æˆ– 0ï¼Œè·³è¿‡å¸‚å€¼æ£€æŸ¥")
                            elif is_target_stock:
                                print(f"[vercel_scan_helper] âš ï¸ ç…œé‚¦ç”µåŠ›ï¼šå¸‚å€¼è·å–è¶…æ—¶ï¼ˆ2.5ç§’ï¼‰ï¼Œè·³è¿‡å¸‚å€¼æ£€æŸ¥")
                        except Exception as e:
                            # å¸‚å€¼è·å–å¤±è´¥ï¼Œè·³è¿‡å¸‚å€¼æ£€æŸ¥ï¼Œç»§ç»­å¤„ç†è¯¥è‚¡ç¥¨
                            if is_target_stock:
                                print(f"[vercel_scan_helper] âš ï¸ ç…œé‚¦ç”µåŠ›ï¼šå¸‚å€¼è·å–å¼‚å¸¸ï¼Œè·³è¿‡å¸‚å€¼æ£€æŸ¥: {e}")
                            pass
                        
                        # å¸‚å€¼æ£€æŸ¥é€šè¿‡ï¼ˆæˆ–å¸‚å€¼è·å–å¤±è´¥ï¼Œè·³è¿‡æ£€æŸ¥ï¼‰ï¼Œè®°å½•è¯¥è‚¡ç¥¨
                        buy_date = weekly_df.iloc[i]['æ—¥æœŸ']
                        if isinstance(buy_date, pd.Timestamp):
                            buy_date_str = buy_date.strftime('%Y-%m-%d')
                        else:
                            buy_date_str = str(buy_date)
                        
                        buy_price = float(weekly_df.iloc[i]['æ”¶ç›˜'])
                        
                        # è®¡ç®—åç»­è¡¨ç°
                        gain_4w = None
                        gain_10w = None
                        max_gain_10w = None
                        gain_20w = None
                        
                        if i + 4 < len(weekly_df):
                            future_price_4w = float(weekly_df.iloc[i + 4]['æ”¶ç›˜'])
                            gain_4w = (future_price_4w - buy_price) / buy_price * 100
                        
                        if i + 10 < len(weekly_df):
                            future_price_10w = float(weekly_df.iloc[i + 10]['æ”¶ç›˜'])
                            gain_10w = (future_price_10w - buy_price) / buy_price * 100
                            max_price_10w = float(weekly_df.iloc[i+1:i+11]['æœ€é«˜'].max())
                            max_gain_10w = (max_price_10w - buy_price) / buy_price * 100
                        
                        if i + 20 < len(weekly_df):
                            future_price_20w = float(weekly_df.iloc[i + 20]['æ”¶ç›˜'])
                            gain_20w = (future_price_20w - buy_price) / buy_price * 100
                        
                        # è®¡ç®—æ­¢æŸå’Œæœ€ä½³å–ç‚¹ï¼ˆç®€åŒ–ç‰ˆï¼‰
                        stop_loss_price = buy_price * 0.90  # 10%æ­¢æŸ
                        ma20 = float(weekly_df.iloc[i]['MA20']) if 'MA20' in weekly_df.columns else buy_price
                        if ma20 > 0:
                            stop_loss_price = min(stop_loss_price, ma20 * 0.95)
                        
                        best_sell_price = None
                        best_sell_date = None
                        if i + 1 < len(weekly_df):
                            future_window = weekly_df.iloc[i+1:]
                            if len(future_window) > 0:
                                max_price_pos = future_window['æœ€é«˜'].values.argmax()
                                max_price = float(future_window.iloc[max_price_pos]['æœ€é«˜'])
                                max_date = future_window.iloc[max_price_pos]['æ—¥æœŸ']
                                if isinstance(max_date, pd.Timestamp):
                                    best_sell_date = max_date.strftime('%Y-%m-%d')
                                else:
                                    best_sell_date = str(max_date)
                                best_sell_price = max_price
                        
                        candidate = {
                            'code': stock_code,
                            'name': stock_name,
                            'buy_date': buy_date_str,
                            'buy_price': round(buy_price, 2),
                            'match_score': round(total_match, 3),
                            'gain_4w': round(gain_4w, 2) if gain_4w is not None else None,
                            'gain_10w': round(gain_10w, 2) if gain_10w is not None else None,
                            'max_gain_10w': round(max_gain_10w, 2) if max_gain_10w is not None else None,
                            'gain_20w': round(gain_20w, 2) if gain_20w is not None else None,
                            'stop_loss_price': round(stop_loss_price, 2),
                            'best_sell_price': round(best_sell_price, 2) if best_sell_price else None,
                            'best_sell_date': best_sell_date,
                            'market_cap': round(market_cap, 2) if market_cap_valid else None
                        }
                        
                        candidates.append(candidate)
                        if is_target_stock:
                            print(f"[vercel_scan_helper] âœ… ç…œé‚¦ç”µåŠ›ï¼šæˆåŠŸæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„ä¹°ç‚¹ï¼")
                            print(f"[vercel_scan_helper] âœ… ä¹°ç‚¹æ—¥æœŸ: {buy_date_str}, ä¹°ç‚¹ä»·æ ¼: {buy_price:.2f}, åŒ¹é…åº¦: {total_match:.4f}, å¸‚å€¼: {market_cap:.2f}äº¿å…ƒ" if market_cap_valid else f"[vercel_scan_helper] âœ… ä¹°ç‚¹æ—¥æœŸ: {buy_date_str}, ä¹°ç‚¹ä»·æ ¼: {buy_price:.2f}, åŒ¹é…åº¦: {total_match:.4f}, å¸‚å€¼: æœªçŸ¥")
                        break  # æ‰¾åˆ°ç¬¬ä¸€ä¸ªç¬¦åˆæ¡ä»¶çš„ä¹°ç‚¹å°±åœæ­¢
                
                except Exception as e:
                    # å•åªè‚¡ç¥¨å¤„ç†å‡ºé”™ï¼Œç»§ç»­ä¸‹ä¸€ä¸ª
                    if is_target_stock:
                        import traceback
                        print(f"[vercel_scan_helper] âŒ ç…œé‚¦ç”µåŠ›ï¼šå¤„ç†ä¹°ç‚¹æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
                        print(f"[vercel_scan_helper] âŒ å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")
                    continue
            
            # æ£€æŸ¥ç…œé‚¦ç”µåŠ›æ˜¯å¦æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„ä¹°ç‚¹
            if is_target_stock and not found_buy_point:
                print(f"[vercel_scan_helper] âŒ ç…œé‚¦ç”µåŠ›ï¼šéå†å®Œæ‰€æœ‰ä¹°ç‚¹ï¼Œæœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„ä¹°ç‚¹")
                print(f"[vercel_scan_helper] âŒ å¯èƒ½åŸå› ï¼š1) åŒ¹é…åº¦ä¸å¤Ÿï¼ˆéœ€è¦ >= {min_match_score}ï¼‰ 2) å¸‚å€¼è¶…è¿‡é™åˆ¶ï¼ˆé™åˆ¶: {max_market_cap} äº¿å…ƒï¼‰ 3) æ•°æ®è´¨é‡é—®é¢˜")
            
            processed_count += 1
            
            # æ›´æ–°è¿›åº¦ï¼ˆæ¯å¤„ç†5åªè‚¡ç¥¨æ›´æ–°ä¸€æ¬¡ï¼Œé¿å…é¢‘ç¹å†™Redisï¼‰
            if processed_count % 5 == 0 or processed_count == batch_size:
                # è®¡ç®—æ•´ä½“è¿›åº¦
                overall_current = start_idx + processed_count
                percentage = (overall_current / total_stocks) * 100 if total_stocks > 0 else 0
                
                progress = {
                    'type': 'scan',
                    'scan_id': scan_id,
                    'current': overall_current,
                    'total': total_stocks,
                    'status': 'è¿›è¡Œä¸­',
                    'detail': f'æ­£åœ¨æ‰«æç¬¬ {batch_num}/{total_batches} æ‰¹: {stock_code} {stock_name}... ({overall_current}/{total_stocks}) | å·²æ‰¾åˆ°: {len(candidates)} åª',
                    'percentage': round(percentage, 1),
                    'found': len(candidates),
                    'batch': batch_num,
                    'total_batches': total_batches,
                    'current_stock': stock_code,
                    'current_stock_name': stock_name,
                    'candidates': candidates[-10:],  # åªä¿å­˜æœ€è¿‘10åªï¼Œé¿å…æ•°æ®è¿‡å¤§
                    'last_update_time': time.time()
                }
                scan_progress_store.save_scan_progress(scan_id, progress)
        
        except Exception as e:
            # å•åªè‚¡ç¥¨å¤„ç†å‡ºé”™ï¼Œç»§ç»­ä¸‹ä¸€ä¸ª
            continue
    
    # æ‰¹æ¬¡å¤„ç†å®Œæˆ
    batch_end_time = time.time()
    batch_duration = batch_end_time - batch_start_time
    
    overall_current = start_idx + batch_size
    percentage = (overall_current / total_stocks) * 100 if total_stocks > 0 else 100.0 if overall_current >= total_stocks else percentage
    
    # åˆ¤æ–­æ˜¯å¦å®Œæˆæ‰€æœ‰æ‰¹æ¬¡
    is_complete = (batch_num >= total_batches)
    
    progress = {
        'type': 'scan',
        'scan_id': scan_id,
        'current': overall_current,
        'total': total_stocks,
        'status': 'å®Œæˆ' if is_complete else 'è¿›è¡Œä¸­',
        'detail': f'ç¬¬ {batch_num}/{total_batches} æ‰¹å®Œæˆï¼Œå·²å¤„ç† {overall_current}/{total_stocks} åªè‚¡ç¥¨ï¼Œæ‰¾åˆ° {len(candidates)} åªç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨' + ('ï¼ˆå…¨éƒ¨å®Œæˆï¼‰' if is_complete else 'ï¼ˆç­‰å¾…ä¸‹ä¸€æ‰¹ï¼‰'),
        'percentage': round(percentage, 1) if not is_complete else 100.0,
        'found': len(candidates),
        'batch': batch_num,
        'total_batches': total_batches,
        'candidates': candidates[-50:],  # ä¿å­˜æœ€è¿‘50åªå€™é€‰è‚¡ç¥¨
        'last_update_time': time.time(),
        'batch_duration': round(batch_duration, 2)
    }
    
    # ä¿å­˜è¿›åº¦
    scan_progress_store.save_scan_progress(scan_id, progress)
    
    # å¦‚æœå®Œæˆï¼Œä¿å­˜æœ€ç»ˆç»“æœ
    if is_complete:
        # è·å–è¿›åº¦ä¿¡æ¯
        progress_info = scan_progress_store.get_scan_progress(scan_id)
        is_global_scan = progress_info and progress_info.get('is_global_scan', False)
        scan_type = progress_info.get('scan_type') if progress_info else None
        scan_date = progress_info.get('scan_date') if progress_info else None
        username = progress_info.get('username', 'anonymous') if progress_info else 'anonymous'
        user_tier = progress_info.get('user_tier') if progress_info else None
        is_auto_scan = progress_info.get('is_auto_scan', False) if progress_info else False
        
        from datetime import datetime, timezone, timedelta
        beijing_tz = timezone(timedelta(hours=8))
        beijing_now = datetime.now(beijing_tz)
        current_date = beijing_now.strftime('%Y-%m-%d')
        
        results = {
            'success': True,
            'message': f'æ‰«æå®Œæˆï¼Œå…±æ‰¾åˆ° {len(candidates)} åªç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨',
            'candidates': candidates,
            'total_scanned': overall_current,
            'found_count': len(candidates),
            'scan_id': scan_id,
            'scan_type': scan_type,
            'scan_date': scan_date or current_date,
            'username': username,
            'user_tier': user_tier,
            'completed_at': beijing_now.strftime('%Y-%m-%d %H:%M:%S')
        }
        scan_progress_store.save_scan_results(scan_id, results)
        
        # å¦‚æœæ˜¯VIPç”¨æˆ·çš„æ‰‹åŠ¨æ‰«æï¼Œä¿å­˜åˆ°ç”¨æˆ·å†å²è®°å½•ï¼ˆ7å¤©ï¼‰
        if user_tier == 'premium' and not is_auto_scan and username != 'anonymous':
            try:
                # ä¿å­˜ç”¨æˆ·æ‰«æå†å²ï¼ˆæŒ‰æ—¥æœŸå’Œç”¨æˆ·åï¼‰
                user_history_key = f'user_scan_history:{username}:{current_date}'
                existing_history = scan_progress_store._upstash_redis_get(user_history_key) if hasattr(scan_progress_store, '_upstash_redis_get') else None
                
                scan_ids_list = []
                if existing_history:
                    if isinstance(existing_history, list):
                        scan_ids_list = existing_history
                    elif isinstance(existing_history, str):
                        try:
                            import json
                            scan_ids_list = json.loads(existing_history)
                        except:
                            scan_ids_list = [existing_history]
                    else:
                        scan_ids_list = [existing_history]
                
                # æ·»åŠ å½“å‰æ‰«æIDï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
                if scan_id not in scan_ids_list:
                    scan_ids_list.append(scan_id)
                    # åªä¿ç•™æœ€è¿‘10æ¬¡æ‰«æ
                    scan_ids_list = scan_ids_list[-10:]
                    
                    # ä¿å­˜å›Redisï¼ˆTTL 30å¤© = 2592000ç§’ï¼‰
                    if hasattr(scan_progress_store, '_upstash_redis_set'):
                        scan_progress_store._upstash_redis_set(user_history_key, json.dumps(scan_ids_list, ensure_ascii=False), ttl=2592000)
                        print(f"[vercel_scan_helper] âœ… VIPç”¨æˆ·æ‰«æå†å²å·²ä¿å­˜ - ç”¨æˆ·: {username}, æ—¥æœŸ: {current_date}, æ‰«æID: {scan_id}")
            except Exception as e:
                print(f"[vercel_scan_helper] âš ï¸ ä¿å­˜VIPç”¨æˆ·æ‰«æå†å²å¤±è´¥: {e}")
        
        # å¦‚æœæ˜¯å…¨å±€æ‰«æï¼Œä¿å­˜åˆ°å…¨å±€æ‰«æç»“æœå­˜å‚¨ï¼ˆæŒ‰ç±»å‹å’Œæ—¥æœŸï¼‰
        if is_global_scan and scan_type and scan_date:
            scan_time_display = '11:30' if scan_type == 'noon' else '15:00'
            
            global_results = {
                'success': True,
                'message': f'æ‰«æå®Œæˆï¼Œå…±æ‰¾åˆ° {len(candidates)} åªç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨',
                'candidates': candidates,
                'total_scanned': overall_current,
                'found_count': len(candidates),
                'scan_id': scan_id,
                'scan_type': scan_type,
                'scan_date': scan_date,
                'scan_time': scan_time_display,  # æ˜¾ç¤ºæ—¶é—´ï¼ˆ11:30 æˆ– 15:00ï¼‰
                'completed_at': beijing_now.strftime('%Y-%m-%d %H:%M:%S')
            }
            scan_progress_store.save_global_scan_results(scan_type, scan_date, global_results)
            print(f"[vercel_scan_helper] âœ… å…¨å±€æ‰«æç»“æœå·²ä¿å­˜ - ç±»å‹: {scan_type}, æ—¥æœŸ: {scan_date}, æ‰«ææ—¶é—´: {scan_time_display}")
    
    return {
        'success': True,
        'progress': progress,
        'candidates': candidates,
        'batch': batch_num,
        'is_complete': is_complete,
        'has_more': not is_complete
    }

