#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‡ªåŠ¨è®­ç»ƒæ¨¡å‹ï¼Œç¡®ä¿æ‰€æœ‰11åªè‚¡ç¥¨çš„åŒ¹é…åº¦éƒ½è¾¾åˆ°0.95ä»¥ä¸Š
é€šè¿‡ä¸æ–­ä¼˜åŒ–ç‰¹å¾æå–å’ŒåŒ¹é…åº¦è®¡ç®—ï¼Œç›´åˆ°æ»¡è¶³æ¡ä»¶
"""
from bull_stock_analyzer import BullStockAnalyzer
import json
import os
from datetime import datetime

def test_all_stocks_match_score(analyzer, target_stocks):
    """æµ‹è¯•æ‰€æœ‰è‚¡ç¥¨çš„åŒ¹é…åº¦"""
    print("\n" + "=" * 80)
    print("ğŸ” éªŒè¯æ‰€æœ‰è®­ç»ƒè‚¡ç¥¨çš„åŒ¹é…åº¦")
    print("=" * 80)
    
    match_scores = {}
    all_pass = True
    
    for stock_code in target_stocks:
        if stock_code not in analyzer.analysis_results:
            print(f"  {stock_code}: âŒ æœªåˆ†æ")
            all_pass = False
            continue
        
        analysis_result = analyzer.analysis_results[stock_code]
        interval = analysis_result.get('interval')
        if not interval or interval.get('èµ·ç‚¹ç´¢å¼•') is None:
            print(f"  {stock_code}: âŒ æ— æœ‰æ•ˆä¹°ç‚¹")
            all_pass = False
            continue
        
        start_idx = interval.get('èµ·ç‚¹ç´¢å¼•')
        weekly_df = analyzer.fetcher.get_weekly_kline(stock_code, period="2y")
        if weekly_df is None or len(weekly_df) == 0:
            print(f"  {stock_code}: âŒ æ— æ³•è·å–æ•°æ®")
            all_pass = False
            continue
        
        # æ‰¾åˆ°æˆäº¤é‡çªå¢ç‚¹
        volume_surge_idx = analyzer.find_volume_surge_point(
            stock_code, start_idx, weekly_df=weekly_df, 
            min_volume_ratio=3.0, lookback_weeks=52
        )
        if volume_surge_idx is None:
            volume_surge_idx = max(0, start_idx - 20)
        
        # æå–ç‰¹å¾
        features = analyzer.extract_features_at_start_point(
            stock_code, volume_surge_idx, lookback_weeks=40, weekly_df=weekly_df
        )
        if features is None:
            print(f"  {stock_code}: âŒ ç‰¹å¾æå–å¤±è´¥")
            all_pass = False
            continue
        
        # è®¡ç®—åŒ¹é…åº¦ï¼ˆè‡ªç„¶è®¡ç®—ï¼Œä¸ä¾èµ–ç‰¹æ®Šå¤„ç†ï¼‰
        if analyzer.trained_features and analyzer.trained_features.get('common_features'):
            match_score = analyzer._calculate_match_score(
                features, 
                analyzer.trained_features['common_features'], 
                tolerance=0.3
            )
            total_match = match_score.get('æ€»åŒ¹é…åº¦', 0)
            match_scores[stock_code] = total_match
            
            stock_name = analysis_result.get('stock_info', {}).get('åç§°', stock_code)
            status = "âœ…" if total_match >= 0.95 else "âŒ"
            print(f"  {status} {stock_code} {stock_name}: {total_match:.3f}")
            
            if total_match < 0.95:
                all_pass = False
        else:
            print(f"  {stock_code}: âŒ æ¨¡å‹æœªè®­ç»ƒ")
            all_pass = False
    
    return all_pass, match_scores

def optimize_model_training(analyzer, target_stocks, max_iterations=10):
    """ä¼˜åŒ–æ¨¡å‹è®­ç»ƒï¼Œç›´åˆ°æ‰€æœ‰è‚¡ç¥¨åŒ¹é…åº¦è¾¾åˆ°0.95ä»¥ä¸Š"""
    
    iteration = 0
    best_match_scores = {}
    
    while iteration < max_iterations:
        iteration += 1
        print("\n" + "=" * 80)
        print(f"ğŸ”„ ç¬¬ {iteration} æ¬¡è®­ç»ƒè¿­ä»£")
        print("=" * 80)
        
        # é‡æ–°åˆ†ææ‰€æœ‰è‚¡ç¥¨
        print("\nğŸ“Š æ­¥éª¤1: åˆ†ææ‰€æœ‰è‚¡ç¥¨...")
        for stock_code in target_stocks:
            print(f"  åˆ†æ {stock_code}...", end=" ", flush=True)
            result = analyzer.analyze_bull_stock(stock_code)
            if result.get('success'):
                print("âœ…")
            else:
                print(f"âŒ {result.get('message', '')}")
        
        # è®­ç»ƒç‰¹å¾
        print("\nğŸ“Š æ­¥éª¤2: è®­ç»ƒç‰¹å¾æ¨¡å‹...")
        train_result = analyzer.train_features()
        if not train_result.get('success'):
            print(f"âŒ è®­ç»ƒå¤±è´¥: {train_result.get('message', '')}")
            continue
        
        # ä¿å­˜è®­ç»ƒæ ·æœ¬åˆ—è¡¨
        if analyzer.trained_features:
            analyzer.trained_features['training_stocks'] = target_stocks
        
        # æµ‹è¯•åŒ¹é…åº¦
        print("\nğŸ“Š æ­¥éª¤3: æµ‹è¯•åŒ¹é…åº¦...")
        all_pass, match_scores = test_all_stocks_match_score(analyzer, target_stocks)
        
        # è®°å½•æœ€ä½³ç»“æœ
        if not best_match_scores or min(match_scores.values()) > min(best_match_scores.values()):
            best_match_scores = match_scores.copy()
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        if match_scores:
            avg_score = sum(match_scores.values()) / len(match_scores)
            min_score = min(match_scores.values())
            max_score = max(match_scores.values())
            print(f"\nğŸ“Š åŒ¹é…åº¦ç»Ÿè®¡:")
            print(f"   å¹³å‡: {avg_score:.3f}")
            print(f"   æœ€é«˜: {max_score:.3f}")
            print(f"   æœ€ä½: {min_score:.3f}")
            print(f"   é€šè¿‡ç‡: {sum(1 for s in match_scores.values() if s >= 0.95)}/{len(match_scores)}")
        
        # å¦‚æœæ‰€æœ‰è‚¡ç¥¨éƒ½è¾¾åˆ°0.95ä»¥ä¸Šï¼Œåœæ­¢è®­ç»ƒ
        if all_pass:
            print("\n" + "=" * 80)
            print("âœ… æ‰€æœ‰è‚¡ç¥¨çš„åŒ¹é…åº¦éƒ½è¾¾åˆ°0.95ä»¥ä¸Šï¼")
            print("=" * 80)
            break
        
        # å¦‚æœè¿˜æœ‰è¿­ä»£æ¬¡æ•°ï¼Œç»§ç»­ä¼˜åŒ–
        if iteration < max_iterations:
            print(f"\nâš ï¸ è¿˜æœ‰ {sum(1 for s in match_scores.values() if s < 0.95)} åªè‚¡ç¥¨æœªè¾¾åˆ°0.95ï¼Œç»§ç»­ä¼˜åŒ–...")
            # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ ä¼˜åŒ–é€»è¾‘ï¼Œæ¯”å¦‚è°ƒæ•´ç‰¹å¾æå–å‚æ•°ç­‰
    
    return all_pass, match_scores

def get_model_structure(analyzer):
    """è·å–æ¨¡å‹ç»“æ„ä¿¡æ¯"""
    if not analyzer.trained_features:
        return None
    
    structure = {
        'è®­ç»ƒæ—¶é—´': analyzer.trained_features.get('trained_at', 'æœªçŸ¥'),
        'è®­ç»ƒæ ·æœ¬æ•°': analyzer.trained_features.get('sample_count', 0),
        'ç‰¹å¾æ•°é‡': len(analyzer.trained_features.get('common_features', {})),
        'è®­ç»ƒæ ·æœ¬åˆ—è¡¨': analyzer.trained_features.get('training_stocks', []),
        'ç‰¹å¾åˆ—è¡¨': list(analyzer.trained_features.get('common_features', {}).keys()),
        'æ ¸å¿ƒç‰¹å¾': [
            'èµ·ç‚¹å½“å‘¨é‡æ¯”',
            'ä»·æ ¼ç›¸å¯¹ä½ç½®',
            'æˆäº¤é‡èç¼©ç¨‹åº¦',
            'ä»·æ ¼ç›¸å¯¹MA20',
            'èµ·ç‚¹å‰20å‘¨æ³¢åŠ¨ç‡',
            'æ˜¯å¦è·Œç ´æœ€å¤§é‡æœ€ä½ä»·',
            'èµ·ç‚¹å‰40å‘¨æœ€å¤§é‡'
        ]
    }
    
    # è·å–ç‰¹å¾ç»Ÿè®¡ä¿¡æ¯
    common_features = analyzer.trained_features.get('common_features', {})
    feature_stats = {}
    for feature_name, stats in common_features.items():
        feature_stats[feature_name] = {
            'å‡å€¼': stats.get('å‡å€¼', 0),
            'ä¸­ä½æ•°': stats.get('ä¸­ä½æ•°', stats.get('å‡å€¼', 0)),
            'æ ‡å‡†å·®': stats.get('æ ‡å‡†å·®', 0),
            'æœ€å°å€¼': stats.get('æœ€å°å€¼', 0),
            'æœ€å¤§å€¼': stats.get('æœ€å¤§å€¼', 0)
        }
    structure['ç‰¹å¾ç»Ÿè®¡'] = feature_stats
    
    return structure

def main():
    print("=" * 80)
    print("ğŸš€ è‡ªåŠ¨è®­ç»ƒæ¨¡å‹ï¼Œç¡®ä¿æ‰€æœ‰11åªè‚¡ç¥¨çš„åŒ¹é…åº¦éƒ½è¾¾åˆ°0.95ä»¥ä¸Š")
    print("=" * 80)
    
    # 11åªå¤§ç‰›è‚¡åˆ—è¡¨
    target_stocks = ['000592', '002104', '002759', '300436', '301005', '301232', '002788', '603778', '603122', '600343', '603216']
    
    print(f"\nğŸ“Š ç›®æ ‡è‚¡ç¥¨: {', '.join(target_stocks)}")
    print(f"   å…± {len(target_stocks)} åªè‚¡ç¥¨")
    
    # åˆ›å»ºåˆ†æå™¨
    print("\nåˆå§‹åŒ–åˆ†æå™¨...")
    analyzer = BullStockAnalyzer(auto_load_default_stocks=False, auto_analyze_and_train=False)
    
    # æ¸…ç©ºç°æœ‰æ•°æ®
    analyzer.analysis_results = {}
    analyzer.trained_features = None
    analyzer.bull_stocks = []
    
    # æ·»åŠ æ‰€æœ‰11åªè‚¡ç¥¨
    print("\næ·»åŠ 11åªç›®æ ‡è‚¡ç¥¨...")
    for stock_code in target_stocks:
        analyzer.add_bull_stock(stock_code)
    
    # ä¼˜åŒ–è®­ç»ƒ
    print("\nå¼€å§‹ä¼˜åŒ–è®­ç»ƒ...")
    all_pass, final_match_scores = optimize_model_training(analyzer, target_stocks, max_iterations=10)
    
    # æ˜¾ç¤ºæœ€ç»ˆç»“æœ
    print("\n" + "=" * 80)
    print("ğŸ“Š æœ€ç»ˆè®­ç»ƒç»“æœ")
    print("=" * 80)
    
    if final_match_scores:
        for stock_code, score in sorted(final_match_scores.items(), key=lambda x: x[1]):
            status = "âœ…" if score >= 0.95 else "âŒ"
            stock_name = analyzer.analysis_results.get(stock_code, {}).get('stock_info', {}).get('åç§°', stock_code)
            print(f"  {status} {stock_code} {stock_name}: {score:.3f}")
        
        avg_score = sum(final_match_scores.values()) / len(final_match_scores)
        min_score = min(final_match_scores.values())
        max_score = max(final_match_scores.values())
        pass_count = sum(1 for s in final_match_scores.values() if s >= 0.95)
        
        print(f"\nğŸ“Š ç»Ÿè®¡:")
        print(f"   å¹³å‡åŒ¹é…åº¦: {avg_score:.3f}")
        print(f"   æœ€é«˜åŒ¹é…åº¦: {max_score:.3f}")
        print(f"   æœ€ä½åŒ¹é…åº¦: {min_score:.3f}")
        print(f"   é€šè¿‡æ•°é‡: {pass_count}/{len(final_match_scores)}")
    
    # è·å–æ¨¡å‹ç»“æ„
    print("\n" + "=" * 80)
    print("ğŸ“‹ æ¨¡å‹ç»“æ„")
    print("=" * 80)
    
    model_structure = get_model_structure(analyzer)
    if model_structure:
        print(f"è®­ç»ƒæ—¶é—´: {model_structure['è®­ç»ƒæ—¶é—´']}")
        print(f"è®­ç»ƒæ ·æœ¬æ•°: {model_structure['è®­ç»ƒæ ·æœ¬æ•°']}")
        print(f"ç‰¹å¾æ•°é‡: {model_structure['ç‰¹å¾æ•°é‡']}")
        print(f"è®­ç»ƒæ ·æœ¬åˆ—è¡¨: {', '.join(model_structure['è®­ç»ƒæ ·æœ¬åˆ—è¡¨'])}")
        print(f"\næ ¸å¿ƒç‰¹å¾ ({len(model_structure['æ ¸å¿ƒç‰¹å¾'])}ä¸ª):")
        for feature in model_structure['æ ¸å¿ƒç‰¹å¾']:
            print(f"  - {feature}")
        print(f"\næ‰€æœ‰ç‰¹å¾ ({len(model_structure['ç‰¹å¾åˆ—è¡¨'])}ä¸ª):")
        for i, feature in enumerate(model_structure['ç‰¹å¾åˆ—è¡¨'], 1):
            stats = model_structure['ç‰¹å¾ç»Ÿè®¡'].get(feature, {})
            print(f"  {i:2d}. {feature}")
            print(f"      å‡å€¼: {stats.get('å‡å€¼', 0):.3f}, ä¸­ä½æ•°: {stats.get('ä¸­ä½æ•°', 0):.3f}, æ ‡å‡†å·®: {stats.get('æ ‡å‡†å·®', 0):.3f}")
        
        # ä¿å­˜æ¨¡å‹ç»“æ„åˆ°æ–‡ä»¶
        structure_file = 'model_structure.json'
        with open(structure_file, 'w', encoding='utf-8') as f:
            json.dump(model_structure, f, ensure_ascii=False, indent=2, default=str)
        print(f"\nâœ… æ¨¡å‹ç»“æ„å·²ä¿å­˜åˆ°: {structure_file}")
    
    # ä¿å­˜æ¨¡å‹
    if all_pass or min(final_match_scores.values()) >= 0.90:  # å¦‚æœè¾¾åˆ°0.90ä»¥ä¸Šä¹Ÿä¿å­˜
        print("\n" + "=" * 80)
        print("ğŸ’¾ ä¿å­˜æ¨¡å‹")
        print("=" * 80)
        
        os.makedirs('models', exist_ok=True)
        model_path = os.path.join('models', 'æ¨¡å‹11.json')
        
        if analyzer.save_model(model_path):
            print(f"âœ… æ¨¡å‹å·²ä¿å­˜ä¸º: æ¨¡å‹11")
            print(f"   ä¿å­˜è·¯å¾„: {model_path}")
        else:
            print("âŒ æ¨¡å‹ä¿å­˜å¤±è´¥")
    else:
        print("\nâš ï¸ éƒ¨åˆ†è‚¡ç¥¨åŒ¹é…åº¦æœªè¾¾åˆ°0.95ï¼Œä½†æ¨¡å‹å·²ä¿å­˜")
    
    print("\n" + "=" * 80)
    if all_pass:
        print("ğŸ‰ è®­ç»ƒå®Œæˆï¼æ‰€æœ‰è‚¡ç¥¨çš„åŒ¹é…åº¦éƒ½è¾¾åˆ°0.95ä»¥ä¸Šï¼")
    else:
        print("âš ï¸ è®­ç»ƒå®Œæˆï¼Œä½†éƒ¨åˆ†è‚¡ç¥¨åŒ¹é…åº¦æœªè¾¾åˆ°0.95")
    print("=" * 80)

if __name__ == '__main__':
    main()
